{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:/Users/SeoKyung/Desktop/PA/Paper Assistant.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractRecurrent neural network grammars (RNNGs) are generative models of (tree , string ) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe introduce the novel task of predicting adverbial presupposition triggers, which is useful for natural language generation tasks such as summarization and dialogue systems. We introduce two new corpora, derived from the Penn Treebank and the Annotated English Gigaword dataset and investigate the use of a novel attention mechanism tailored to this task. Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters, minimizing the added computational cost of our mechanism. We demonstrate that this model statistically outperforms our baselines.\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe propose a novel paradigm of grounding comparative adjectives within the realm of color descriptions. Given a reference RGB color and a comparative term (e.g., lighter, darker), our model learns to ground the comparative as a direction in the RGB space such that the colors along the vector, rooted at the reference color, satisfy the comparison. Our model generates grounded representations of comparative adjectives with an average accuracy of 0.65 cosine similarity to the desired direction of change. These vectors approach colors with Delta-E scores of under 7 compared to the target colors, indicating the differences are very small with respect to human perception. Our approach makes use of a newly created dataset for this task derived from existing labeled color data.\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractMany recent papers address reading comprehension, where examples consist of (question, passage, answer) tuples. Presumably, a model must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50% accuracy, sometimes matching the full model. Interestingly, while CBT provides 20-sentence passages, only the last is needed for accurate prediction. By comparison, SQuAD and CNN appear better-constructed.\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractEven though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.The contribution of this work apart from the open-sourced dataset is two-fold:firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractCurrent state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features. However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax. In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL. Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates. Syntax is incorporated by training one attention head to attend to syntactic parents for each token. Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model. In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10% reduction in error. On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1. LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractMachine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT’14 English-French and WMT’16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points. On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semi-supervised and supervised approaches leveraging the paucity of available bitexts. Our code for NMT and PBSMT is publicly available.\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractFollowing the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones.\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractMulti-label classification is an important yet challenging task in natural language processing. It is more complex than single-label classification in that the labels tend to be correlated. Existing methods tend to ignore the correlations between labels. Besides, different parts of the text can contribute differently for predicting different labels, which is not considered by existing models. In this paper, we propose to view the multi-label classification task as a sequence generation problem, and apply a sequence generation model with a novel decoder structure to solve it. Extensive experimental results show that our proposed methods outperform previous work by a substantial margin. Further analysis of experimental results demonstrates that the proposed methods not only capture the correlations between labels, but also select the most informative words automatically when predicting different labels.\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe study German affixoids, a type of morpheme in between affixes and free stems. Several properties have been associated with them – increased productivity; a bleached semantics, which is often evaluative and/or intensifying and thus of relevance to sentiment analysis; and the existence of a free morpheme counterpart – but not been validated empirically. In experiments on a new data set that we make available, we put these key assumptions from the morphological literature to the test and show that despite the fact that affixoids generate many low-frequency formations, we can classify these as affixoid or non-affixoid instances with a best F1-score of 74%.\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractMost previous work in unsupervised semantic modeling in the presence of metadata has assumed that our goal is to make latent dimensions more correlated with metadata, but in practice the exact opposite is often true. Some users want topic models that highlight differences between, for example, authors, but others seek more subtle connections across authors. We introduce three metrics for identifying topics that are highly correlated with metadata, and demonstrate that this problem affects between 30 and 50% of the topics in models trained on two real-world collections, regardless of the size of the model. We find that we can predict which words cause this phenomenon and that by selectively subsampling these words we dramatically reduce topic-metadata correlation, improve topic stability, and maintain or even improve model quality.\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractThe aim of this paper is to argue for a coherent Universal Dependencies approach to the core vs. non-core distinction. We demonstrate inconsistencies in the current version 2 of UD in this respect – mostly resulting from the preservation of the argument–adjunct dichotomy despite the declared avoidance of this distinction – and propose a relatively conservative modification of UD that is free from these problems.\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractIn this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available. We release our implementations as an open-source toolkit.\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractIn this paper, we present AnlamVer, which is a semantic model evaluation dataset for Turkish designed to evaluate word similarity and word relatedness tasks while discriminating those two relations from each other. Our dataset consists of 500 word-pairs annotated by 12 human subjects, and each pair has two distinct scores for similarity and relatedness. Word-pairs are selected to enable the evaluation of distributional semantic models by multiple attributes of words and word-pair relations such as frequency, morphology, concreteness and relation types (e.g., synonymy, antonymy). Our aim is to provide insights to semantic model researchers by evaluating models in multiple attributes. We balance dataset word-pairs by their frequencies to evaluate the robustness of semantic models concerning out-of-vocabulary and rare words problems, which are caused by the rich derivational and inflectional morphology of the Turkish language.\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe provide a detailed overview of the various approaches that were proposed to date to solve the task of Open Information Extraction. We present the major challenges that such systems face, show the evolution of the suggested approaches over time and depict the specific issues they address. In addition, we provide a critique of the commonly applied evaluation procedures for assessing the performance of Open IE systems and highlight some directions for future work.\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractWe investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural networks models for NLP are typically implemented without the explicit\n",
      "encoding of language rules and yet they are able to break one performance\n",
      "record after another. This has generated a lot of research interest in\n",
      "interpreting the representations learned by these networks. We propose here a\n",
      "novel interpretation approach that relies on the only processing system we have\n",
      "that does understand language: the human brain. We use brain imaging recordings\n",
      "of subjects reading complex natural text to interpret word and sequence\n",
      "embeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\n",
      "study how their representations differ across layer depth, context length, and\n",
      "attention type. Our results reveal differences in the context-related\n",
      "representations across these models. Further, in the transformer models, we\n",
      "find an interaction between layer depth and context length, and between layer\n",
      "depth and attention type. We finally hypothesize that altering BERT to better\n",
      "align with brain recordings would enable it to also better understand language.\n",
      "Probing the altered BERT using syntactic NLP tasks reveals that the model with\n",
      "increased brain-alignment outperforms the original model. Cognitive\n",
      "neuroscientists have already begun using NLP networks to study the brain, and\n",
      "this work closes the loop to allow the interaction between NLP and cognitive\n",
      "neuroscience to be a true cross-pollination.\n",
      "\n",
      "    \n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we demonstrate that 3D poses in video can be effectively\n",
      "estimated with a fully convolutional model based on dilated temporal\n",
      "convolutions over 2D keypoints. We also introduce back-projection, a simple and\n",
      "effective semi-supervised training method that leverages unlabeled video data.\n",
      "We start with predicted 2D keypoints for unlabeled video, then estimate 3D\n",
      "poses and finally back-project to the input 2D keypoints. In the supervised\n",
      "setting, our fully-convolutional model outperforms the previous best result\n",
      "from the literature by 6 mm mean per-joint position error on Human3.6M,\n",
      "corresponding to an error reduction of 11%, and the model also shows\n",
      "significant improvements on HumanEva-I. Moreover, experiments with\n",
      "back-projection show that it comfortably outperforms previous state-of-the-art\n",
      "results in semi-supervised settings where labeled data is scarce. Code and\n",
      "models are available at this https URL\n",
      "\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a unified formulation for the problem of 3D human pose estimation\n",
      "from a single raw RGB image that reasons jointly about 2D joint estimation and\n",
      "3D pose reconstruction to improve both tasks. We take an integrated approach\n",
      "that fuses probabilistic knowledge of 3D human pose with a multi-stage CNN\n",
      "architecture and uses the knowledge of plausible 3D landmark locations to\n",
      "refine the search for better 2D locations. The entire process is trained\n",
      "end-to-end, is extremely efficient and obtains state- of-the-art results on\n",
      "Human3.6M outperforming previous approaches both on 2D and 3D errors.\n",
      "\n",
      "    \n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present some updates to YOLO! We made a bunch of little design changes to\n",
      "make it better. We also trained this new network that's pretty swell. It's a\n",
      "little bigger than last time but more accurate. It's still fast though, don't\n",
      "worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but\n",
      "three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3\n",
      "is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5\n",
      "mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always,\n",
      "all the code is online at this https URL\n",
      "\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present YOLO, a new approach to object detection. Prior work on object\n",
      "detection repurposes classifiers to perform detection. Instead, we frame object\n",
      "detection as a regression problem to spatially separated bounding boxes and\n",
      "associated class probabilities. A single neural network predicts bounding boxes\n",
      "and class probabilities directly from full images in one evaluation. Since the\n",
      "whole detection pipeline is a single network, it can be optimized end-to-end\n",
      "directly on detection performance.\n",
      "Our unified architecture is extremely fast. Our base YOLO model processes\n",
      "images in real-time at 45 frames per second. A smaller version of the network,\n",
      "Fast YOLO, processes an astounding 155 frames per second while still achieving\n",
      "double the mAP of other real-time detectors. Compared to state-of-the-art\n",
      "detection systems, YOLO makes more localization errors but is far less likely\n",
      "to predict false detections where nothing exists. Finally, YOLO learns very\n",
      "general representations of objects. It outperforms all other detection methods,\n",
      "including DPM and R-CNN, by a wide margin when generalizing from natural images\n",
      "to artwork on both the Picasso Dataset and the People-Art Dataset.\n",
      "\n",
      "    \n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes a distributed Multi-Agent Reinforcement Learning (MARL)\n",
      "algorithm for a team of Unmanned Aerial Vehicles (UAVs). The proposed MARL\n",
      "algorithm allows UAVs to learn cooperatively to provide a full coverage of an\n",
      "unknown field of interest while minimizing the overlapping sections among their\n",
      "field of views. Two challenges in MARL for such a system are discussed in the\n",
      "paper: firstly, the complex dynamic of the joint-actions of the UAV team, that\n",
      "will be solved using game-theoretic correlated equilibrium, and secondly, the\n",
      "challenge in huge dimensional state space representation will be tackled with\n",
      "efficient function approximation techniques. We also provide our experimental\n",
      "results in detail with both simulation and physical implementation to show that\n",
      "the UAV team can successfully learn to accomplish the task.\n",
      "\n",
      "    \n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Flocking control has been studied extensively along with the wide application\n",
      "of multi-vehicle systems. In this paper the Multi-vehicles System (MVS)\n",
      "flocking control with collision avoidance and communication preserving is\n",
      "considered based on the deep reinforcement learning framework. Specifically the\n",
      "deep deterministic policy gradient (DDPG) with centralized training and\n",
      "distributed execution process is implemented to obtain the flocking control\n",
      "policy. First, to avoid the dynamically changed observation of state, a three\n",
      "layers tensor based representation of the observation is used so that the state\n",
      "remains constant although the observation dimension is changing. A reward\n",
      "function is designed to guide the way-points tracking, collision avoidance and\n",
      "communication preserving. The reward function is augmented by introducing the\n",
      "local reward function of neighbors. Finally, a centralized training process\n",
      "which trains the shared policy based on common training set among all agents.\n",
      "The proposed method is tested under simulated scenarios with different setup.\n",
      "\n",
      "    \n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we study the problem of steering a team of Unmanned Aerial\n",
      "Vehicles (UAVs) toward a static configuration which maximizes the visibility of\n",
      "a 3D environment. The UAVs are assumed to be equipped with visual sensors\n",
      "constrained by a maximum sensing range and the prior knowledge on the\n",
      "environment is considered to be very sparse. To solve this problem on-line,\n",
      "derivative-free measurement-based optimization algorithms can be adopted, even\n",
      "though they are strongly limited by local optimality. To overcome this\n",
      "limitation, we propose to exploit the partial initial knowledge on the\n",
      "environment to find suitable initial configurations from which the agents start\n",
      "the local optimization. In particular, a constrained centroidal Voronoi\n",
      "tessellation on a coarse approximation of the surface to cover is proposed. The\n",
      "behavior of the agent is so based on a two-step optimization approach, where a\n",
      "stochastic optimization algorithm based on the on-line acquired information\n",
      "follows the geometrical-based initialization. The algorithm performance is\n",
      "evaluated in simulation and in particular the improvement on the solution\n",
      "brought by the Voronoi tessellation with respect to different initializations\n",
      "is analyzed.\n",
      "\n",
      "    \n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, based\n",
      "solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to be\n",
      "superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014\n",
      "English-to-German translation task, improving over the existing best results,\n",
      "including ensembles by over 2 BLEU. On the WMT 2014 English-to-French\n",
      "translation task, our model establishes a new single-model state-of-the-art\n",
      "BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\n",
      "of the training costs of the best models from the literature. We show that the\n",
      "Transformer generalizes well to other tasks by applying it successfully to\n",
      "English constituency parsing both with large and limited training data.\n",
      "\n",
      "    \n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new language representation model called BERT, which stands\n",
      "for Bidirectional Encoder Representations from Transformers. Unlike recent\n",
      "language representation models, BERT is designed to pre-train deep\n",
      "bidirectional representations from unlabeled text by jointly conditioning on\n",
      "both left and right context in all layers. As a result, the pre-trained BERT\n",
      "model can be fine-tuned with just one additional output layer to create\n",
      "state-of-the-art models for a wide range of tasks, such as question answering\n",
      "and language inference, without substantial task-specific architecture\n",
      "modifications.\n",
      "BERT is conceptually simple and empirically powerful. It obtains new\n",
      "state-of-the-art results on eleven natural language processing tasks, including\n",
      "pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\n",
      "accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\n",
      "Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n",
      "(5.1 point absolute improvement).\n",
      "\n",
      "    \n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we establish dense correspondences between RGB image and a\n",
      "surface-based representation of the human body, a task we refer to as dense\n",
      "human pose estimation. We first gather dense correspondences for 50K persons\n",
      "appearing in the COCO dataset by introducing an efficient annotation pipeline.\n",
      "We then use our dataset to train CNN-based systems that deliver dense\n",
      "correspondence 'in the wild', namely in the presence of background, occlusions\n",
      "and scale variations. We improve our training set's effectiveness by training\n",
      "an 'inpainting' network that can fill in missing groundtruth values and report\n",
      "clear improvements with respect to the best results that would be achievable in\n",
      "the past. We experiment with fully-convolutional networks and region-based\n",
      "models and observe a superiority of the latter; we further improve accuracy\n",
      "through cascading, obtaining a system that delivers highly0accurate results in\n",
      "real time. Supplementary materials and videos are provided on the project page\n",
      "this http URL\n",
      "\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe Human Mesh Recovery (HMR), an end-to-end framework for\n",
      "reconstructing a full 3D mesh of a human body from a single RGB image. In\n",
      "contrast to most current methods that compute 2D or 3D joint locations, we\n",
      "produce a richer and more useful mesh representation that is parameterized by\n",
      "shape and 3D joint angles. The main objective is to minimize the reprojection\n",
      "loss of keypoints, which allow our model to be trained using images in-the-wild\n",
      "that only have ground truth 2D annotations. However, the reprojection loss\n",
      "alone leaves the model highly under constrained. In this work we address this\n",
      "problem by introducing an adversary trained to tell whether a human body\n",
      "parameter is real or not using a large database of 3D human meshes. We show\n",
      "that HMR can be trained with and without using any paired 2D-to-3D supervision.\n",
      "We do not rely on intermediate 2D keypoint detections and infer 3D pose and\n",
      "shape parameters directly from image pixels. Our model runs in real-time given\n",
      "a bounding box containing the person. We demonstrate our approach on various\n",
      "images in-the-wild and out-perform previous optimization based methods that\n",
      "output 3D meshes and show competitive results on tasks such as 3D joint\n",
      "location estimation and part segmentation.\n",
      "\n",
      "    \n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents a simple method for \"do as I do\" motion transfer: given a\n",
      "source video of a person dancing, we can transfer that performance to a novel\n",
      "(amateur) target after only a few minutes of the target subject performing\n",
      "standard moves. We approach this problem as video-to-video translation using\n",
      "pose as an intermediate representation. To transfer the motion, we extract\n",
      "poses from the source subject and apply the learned pose-to-appearance mapping\n",
      "to generate the target subject. We predict two consecutive frames for\n",
      "temporally coherent video results and introduce a separate pipeline for\n",
      "realistic face synthesis. Although our method is quite simple, it produces\n",
      "surprisingly compelling results (see video). This motivates us to also provide\n",
      "a forensics tool for reliable synthetic content detection, which is able to\n",
      "distinguish videos synthesized by our system from real data. In addition, we\n",
      "release a first-of-its-kind open-source dataset of videos that can be legally\n",
      "used for training and motion transfer.\n",
      "\n",
      "    \n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Vector representations of sentences, trained on massive text corpora, are\n",
      "widely used as generic sentence embeddings across a variety of NLP problems.\n",
      "The learned representations are generally assumed to be continuous and\n",
      "real-valued, giving rise to a large memory footprint and slow retrieval speed,\n",
      "which hinders their applicability to low-resource (memory and computation)\n",
      "platforms, such as mobile devices. In this paper, we propose four different\n",
      "strategies to transform continuous and generic sentence embeddings into a\n",
      "binarized form, while preserving their rich semantic information. The\n",
      "introduced methods are evaluated across a wide range of downstream tasks, where\n",
      "the binarized sentence embeddings are demonstrated to degrade performance by\n",
      "only about 2% relative to their continuous counterparts, while reducing the\n",
      "storage requirement by over 98%. Moreover, with the learned binary\n",
      "representations, the semantic relatedness of two sentences can be evaluated by\n",
      "simply calculating their Hamming distance, which is more computational\n",
      "efficient compared with the inner product operation between continuous\n",
      "embeddings. Detailed analysis and case study further validate the effectiveness\n",
      "of proposed methods.\n",
      "\n",
      "    \n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Bidirectional Encoder Representations from Transformers (BERT) has shown\n",
      "marvelous improvements across various NLP tasks. Recently, an upgraded version\n",
      "of BERT has been released with Whole Word Masking (WWM), which mitigate the\n",
      "drawbacks of masking partial WordPiece tokens in pre-training BERT. In this\n",
      "technical report, we adapt whole word masking in Chinese text, that masking the\n",
      "whole word instead of masking Chinese characters, which could bring another\n",
      "challenge in Masked Language Model (MLM) pre-training task. The proposed models\n",
      "are verified on various NLP tasks, across sentence-level to document-level,\n",
      "including machine reading comprehension (CMRC 2018, DRCD, CJRC), natural\n",
      "language inference (XNLI), sentiment classification (ChnSentiCorp), sentence\n",
      "pair matching (LCQMC, BQ Corpus), and document classification (THUCNews).\n",
      "Experimental results on these datasets show that the whole word masking could\n",
      "bring another significant gain. Moreover, we also examine the effectiveness of\n",
      "the Chinese pre-trained models: BERT, ERNIE, BERT-wwm, BERT-wwm-ext,\n",
      "RoBERTa-wwm-ext, and RoBERTa-wwm-ext-large. We release all the pre-trained\n",
      "models: \\url{this https URL\n",
      "\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While deep learning techniques have shown promising results in many natural\n",
      "language processing (NLP) tasks, it has not been widely applied to the clinical\n",
      "domain. The lack of large datasets and the pervasive use of domain-specific\n",
      "language (i.e. abbreviations and acronyms) in the clinical domain causes slower\n",
      "progress in NLP tasks than that of the general NLP tasks. To fill this gap, we\n",
      "employ word/subword-level based models that adopt large-scale data-driven\n",
      "methods such as pre-trained language models and transfer learning in analyzing\n",
      "text for the clinical domain. Empirical results demonstrate the superiority of\n",
      "the proposed methods by achieving 90.6% accuracy in medical domain natural\n",
      "language inference task. Furthermore, we inspect the independent strengths of\n",
      "the proposed approaches in quantitative and qualitative manners. This analysis\n",
      "will help researchers to select necessary components in building models for the\n",
      "medical domain.\n",
      "\n",
      "    \n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an end-to-end approach to extract semantic concepts directly from\n",
      "the speech audio signal. To overcome the lack of data available for this spoken\n",
      "language understanding approach, we investigate the use of a transfer learning\n",
      "strategy based on the principles of curriculum learning. This approach allows\n",
      "us to exploit out-of-domain data that can help to prepare a fully neural\n",
      "architecture. Experiments are carried out on the French MEDIA and PORTMEDIA\n",
      "corpora and show that this end-to-end SLU approach reaches the best results\n",
      "ever published on this task. We compare our approach to a classical pipeline\n",
      "approach that uses ASR, POS tagging, lemmatizer, chunker... and other NLP tools\n",
      "that aim to enrich ASR outputs that feed an SLU text to concepts system. Last,\n",
      "we explore the promising capacity of our end-to-end SLU approach to address the\n",
      "problem of domain portability.\n",
      "\n",
      "    \n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in language modeling using deep neural networks have shown\n",
      "that these models learn representations, that vary with the network depth from\n",
      "morphology to semantic relationships like co-reference. We apply pre-trained\n",
      "language models to low-resource named entity recognition for Historic German.\n",
      "We show on a series of experiments that character-based pre-trained language\n",
      "models do not run into trouble when faced with low-resource datasets. Our\n",
      "pre-trained character-based language models improve upon classical CRF-based\n",
      "methods and previous work on Bi-LSTMs by boosting F1 score performance by up to\n",
      "6%. Our pre-trained language and NER models are publicly available under\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes a new method to extract relevant keywords from patent\n",
      "claims, as part of the task of retrieving other patents with similar claims\n",
      "(search for prior art). The method combines a qualitative analysis of the\n",
      "writing style of the claims with NLP methods to parse text, in order to\n",
      "represent a legal text as a specialization arborescence of terms. In this\n",
      "setting, the set of extracted keywords are yielding better search results than\n",
      "keywords extracted with traditional methods such as tf-idf. The performance is\n",
      "measured on the search results of a query consisting of the extracted keywords.\n",
      "\n",
      "    \n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper addresses the task of readability assessment for the texts aimed\n",
      "at second language (L2) learners. One of the major challenges in this task is\n",
      "the lack of significantly sized level-annotated data. For the present work, we\n",
      "collected a dataset of CEFR-graded texts tailored for learners of English as an\n",
      "L2 and investigated text readability assessment for both native and L2\n",
      "learners. We applied a generalization method to adapt models trained on larger\n",
      "native corpora to estimate text readability for learners, and explored domain\n",
      "adaptation and self-learning techniques to make use of the native data to\n",
      "improve system performance on the limited L2 data. In our experiments, the best\n",
      "performing model for readability on learner texts achieves an accuracy of 0.797\n",
      "and PCC of $0.938$.\n",
      "\n",
      "    \n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a novel method for constructing Variational Autoencoder (VAE).\n",
      "Instead of using pixel-by-pixel loss, we enforce deep feature consistency\n",
      "between the input and the output of a VAE, which ensures the VAE's output to\n",
      "preserve the spatial correlation characteristics of the input, thus leading the\n",
      "output to have a more natural visual appearance and better perceptual quality.\n",
      "Based on recent deep learning works such as style transfer, we employ a\n",
      "pre-trained deep convolutional neural network (CNN) and use its hidden features\n",
      "to define a feature perceptual loss for VAE training. Evaluated on the CelebA\n",
      "face dataset, we show that our model produces better results than other methods\n",
      "in the literature. We also show that our method can produce latent vectors that\n",
      "can capture the semantic information of face expressions and can be used to\n",
      "achieve state-of-the-art performance in facial attribute prediction.\n",
      "\n",
      "    \n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We study the problem of video-to-video synthesis, whose goal is to learn a\n",
      "mapping function from an input source video (e.g., a sequence of semantic\n",
      "segmentation masks) to an output photorealistic video that precisely depicts\n",
      "the content of the source video. While its image counterpart, the\n",
      "image-to-image synthesis problem, is a popular topic, the video-to-video\n",
      "synthesis problem is less explored in the literature. Without understanding\n",
      "temporal dynamics, directly applying existing image synthesis approaches to an\n",
      "input video often results in temporally incoherent videos of low visual\n",
      "quality. In this paper, we propose a novel video-to-video synthesis approach\n",
      "under the generative adversarial learning framework. Through carefully-designed\n",
      "generator and discriminator architectures, coupled with a spatio-temporal\n",
      "adversarial objective, we achieve high-resolution, photorealistic, temporally\n",
      "coherent video results on a diverse set of input formats including segmentation\n",
      "masks, sketches, and poses. Experiments on multiple benchmarks show the\n",
      "advantage of our method compared to strong baselines. In particular, our model\n",
      "is capable of synthesizing 2K resolution videos of street scenes up to 30\n",
      "seconds long, which significantly advances the state-of-the-art of video\n",
      "synthesis. Finally, we apply our approach to future video prediction,\n",
      "outperforming several state-of-the-art competing systems.\n",
      "\n",
      "    \n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Designing convolutional neural networks (CNN) for mobile devices is\n",
      "challenging because mobile models need to be small and fast, yet still\n",
      "accurate. Although significant efforts have been dedicated to design and\n",
      "improve mobile CNNs on all dimensions, it is very difficult to manually balance\n",
      "these trade-offs when there are so many architectural possibilities to\n",
      "consider. In this paper, we propose an automated mobile neural architecture\n",
      "search (MNAS) approach, which explicitly incorporate model latency into the\n",
      "main objective so that the search can identify a model that achieves a good\n",
      "trade-off between accuracy and latency. Unlike previous work, where latency is\n",
      "considered via another, often inaccurate proxy (e.g., FLOPS), our approach\n",
      "directly measures real-world inference latency by executing the model on mobile\n",
      "phones. To further strike the right balance between flexibility and search\n",
      "space size, we propose a novel factorized hierarchical search space that\n",
      "encourages layer diversity throughout the network. Experimental results show\n",
      "that our approach consistently outperforms state-of-the-art mobile CNN models\n",
      "across multiple vision tasks. On the ImageNet classification task, our MnasNet\n",
      "achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x\n",
      "faster than MobileNetV2 [29] with 0.5% higher accuracy and 2.3x faster than\n",
      "NASNet [36] with 1.2% higher accuracy. Our MnasNet also achieves better mAP\n",
      "quality than MobileNets for COCO object detection. Code is at\n",
      "this https URL\n",
      "\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce instancewise feature selection as a methodology for model\n",
      "interpretation. Our method is based on learning a function to extract a subset\n",
      "of features that are most informative for each given example. This feature\n",
      "selector is trained to maximize the mutual information between selected\n",
      "features and the response variable, where the conditional distribution of the\n",
      "response variable given the input is the model to be explained. We develop an\n",
      "efficient variational approximation to the mutual information, and show the\n",
      "effectiveness of our method on a variety of synthetic and real data sets using\n",
      "both quantitative metrics and human evaluation.\n",
      "\n",
      "    \n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Existing deep learning based image inpainting methods use a standard\n",
      "convolutional network over the corrupted image, using convolutional filter\n",
      "responses conditioned on both valid pixels as well as the substitute values in\n",
      "the masked holes (typically the mean value). This often leads to artifacts such\n",
      "as color discrepancy and blurriness. Post-processing is usually used to reduce\n",
      "such artifacts, but are expensive and may fail. We propose the use of partial\n",
      "convolutions, where the convolution is masked and renormalized to be\n",
      "conditioned on only valid pixels. We further include a mechanism to\n",
      "automatically generate an updated mask for the next layer as part of the\n",
      "forward pass. Our model outperforms other methods for irregular masks. We show\n",
      "qualitative and quantitative comparisons with other methods to validate our\n",
      "approach.\n",
      "\n",
      "    \n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we describe a new mobile architecture, MobileNetV2, that\n",
      "improves the state of the art performance of mobile models on multiple tasks\n",
      "and benchmarks as well as across a spectrum of different model sizes. We also\n",
      "describe efficient ways of applying these mobile models to object detection in\n",
      "a novel framework we call SSDLite. Additionally, we demonstrate how to build\n",
      "mobile semantic segmentation models through a reduced form of DeepLabv3 which\n",
      "we call Mobile DeepLabv3.\n",
      "The MobileNetV2 architecture is based on an inverted residual structure where\n",
      "the input and output of the residual block are thin bottleneck layers opposite\n",
      "to traditional residual models which use expanded representations in the input\n",
      "an MobileNetV2 uses lightweight depthwise convolutions to filter features in\n",
      "the intermediate expansion layer. Additionally, we find that it is important to\n",
      "remove non-linearities in the narrow layers in order to maintain\n",
      "representational power. We demonstrate that this improves performance and\n",
      "provide an intuition that led to this design. Finally, our approach allows\n",
      "decoupling of the input/output domains from the expressiveness of the\n",
      "transformation, which provides a convenient framework for further analysis. We\n",
      "measure our performance on Imagenet classification, COCO object detection, VOC\n",
      "image segmentation. We evaluate the trade-offs between accuracy, and number of\n",
      "operations measured by multiply-adds (MAdd), as well as the number of\n",
      "parameters\n",
      "\n",
      "    \n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite recent progress in generative image modeling, successfully generating\n",
      "high-resolution, diverse samples from complex datasets such as ImageNet remains\n",
      "an elusive goal. To this end, we train Generative Adversarial Networks at the\n",
      "largest scale yet attempted, and study the instabilities specific to such\n",
      "scale. We find that applying orthogonal regularization to the generator renders\n",
      "it amenable to a simple \"truncation trick,\" allowing fine control over the\n",
      "trade-off between sample fidelity and variety by reducing the variance of the\n",
      "Generator's input. Our modifications lead to models which set the new state of\n",
      "the art in class-conditional image synthesis. When trained on ImageNet at\n",
      "128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of\n",
      "166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous\n",
      "best IS of 52.52 and FID of 18.6.\n",
      "\n",
      "    \n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  An analysis of different techniques for recognizing and detecting objects\n",
      "under extreme scale variation is presented. Scale specific and scale invariant\n",
      "design of detectors are compared by training them with different configurations\n",
      "of input data. By evaluating the performance of different network architectures\n",
      "for classifying small objects on ImageNet, we show that CNNs are not robust to\n",
      "changes in scale. Based on this analysis, we propose to train and test\n",
      "detectors on the same scales of an image-pyramid. Since small and large objects\n",
      "are difficult to recognize at smaller and larger scales respectively, we\n",
      "present a novel training scheme called Scale Normalization for Image Pyramids\n",
      "(SNIP) which selectively back-propagates the gradients of object instances of\n",
      "different sizes as a function of the image scale. On the COCO dataset, our\n",
      "single model performance is 45.7% and an ensemble of 3 networks obtains an mAP\n",
      "of 48.3%. We use off-the-shelf ImageNet-1000 pre-trained models and only train\n",
      "with bounding box supervision. Our submission won the Best Student Entry in the\n",
      "COCO 2017 challenge. Code will be made available at\n",
      "\\url{this http URL}.\n",
      "\n",
      "    \n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Hardware support for deep convolutional neural networks (CNNs) is critical to\n",
      "advanced computer vision in mobile and embedded devices. Current designs,\n",
      "however, accelerate generic CNNs; they do not exploit the unique\n",
      "characteristics of real-time vision. We propose to use the temporal redundancy\n",
      "in natural video to avoid unnecessary computation on most frames. A new\n",
      "algorithm, activation motion compensation, detects changes in the visual input\n",
      "and incrementally updates a previously-computed output. The technique takes\n",
      "inspiration from video compression and applies well-known motion estimation\n",
      "techniques to adapt to visual changes. We use an adaptive key frame rate to\n",
      "control the trade-off between efficiency and vision quality as the input\n",
      "changes. We implement the technique in hardware as an extension to existing\n",
      "state-of-the-art CNN accelerator designs. The new unit reduces the average\n",
      "energy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%\n",
      "loss in vision accuracy.\n",
      "\n",
      "    \n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Image restoration algorithms are typically evaluated by some distortion\n",
      "measure (e.g. PSNR, SSIM, IFC, VIF) or by human opinion scores that quantify\n",
      "perceived perceptual quality. In this paper, we prove mathematically that\n",
      "distortion and perceptual quality are at odds with each other. Specifically, we\n",
      "study the optimal probability for correctly discriminating the outputs of an\n",
      "image restoration algorithm from real images. We show that as the mean\n",
      "distortion decreases, this probability must increase (indicating worse\n",
      "perceptual quality). As opposed to the common belief, this result holds true\n",
      "for any distortion measure, and is not only a problem of the PSNR or SSIM\n",
      "criteria. We also show that generative-adversarial-nets (GANs) provide a\n",
      "principled way to approach the perception-distortion bound. This constitutes\n",
      "theoretical support to their observed success in low-level vision tasks. Based\n",
      "on our analysis, we propose a new methodology for evaluating image restoration\n",
      "methods, and use it to perform an extensive comparison between recent\n",
      "super-resolution algorithms.\n",
      "\n",
      "    \n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a data-driven approach for unsupervised video retargeting that\n",
      "translates content from one domain to another while preserving the style native\n",
      "to a domain, i.e., if contents of John Oliver's speech were to be transferred\n",
      "to Stephen Colbert, then the generated content/speech should be in Stephen\n",
      "Colbert's style. Our approach combines both spatial and temporal information\n",
      "along with adversarial losses for content translation and style preservation.\n",
      "In this work, we first study the advantages of using spatiotemporal constraints\n",
      "over spatial constraints for effective retargeting. We then demonstrate the\n",
      "proposed approach for the problems where information in both space and time\n",
      "matters such as face-to-face translation, flower-to-flower, wind and cloud\n",
      "synthesis, sunrise and sunset.\n",
      "\n",
      "    \n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Obtaining models that capture imaging markers relevant for disease\n",
      "progression and treatment monitoring is challenging. Models are typically based\n",
      "on large amounts of data with annotated examples of known markers aiming at\n",
      "automating detection. High annotation effort and the limitation to a vocabulary\n",
      "of known markers limit the power of such approaches. Here, we perform\n",
      "unsupervised learning to identify anomalies in imaging data as candidates for\n",
      "markers. We propose AnoGAN, a deep convolutional generative adversarial network\n",
      "to learn a manifold of normal anatomical variability, accompanying a novel\n",
      "anomaly scoring scheme based on the mapping from image space to a latent space.\n",
      "Applied to new data, the model labels anomalies, and scores image patches\n",
      "indicating their fit into the learned distribution. Results on optical\n",
      "coherence tomography images of the retina demonstrate that the approach\n",
      "correctly identifies anomalous images, such as images containing retinal fluid\n",
      "or hyperreflective foci.\n",
      "\n",
      "    \n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Flow-based generative models (Dinh et al., 2014) are conceptually attractive\n",
      "due to tractability of the exact log-likelihood, tractability of exact\n",
      "latent-variable inference, and parallelizability of both training and\n",
      "synthesis. In this paper we propose Glow, a simple type of generative flow\n",
      "using an invertible 1x1 convolution. Using our method we demonstrate a\n",
      "significant improvement in log-likelihood on standard benchmarks. Perhaps most\n",
      "strikingly, we demonstrate that a generative model optimized towards the plain\n",
      "log-likelihood objective is capable of efficient realistic-looking synthesis\n",
      "and manipulation of large images. The code for our model is available at\n",
      "this https URL\n",
      "\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning systems have become ubiquitous in many aspects of our lives.\n",
      "Unfortunately, it has been shown that such systems are vulnerable to\n",
      "adversarial attacks, making them prone to potential unlawful uses. Designing\n",
      "deep neural networks that are robust to adversarial attacks is a fundamental\n",
      "step in making such systems safer and deployable in a broader variety of\n",
      "applications (e.g. autonomous driving), but more importantly is a necessary\n",
      "step to design novel and more advanced architectures built on new computational\n",
      "paradigms rather than marginally building on the existing ones. In this paper\n",
      "we introduce PeerNets, a novel family of convolutional networks alternating\n",
      "classical Euclidean convolutions with graph convolutions to harness information\n",
      "from a graph of peer samples. This results in a form of non-local forward\n",
      "propagation in the model, where latent features are conditioned on the global\n",
      "structure induced by the graph, that is up to 3 times more robust to a variety\n",
      "of white- and black-box adversarial attacks compared to conventional\n",
      "architectures with almost no drop in accuracy.\n",
      "\n",
      "    \n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Current neural network-based classifiers are susceptible to adversarial\n",
      "examples even in the black-box setting, where the attacker only has query\n",
      "access to the model. In practice, the threat model for real-world systems is\n",
      "often more restrictive than the typical black-box model where the adversary can\n",
      "observe the full output of the network on arbitrarily many chosen inputs. We\n",
      "define three realistic threat models that more accurately characterize many\n",
      "real-world classifiers: the query-limited setting, the partial-information\n",
      "setting, and the label-only setting. We develop new attacks that fool\n",
      "classifiers under these more restrictive threat models, where previous methods\n",
      "would be impractical or ineffective. We demonstrate that our methods are\n",
      "effective against an ImageNet classifier under our proposed threat models. We\n",
      "also demonstrate a targeted black-box attack against a commercial classifier,\n",
      "overcoming the challenges of limited query access, partial information, and\n",
      "other practical issues to break the Google Cloud Vision API.\n",
      "\n",
      "    \n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional neural networks (CNNs) have been successfully applied to many\n",
      "recognition and learning tasks using a universal recipe; training a deep model\n",
      "on a very large dataset of supervised examples. However, this approach is\n",
      "rather restrictive in practice since collecting a large set of labeled images\n",
      "is very expensive. One way to ease this problem is coming up with smart ways\n",
      "for choosing images to be labelled from a very large collection (ie. active\n",
      "learning).\n",
      "Our empirical study suggests that many of the active learning heuristics in\n",
      "the literature are not effective when applied to CNNs in batch setting.\n",
      "Inspired by these limitations, we define the problem of active learning as\n",
      "core-set selection, ie. choosing set of points such that a model learned over\n",
      "the selected subset is competitive for the remaining data points. We further\n",
      "present a theoretical result characterizing the performance of any selected\n",
      "subset using the geometry of the datapoints. As an active learning algorithm,\n",
      "we choose the subset which is expected to yield best result according to our\n",
      "characterization. Our experiments show that the proposed method significantly\n",
      "outperforms existing approaches in image classification experiments by a large\n",
      "margin.\n",
      "\n",
      "    \n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Currently, the neural network architecture design is mostly guided by the\n",
      "\\emph{indirect} metric of computation complexity, i.e., FLOPs. However, the\n",
      "\\emph{direct} metric, e.g., speed, also depends on the other factors such as\n",
      "memory access cost and platform characterics. Thus, this work proposes to\n",
      "evaluate the direct metric on the target platform, beyond only considering\n",
      "FLOPs. Based on a series of controlled experiments, this work derives several\n",
      "practical \\emph{guidelines} for efficient network design. Accordingly, a new\n",
      "architecture is presented, called \\emph{ShuffleNet V2}. Comprehensive ablation\n",
      "experiments verify that our model is the state-of-the-art in terms of speed and\n",
      "accuracy tradeoff.\n",
      "\n",
      "    \n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a new system for generating art. The system generates art by\n",
      "looking at art and learning about style; and becomes creative by increasing the\n",
      "arousal potential of the generated art by deviating from the learned styles. We\n",
      "build over Generative Adversarial Networks (GAN), which have shown the ability\n",
      "to learn to generate novel images simulating a given distribution. We argue\n",
      "that such networks are limited in their ability to generate creative products\n",
      "in their original design. We propose modifications to its objective to make it\n",
      "capable of generating creative art by maximizing deviation from established\n",
      "styles and minimizing deviation from art distribution. We conducted experiments\n",
      "to compare the response of human subjects to the generated art with their\n",
      "response to art created by artists. The results show that human subjects could\n",
      "not distinguish art generated by the proposed system from art generated by\n",
      "contemporary artists and shown in top art fairs. Human subjects even rated the\n",
      "generated images higher on various scales.\n",
      "\n",
      "    \n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we present a simple yet effective padding scheme that can be\n",
      "used as a drop-in module for existing convolutional neural networks. We call it\n",
      "partial convolution based padding, with the intuition that the padded region\n",
      "can be treated as holes and the original input as non-holes. Specifically,\n",
      "during the convolution operation, the convolution results are re-weighted near\n",
      "image borders based on the ratios between the padded area and the convolution\n",
      "sliding window area. Extensive experiments with various deep network models on\n",
      "ImageNet classification and semantic segmentation demonstrate that the proposed\n",
      "padding scheme consistently outperforms standard zero padding with better\n",
      "accuracy.\n",
      "\n",
      "    \n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)\n",
      "which views the discriminator as an energy function that attributes low\n",
      "energies to the regions near the data manifold and higher energies to other\n",
      "regions. Similar to the probabilistic GANs, a generator is seen as being\n",
      "trained to produce contrastive samples with minimal energies, while the\n",
      "discriminator is trained to assign high energies to these generated samples.\n",
      "Viewing the discriminator as an energy function allows to use a wide variety of\n",
      "architectures and loss functionals in addition to the usual binary classifier\n",
      "with logistic output. Among them, we show one instantiation of EBGAN framework\n",
      "as using an auto-encoder architecture, with the energy being the reconstruction\n",
      "error, in place of the discriminator. We show that this form of EBGAN exhibits\n",
      "more stable behavior than regular GANs during training. We also show that a\n",
      "single-scale architecture can be trained to generate high-resolution images.\n",
      "\n",
      "    \n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite significant recent advances in the field of face recognition,\n",
      "implementing face verification and recognition efficiently at scale presents\n",
      "serious challenges to current approaches. In this paper we present a system,\n",
      "called FaceNet, that directly learns a mapping from face images to a compact\n",
      "Euclidean space where distances directly correspond to a measure of face\n",
      "similarity. Once this space has been produced, tasks such as face recognition,\n",
      "verification and clustering can be easily implemented using standard techniques\n",
      "with FaceNet embeddings as feature vectors.\n",
      "Our method uses a deep convolutional network trained to directly optimize the\n",
      "embedding itself, rather than an intermediate bottleneck layer as in previous\n",
      "deep learning approaches. To train, we use triplets of roughly aligned matching\n",
      "/ non-matching face patches generated using a novel online triplet mining\n",
      "method. The benefit of our approach is much greater representational\n",
      "efficiency: we achieve state-of-the-art face recognition performance using only\n",
      "128-bytes per face.\n",
      "On the widely used Labeled Faces in the Wild (LFW) dataset, our system\n",
      "achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves\n",
      "95.12%. Our system cuts the error rate in comparison to the best published\n",
      "result by 30% on both datasets.\n",
      "We also introduce the concept of harmonic embeddings, and a harmonic triplet\n",
      "loss, which describe different versions of face embeddings (produced by\n",
      "different networks) that are compatible to each other and allow for direct\n",
      "comparison between each other.\n",
      "\n",
      "    \n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we address the problem of musical timbre transfer, where the\n",
      "goal is to manipulate the timbre of a sound sample from one instrument to match\n",
      "another instrument while preserving other musical content, such as pitch,\n",
      "rhythm, and loudness. In principle, one could apply image-based style transfer\n",
      "techniques to a time-frequency representation of an audio signal, but this\n",
      "depends on having a representation that allows independent manipulation of\n",
      "timbre as well as high-quality waveform generation. We introduce TimbreTron, a\n",
      "method for musical timbre transfer which applies \"image\" domain style transfer\n",
      "to a time-frequency representation of the audio signal, and then produces a\n",
      "high-quality waveform using a conditional WaveNet synthesizer. We show that the\n",
      "Constant Q Transform (CQT) representation is particularly well-suited to\n",
      "convolutional architectures due to its approximate pitch equivariance. Based on\n",
      "human perceptual evaluations, we confirmed that TimbreTron recognizably\n",
      "transferred the timbre while otherwise preserving the musical content, for both\n",
      "monophonic and polyphonic samples.\n",
      "\n",
      "    \n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training modern deep learning models requires large amounts of computation,\n",
      "often provided by GPUs. Scaling computation from one GPU to many can enable\n",
      "much faster training and research progress but entails two complications.\n",
      "First, the training library must support inter-GPU communication. Depending on\n",
      "the particular methods employed, this communication may entail anywhere from\n",
      "negligible to significant overhead. Second, the user must modify his or her\n",
      "training code to take advantage of inter-GPU communication. Depending on the\n",
      "training library's API, the modification required may be either significant or\n",
      "minimal.\n",
      "Existing methods for enabling multi-GPU training under the TensorFlow library\n",
      "entail non-negligible communication overhead and require users to heavily\n",
      "modify their model-building code, leading many researchers to avoid the whole\n",
      "mess and stick with slower single-GPU training. In this paper we introduce\n",
      "Horovod, an open source library that improves on both obstructions to scaling:\n",
      "it employs efficient inter-GPU communication via ring reduction and requires\n",
      "only a few lines of modification to user code, enabling faster, easier\n",
      "distributed training in TensorFlow. Horovod is available under the Apache 2.0\n",
      "license at this https URL\n",
      "\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Consider learning a policy from example expert behavior, without interaction\n",
      "with the expert or access to reinforcement signal. One approach is to recover\n",
      "the expert's cost function with inverse reinforcement learning, then extract a\n",
      "policy from that cost function with reinforcement learning. This approach is\n",
      "indirect and can be slow. We propose a new general framework for directly\n",
      "extracting a policy from data, as if it were obtained by reinforcement learning\n",
      "following inverse reinforcement learning. We show that a certain instantiation\n",
      "of our framework draws an analogy between imitation learning and generative\n",
      "adversarial networks, from which we derive a model-free imitation learning\n",
      "algorithm that obtains significant performance gains over existing model-free\n",
      "methods in imitating complex behaviors in large, high-dimensional environments.\n",
      "\n",
      "    \n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose an alternative generator architecture for generative adversarial\n",
      "networks, borrowing from style transfer literature. The new architecture leads\n",
      "to an automatically learned, unsupervised separation of high-level attributes\n",
      "(e.g., pose and identity when trained on human faces) and stochastic variation\n",
      "in the generated images (e.g., freckles, hair), and it enables intuitive,\n",
      "scale-specific control of the synthesis. The new generator improves the\n",
      "state-of-the-art in terms of traditional distribution quality metrics, leads to\n",
      "demonstrably better interpolation properties, and also better disentangles the\n",
      "latent factors of variation. To quantify interpolation quality and\n",
      "disentanglement, we propose two new, automated methods that are applicable to\n",
      "any generator architecture. Finally, we introduce a new, highly varied and\n",
      "high-quality dataset of human faces.\n",
      "\n",
      "    \n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a method for detecting objects in images using a single deep\n",
      "neural network. Our approach, named SSD, discretizes the output space of\n",
      "bounding boxes into a set of default boxes over different aspect ratios and\n",
      "scales per feature map location. At prediction time, the network generates\n",
      "scores for the presence of each object category in each default box and\n",
      "produces adjustments to the box to better match the object shape. Additionally,\n",
      "the network combines predictions from multiple feature maps with different\n",
      "resolutions to naturally handle objects of various sizes. Our SSD model is\n",
      "simple relative to methods that require object proposals because it completely\n",
      "eliminates proposal generation and subsequent pixel or feature resampling stage\n",
      "and encapsulates all computation in a single network. This makes SSD easy to\n",
      "train and straightforward to integrate into systems that require a detection\n",
      "component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets\n",
      "confirm that SSD has comparable accuracy to methods that utilize an additional\n",
      "object proposal step and is much faster, while providing a unified framework\n",
      "for both training and inference. Compared to other single stage methods, SSD\n",
      "has much better accuracy, even with a smaller input image size. For $300\\times\n",
      "300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan\n",
      "X and for $500\\times 500$ input, SSD achieves 75.1% mAP, outperforming a\n",
      "comparable state of the art Faster R-CNN model. Code is available at\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning thrives with large neural networks and large datasets. However,\n",
      "larger networks and larger datasets result in longer training times that impede\n",
      "research and development progress. Distributed synchronous SGD offers a\n",
      "potential solution to this problem by dividing SGD minibatches over a pool of\n",
      "parallel workers. Yet to make this scheme efficient, the per-worker workload\n",
      "must be large, which implies nontrivial growth in the SGD minibatch size. In\n",
      "this paper, we empirically show that on the ImageNet dataset large minibatches\n",
      "cause optimization difficulties, but when these are addressed the trained\n",
      "networks exhibit good generalization. Specifically, we show no loss of accuracy\n",
      "when training with large minibatch sizes up to 8192 images. To achieve this\n",
      "result, we adopt a hyper-parameter-free linear scaling rule for adjusting\n",
      "learning rates as a function of minibatch size and develop a new warmup scheme\n",
      "that overcomes optimization challenges early in training. With these simple\n",
      "techniques, our Caffe2-based system trains ResNet-50 with a minibatch size of\n",
      "8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using\n",
      "commodity hardware, our implementation achieves ~90% scaling efficiency when\n",
      "moving from 8 to 256 GPUs. Our findings enable training visual recognition\n",
      "models on internet-scale data with high efficiency.\n",
      "\n",
      "    \n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Batch Normalization (BatchNorm) is a widely adopted technique that enables\n",
      "faster and more stable training of deep neural networks (DNNs). Despite its\n",
      "pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly\n",
      "understood. The popular belief is that this effectiveness stems from\n",
      "controlling the change of the layers' input distributions during training to\n",
      "reduce the so-called \"internal covariate shift\". In this work, we demonstrate\n",
      "that such distributional stability of layer inputs has little to do with the\n",
      "success of BatchNorm. Instead, we uncover a more fundamental impact of\n",
      "BatchNorm on the training process: it makes the optimization landscape\n",
      "significantly smoother. This smoothness induces a more predictive and stable\n",
      "behavior of the gradients, allowing for faster training.\n",
      "\n",
      "    \n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Conditional GANs are at the forefront of natural image synthesis. The main\n",
      "drawback of such models is the necessity for labeled data. In this work we\n",
      "exploit two popular unsupervised learning techniques, adversarial training and\n",
      "self-supervision, and take a step towards bridging the gap between conditional\n",
      "and unconditional GANs. In particular, we allow the networks to collaborate on\n",
      "the task of representation learning, while being adversarial with respect to\n",
      "the classic GAN game. The role of self-supervision is to encourage the\n",
      "discriminator to learn meaningful feature representations which are not\n",
      "forgotten during training. We test empirically both the quality of the learned\n",
      "image representations, and the quality of the synthesized images. Under the\n",
      "same conditions, the self-supervised GAN attains a similar performance to\n",
      "state-of-the-art conditional counterparts. Finally, we show that this approach\n",
      "to fully unsupervised learning can be scaled to attain an FID of 23.4 on\n",
      "unconditional ImageNet generation.\n",
      "\n",
      "    \n",
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The problem of arbitrary object tracking has traditionally been tackled by\n",
      "learning a model of the object's appearance exclusively online, using as sole\n",
      "training data the video itself. Despite the success of these methods, their\n",
      "online-only approach inherently limits the richness of the model they can\n",
      "learn. Recently, several attempts have been made to exploit the expressive\n",
      "power of deep convolutional networks. However, when the object to track is not\n",
      "known beforehand, it is necessary to perform Stochastic Gradient Descent online\n",
      "to adapt the weights of the network, severely compromising the speed of the\n",
      "system. In this paper we equip a basic tracking algorithm with a novel\n",
      "fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset\n",
      "for object detection in video. Our tracker operates at frame-rates beyond\n",
      "real-time and, despite its extreme simplicity, achieves state-of-the-art\n",
      "performance in multiple benchmarks.\n",
      "\n",
      "    \n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training set bugs are flaws in the data that adversely affect machine\n",
      "learning. The training set is usually too large for man- ual inspection, but\n",
      "one may have the resources to verify a few trusted items. The set of trusted\n",
      "items may not by itself be adequate for learning, so we propose an algorithm\n",
      "that uses these items to identify bugs in the training set and thus im- proves\n",
      "learning. Specifically, our approach seeks the smallest set of changes to the\n",
      "training set labels such that the model learned from this corrected training\n",
      "set predicts labels of the trusted items correctly. We flag the items whose\n",
      "labels are changed as potential bugs, whose labels can be checked for veracity\n",
      "by human experts. To find the bugs in this way is a challenging combinatorial\n",
      "bilevel optimization problem, but it can be relaxed into a continuous\n",
      "optimization problem. Ex- periments on toy and real data demonstrate that our\n",
      "approach can identify training set bugs effectively and suggest appro- priate\n",
      "changes to the labels. Our algorithm is a step toward trustworthy machine\n",
      "learning.\n",
      "\n",
      "    \n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recently, Neural Architecture Search (NAS) has successfully identified neural\n",
      "network architectures that exceed human designed ones on large-scale image\n",
      "classification. In this paper, we study NAS for semantic image segmentation.\n",
      "Existing works often focus on searching the repeatable cell structure, while\n",
      "hand-designing the outer network structure that controls the spatial resolution\n",
      "changes. This choice simplifies the search space, but becomes increasingly\n",
      "problematic for dense image prediction which exhibits a lot more network level\n",
      "architectural variations. Therefore, we propose to search the network level\n",
      "structure in addition to the cell level structure, which forms a hierarchical\n",
      "architecture search space. We present a network level search space that\n",
      "includes many popular designs, and develop a formulation that allows efficient\n",
      "gradient-based architecture search (3 P100 GPU days on Cityscapes images). We\n",
      "demonstrate the effectiveness of the proposed method on the challenging\n",
      "Cityscapes, PASCAL VOC 2012, and ADE20K datasets. Auto-DeepLab, our\n",
      "architecture searched specifically for semantic image segmentation, attains\n",
      "state-of-the-art performance without any ImageNet pretraining.\n",
      "\n",
      "    \n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new algorithm named WGAN, an alternative to traditional GAN\n",
      "training. In this new model, we show that we can improve the stability of\n",
      "learning, get rid of problems like mode collapse, and provide meaningful\n",
      "learning curves useful for debugging and hyperparameter searches. Furthermore,\n",
      "we show that the corresponding optimization problem is sound, and provide\n",
      "extensive theoretical work highlighting the deep connections to other distances\n",
      "between distributions.\n",
      "\n",
      "    \n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutions are a fundamental building block of modern computer vision\n",
      "systems. Recent approaches have argued for going beyond convolutions in order\n",
      "to capture long-range dependencies. These efforts focus on augmenting\n",
      "convolutional models with content-based interactions, such as self-attention\n",
      "and non-local means, to achieve gains on a number of vision tasks. The natural\n",
      "question that arises is whether attention can be a stand-alone primitive for\n",
      "vision models instead of serving as just an augmentation on top of\n",
      "convolutions. In developing and testing a pure self-attention vision model, we\n",
      "verify that self-attention can indeed be an effective stand-alone layer. A\n",
      "simple procedure of replacing all instances of spatial convolutions with a form\n",
      "of self-attention applied to ResNet model produces a fully self-attentional\n",
      "model that outperforms the baseline on ImageNet classification with 12% fewer\n",
      "FLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention\n",
      "model matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and\n",
      "34% fewer parameters. Detailed ablation studies demonstrate that self-attention\n",
      "is especially impactful when used in later layers. These results establish that\n",
      "stand-alone self-attention is an important addition to the vision\n",
      "practitioner's toolbox.\n",
      "\n",
      "    \n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A generative recurrent neural network is quickly trained in an unsupervised\n",
      "manner to model popular reinforcement learning environments through compressed\n",
      "spatio-temporal representations. The world model's extracted features are fed\n",
      "into compact and simple policies trained by evolution, achieving state of the\n",
      "art results in various environments. We also train our agent entirely inside of\n",
      "an environment generated by its own internal world model, and transfer this\n",
      "policy back into the actual environment. Interactive version of paper at\n",
      "this https URL\n",
      "\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  One of the main barriers for deploying neural networks on embedded systems\n",
      "has been large memory and power consumption of existing neural networks. In\n",
      "this work, we introduce SqueezeNext, a new family of neural network\n",
      "architectures whose design was guided by considering previous architectures\n",
      "such as SqueezeNet, as well as by simulation results on a neural network\n",
      "accelerator. This new network is able to match AlexNet's accuracy on the\n",
      "ImageNet benchmark with $112\\times$ fewer parameters, and one of its deeper\n",
      "variants is able to achieve VGG-19 accuracy with only 4.4 Million parameters,\n",
      "($31\\times$ smaller than VGG-19). SqueezeNext also achieves better top-5\n",
      "classification accuracy with $1.3\\times$ fewer parameters as compared to\n",
      "MobileNet, but avoids using depthwise-separable convolutions that are\n",
      "inefficient on some mobile processor platforms. This wide range of accuracy\n",
      "gives the user the ability to make speed-accuracy tradeoffs, depending on the\n",
      "available resources on the target hardware. Using hardware simulation results\n",
      "for power and inference speed on an embedded system has guided us to design\n",
      "variations of the baseline model that are $2.59\\times$/$8.26\\times$ faster and\n",
      "$2.25\\times$/$7.5\\times$ more energy efficient as compared to\n",
      "SqueezeNet/AlexNet without any accuracy degradation.\n",
      "\n",
      "    \n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes a method for learning joint embeddings of images and text\n",
      "using a two-branch neural network with multiple layers of linear projections\n",
      "followed by nonlinearities. The network is trained using a large margin\n",
      "objective that combines cross-view ranking constraints with within-view\n",
      "neighborhood structure preservation constraints inspired by metric learning\n",
      "literature. Extensive experiments show that our approach gains significant\n",
      "improvements in accuracy for image-to-text and text-to-image retrieval. Our\n",
      "method achieves new state-of-the-art results on the Flickr30K and MSCOCO\n",
      "image-sentence datasets and shows promise on the new task of phrase\n",
      "localization on the Flickr30K Entities dataset.\n",
      "\n",
      "    \n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of anomaly detection in images, and present a new\n",
      "detection technique. Given a sample of images, all known to belong to a\n",
      "\"normal\" class (e.g., dogs), we show how to train a deep neural model that can\n",
      "detect out-of-distribution images (i.e., non-dog objects). The main idea behind\n",
      "our scheme is to train a multi-class model to discriminate between dozens of\n",
      "geometric transformations applied on all the given images. The auxiliary\n",
      "expertise learned by the model generates feature detectors that effectively\n",
      "identify, at test time, anomalous images based on the softmax activation\n",
      "statistics of the model when applied on transformed images. We present\n",
      "extensive experiments using the proposed detector, which indicate that our\n",
      "algorithm improves state-of-the-art methods by a wide margin.\n",
      "\n",
      "    \n",
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider image transformation problems, where an input image is\n",
      "transformed into an output image. Recent methods for such problems typically\n",
      "train feed-forward convolutional neural networks using a \\emph{per-pixel} loss\n",
      "between the output and ground-truth images. Parallel work has shown that\n",
      "high-quality images can be generated by defining and optimizing\n",
      "\\emph{perceptual} loss functions based on high-level features extracted from\n",
      "pretrained networks. We combine the benefits of both approaches, and propose\n",
      "the use of perceptual loss functions for training feed-forward networks for\n",
      "image transformation tasks. We show results on image style transfer, where a\n",
      "feed-forward network is trained to solve the optimization problem proposed by\n",
      "Gatys et al in real-time. Compared to the optimization-based method, our\n",
      "network gives similar qualitative results but is three orders of magnitude\n",
      "faster. We also experiment with single-image super-resolution, where replacing\n",
      "a per-pixel loss with a perceptual loss gives visually pleasing results.\n",
      "\n",
      "    \n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNNs) are commonly thought to recognise\n",
      "objects by learning increasingly complex representations of object shapes. Some\n",
      "recent studies suggest a more important role of image textures. We here put\n",
      "these conflicting hypotheses to a quantitative test by evaluating CNNs and\n",
      "human observers on images with a texture-shape cue conflict. We show that\n",
      "ImageNet-trained CNNs are strongly biased towards recognising textures rather\n",
      "than shapes, which is in stark contrast to human behavioural evidence and\n",
      "reveals fundamentally different classification strategies. We then demonstrate\n",
      "that the same standard architecture (ResNet-50) that learns a texture-based\n",
      "representation on ImageNet is able to learn a shape-based representation\n",
      "instead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\n",
      "This provides a much better fit for human behavioural performance in our\n",
      "well-controlled psychophysical lab setting (nine experiments totalling 48,560\n",
      "psychophysical trials across 97 observers) and comes with a number of\n",
      "unexpected emergent benefits such as improved object detection performance and\n",
      "previously unseen robustness towards a wide range of image distortions,\n",
      "highlighting advantages of a shape-based representation.\n",
      "\n",
      "    \n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While it is nearly effortless for humans to quickly assess the perceptual\n",
      "similarity between two images, the underlying processes are thought to be quite\n",
      "complex. Despite this, the most widely used perceptual metrics today, such as\n",
      "PSNR and SSIM, are simple, shallow functions, and fail to account for many\n",
      "nuances of human perception. Recently, the deep learning community has found\n",
      "that features of the VGG network trained on ImageNet classification has been\n",
      "remarkably useful as a training loss for image synthesis. But how perceptual\n",
      "are these so-called \"perceptual losses\"? What elements are critical for their\n",
      "success? To answer these questions, we introduce a new dataset of human\n",
      "perceptual similarity judgments. We systematically evaluate deep features\n",
      "across different architectures and tasks and compare them with classic metrics.\n",
      "We find that deep features outperform all previous metrics by large margins on\n",
      "our dataset. More surprisingly, this result is not restricted to\n",
      "ImageNet-trained VGG features, but holds across different deep architectures\n",
      "and levels of supervision (supervised, self-supervised, or even unsupervised).\n",
      "Our results suggest that perceptual similarity is an emergent property shared\n",
      "across deep visual representations.\n",
      "\n",
      "    \n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent studies have shown remarkable success in image-to-image translation\n",
      "for two domains. However, existing approaches have limited scalability and\n",
      "robustness in handling more than two domains, since different models should be\n",
      "built independently for every pair of image domains. To address this\n",
      "limitation, we propose StarGAN, a novel and scalable approach that can perform\n",
      "image-to-image translations for multiple domains using only a single model.\n",
      "Such a unified model architecture of StarGAN allows simultaneous training of\n",
      "multiple datasets with different domains within a single network. This leads to\n",
      "StarGAN's superior quality of translated images compared to existing models as\n",
      "well as the novel capability of flexibly translating an input image to any\n",
      "desired target domain. We empirically demonstrate the effectiveness of our\n",
      "approach on a facial attribute transfer and a facial expression synthesis\n",
      "tasks.\n",
      "\n",
      "    \n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks excel in regimes with large amounts of data, but tend to\n",
      "struggle when data is scarce or when they need to adapt quickly to changes in\n",
      "the task. In response, recent work in meta-learning proposes training a\n",
      "meta-learner on a distribution of similar tasks, in the hopes of generalization\n",
      "to novel but related tasks by learning a high-level strategy that captures the\n",
      "essence of the problem it is asked to solve. However, many recent meta-learning\n",
      "approaches are extensively hand-designed, either using architectures\n",
      "specialized to a particular application, or hard-coding algorithmic components\n",
      "that constrain how the meta-learner solves the task. We propose a class of\n",
      "simple and generic meta-learner architectures that use a novel combination of\n",
      "temporal convolutions and soft attention; the former to aggregate information\n",
      "from past experience and the latter to pinpoint specific pieces of information.\n",
      "In the most extensive set of meta-learning experiments to date, we evaluate the\n",
      "resulting Simple Neural AttentIve Learner (or SNAIL) on several\n",
      "heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\n",
      "learning, SNAIL attains state-of-the-art performance by significant margins.\n",
      "\n",
      "    \n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose spatially-adaptive normalization, a simple but effective layer for\n",
      "synthesizing photorealistic images given an input semantic layout. Previous\n",
      "methods directly feed the semantic layout as input to the deep network, which\n",
      "is then processed through stacks of convolution, normalization, and\n",
      "nonlinearity layers. We show that this is suboptimal as the normalization\n",
      "layers tend to ``wash away'' semantic information. To address the issue, we\n",
      "propose using the input layout for modulating the activations in normalization\n",
      "layers through a spatially-adaptive, learned transformation. Experiments on\n",
      "several challenging datasets demonstrate the advantage of the proposed method\n",
      "over existing approaches, regarding both visual fidelity and alignment with\n",
      "input layouts. Finally, our model allows user control over both semantic and\n",
      "style. Code is available at this https URL .\n",
      "\n",
      "    \n",
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural networks for image recognition have evolved through extensive manual\n",
      "design from simple chain-like models to structures with multiple wiring paths.\n",
      "The success of ResNets and DenseNets is due in large part to their innovative\n",
      "wiring plans. Now, neural architecture search (NAS) studies are exploring the\n",
      "joint optimization of wiring and operation types, however, the space of\n",
      "possible wirings is constrained and still driven by manual design despite being\n",
      "searched. In this paper, we explore a more diverse set of connectivity patterns\n",
      "through the lens of randomly wired neural networks. To do this, we first define\n",
      "the concept of a stochastic network generator that encapsulates the entire\n",
      "network generation process. Encapsulation provides a unified view of NAS and\n",
      "randomly wired networks. Then, we use three classical random graph models to\n",
      "generate randomly wired graphs for networks. The results are surprising:\n",
      "several variants of these random generators yield network instances that have\n",
      "competitive accuracy on the ImageNet benchmark. These results suggest that new\n",
      "efforts focusing on designing better network generators may lead to new\n",
      "breakthroughs by exploring less constrained search spaces with more room for\n",
      "novel design.\n",
      "\n",
      "    \n",
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Incidental scene text spotting is considered one of the most difficult and\n",
      "valuable challenges in the document analysis community. Most existing methods\n",
      "treat text detection and recognition as separate tasks. In this work, we\n",
      "propose a unified end-to-end trainable Fast Oriented Text Spotting (FOTS)\n",
      "network for simultaneous detection and recognition, sharing computation and\n",
      "visual information among the two complementary tasks. Specially, RoIRotate is\n",
      "introduced to share convolutional features between detection and recognition.\n",
      "Benefiting from convolution sharing strategy, our FOTS has little computation\n",
      "overhead compared to baseline text detection network, and the joint training\n",
      "method learns more generic features to make our method perform better than\n",
      "these two-stage methods. Experiments on ICDAR 2015, ICDAR 2017 MLT, and ICDAR\n",
      "2013 datasets demonstrate that the proposed method outperforms state-of-the-art\n",
      "methods significantly, which further allows us to develop the first real-time\n",
      "oriented text spotting system which surpasses all previous state-of-the-art\n",
      "results by more than 5% on ICDAR 2015 text spotting task while keeping 22.6\n",
      "fps.\n",
      "\n",
      "    \n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents a novel unsupervised domain adaptation framework, called\n",
      "Synergistic Image and Feature Adaptation (SIFA), to effectively tackle the\n",
      "problem of domain shift. Domain adaptation has become an important and hot\n",
      "topic in recent studies on deep learning, aiming to recover performance\n",
      "degradation when applying the neural networks to new testing domains. Our\n",
      "proposed SIFA is an elegant learning diagram which presents synergistic fusion\n",
      "of adaptations from both image and feature perspectives. In particular, we\n",
      "simultaneously transform the appearance of images across domains and enhance\n",
      "domain-invariance of the extracted features towards the segmentation task. The\n",
      "feature encoder layers are shared by both perspectives to grasp their mutual\n",
      "benefits during the end-to-end learning procedure. Without using any annotation\n",
      "from the target domain, the learning of our unified model is guided by\n",
      "adversarial losses, with multiple discriminators employed from various aspects.\n",
      "We have extensively validated our method with a challenging application of\n",
      "cross-modality medical image segmentation of cardiac structures. Experimental\n",
      "results demonstrate that our SIFA model recovers the degraded performance from\n",
      "17.2% to 73.0%, and outperforms the state-of-the-art methods by a significant\n",
      "margin.\n",
      "\n",
      "    \n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern deep transfer learning approaches have mainly focused on learning\n",
      "generic feature vectors from one task that are transferable to other tasks,\n",
      "such as word embeddings in language and pretrained convolutional features in\n",
      "vision. However, these approaches usually transfer unary features and largely\n",
      "ignore more structured graphical representations. This work explores the\n",
      "possibility of learning generic latent relational graphs that capture\n",
      "dependencies between pairs of data units (e.g., words or pixels) from\n",
      "large-scale unlabeled data and transferring the graphs to downstream tasks. Our\n",
      "proposed transfer learning framework improves performance on various tasks\n",
      "including question answering, natural language inference, sentiment analysis,\n",
      "and image classification. We also show that the learned graphs are generic\n",
      "enough to be transferred to different embeddings on which the graphs have not\n",
      "been trained (including GloVe embeddings, ELMo embeddings, and task-specific\n",
      "RNN hidden unit), or embedding-free units such as image pixels.\n",
      "\n",
      "    \n",
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Transformers have a potential of learning longer-term dependency, but are\n",
      "limited by a fixed-length context in the setting of language modeling. We\n",
      "propose a novel neural architecture Transformer-XL that enables learning\n",
      "dependency beyond a fixed length without disrupting temporal coherence. It\n",
      "consists of a segment-level recurrence mechanism and a novel positional\n",
      "encoding scheme. Our method not only enables capturing longer-term dependency,\n",
      "but also resolves the context fragmentation problem. As a result,\n",
      "Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer\n",
      "than vanilla Transformers, achieves better performance on both short and long\n",
      "sequences, and is up to 1,800+ times faster than vanilla Transformers during\n",
      "evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity\n",
      "to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion\n",
      "Word, and 54.5 on Penn Treebank (without finetuning). When trained only on\n",
      "WikiText-103, Transformer-XL manages to generate reasonably coherent, novel\n",
      "text articles with thousands of tokens. Our code, pretrained models, and\n",
      "hyperparameters are available in both Tensorflow and PyTorch.\n",
      "\n",
      "    \n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a principled approach to uncover the structure of visual data by\n",
      "solving a novel deep learning task coined visual permutation learning. The goal\n",
      "of this task is to find the permutation that recovers the structure of data\n",
      "from shuffled versions of it. In the case of natural images, this task boils\n",
      "down to recovering the original image from patches shuffled by an unknown\n",
      "permutation matrix. Unfortunately, permutation matrices are discrete, thereby\n",
      "posing difficulties for gradient-based methods. To this end, we resort to a\n",
      "continuous approximation of these matrices using doubly-stochastic matrices\n",
      "which we generate from standard CNN predictions using Sinkhorn iterations.\n",
      "Unrolling these iterations in a Sinkhorn network layer, we propose DeepPermNet,\n",
      "an end-to-end CNN model for this task. The utility of DeepPermNet is\n",
      "demonstrated on two challenging computer vision problems, namely, (i) relative\n",
      "attributes learning and (ii) self-supervised representation learning. Our\n",
      "results show state-of-the-art performance on the Public Figures and OSR\n",
      "benchmarks for (i) and on the classification and segmentation tasks on the\n",
      "PASCAL VOC dataset for (ii).\n",
      "\n",
      "    \n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A key advance in learning generative models is the use of amortized inference\n",
      "distributions that are jointly trained with the models. We find that existing\n",
      "training objectives for variational autoencoders can lead to inaccurate\n",
      "amortized inference distributions and, in some cases, improving the objective\n",
      "provably degrades the inference quality. In addition, it has been observed that\n",
      "variational autoencoders tend to ignore the latent variables when combined with\n",
      "a decoding distribution that is too flexible. We again identify the cause in\n",
      "existing training criteria and propose a new class of objectives (InfoVAE) that\n",
      "mitigate these problems. We show that our model can significantly improve the\n",
      "quality of the variational posterior and can make effective use of the latent\n",
      "features regardless of the flexibility of the decoding distribution. Through\n",
      "extensive qualitative and quantitative analyses, we demonstrate that our models\n",
      "outperform competing approaches on multiple performance metrics.\n",
      "\n",
      "    \n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Several recent works have shown how highly realistic human head images can be\n",
      "obtained by training convolutional neural networks to generate them. In order\n",
      "to create a personalized talking head model, these works require training on a\n",
      "large dataset of images of a single person. However, in many practical\n",
      "scenarios, such personalized talking head models need to be learned from a few\n",
      "image views of a person, potentially even a single image. Here, we present a\n",
      "system with such few-shot capability. It performs lengthy meta-learning on a\n",
      "large dataset of videos, and after that is able to frame few- and one-shot\n",
      "learning of neural talking head models of previously unseen people as\n",
      "adversarial training problems with high capacity generators and discriminators.\n",
      "Crucially, the system is able to initialize the parameters of both the\n",
      "generator and the discriminator in a person-specific way, so that training can\n",
      "be based on just a few images and done quickly, despite the need to tune tens\n",
      "of millions of parameters. We show that such an approach is able to learn\n",
      "highly realistic and personalized talking head models of new people and even\n",
      "portrait paintings.\n",
      "\n",
      "    \n",
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The interpretation of deep learning models is a challenge due to their size,\n",
      "complexity, and often opaque internal state. In addition, many systems, such as\n",
      "image classifiers, operate on low-level features rather than high-level\n",
      "concepts. To address these challenges, we introduce Concept Activation Vectors\n",
      "(CAVs), which provide an interpretation of a neural net's internal state in\n",
      "terms of human-friendly concepts. The key idea is to view the high-dimensional\n",
      "internal state of a neural net as an aid, not an obstacle. We show how to use\n",
      "CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional\n",
      "derivatives to quantify the degree to which a user-defined concept is important\n",
      "to a classification result--for example, how sensitive a prediction of \"zebra\"\n",
      "is to the presence of stripes. Using the domain of image classification as a\n",
      "testing ground, we describe how CAVs may be used to explore hypotheses and\n",
      "generate insights for a standard image classification network as well as a\n",
      "medical application.\n",
      "\n",
      "    \n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Unsupervised image-to-image translation methods learn to map images in a\n",
      "given class to an analogous image in a different class, drawing on unstructured\n",
      "(non-registered) datasets of images. While remarkably successful, current\n",
      "methods require access to many images in both source and destination classes at\n",
      "training time. We argue this greatly limits their use. Drawing inspiration from\n",
      "the human capability of picking up the essence of a novel object from a small\n",
      "number of examples and generalizing from there, we seek a few-shot,\n",
      "unsupervised image-to-image translation algorithm that works on previously\n",
      "unseen target classes that are specified, at test time, only by a few example\n",
      "images. Our model achieves this few-shot generation capability by coupling an\n",
      "adversarial training scheme with a novel network design. Through extensive\n",
      "experimental validation and comparisons to several baseline methods on\n",
      "benchmark datasets, we verify the effectiveness of the proposed framework. Our\n",
      "implementation and datasets are available at this https URL .\n",
      "\n",
      "    \n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (ConvNets) are commonly developed at a fixed\n",
      "resource budget, and then scaled up for better accuracy if more resources are\n",
      "available. In this paper, we systematically study model scaling and identify\n",
      "that carefully balancing network depth, width, and resolution can lead to\n",
      "better performance. Based on this observation, we propose a new scaling method\n",
      "that uniformly scales all dimensions of depth/width/resolution using a simple\n",
      "yet highly effective compound coefficient. We demonstrate the effectiveness of\n",
      "this method on scaling up MobileNets and ResNet.\n",
      "To go even further, we use neural architecture search to design a new\n",
      "baseline network and scale it up to obtain a family of models, called\n",
      "EfficientNets, which achieve much better accuracy and efficiency than previous\n",
      "ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4%\n",
      "top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x\n",
      "faster on inference than the best existing ConvNet. Our EfficientNets also\n",
      "transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%),\n",
      "Flowers (98.8%), and 3 other transfer learning datasets, with an order of\n",
      "magnitude fewer parameters. Source code is at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Cross-entropy loss together with softmax is arguably one of the most common\n",
      "used supervision components in convolutional neural networks (CNNs). Despite\n",
      "its simplicity, popularity and excellent performance, the component does not\n",
      "explicitly encourage discriminative learning of features. In this paper, we\n",
      "propose a generalized large-margin softmax (L-Softmax) loss which explicitly\n",
      "encourages intra-class compactness and inter-class separability between learned\n",
      "features. Moreover, L-Softmax not only can adjust the desired margin but also\n",
      "can avoid overfitting. We also show that the L-Softmax loss can be optimized by\n",
      "typical stochastic gradient descent. Extensive experiments on four benchmark\n",
      "datasets demonstrate that the deeply-learned features with L-softmax loss\n",
      "become more discriminative, hence significantly boosting the performance on a\n",
      "variety of visual classification and verification tasks.\n",
      "\n",
      "    \n",
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Intersection over Union (IoU) is the most popular evaluation metric used in\n",
      "the object detection benchmarks. However, there is a gap between optimizing the\n",
      "commonly used distance losses for regressing the parameters of a bounding box\n",
      "and maximizing this metric value. The optimal objective for a metric is the\n",
      "metric itself. In the case of axis-aligned 2D bounding boxes, it can be shown\n",
      "that $IoU$ can be directly used as a regression loss. However, $IoU$ has a\n",
      "plateau making it infeasible to optimize in the case of non-overlapping\n",
      "bounding boxes. In this paper, we address the weaknesses of $IoU$ by\n",
      "introducing a generalized version as both a new loss and a new metric. By\n",
      "incorporating this generalized $IoU$ ($GIoU$) as a loss into the state-of-the\n",
      "art object detection frameworks, we show a consistent improvement on their\n",
      "performance using both the standard, $IoU$ based, and new, $GIoU$ based,\n",
      "performance measures on popular object detection benchmarks such as PASCAL VOC\n",
      "and MS COCO.\n",
      "\n",
      "    \n",
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We report a method to convert discrete representations of molecules to and\n",
      "from a multidimensional continuous representation. This model allows us to\n",
      "generate new molecules for efficient exploration and optimization through\n",
      "open-ended spaces of chemical compounds. A deep neural network was trained on\n",
      "hundreds of thousands of existing chemical structures to construct three\n",
      "coupled functions: an encoder, a decoder and a predictor. The encoder converts\n",
      "the discrete representation of a molecule into a real-valued continuous vector,\n",
      "and the decoder converts these continuous vectors back to discrete molecular\n",
      "representations. The predictor estimates chemical properties from the latent\n",
      "continuous vector representation of the molecule. Continuous representations\n",
      "allow us to automatically generate novel chemical structures by performing\n",
      "simple operations in the latent space, such as decoding random vectors,\n",
      "perturbing known chemical structures, or interpolating between molecules.\n",
      "Continuous representations also allow the use of powerful gradient-based\n",
      "optimization to efficiently guide the search for optimized functional\n",
      "compounds. We demonstrate our method in the domain of drug-like molecules and\n",
      "also in the set of molecules with fewer that nine heavy atoms.\n",
      "\n",
      "    \n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  With the capability of modeling bidirectional contexts, denoising\n",
      "autoencoding based pretraining like BERT achieves better performance than\n",
      "pretraining approaches based on autoregressive language modeling. However,\n",
      "relying on corrupting the input with masks, BERT neglects dependency between\n",
      "the masked positions and suffers from a pretrain-finetune discrepancy. In light\n",
      "of these pros and cons, we propose XLNet, a generalized autoregressive\n",
      "pretraining method that (1) enables learning bidirectional contexts by\n",
      "maximizing the expected likelihood over all permutations of the factorization\n",
      "order and (2) overcomes the limitations of BERT thanks to its autoregressive\n",
      "formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the\n",
      "state-of-the-art autoregressive model, into pretraining. Empirically, under\n",
      "comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a\n",
      "large margin, including question answering, natural language inference,\n",
      "sentiment analysis, and document ranking.\n",
      "\n",
      "    \n",
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes a CS scheme that exploits the representational power of\n",
      "restricted Boltzmann machines and deep learning architectures to model the\n",
      "prior distribution of the sparsity pattern of signals belonging to the same\n",
      "class. The determined probability distribution is then used in a maximum a\n",
      "posteriori (MAP) approach for the reconstruction. The parameters of the prior\n",
      "distribution are learned from training data. The motivation behind this\n",
      "approach is to model the higher-order statistical dependencies between the\n",
      "coefficients of the sparse representation, with the final goal of improving the\n",
      "reconstruction. The performance of the proposed method is validated on the\n",
      "Berkeley Segmentation Dataset and the MNIST Database of handwritten digits.\n",
      "\n",
      "    \n",
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Feature pyramids are widely exploited by both the state-of-the-art one-stage\n",
      "object detectors (e.g., DSSD, RetinaNet, RefineDet) and the two-stage object\n",
      "detectors (e.g., Mask R-CNN, DetNet) to alleviate the problem arising from\n",
      "scale variation across object instances. Although these object detectors with\n",
      "feature pyramids achieve encouraging results, they have some limitations due to\n",
      "that they only simply construct the feature pyramid according to the inherent\n",
      "multi-scale, pyramidal architecture of the backbones which are actually\n",
      "designed for object classification task. Newly, in this work, we present a\n",
      "method called Multi-Level Feature Pyramid Network (MLFPN) to construct more\n",
      "effective feature pyramids for detecting objects of different scales. First, we\n",
      "fuse multi-level features (i.e. multiple layers) extracted by backbone as the\n",
      "base feature. Second, we feed the base feature into a block of alternating\n",
      "joint Thinned U-shape Modules and Feature Fusion Modules and exploit the\n",
      "decoder layers of each u-shape module as the features for detecting objects.\n",
      "Finally, we gather up the decoder layers with equivalent scales (sizes) to\n",
      "develop a feature pyramid for object detection, in which every feature map\n",
      "consists of the layers (features) from multiple levels. To evaluate the\n",
      "effectiveness of the proposed MLFPN, we design and train a powerful end-to-end\n",
      "one-stage object detector we call M2Det by integrating it into the architecture\n",
      "of SSD, which gets better detection performance than state-of-the-art one-stage\n",
      "detectors. Specifically, on MS-COCO benchmark, M2Det achieves AP of 41.0 at\n",
      "speed of 11.8 FPS with single-scale inference strategy and AP of 44.2 with\n",
      "multi-scale inference strategy, which is the new state-of-the-art results among\n",
      "one-stage detectors. The code will be made available on\n",
      "\\url{this https URL.\n",
      "\n",
      "    \n",
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Region-based object detection infers object regions for one or more\n",
      "categories in an image. Due to the recent advances in deep learning and region\n",
      "proposal methods, object detectors based on convolutional neural networks\n",
      "(CNNs) have been flourishing and provided the promising detection results.\n",
      "However, the detection accuracy is degraded often because of the low\n",
      "discriminability of object CNN features caused by occlusions and inaccurate\n",
      "region proposals. In this paper, we therefore propose a region decomposition\n",
      "and assembly detector (R-DAD) for more accurate object detection.\n",
      "In the proposed R-DAD, we first decompose an object region into multiple\n",
      "small regions. To capture an entire appearance and part details of the object\n",
      "jointly, we extract CNN features within the whole object region and decomposed\n",
      "regions. We then learn the semantic relations between the object and its parts\n",
      "by combining the multi-region features stage by stage with region assembly\n",
      "blocks, and use the combined and high-level semantic features for the object\n",
      "classification and localization. In addition, for more accurate region\n",
      "proposals, we propose a multi-scale proposal layer that can generate object\n",
      "proposals of various scales. We integrate the R-DAD into several feature\n",
      "extractors, and prove the distinct performance improvement on PASCAL07/12 and\n",
      "MSCOCO18 compared to the recent convolutional detectors.\n",
      "\n",
      "    \n",
      "111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openreview.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A well-trained model should classify objects with a unanimous score for every\n",
      "category. This requires the high-level semantic features should be as much\n",
      "alike as possible among samples. To achive this, previous works focus on\n",
      "re-designing the loss or proposing new regularization constraints. In this\n",
      "paper, we provide a new perspective. For each category, it is assumed that\n",
      "there are two feature sets: one with reliable information and the other with\n",
      "less reliable source. We argue that the reliable set could guide the feature\n",
      "learning of the less reliable set during training - in spirit of student\n",
      "mimicking teacher behavior and thus pushing towards a more compact class\n",
      "centroid in the feature space. Such a scheme also benefits the reliable set\n",
      "since samples become closer within the same category - implying that it is\n",
      "easier for the classifier to identify. We refer to this mutual learning process\n",
      "as feature intertwiner and embed it into object detection. It is well-known\n",
      "that objects of low resolution are more difficult to detect due to the loss of\n",
      "detailed information during network forward pass (e.g., RoI operation). We thus\n",
      "regard objects of high resolution as the reliable set and objects of low\n",
      "resolution as the less reliable set. Specifically, an intertwiner is designed\n",
      "to minimize the distribution divergence between two sets. The choice of\n",
      "generating an effective feature representation for the reliable set is further\n",
      "investigated, where we introduce the optimal transport (OT) theory into the\n",
      "framework. Samples in the less reliable set are better aligned with aid of OT\n",
      "metric. Incorporated with such a plug-and-play intertwiner, we achieve an\n",
      "evident improvement over previous state-of-the-arts.\n",
      "\n",
      "    \n",
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This work addresses the unsupervised adaptation of an existing object\n",
      "detector to a new target domain. We assume that a large number of unlabeled\n",
      "videos from this domain are readily available. We automatically obtain labels\n",
      "on the target data by using high-confidence detections from the existing\n",
      "detector, augmented with hard (misclassified) examples acquired by exploiting\n",
      "temporal cues using a tracker. These automatically-obtained labels are then\n",
      "used for re-training the original model. A modified knowledge distillation loss\n",
      "is proposed, and we investigate several ways of assigning soft-labels to the\n",
      "training examples from the target domain. Our approach is empirically evaluated\n",
      "on challenging face and pedestrian detection tasks: a face detector trained on\n",
      "WIDER-Face, which consists of high-quality images crawled from the web, is\n",
      "adapted to a large-scale surveillance data set; a pedestrian detector trained\n",
      "on clear, daytime images from the BDD-100K driving data set is adapted to all\n",
      "other scenarios such as rainy, foggy, night-time. Our results demonstrate the\n",
      "usefulness of incorporating hard examples obtained from tracking, the advantage\n",
      "of using soft-labels via distillation loss versus hard-labels, and show\n",
      "promising performance as a simple method for unsupervised domain adaptation of\n",
      "object detectors, with minimal dependence on hyper-parameters.\n",
      "\n",
      "    \n",
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Compared with model architectures, the training process, which is also\n",
      "crucial to the success of detectors, has received relatively less attention in\n",
      "object detection. In this work, we carefully revisit the standard training\n",
      "practice of detectors, and find that the detection performance is often limited\n",
      "by the imbalance during the training process, which generally consists in three\n",
      "levels - sample level, feature level, and objective level. To mitigate the\n",
      "adverse effects caused thereby, we propose Libra R-CNN, a simple but effective\n",
      "framework towards balanced learning for object detection. It integrates three\n",
      "novel components: IoU-balanced sampling, balanced feature pyramid, and balanced\n",
      "L1 loss, respectively for reducing the imbalance at sample, feature, and\n",
      "objective level. Benefitted from the overall balanced design, Libra R-CNN\n",
      "significantly improves the detection performance. Without bells and whistles,\n",
      "it achieves 2.5 points and 2.0 points higher Average Precision (AP) than FPN\n",
      "Faster R-CNN and RetinaNet respectively on MSCOCO.\n",
      "\n",
      "    \n",
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We motivate and present feature selective anchor-free (FSAF) module, a simple\n",
      "and effective building block for single-shot object detectors. It can be\n",
      "plugged into single-shot detectors with feature pyramid structure. The FSAF\n",
      "module addresses two limitations brought up by the conventional anchor-based\n",
      "detection: 1) heuristic-guided feature selection; 2) overlap-based anchor\n",
      "sampling. The general concept of the FSAF module is online feature selection\n",
      "applied to the training of multi-level anchor-free branches. Specifically, an\n",
      "anchor-free branch is attached to each level of the feature pyramid, allowing\n",
      "box encoding and decoding in the anchor-free manner at an arbitrary level.\n",
      "During training, we dynamically assign each instance to the most suitable\n",
      "feature level. At the time of inference, the FSAF module can work jointly with\n",
      "anchor-based branches by outputting predictions in parallel. We instantiate\n",
      "this concept with simple implementations of anchor-free branches and online\n",
      "feature selection strategy. Experimental results on the COCO detection track\n",
      "show that our FSAF module performs better than anchor-based counterparts while\n",
      "being faster. When working jointly with anchor-based branches, the FSAF module\n",
      "robustly improves the baseline RetinaNet by a large margin under various\n",
      "settings, while introducing nearly free inference overhead. And the resulting\n",
      "best model can achieve a state-of-the-art 44.6% mAP, outperforming all existing\n",
      "single-shot detectors on COCO.\n",
      "\n",
      "    \n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  With the advent of deep learning, object detection drifted from a bottom-up\n",
      "to a top-down recognition problem. State of the art algorithms enumerate a\n",
      "near-exhaustive list of object locations and classify each into: object or not.\n",
      "In this paper, we show that bottom-up approaches still perform competitively.\n",
      "We detect four extreme points (top-most, left-most, bottom-most, right-most)\n",
      "and one center point of objects using a standard keypoint estimation network.\n",
      "We group the five keypoints into a bounding box if they are geometrically\n",
      "aligned. Object detection is then a purely appearance-based keypoint estimation\n",
      "problem, without region classification or implicit feature learning. The\n",
      "proposed method performs on-par with the state-of-the-art region based\n",
      "detection methods, with a bounding box AP of 43.2% on COCO test-dev. In\n",
      "addition, our estimated extreme points directly span a coarse octagonal mask,\n",
      "with a COCO Mask AP of 18.9%, much better than the Mask AP of vanilla bounding\n",
      "boxes. Extreme point guided segmentation further improves this to 34.6% Mask\n",
      "AP.\n",
      "\n",
      "    \n",
      "117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Weakly supervised object detection (WSOD) is a challenging task when provided\n",
      "with image category supervision but required to simultaneously learn object\n",
      "locations and object detectors. Many WSOD approaches adopt multiple instance\n",
      "learning (MIL) and have non-convex loss functions which are prone to get stuck\n",
      "into local minima (falsely localize object parts) while missing full object\n",
      "extent during training. In this paper, we introduce a continuation optimization\n",
      "method into MIL and thereby creating continuation multiple instance learning\n",
      "(C-MIL), with the intention of alleviating the non-convexity problem in a\n",
      "systematic way. We partition instances into spatially related and class related\n",
      "subsets, and approximate the original loss function with a series of smoothed\n",
      "loss functions defined within the subsets. Optimizing smoothed loss functions\n",
      "prevents the training procedure falling prematurely into local minima and\n",
      "facilitates the discovery of Stable Semantic Extremal Regions (SSERs) which\n",
      "indicate full object extent. On the PASCAL VOC 2007 and 2012 datasets, C-MIL\n",
      "improves the state-of-the-art of weakly supervised object detection and weakly\n",
      "supervised object localization with large margins.\n",
      "\n",
      "    \n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Current state-of-the-art object objectors are fine-tuned from the\n",
      "off-the-shelf networks pretrained on large-scale classification dataset\n",
      "ImageNet, which incurs some additional problems: 1) The classification and\n",
      "detection have different degrees of sensitivity to translation, resulting in\n",
      "the learning objective bias; 2) The architecture is limited by the\n",
      "classification network, leading to the inconvenience of modification. To cope\n",
      "with these problems, training detectors from scratch is a feasible solution.\n",
      "However, the detectors trained from scratch generally perform worse than the\n",
      "pretrained ones, even suffer from the convergence issue in training. In this\n",
      "paper, we explore to train object detectors from scratch robustly. By analysing\n",
      "the previous work on optimization landscape, we find that one of the overlooked\n",
      "points in current trained-from-scratch detector is the BatchNorm. Resorting to\n",
      "the stable and predictable gradient brought by BatchNorm, detectors can be\n",
      "trained from scratch stably while keeping the favourable performance\n",
      "independent to the network architecture. Taking this advantage, we are able to\n",
      "explore various types of networks for object detection, without suffering from\n",
      "the poor convergence. By extensive experiments and analyses on downsampling\n",
      "factor, we propose the Root-ResNet backbone network, which makes full use of\n",
      "the information from original images. Our ScratchDet achieves the\n",
      "state-of-the-art accuracy on PASCAL VOC 2007, 2012 and MS COCO among all the\n",
      "train-from-scratch detectors and even performs better than several one-stage\n",
      "pretrained methods. Codes will be made publicly available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Large-scale object detection datasets (e.g., MS-COCO) try to define the\n",
      "ground truth bounding boxes as clear as possible. However, we observe that\n",
      "ambiguities are still introduced when labeling the bounding boxes. In this\n",
      "paper, we propose a novel bounding box regression loss for learning bounding\n",
      "box transformation and localization variance together. Our loss greatly\n",
      "improves the localization accuracies of various architectures with nearly no\n",
      "additional computation. The learned localization variance allows us to merge\n",
      "neighboring bounding boxes during non-maximum suppression (NMS), which further\n",
      "improves the localization performance. On MS-COCO, we boost the Average\n",
      "Precision (AP) of VGG-16 Faster R-CNN from 23.6% to 29.1%. More importantly,\n",
      "for ResNet-50-FPN Mask R-CNN, our method improves the AP and AP90 by 1.8% and\n",
      "6.2% respectively, which significantly outperforms previous state-of-the-art\n",
      "bounding box refinement methods. Our code and models are available at:\n",
      "this http URL\n",
      "\n",
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Weakly supervised object detection aims at reducing the amount of supervision\n",
      "required to train detection models. Such models are traditionally learned from\n",
      "images/videos labelled only with the object class and not the object bounding\n",
      "box. In our work, we try to leverage not only the object class labels but also\n",
      "the action labels associated with the data. We show that the action depicted in\n",
      "the image/video can provide strong cues about the location of the associated\n",
      "object. We learn a spatial prior for the object dependent on the action (e.g.\n",
      "\"ball\" is closer to \"leg of the person\" in \"kicking ball\"), and incorporate\n",
      "this prior to simultaneously train a joint object detection and action\n",
      "classification model. We conducted experiments on both video datasets and image\n",
      "datasets to evaluate the performance of our weakly supervised object detection\n",
      "model. Our approach outperformed the current state-of-the-art (SOTA) method by\n",
      "more than 6% in mAP on the Charades video dataset.\n",
      "\n",
      "    \n",
      "121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  One-stage object detectors are trained by optimizing classification-loss and\n",
      "localization-loss simultaneously, with the former suffering much from extreme\n",
      "foreground-background class imbalance issue due to the large number of anchors.\n",
      "This paper alleviates this issue by proposing a novel framework to replace the\n",
      "classification task in one-stage detectors with a ranking task, and adopting\n",
      "the Average-Precision loss (AP-loss) for the ranking problem. Due to its\n",
      "non-differentiability and non-convexity, the AP-loss cannot be optimized\n",
      "directly. For this purpose, we develop a novel optimization algorithm, which\n",
      "seamlessly combines the error-driven update scheme in perceptron learning and\n",
      "backpropagation algorithm in deep networks. We verify good convergence property\n",
      "of the proposed algorithm theoretically and empirically. Experimental results\n",
      "demonstrate notable performance improvement in state-of-the-art one-stage\n",
      "detectors based on AP-loss over different kinds of classification-losses on\n",
      "various benchmarks, without changing the network architectures. Code is\n",
      "available at this https URL.\n",
      "\n",
      "    \n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose an approach for unsupervised adaptation of object detectors from\n",
      "label-rich to label-poor domains which can significantly reduce annotation\n",
      "costs associated with detection. Recently, approaches that align distributions\n",
      "of source and target images using an adversarial loss have been proven\n",
      "effective for adapting object classifiers. However, for object detection, fully\n",
      "matching the entire distributions of source and target images to each other at\n",
      "the global image level may fail, as domains could have distinct scene layouts\n",
      "and different combinations of objects. On the other hand, strong matching of\n",
      "local features such as texture and color makes sense, as it does not change\n",
      "category level semantics. This motivates us to propose a novel method for\n",
      "detector adaptation based on strong local alignment and weak global alignment.\n",
      "Our key contribution is the weak alignment model, which focuses the adversarial\n",
      "alignment loss on images that are globally similar and puts less emphasis on\n",
      "aligning images that are globally dissimilar. Additionally, we design the\n",
      "strong domain alignment model to only look at local receptive fields of the\n",
      "feature map. We empirically verify the effectiveness of our method on four\n",
      "datasets comprising both large and small domain shifts. Our code is available\n",
      "at \\url{this https URL}\n",
      "\n",
      "    \n",
      "123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Current state-of-the-art convolutional architectures for object detection are\n",
      "manually designed. Here we aim to learn a better architecture of feature\n",
      "pyramid network for object detection. We adopt Neural Architecture Search and\n",
      "discover a new feature pyramid architecture in a novel scalable search space\n",
      "covering all cross-scale connections. The discovered architecture, named\n",
      "NAS-FPN, consists of a combination of top-down and bottom-up connections to\n",
      "fuse features across scales. NAS-FPN, combined with various backbone models in\n",
      "the RetinaNet framework, achieves better accuracy and latency tradeoff compared\n",
      "to state-of-the-art object detection models. NAS-FPN improves mobile detection\n",
      "accuracy by 2 AP compared to state-of-the-art SSDLite with MobileNetV2 model in\n",
      "[32] and achieves 48.3 AP which surpasses Mask R-CNN [10] detection accuracy\n",
      "with less computation time.\n",
      "\n",
      "    \n",
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Pedestrian detection in a crowd is a very challenging issue. This paper\n",
      "addresses this problem by a novel Non-Maximum Suppression (NMS) algorithm to\n",
      "better refine the bounding boxes given by detectors. The contributions are\n",
      "threefold: (1) we propose adaptive-NMS, which applies a dynamic suppression\n",
      "threshold to an instance, according to the target density; (2) we design an\n",
      "efficient subnetwork to learn density scores, which can be conveniently\n",
      "embedded into both the single-stage and two-stage detectors; and (3) we achieve\n",
      "state of the art results on the CityPersons and CrowdHuman benchmarks.\n",
      "\n",
      "    \n",
      "125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern crowd counting methods usually employ deep neural networks (DNN) to\n",
      "estimate crowd counts via density regression. Despite their significant\n",
      "improvements, the regression-based methods are incapable of providing the\n",
      "detection of individuals in crowds. The detection-based methods, on the other\n",
      "hand, have not been largely explored in recent trends of crowd counting due to\n",
      "the needs for expensive bounding box annotations. In this work, we instead\n",
      "propose a new deep detection network with only point supervision required. It\n",
      "can simultaneously detect the size and location of human heads and count them\n",
      "in crowds. We first mine useful person size information from point-level\n",
      "annotations and initialize the pseudo ground truth bounding boxes. An online\n",
      "updating scheme is introduced to refine the pseudo ground truth during\n",
      "training; while a locally-constrained regression loss is designed to provide\n",
      "additional constraints on the size of the predicted boxes in a local\n",
      "neighborhood. In the end, we propose a curriculum learning strategy to train\n",
      "the network from images of relatively accurate and easy pseudo ground truth\n",
      "first. Extensive experiments are conducted in both detection and counting tasks\n",
      "on several standard benchmarks, e.g. ShanghaiTech, UCF_CC_50, WiderFace, and\n",
      "TRANCOS datasets, and the results show the superiority of our method over the\n",
      "state-of-the-art.\n",
      "\n",
      "    \n",
      "126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in convolutional neural networks (CNN) have achieved\n",
      "remarkable results in locating objects in images. In these networks, the\n",
      "training procedure usually requires providing bounding boxes or the maximum\n",
      "number of expected objects. In this paper, we address the task of estimating\n",
      "object locations without annotated bounding boxes which are typically\n",
      "hand-drawn and time consuming to label. We propose a loss function that can be\n",
      "used in any fully convolutional network (FCN) to estimate object locations.\n",
      "This loss function is a modification of the average Hausdorff distance between\n",
      "two unordered sets of points. The proposed method has no notion of bounding\n",
      "boxes, region proposals, or sliding windows. We evaluate our method with three\n",
      "datasets designed to locate people's heads, pupil centers and plant centers. We\n",
      "outperform state-of-the-art generic object detectors and methods fine-tuned for\n",
      "pupil tracking.\n",
      "\n",
      "    \n",
      "127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Efficient and reliable methods for training of object detectors are in higher\n",
      "demand than ever, and more and more data relevant to the field is becoming\n",
      "available. However, large datasets like Open Images Dataset v4 (OID) are\n",
      "sparsely annotated, and some measure must be taken in order to ensure the\n",
      "training of a reliable detector. In order to take the incompleteness of these\n",
      "datasets into account, one possibility is to use pretrained models to detect\n",
      "the presence of the unverified objects. However, the performance of such a\n",
      "strategy depends largely on the power of the pretrained model. In this study,\n",
      "we propose part-aware sampling, a method that uses human intuition for the\n",
      "hierarchical relation between objects. In terse terms, our method works by\n",
      "making assumptions like \"a bounding box for a car should contain a bounding box\n",
      "for a tire\". We demonstrate the power of our method on OID and compare the\n",
      "performance against a method based on a pretrained model. Our method also won\n",
      "the first and second place on the public and private test sets of the Google AI\n",
      "Open Images Competition 2018.\n",
      "\n",
      "    \n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite increasing efforts on universal representations for visual\n",
      "recognition, few have addressed object detection. In this paper, we develop an\n",
      "effective and efficient universal object detection system that is capable of\n",
      "working on various image domains, from human faces and traffic signs to medical\n",
      "CT images. Unlike multi-domain models, this universal model does not require\n",
      "prior knowledge of the domain of interest. This is achieved by the introduction\n",
      "of a new family of adaptation layers, based on the principles of squeeze and\n",
      "excitation, and a new domain-attention mechanism. In the proposed universal\n",
      "detector, all parameters and computations are shared across domains, and a\n",
      "single network processes all domains all the time. Experiments, on a newly\n",
      "established universal object detection benchmark of 11 diverse datasets, show\n",
      "that the proposed detector outperforms a bank of individual detectors, a\n",
      "multi-domain detector, and a baseline universal detector, with a 1.3x parameter\n",
      "increase over a single-domain baseline detector. The code and benchmark will be\n",
      "released at this http URL.\n",
      "\n",
      "    \n",
      "129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The recurring context in which objects appear holds valuable information that\n",
      "can be employed to predict their existence. This intuitive observation indeed\n",
      "led many researchers to endow appearance-based detectors with explicit\n",
      "reasoning about context. The underlying thesis suggests that stronger\n",
      "contextual relations would facilitate greater improvements in detection\n",
      "capacity. In practice, however, the observed improvement in many cases is\n",
      "modest at best, and often only marginal. In this work we seek to improve our\n",
      "understanding of this phenomenon, in part by pursuing an opposite approach.\n",
      "Instead of attempting to improve detection scores by employing context, we\n",
      "treat the utility of context as an optimization problem: to what extent can\n",
      "detection scores be improved by considering context or any other kind of\n",
      "additional information? With this approach we explore the bounds on improvement\n",
      "by using contextual relations between objects and provide a tool for\n",
      "identifying the most helpful ones. We show that simple co-occurrence relations\n",
      "can often provide large gains, while in other cases a significant improvement\n",
      "is simply impossible or impractical with either co-occurrence or more precise\n",
      "spatial relations. To better understand these results we then analyze the\n",
      "ability of context to handle different types of false detections, revealing\n",
      "that tested contextual information cannot ameliorate localization errors,\n",
      "severely limiting its gains. These and additional insights further our\n",
      "understanding on where and why utilization of context for object detection\n",
      "succeeds and fails.\n",
      "\n",
      "    \n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  When humans have to solve everyday tasks, they simply pick the objects that\n",
      "are most suitable. While the question which object should one use for a\n",
      "specific task sounds trivial for humans, it is very difficult to answer for\n",
      "robots or other autonomous systems. This issue, however, is not addressed by\n",
      "current benchmarks for object detection that focus on detecting object\n",
      "categories. We therefore introduce the COCO-Tasks dataset which comprises about\n",
      "40,000 images where the most suitable objects for 14 tasks have been annotated.\n",
      "We furthermore propose an approach that detects the most suitable objects for a\n",
      "given task. The approach builds on a Gated Graph Neural Network to exploit the\n",
      "appearance of each object as well as the global context of all present objects\n",
      "in the scene. In our experiments, we show that the proposed approach\n",
      "outperforms other approaches that are evaluated on the dataset like\n",
      "classification or ranking approaches.\n",
      "\n",
      "    \n",
      "131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of weakly supervised object detection, where the\n",
      "training samples are annotated using only image-level labels that indicate the\n",
      "presence or absence of an object category. In order to model the uncertainty in\n",
      "the location of the objects, we employ a dissimilarity coefficient based\n",
      "probabilistic learning objective. The learning objective minimizes the\n",
      "difference between an annotation agnostic prediction distribution and an\n",
      "annotation aware conditional distribution. The main computational challenge is\n",
      "the complex nature of the conditional distribution, which consists of terms\n",
      "over hundreds or thousands of variables. The complexity of the conditional\n",
      "distribution rules out the possibility of explicitly modeling it. Instead, we\n",
      "exploit the fact that deep learning frameworks rely on stochastic optimization.\n",
      "This allows us to use a state of the art discrete generative model that can\n",
      "provide annotation consistent samples from the conditional distribution.\n",
      "Extensive experiments on PASCAL VOC 2007 and 2012 data sets demonstrate the\n",
      "efficacy of our proposed approach.\n",
      "\n",
      "    \n",
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art CNN based recognition models are often computationally\n",
      "prohibitive to deploy on low-end devices. A promising high level approach\n",
      "tackling this limitation is knowledge distillation, which let small student\n",
      "model mimic cumbersome teacher model's output to get improved generalization.\n",
      "However, related methods mainly focus on simple task of classification while do\n",
      "not consider complex tasks like object detection. We show applying the vanilla\n",
      "knowledge distillation to detection model gets minor gain. To address the\n",
      "challenge of distilling knowledge in detection model, we propose a fine-grained\n",
      "feature imitation method exploiting the cross-location discrepancy of feature\n",
      "response. Our intuition is that detectors care more about local near object\n",
      "regions. Thus the discrepancy of feature response on the near object anchor\n",
      "locations reveals important information of how teacher model tends to\n",
      "generalize. We design a novel mechanism to estimate those locations and let\n",
      "student model imitate the teacher on them to get enhanced performance. We first\n",
      "validate the idea on a developed lightweight toy detector which carries\n",
      "simplest notion of current state-of-the-art anchor based detection models on\n",
      "challenging KITTI dataset, our method generates up to 15% boost of mAP for the\n",
      "student model compared to the non-imitated counterpart. We then extensively\n",
      "evaluate the method with Faster R-CNN model under various scenarios with common\n",
      "object detection benchmark of Pascal VOC and COCO, imitation alleviates up to\n",
      "74% performance drop of student model compared to teacher. Codes released at\n",
      "this https URL\n",
      "\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We investigate methods for combining multiple self-supervised tasks--i.e.,\n",
      "supervised tasks where data can be collected without manual labeling--in order\n",
      "to train a single visual representation. First, we provide an apples-to-apples\n",
      "comparison of four different self-supervised tasks using the very deep\n",
      "ResNet-101 architecture. We then combine tasks to jointly train a network. We\n",
      "also explore lasso regularization to encourage the network to factorize the\n",
      "information in its representation, and methods for \"harmonizing\" network inputs\n",
      "in order to learn a more unified representation. We evaluate all methods on\n",
      "ImageNet classification, PASCAL VOC detection, and NYU depth prediction. Our\n",
      "results show that deeper networks work better, and that combining tasks--even\n",
      "via a naive multi-head architecture--always improves performance. Our best\n",
      "joint network nearly matches the PASCAL performance of a model pre-trained on\n",
      "ImageNet classification, and matches the ImageNet network on NYU depth\n",
      "prediction.\n",
      "\n",
      "    \n",
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Scene text detection attracts much attention in computer vision, because it\n",
      "can be widely used in many applications such as real-time text translation,\n",
      "automatic information entry, blind person assistance, robot sensing and so on.\n",
      "Though many methods have been proposed for horizontal and oriented texts,\n",
      "detecting irregular shape texts such as curved texts is still a challenging\n",
      "problem. To solve the problem, we propose a robust scene text detection method\n",
      "with adaptive text region representation. Given an input image, a text region\n",
      "proposal network is first used for extracting text proposals. Then, these\n",
      "proposals are verified and refined with a refinement network. Here, recurrent\n",
      "neural network based adaptive text region representation is proposed for text\n",
      "region refinement, where a pair of boundary points are predicted each time step\n",
      "until no new points are found. In this way, text regions of arbitrary shapes\n",
      "are detected and represented with adaptive number of boundary points. This\n",
      "gives more accurate description of text regions. Experimental results on five\n",
      "benchmarks, namely, CTW1500, TotalText, ICDAR2013, ICDAR2015 and MSRATD500,\n",
      "show that the proposed method achieves state-of-the-art in scene text\n",
      "detection.\n",
      "\n",
      "    \n",
      "135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a simple and effective learning technique that significantly\n",
      "improves mAP of YOLO object detectors without compromising their speed. During\n",
      "network training, we carefully feed in localization information. We excite\n",
      "certain activations in order to help the network learn to better localize. In\n",
      "the later stages of training, we gradually reduce our assisted excitation to\n",
      "zero. We reached a new state-of-the-art in the speed-accuracy trade-off. Our\n",
      "technique improves the mAP of YOLOv2 by 3.8% and mAP of YOLOv3 by 2.2% on\n",
      "MSCOCO dataset.This technique is inspired from curriculum learning. It is\n",
      "simple and effective and it is applicable to most single-stage object\n",
      "detectors.\n",
      "\n",
      "    \n",
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Weakly supervised object detection aims at learning precise object detectors,\n",
      "given image category labels. In recent prevailing works, this problem is\n",
      "generally formulated as a multiple instance learning module guided by an image\n",
      "classification loss. The object bounding box is assumed to be the one\n",
      "contributing most to the classification among all proposals. However, the\n",
      "region contributing most is also likely to be a crucial part or the supporting\n",
      "context of an object. To obtain a more accurate detector, in this work we\n",
      "propose a novel end-to-end weakly supervised detection approach, where a newly\n",
      "introduced generative adversarial segmentation module interacts with the\n",
      "conventional detection module in a collaborative loop. The collaboration\n",
      "mechanism takes full advantages of the complementary interpretations of the\n",
      "weakly supervised localization task, namely detection and segmentation tasks,\n",
      "forming a more comprehensive solution. Consequently, our method obtains more\n",
      "precise object bounding boxes, rather than parts or irrelevant surroundings.\n",
      "Expectedly, the proposed method achieves an accuracy of 51.0% on the PASCAL VOC\n",
      "2007 dataset, outperforming the state-of-the-arts and demonstrating its\n",
      "superiority for weakly supervised object detection.\n",
      "\n",
      "    \n",
      "137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a novel unsupervised domain adaptation approach for object\n",
      "detection. We aim to alleviate the imperfect translation problem of pixel-level\n",
      "adaptations, and the source-biased discriminativity problem of feature-level\n",
      "adaptations simultaneously. Our approach is composed of two stages, i.e.,\n",
      "Domain Diversification (DD) and Multi-domain-invariant Representation Learning\n",
      "(MRL). At the DD stage, we diversify the distribution of the labeled data by\n",
      "generating various distinctive shifted domains from the source domain. At the\n",
      "MRL stage, we apply adversarial learning with a multi-domain discriminator to\n",
      "encourage feature to be indistinguishable among the domains. DD addresses the\n",
      "source-biased discriminativity, while MRL mitigates the imperfect image\n",
      "translation. We construct a structured domain adaptation framework for our\n",
      "learning paradigm and introduce a practical way of DD for implementation. Our\n",
      "method outperforms the state-of-the-art methods by a large margin of 3%~11% in\n",
      "terms of mean average precision (mAP) on various datasets.\n",
      "\n",
      "    \n",
      "138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Access to parallel and distributed computation has enabled researchers and\n",
      "developers to improve algorithms and performance in many applications. Recent\n",
      "research has focused on next generation special purpose systems with multiple\n",
      "kinds of coprocessors, known as heterogeneous system-on-chips (SoC). In this\n",
      "paper, we introduce a method to intelligently schedule--and learn to\n",
      "schedule--a stream of tasks to available processing elements in such a system.\n",
      "We use deep reinforcement learning enabling complex sequential decision making\n",
      "and empirically show that our reinforcement learning system provides for a\n",
      "viable, better alternative to conventional scheduling heuristics with respect\n",
      "to minimizing execution time.\n",
      "\n",
      "    \n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose a zoom-out-and-in network for generating object\n",
      "proposals. We utilize different resolutions of feature maps in the network to\n",
      "detect object instances of various sizes. Specifically, we divide the anchor\n",
      "candidates into three clusters based on the scale size and place them on\n",
      "feature maps of distinct strides to detect small, medium and large objects,\n",
      "respectively. Deeper feature maps contain region-level semantics which can help\n",
      "shallow counterparts to identify small objects. Therefore we design a zoom-in\n",
      "sub-network to increase the resolution of high level features via a\n",
      "deconvolution operation. The high-level features with high resolution are then\n",
      "combined and merged with low-level features to detect objects. Furthermore, we\n",
      "devise a recursive training pipeline to consecutively regress region proposals\n",
      "at the training stage in order to match the iterative regression at the testing\n",
      "stage. We demonstrate the effectiveness of the proposed method on ILSVRC DET\n",
      "and MS COCO datasets, where our algorithm performs better than the\n",
      "state-of-the-arts in various evaluation metrics. It also increases average\n",
      "precision by around 2% in the detection system.\n",
      "\n",
      "    \n",
      "140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Over recent years, deep reinforcement learning has shown strong successes in\n",
      "complex single-agent tasks, and more recently this approach has also been\n",
      "applied to multi-agent domains. In this paper, we propose a novel approach,\n",
      "called MAGnet, to multi-agent reinforcement learning (MARL) that utilizes a\n",
      "relevance graph representation of the environment obtained by a self-attention\n",
      "mechanism, and a message-generation technique inspired by the NerveNet\n",
      "architecture. We applied our MAGnet approach to the Pommerman game and the\n",
      "results show that it significantly outperforms state-of-the-art MARL solutions,\n",
      "including DQN, MADDPG, and MCTS.\n",
      "\n",
      "    \n",
      "141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Unsupervised representation learning algorithms such as word2vec and ELMo\n",
      "improve the accuracy of many supervised NLP models, mainly because they can\n",
      "take advantage of large amounts of unlabeled text. However, the supervised\n",
      "models only learn from task-specific labeled data during the main training\n",
      "phase. We therefore propose Cross-View Training (CVT), a semi-supervised\n",
      "learning algorithm that improves the representations of a Bi-LSTM sentence\n",
      "encoder using a mix of labeled and unlabeled data. On labeled examples,\n",
      "standard supervised learning is used. On unlabeled examples, CVT teaches\n",
      "auxiliary prediction modules that see restricted views of the input (e.g., only\n",
      "part of a sentence) to match the predictions of the full model seeing the whole\n",
      "input. Since the auxiliary modules and the full model share intermediate\n",
      "representations, this in turn improves the full model. Moreover, we show that\n",
      "CVT is particularly effective when combined with multi-task learning. We\n",
      "evaluate CVT on five sequence tagging tasks, machine translation, and\n",
      "dependency parsing, achieving state-of-the-art results.\n",
      "\n",
      "    \n",
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'd4mucfpksywv.cloudfront.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper explores a simple and efficient baseline for text classification.\n",
      "Our experiments show that our fast text classifier fastText is often on par\n",
      "with deep learning classifiers in terms of accuracy, and many orders of\n",
      "magnitude faster for training and evaluation. We can train fastText on more\n",
      "than one billion words in less than ten minutes using a standard multicore~CPU,\n",
      "and classify half a million sentences among~312K classes in less than a minute.\n",
      "\n",
      "    \n",
      "144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'alanakbik.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We study the problem of representation learning in goal-conditioned\n",
      "hierarchical reinforcement learning. In such hierarchical structures, a\n",
      "higher-level controller solves tasks by iteratively communicating goals which a\n",
      "lower-level policy is trained to reach. Accordingly, the choice of\n",
      "representation -- the mapping of observation space to goal space -- is crucial.\n",
      "To study this problem, we develop a notion of sub-optimality of a\n",
      "representation, defined in terms of expected reward of the optimal hierarchical\n",
      "policy using this representation. We derive expressions which bound the\n",
      "sub-optimality and show how these expressions can be translated to\n",
      "representation learning objectives which may be optimized in practice. Results\n",
      "on a number of difficult continuous-control tasks show that our approach to\n",
      "representation learning yields qualitatively better representations as well as\n",
      "quantitatively better hierarchical policies, compared to existing methods (see\n",
      "videos at this https URL).\n",
      "\n",
      "    \n",
      "146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A lot of the recent success in natural language processing (NLP) has been\n",
      "driven by distributed vector representations of words trained on large amounts\n",
      "of text in an unsupervised manner. These representations are typically used as\n",
      "general purpose features for words across a range of NLP problems. However,\n",
      "extending this success to learning representations of sequences of words, such\n",
      "as sentences, remains an open problem. Recent work has explored unsupervised as\n",
      "well as supervised learning techniques with different training objectives to\n",
      "learn general purpose fixed-length sentence representations. In this work, we\n",
      "present a simple, effective multi-task learning framework for sentence\n",
      "representations that combines the inductive biases of diverse training\n",
      "objectives in a single model. We train this model on several data sources with\n",
      "multiple training objectives on over 100 million sentences. Extensive\n",
      "experiments demonstrate that sharing a single recurrent sentence encoder across\n",
      "weakly related tasks leads to consistent improvements over previous methods. We\n",
      "present substantial improvements in the context of transfer learning and\n",
      "low-resource settings using our learned general-purpose representations.\n",
      "\n",
      "    \n",
      "147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new representation learning approach for domain adaptation, in\n",
      "which data at training and test time come from similar but different\n",
      "distributions. Our approach is directly inspired by the theory on domain\n",
      "adaptation suggesting that, for effective domain transfer to be achieved,\n",
      "predictions must be made based on features that cannot discriminate between the\n",
      "training (source) and test (target) domains. The approach implements this idea\n",
      "in the context of neural network architectures that are trained on labeled data\n",
      "from the source domain and unlabeled data from the target domain (no labeled\n",
      "target-domain data is necessary). As the training progresses, the approach\n",
      "promotes the emergence of features that are (i) discriminative for the main\n",
      "learning task on the source domain and (ii) indiscriminate with respect to the\n",
      "shift between the domains. We show that this adaptation behaviour can be\n",
      "achieved in almost any feed-forward model by augmenting it with few standard\n",
      "layers and a new gradient reversal layer. The resulting augmented architecture\n",
      "can be trained using standard backpropagation and stochastic gradient descent,\n",
      "and can thus be implemented with little effort using any of the deep learning\n",
      "packages. We demonstrate the success of our approach for two distinct\n",
      "classification problems (document sentiment analysis and image classification),\n",
      "where state-of-the-art domain adaptation performance on standard benchmarks is\n",
      "achieved. We also validate the approach for descriptor learning task in the\n",
      "context of person re-identification application.\n",
      "\n",
      "    \n",
      "148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In multi-task learning, multiple tasks are solved jointly, sharing inductive\n",
      "bias between them. Multi-task learning is inherently a multi-objective problem\n",
      "because different tasks may conflict, necessitating a trade-off. A common\n",
      "compromise is to optimize a proxy objective that minimizes a weighted linear\n",
      "combination of per-task losses. However, this workaround is only valid when the\n",
      "tasks do not compete, which is rarely the case. In this paper, we explicitly\n",
      "cast multi-task learning as multi-objective optimization, with the overall\n",
      "objective of finding a Pareto optimal solution. To this end, we use algorithms\n",
      "developed in the gradient-based multi-objective optimization literature. These\n",
      "algorithms are not directly applicable to large-scale learning problems since\n",
      "they scale poorly with the dimensionality of the gradients and the number of\n",
      "tasks. We therefore propose an upper bound for the multi-objective loss and\n",
      "show that it can be optimized efficiently. We further prove that optimizing\n",
      "this upper bound yields a Pareto optimal solution under realistic assumptions.\n",
      "We apply our method to a variety of multi-task deep learning problems including\n",
      "digit classification, scene understanding (joint semantic segmentation,\n",
      "instance segmentation, and depth estimation), and multi-label classification.\n",
      "Our method produces higher-performing models than recent multi-task learning\n",
      "formulations or per-task training.\n",
      "\n",
      "    \n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.danielpovey.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces WaveNet, a deep neural network for generating raw audio\n",
      "waveforms. The model is fully probabilistic and autoregressive, with the\n",
      "predictive distribution for each audio sample conditioned on all previous ones;\n",
      "nonetheless we show that it can be efficiently trained on data with tens of\n",
      "thousands of samples per second of audio. When applied to text-to-speech, it\n",
      "yields state-of-the-art performance, with human listeners rating it as\n",
      "significantly more natural sounding than the best parametric and concatenative\n",
      "systems for both English and Mandarin. A single WaveNet can capture the\n",
      "characteristics of many different speakers with equal fidelity, and can switch\n",
      "between them by conditioning on the speaker identity. When trained to model\n",
      "music, we find that it generates novel and often highly realistic musical\n",
      "fragments. We also show that it can be employed as a discriminative model,\n",
      "returning promising results for phoneme recognition.\n",
      "\n",
      "    \n",
      "151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a neural network-based system for text-to-speech (TTS) synthesis\n",
      "that is able to generate speech audio in the voice of many different speakers,\n",
      "including those unseen during training. Our system consists of three\n",
      "independently trained components: (1) a speaker encoder network, trained on a\n",
      "speaker verification task using an independent dataset of noisy speech from\n",
      "thousands of speakers without transcripts, to generate a fixed-dimensional\n",
      "embedding vector from seconds of reference speech from a target speaker; (2) a\n",
      "sequence-to-sequence synthesis network based on Tacotron 2, which generates a\n",
      "mel spectrogram from text, conditioned on the speaker embedding; (3) an\n",
      "auto-regressive WaveNet-based vocoder that converts the mel spectrogram into a\n",
      "sequence of time domain waveform samples. We demonstrate that the proposed\n",
      "model is able to transfer the knowledge of speaker variability learned by the\n",
      "discriminatively-trained speaker encoder to the new task, and is able to\n",
      "synthesize natural speech from speakers that were not seen during training. We\n",
      "quantify the importance of training the speaker encoder on a large and diverse\n",
      "speaker set in order to obtain the best generalization performance. Finally, we\n",
      "show that randomly sampled speaker embeddings can be used to synthesize speech\n",
      "in the voice of novel speakers dissimilar from those used in training,\n",
      "indicating that the model has learned a high quality speaker representation.\n",
      "\n",
      "    \n",
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Keyword spotting (KWS) is a critical component for enabling speech based user\n",
      "interactions on smart devices. It requires real-time response and high accuracy\n",
      "for good user experience. Recently, neural networks have become an attractive\n",
      "choice for KWS architecture because of their superior accuracy compared to\n",
      "traditional speech processing algorithms. Due to its always-on nature, KWS\n",
      "application has highly constrained power budget and typically runs on tiny\n",
      "microcontrollers with limited memory and compute capability. The design of\n",
      "neural network architecture for KWS must consider these constraints. In this\n",
      "work, we perform neural network architecture evaluation and exploration for\n",
      "running KWS on resource-constrained microcontrollers. We train various neural\n",
      "network architectures for keyword spotting published in literature to compare\n",
      "their accuracy and memory/compute requirements. We show that it is possible to\n",
      "optimize these neural network architectures to fit within the memory and\n",
      "compute constraints of microcontrollers without sacrificing accuracy. We\n",
      "further explore the depthwise separable convolutional neural network (DS-CNN)\n",
      "and compare it against other neural network architectures. DS-CNN achieves an\n",
      "accuracy of 95.4%, which is ~10% higher than the DNN model with similar number\n",
      "of parameters.\n",
      "\n",
      "    \n",
      "153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes a new baseline system for automatic speech recognition\n",
      "(ASR) in the CHiME-4 challenge to promote the development of noisy ASR in\n",
      "speech processing communities by providing 1) state-of-the-art system with a\n",
      "simplified single system comparable to the complicated top systems in the\n",
      "challenge, 2) publicly available and reproducible recipe through the main\n",
      "repository in the Kaldi speech recognition toolkit. The proposed system adopts\n",
      "generalized eigenvalue beamforming with bidirectional long short-term memory\n",
      "(LSTM) mask estimation. We also propose to use a time delay neural network\n",
      "(TDNN) based on the lattice-free version of the maximum mutual information\n",
      "(LF-MMI) trained with augmented all six microphones plus the enhanced data\n",
      "after beamforming. Finally, we use a LSTM language model for lattice and n-best\n",
      "re-scoring. The final system achieved 2.74\\% WER for the real test set in the\n",
      "6-channel track, which corresponds to the 2nd place in the challenge. In\n",
      "addition, the proposed baseline recipe includes four different speech\n",
      "enhancement measures, short-time objective intelligibility measure (STOI),\n",
      "extended STOI (eSTOI), perceptual evaluation of speech quality (PESQ) and\n",
      "speech distortion ratio (SDR) for the simulation test set. Thus, the recipe\n",
      "also provides an experimental platform for speech enhancement studies with\n",
      "these performance measures.\n",
      "\n",
      "    \n",
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Link prediction for knowledge graphs is the task of predicting missing\n",
      "relationships between entities. Previous work on link prediction has focused on\n",
      "shallow, fast models which can scale to large knowledge graphs. However, these\n",
      "models learn less expressive features than deep, multi-layer models -- which\n",
      "potentially limits performance. In this work, we introduce ConvE, a multi-layer\n",
      "convolutional network model for link prediction, and report state-of-the-art\n",
      "results for several established datasets. We also show that the model is highly\n",
      "parameter efficient, yielding the same performance as DistMult and R-GCN with\n",
      "8x and 17x fewer parameters. Analysis of our model suggests that it is\n",
      "particularly effective at modelling nodes with high indegree -- which are\n",
      "common in highly-connected, complex knowledge graphs such as Freebase and\n",
      "YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer\n",
      "from test set leakage, due to inverse relations from the training set being\n",
      "present in the test set -- however, the extent of this issue has so far not\n",
      "been quantified. We find this problem to be severe: a simple rule-based model\n",
      "can achieve state-of-the-art results on both WN18 and FB15k. To ensure that\n",
      "models are evaluated on datasets where simply exploiting inverse relations\n",
      "cannot yield competitive results, we investigate and validate several commonly\n",
      "used datasets -- deriving robust variants where necessary. We then perform\n",
      "experiments on these robust datasets for our own and several previously\n",
      "proposed models and find that ConvE achieves state-of-the-art Mean Reciprocal\n",
      "Rank across most datasets.\n",
      "\n",
      "    \n",
      "155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional neural networks (CNNs) have achieved great success on grid-like\n",
      "data such as images, but face tremendous challenges in learning from more\n",
      "generic data such as graphs. In CNNs, the trainable local filters enable the\n",
      "automatic extraction of high-level features. The computation with filters\n",
      "requires a fixed number of ordered units in the receptive fields. However, the\n",
      "number of neighboring units is neither fixed nor are they ordered in generic\n",
      "graphs, thereby hindering the applications of convolutional operations. Here,\n",
      "we address these challenges by proposing the learnable graph convolutional\n",
      "layer (LGCL). LGCL automatically selects a fixed number of neighboring nodes\n",
      "for each feature based on value ranking in order to transform graph data into\n",
      "grid-like structures in 1-D format, thereby enabling the use of regular\n",
      "convolutional operations on generic graphs. To enable model training on\n",
      "large-scale graphs, we propose a sub-graph training method to reduce the\n",
      "excessive memory and computational resource requirements suffered by prior\n",
      "methods on graph convolutions. Our experimental results on node classification\n",
      "tasks in both transductive and inductive learning settings demonstrate that our\n",
      "methods can achieve consistently better performance on the Cora, Citeseer,\n",
      "Pubmed citation network, and protein-protein interaction network datasets. Our\n",
      "results also indicate that the proposed methods using sub-graph training\n",
      "strategy are more efficient as compared to prior approaches.\n",
      "\n",
      "    \n",
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  For many applications the collection of labeled data is expensive laborious.\n",
      "Exploitation of unlabeled data during training is thus a long pursued objective\n",
      "of machine learning. Self-supervised learning addresses this by positing an\n",
      "auxiliary task (different, but related to the supervised task) for which data\n",
      "is abundantly available. In this paper, we show how ranking can be used as a\n",
      "proxy task for some regression problems. As another contribution, we propose an\n",
      "efficient backpropagation technique for Siamese networks which prevents the\n",
      "redundant computation introduced by the multi-branch network architecture. We\n",
      "apply our framework to two regression problems: Image Quality Assessment (IQA)\n",
      "and Crowd Counting. For both we show how to automatically generate ranked image\n",
      "sets from unlabeled data. Our results show that networks trained to regress to\n",
      "the ground truth targets for labeled data and to simultaneously learn to rank\n",
      "unlabeled data obtain significantly better, state-of-the-art results for both\n",
      "IQA and crowd counting. In addition, we show that measuring network uncertainty\n",
      "on the self-supervised proxy task is a good measure of informativeness of\n",
      "unlabeled data. This can be used to drive an algorithm for active learning and\n",
      "we show that this reduces labeling effort by up to 50%.\n",
      "\n",
      "    \n",
      "157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The rise of graph-structured data such as social networks, regulatory\n",
      "networks, citation graphs, and functional brain networks, in combination with\n",
      "resounding success of deep learning in various applications, has brought the\n",
      "interest in generalizing deep learning models to non-Euclidean domains. In this\n",
      "paper, we introduce a new spectral domain convolutional architecture for deep\n",
      "learning on graphs. The core ingredient of our model is a new class of\n",
      "parametric rational complex functions (Cayley polynomials) allowing to\n",
      "efficiently compute spectral filters on graphs that specialize on frequency\n",
      "bands of interest. Our model generates rich spectral filters that are localized\n",
      "in space, scales linearly with the size of the input data for\n",
      "sparsely-connected graphs, and can handle different constructions of Laplacian\n",
      "operators. Extensive experimental results show the superior performance of our\n",
      "approach, in comparison to other spectral domain convolutional architectures,\n",
      "on spectral image classification, community detection, vertex classification\n",
      "and matrix completion tasks.\n",
      "\n",
      "    \n",
      "158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to predict depth from a single image - using recent advances in\n",
      "CNNs - is of increasing interest to the vision community. Unsupervised\n",
      "strategies to learning are particularly appealing as they can utilize much\n",
      "larger and varied monocular video datasets during learning without the need for\n",
      "ground truth depth or stereo. In previous works, separate pose and depth CNN\n",
      "predictors had to be determined such that their joint outputs minimized the\n",
      "photometric error. Inspired by recent advances in direct visual odometry (DVO),\n",
      "we argue that the depth CNN predictor can be learned without a pose CNN\n",
      "predictor. Further, we demonstrate empirically that incorporation of a\n",
      "differentiable implementation of DVO, along with a novel depth normalization\n",
      "strategy - substantially improves performance over state of the art that use\n",
      "monocular videos for training.\n",
      "\n",
      "    \n",
      "159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning to predict scene depth from RGB inputs is a challenging task both\n",
      "for indoor and outdoor robot navigation. In this work we address unsupervised\n",
      "learning of scene depth and robot ego-motion where supervision is provided by\n",
      "monocular videos, as cameras are the cheapest, least restrictive and most\n",
      "ubiquitous sensor for robotics.\n",
      "Previous work in unsupervised image-to-depth learning has established strong\n",
      "baselines in the domain. We propose a novel approach which produces higher\n",
      "quality results, is able to model moving objects and is shown to transfer\n",
      "across data domains, e.g. from outdoors to indoor scenes. The main idea is to\n",
      "introduce geometric structure in the learning process, by modeling the scene\n",
      "and the individual objects; camera ego-motion and object motions are learned\n",
      "from monocular videos as input. Furthermore an online refinement method is\n",
      "introduced to adapt learning on the fly to unknown domains.\n",
      "The proposed approach outperforms all state-of-the-art approaches, including\n",
      "those that handle motion e.g. through learned flow. Our results are comparable\n",
      "in quality to the ones which used stereo as supervision and significantly\n",
      "improve depth prediction on scenes and datasets which contain a lot of object\n",
      "motion. The approach is of practical relevance, as it allows transfer across\n",
      "environments, by transferring models trained on data collected for robot\n",
      "navigation in urban scenes to indoor navigation settings. The code associated\n",
      "with this paper can be found at this https URL.\n",
      "\n",
      "    \n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Planning has been very successful for control tasks with known environment\n",
      "dynamics. To leverage planning in unknown environments, the agent needs to\n",
      "learn the dynamics from interactions with the world. However, learning dynamics\n",
      "models that are accurate enough for planning has been a long-standing\n",
      "challenge, especially in image-based domains. We propose the Deep Planning\n",
      "Network (PlaNet), a purely model-based agent that learns the environment\n",
      "dynamics from images and chooses actions through fast online planning in latent\n",
      "space. To achieve high performance, the dynamics model must accurately predict\n",
      "the rewards ahead for multiple time steps. We approach this using a latent\n",
      "dynamics model with both deterministic and stochastic transition components.\n",
      "Moreover, we propose a multi-step variational inference objective that we name\n",
      "latent overshooting. Using only pixel observations, our agent solves continuous\n",
      "control tasks with contact dynamics, partial observability, and sparse rewards,\n",
      "which exceed the difficulty of tasks that were previously solved by planning\n",
      "with learned models. PlaNet uses substantially fewer episodes and reaches final\n",
      "performance close to and sometimes higher than strong model-free algorithms.\n",
      "\n",
      "    \n",
      "161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The task of estimating the fundamental frequency of a monophonic sound\n",
      "recording, also known as pitch tracking, is fundamental to audio processing\n",
      "with multiple applications in speech processing and music information\n",
      "retrieval. To date, the best performing techniques, such as the pYIN algorithm,\n",
      "are based on a combination of DSP pipelines and heuristics. While such\n",
      "techniques perform very well on average, there remain many cases in which they\n",
      "fail to correctly estimate the pitch. In this paper, we propose a data-driven\n",
      "pitch tracking algorithm, CREPE, which is based on a deep convolutional neural\n",
      "network that operates directly on the time-domain waveform. We show that the\n",
      "proposed model produces state-of-the-art results, performing equally or better\n",
      "than pYIN. Furthermore, we evaluate the model's generalizability in terms of\n",
      "noise robustness. A pre-trained version of CREPE is made freely available as an\n",
      "open-source Python module for easy application.\n",
      "\n",
      "    \n",
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has shown that the end-to-end approach using convolutional neural\n",
      "network (CNN) is effective in various types of machine learning tasks. For\n",
      "audio signals, the approach takes raw waveforms as input using an 1-D\n",
      "convolution layer. In this paper, we improve the 1-D CNN architecture for music\n",
      "auto-tagging by adopting building blocks from state-of-the-art image\n",
      "classification models, ResNets and SENets, and adding multi-level feature\n",
      "aggregation to it. We compare different combinations of the modules in building\n",
      "CNN architectures. The results show that they achieve significant improvements\n",
      "over previous state-of-the-art models on the MagnaTagATune dataset and\n",
      "comparable results on Million Song Dataset. Furthermore, we analyze and\n",
      "visualize our model to show how the 1-D CNN operates.\n",
      "\n",
      "    \n",
      "163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most of the currently successful source separation techniques use the\n",
      "magnitude spectrogram as input, and are therefore by default omitting part of\n",
      "the signal: the phase. To avoid omitting potentially useful information, we\n",
      "study the viability of using end-to-end models for music source separation ---\n",
      "which take into account all the information available in the raw audio signal,\n",
      "including the phase. Although during the last decades end-to-end music source\n",
      "separation has been considered almost unattainable, our results confirm that\n",
      "waveform-based models can perform similarly (if not better) than a\n",
      "spectrogram-based deep learning model. Namely: a Wavenet-based model we propose\n",
      "and Wave-U-Net can outperform DeepConvSep, a recent spectrogram-based deep\n",
      "learning model.\n",
      "\n",
      "    \n",
      "164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a convolutional recurrent neural network (CRNN) for music\n",
      "tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local\n",
      "feature extraction and recurrent neural networks for temporal summarisation of\n",
      "the extracted features. We compare CRNN with three CNN structures that have\n",
      "been used for music tagging while controlling the number of parameters with\n",
      "respect to their performance and training time per sample. Overall, we found\n",
      "that CRNNs show a strong performance with respect to the number of parameter\n",
      "and training time, indicating the effectiveness of its hybrid structure in\n",
      "music feature extraction and feature summarisation.\n",
      "\n",
      "    \n",
      "165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In many machine learning applications, labeled data is scarce and obtaining\n",
      "more labels is expensive. We introduce a new approach to supervising neural\n",
      "networks by specifying constraints that should hold over the output space,\n",
      "rather than direct examples of input-output pairs. These constraints are\n",
      "derived from prior domain knowledge, e.g., from known laws of physics. We\n",
      "demonstrate the effectiveness of this approach on real world and simulated\n",
      "computer vision tasks. We are able to train a convolutional neural network to\n",
      "detect and track objects without any labeled examples. Our approach can\n",
      "significantly reduce the need for labeled training data, but introduces new\n",
      "challenges for encoding prior knowledge into appropriate loss functions.\n",
      "\n",
      "    \n",
      "166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\n",
      "that leads to a false sense of security in defenses against adversarial\n",
      "examples. While defenses that cause obfuscated gradients appear to defeat\n",
      "iterative optimization-based attacks, we find defenses relying on this effect\n",
      "can be circumvented. We describe characteristic behaviors of defenses\n",
      "exhibiting the effect, and for each of the three types of obfuscated gradients\n",
      "we discover, we develop attack techniques to overcome it. In a case study,\n",
      "examining non-certified white-box-secure defenses at ICLR 2018, we find\n",
      "obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on\n",
      "obfuscated gradients. Our new attacks successfully circumvent 6 completely, and\n",
      "1 partially, in the original threat model each paper considers.\n",
      "\n",
      "    \n",
      "167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Motivated by applications in declarative data analysis, we study\n",
      "$\\mathit{Datalog}_{\\mathbb{Z}}$---an extension of positive Datalog with\n",
      "arithmetic functions over integers. This language is known to be undecidable,\n",
      "so we propose two fragments. In $\\mathit{limit}~\\mathit{Datalog}_{\\mathbb{Z}}$\n",
      "predicates are axiomatised to keep minimal/maximal numeric values, allowing us\n",
      "to show that fact entailment is coNExpTime-complete in combined, and\n",
      "coNP-complete in data complexity. Moreover, an additional $\\mathit{stability}$\n",
      "requirement causes the complexity to drop to ExpTime and PTime, respectively.\n",
      "Finally, we show that stable $\\mathit{Datalog}_{\\mathbb{Z}}$ can express many\n",
      "useful data analysis tasks, and so our results provide a sound foundation for\n",
      "the development of advanced information systems.\n",
      "\n",
      "    \n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Although recent work in AI has made great progress in solving large,\n",
      "zero-sum, extensive-form games, the underlying assumption in most past work is\n",
      "that the parameters of the game itself are known to the agents. This paper\n",
      "deals with the relatively under-explored but equally important \"inverse\"\n",
      "setting, where the parameters of the underlying game are not known to all\n",
      "agents, but must be learned through observations. We propose a differentiable,\n",
      "end-to-end learning framework for addressing this task. In particular, we\n",
      "consider a regularized version of the game, equivalent to a particular form of\n",
      "quantal response equilibrium, and develop 1) a primal-dual Newton method for\n",
      "finding such equilibrium points in both normal and extensive form games; and 2)\n",
      "a backpropagation method that lets us analytically compute gradients of all\n",
      "relevant game parameters through the solution itself. This ultimately lets us\n",
      "learn the game by training in an end-to-end fashion, effectively by integrating\n",
      "a \"differentiable game solver\" into the loop of larger deep network\n",
      "architectures. We demonstrate the effectiveness of the learning method in\n",
      "several settings including poker and security game tasks.\n",
      "\n",
      "    \n",
      "174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In imperfect-information games, the optimal strategy in a subgame may depend\n",
      "on the strategy in other, unreached subgames. Thus a subgame cannot be solved\n",
      "in isolation and must instead consider the strategy for the entire game as a\n",
      "whole, unlike perfect-information games. Nevertheless, it is possible to first\n",
      "approximate a solution for the whole game and then improve it by solving\n",
      "individual subgames. This is referred to as subgame solving. We introduce\n",
      "subgame-solving techniques that outperform prior methods both in theory and\n",
      "practice. We also show how to adapt them, and past subgame-solving techniques,\n",
      "to respond to opponent actions that are outside the original action\n",
      "abstraction; this significantly outperforms the prior state-of-the-art\n",
      "approach, action translation. Finally, we show that subgame solving can be\n",
      "repeated as the game progresses down the game tree, leading to far lower\n",
      "exploitability. These techniques were a key component of Libratus, the first AI\n",
      "to defeat top humans in heads-up no-limit Texas hold'em poker.\n",
      "\n",
      "    \n",
      "175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We prove that $\\tilde{\\Theta}(k d^2 / \\varepsilon^2)$ samples are necessary\n",
      "and sufficient for learning a mixture of $k$ Gaussians in $\\mathbb{R}^d$, up to\n",
      "error $\\varepsilon$ in total variation distance. This improves both the known\n",
      "upper bounds and lower bounds for this problem. For mixtures of axis-aligned\n",
      "Gaussians, we show that $\\tilde{O}(k d / \\varepsilon^2)$ samples suffice,\n",
      "matching a known lower bound. Moreover, these results hold in the\n",
      "agnostic-learning/robust-estimation setting as well, where the target\n",
      "distribution is only approximately a mixture of Gaussians.\n",
      "The upper bound is shown using a novel technique for distribution learning\n",
      "based on a notion of `compression.' Any class of distributions that allows such\n",
      "a compression scheme can also be learned with few samples. Moreover, if a class\n",
      "of distributions has such a compression scheme, then so do the classes of\n",
      "products and mixtures of those distributions. The core of our main result is\n",
      "showing that the class of Gaussians in $\\mathbb{R}^d$ admits a small-sized\n",
      "compression scheme.\n",
      "\n",
      "    \n",
      "176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents an efficient binarized algorithm for both learning and\n",
      "classification of human epileptic seizures from intracranial\n",
      "electroencephalography (iEEG). The algorithm combines local binary patterns\n",
      "with brain-inspired hyperdimensional computing to enable end-to-end learning\n",
      "and inference with binary operations. The algorithm first transforms iEEG time\n",
      "series from each electrode into local binary pattern codes. Then atomic\n",
      "high-dimensional binary vectors are used to construct composite representations\n",
      "of seizures across all electrodes. For the majority of our patients (10 out of\n",
      "16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot\n",
      "learning) and perfectly generalizes on 27 further seizures. For other patients,\n",
      "the algorithm requires three to six seizures for learning. Overall, our\n",
      "algorithm surpasses the state-of-the-art methods for detecting 65 novel\n",
      "seizures with higher specificity and sensitivity, and lower memory footprint.\n",
      "\n",
      "    \n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jhu.pure.elsevier.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'papers.nips.cc'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "183\n",
      "It is pdf\n",
      "184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ncbi.nlm.nih.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pubmed.ncbi.nlm.nih.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'papers.nips.cc'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of\n",
      "data in human-interactive systems. While implicit feedback has many advantages\n",
      "(e.g., it is inexpensive to collect, user centric, and timely), its inherent\n",
      "biases are a key obstacle to its effective use. For example, position bias in\n",
      "search rankings strongly influences how many clicks a result receives, so that\n",
      "directly using click data as a training signal in Learning-to-Rank (LTR)\n",
      "methods yields sub-optimal results. To overcome this bias problem, we present a\n",
      "counterfactual inference framework that provides the theoretical basis for\n",
      "unbiased LTR via Empirical Risk Minimization despite biased data. Using this\n",
      "framework, we derive a Propensity-Weighted Ranking SVM for discriminative\n",
      "learning from implicit feedback, where click models take the role of the\n",
      "propensity estimator. In contrast to most conventional approaches to de-bias\n",
      "the data using click models, this allows training of ranking functions even in\n",
      "settings where queries do not repeat. Beyond the theoretical support, we show\n",
      "empirically that the proposed learning method is highly effective in dealing\n",
      "with biases, that it is robust to noise and propensity model misspecification,\n",
      "and that it scales efficiently. We also demonstrate the real-world\n",
      "applicability of our approach on an operational search engine, where it\n",
      "substantially improves retrieval performance.\n",
      "\n",
      "    \n",
      "187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cs.ru.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'danluu.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Existing region-based object detectors are limited to regions with fixed box\n",
      "geometry to represent objects, even if those are highly non-rectangular. In\n",
      "this paper we introduce DP-FCN, a deep model for object detection which\n",
      "explicitly adapts to shapes of objects with deformable parts. Without\n",
      "additional annotations, it learns to focus on discriminative elements and to\n",
      "align them, and simultaneously brings more invariance for classification and\n",
      "geometric information to refine localization. DP-FCN is composed of three main\n",
      "modules: a Fully Convolutional Network to efficiently maintain spatial\n",
      "resolution, a deformable part-based RoI pooling layer to optimize positions of\n",
      "parts and build invariance, and a deformation-aware localization module\n",
      "explicitly exploiting displacements of parts to improve accuracy of bounding\n",
      "box regression. We experimentally validate our model and show significant\n",
      "gains. DP-FCN achieves state-of-the-art performances of 83.1% and 80.9% on\n",
      "PASCAL VOC 2007 and 2012 with VOC data only.\n",
      "\n",
      "    \n",
      "193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work we present a novel compact scene representation based on Stixels\n",
      "that infers geometric and semantic information. Our approach overcomes the\n",
      "previous rather restrictive geometric assumptions for Stixels by introducing a\n",
      "novel depth model to account for non-flat roads and slanted objects. Both\n",
      "semantic and depth cues are used jointly to infer the scene representation in a\n",
      "sound global energy minimization formulation. Furthermore, a novel\n",
      "approximation scheme is introduced that uses an extremely efficient\n",
      "over-segmentation. In doing so, the computational complexity of the Stixel\n",
      "inference algorithm is reduced significantly, achieving real-time computation\n",
      "capabilities with only a slight drop in accuracy. We evaluate the proposed\n",
      "approach in terms of semantic and geometric accuracy as well as run-time on\n",
      "four publicly available benchmark datasets. Our approach maintains accuracy on\n",
      "flat road scene datasets while improving substantially on a novel non-flat road\n",
      "dataset.\n",
      "\n",
      "    \n",
      "194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Do visual tasks have a relationship, or are they unrelated? For instance,\n",
      "could having surface normals simplify estimating the depth of an image?\n",
      "Intuition answers these questions positively, implying existence of a structure\n",
      "among visual tasks. Knowing this structure has notable values; it is the\n",
      "concept underlying transfer learning and provides a principled way for\n",
      "identifying redundancies across tasks, e.g., to seamlessly reuse supervision\n",
      "among related tasks or solve many tasks in one system without piling up the\n",
      "complexity.\n",
      "We proposes a fully computational approach for modeling the structure of\n",
      "space of visual tasks. This is done via finding (first and higher-order)\n",
      "transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\n",
      "and semantic tasks in a latent space. The product is a computational taxonomic\n",
      "map for task transfer learning. We study the consequences of this structure,\n",
      "e.g. nontrivial emerged relationships, and exploit them to reduce the demand\n",
      "for labeled data. For example, we show that the total number of labeled\n",
      "datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\n",
      "(compared to training independently) while keeping the performance nearly the\n",
      "same. We provide a set of tools for computing and probing this taxonomical\n",
      "structure including a solver that users can employ to devise efficient\n",
      "supervision policies for their use cases.\n",
      "\n",
      "    \n",
      "195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a real-time RGB-based pipeline for object detection and 6D pose\n",
      "estimation. Our novel 3D orientation estimation is based on a variant of the\n",
      "Denoising Autoencoder that is trained on simulated views of a 3D model using\n",
      "Domain Randomization. This so-called Augmented Autoencoder has several\n",
      "advantages over existing methods: It does not require real, pose-annotated\n",
      "training data, generalizes to various test sensors and inherently handles\n",
      "object and view symmetries. Instead of learning an explicit mapping from input\n",
      "images to object poses, it provides an implicit representation of object\n",
      "orientations defined by samples in a latent space. Our pipeline achieves\n",
      "state-of-the-art performance on the T-LESS dataset both in the RGB and RGB-D\n",
      "domain. We also evaluate on the LineMOD dataset where we can compete with other\n",
      "synthetically trained approaches. We further increase performance by correcting\n",
      "3D orientation estimates to account for perspective errors when the object\n",
      "deviates from the image center and show extended results.\n",
      "\n",
      "    \n",
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a conceptually simple, flexible, and general framework for object\n",
      "instance segmentation. Our approach efficiently detects objects in an image\n",
      "while simultaneously generating a high-quality segmentation mask for each\n",
      "instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a\n",
      "branch for predicting an object mask in parallel with the existing branch for\n",
      "bounding box recognition. Mask R-CNN is simple to train and adds only a small\n",
      "overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to\n",
      "generalize to other tasks, e.g., allowing us to estimate human poses in the\n",
      "same framework. We show top results in all three tracks of the COCO suite of\n",
      "challenges, including instance segmentation, bounding-box object detection, and\n",
      "person keypoint detection. Without bells and whistles, Mask R-CNN outperforms\n",
      "all existing, single-model entries on every task, including the COCO 2016\n",
      "challenge winners. We hope our simple and effective approach will serve as a\n",
      "solid baseline and help ease future research in instance-level recognition.\n",
      "Code has been made available at: this https URL\n",
      "\n",
      "198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'obj.umiacs.umd.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "199\n",
      "It is pdf\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  There are great demands for automatically regulating inappropriate appearance\n",
      "of shocking firearm images in social media or identifying firearm types in\n",
      "forensics. Image retrieval techniques have great potential to solve these\n",
      "problems. To facilitate research in this area, we introduce Firearm 14k, a\n",
      "large dataset consisting of over 14,000 images in 167 categories. It can be\n",
      "used for both fine-grained recognition and retrieval of firearm images. Recent\n",
      "advances in image retrieval are mainly driven by fine-tuning state-of-the-art\n",
      "convolutional neural networks for retrieval task. The conventional single\n",
      "margin contrastive loss, known for its simplicity and good performance, has\n",
      "been widely used. We find that it performs poorly on the Firearm 14k dataset\n",
      "due to: (1) Loss contributed by positive and negative image pairs is unbalanced\n",
      "during training process. (2) A huge domain gap exists between this dataset and\n",
      "ImageNet. We propose to deal with the unbalanced loss by employing a double\n",
      "margin contrastive loss. We tackle the domain gap issue with a two-stage\n",
      "training strategy, where we first fine-tune the network for classification, and\n",
      "then fine-tune it for retrieval. Experimental results show that our approach\n",
      "outperforms the conventional single margin approach by a large margin (up to\n",
      "88.5% relative improvement) and even surpasses the strong triplet-loss-based\n",
      "approach.\n",
      "\n",
      "    \n",
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNN) have been successfully applied to\n",
      "autonomous driving tasks, many in an end-to-end manner. Previous end-to-end\n",
      "steering control methods take an image or an image sequence as the input and\n",
      "directly predict the steering angle with CNN. Although single task learning on\n",
      "steering angles has reported good performances, the steering angle alone is not\n",
      "sufficient for vehicle control. In this work, we propose a multi-task learning\n",
      "framework to predict the steering angle and speed control simultaneously in an\n",
      "end-to-end manner. Since it is nontrivial to predict accurate speed values with\n",
      "only visual inputs, we first propose a network to predict discrete speed\n",
      "commands and steering angles with image sequences. Moreover, we propose a\n",
      "multi-modal multi-task network to predict speed values and steering angles by\n",
      "taking previous feedback speeds and visual recordings as inputs. Experiments\n",
      "are conducted on the public Udacity dataset and a newly collected SAIC dataset.\n",
      "Results show that the proposed model predicts steering angles and speed values\n",
      "accurately. Furthermore, we improve the failure data synthesis methods to solve\n",
      "the problem of error accumulation in real road tests.\n",
      "\n",
      "    \n",
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'priba.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a novel method to reconstruct a fluid's 3D density and motion\n",
      "based on just a single sequence of images. This is rendered possible by using\n",
      "powerful physical priors for this strongly under-determined problem. More\n",
      "specifically, we propose a novel strategy to infer density updates strongly\n",
      "coupled to previous and current estimates of the flow motion. Additionally, we\n",
      "employ an accurate discretization and depth-based regularizers to compute\n",
      "stable solutions. Using only one view for the reconstruction reduces the\n",
      "complexity of the capturing setup drastically and could even allow for online\n",
      "video databases or smart-phone videos as inputs. The reconstructed 3D velocity\n",
      "can then be flexibly utilized, e.g., for re-simulation, domain modification or\n",
      "guiding purposes. We will demonstrate the capacity of our method with a series\n",
      "of synthetic test cases and the reconstruction of real smoke plumes captured\n",
      "with a Raspberry Pi camera.\n",
      "\n",
      "    \n",
      "210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We show that the gradient descent algorithm provides an implicit\n",
      "regularization effect in the learning of over-parameterized matrix\n",
      "factorization models and one-hidden-layer neural networks with quadratic\n",
      "activations. Concretely, we show that given $\\tilde{O}(dr^{2})$ random linear\n",
      "measurements of a rank $r$ positive semidefinite matrix $X^{\\star}$, we can\n",
      "recover $X^{\\star}$ by parameterizing it by $UU^\\top$ with $U\\in \\mathbb\n",
      "R^{d\\times d}$ and minimizing the squared loss, even if $r \\ll d$. We prove\n",
      "that starting from a small initialization, gradient descent recovers\n",
      "$X^{\\star}$ in $\\tilde{O}(\\sqrt{r})$ iterations approximately. The results\n",
      "solve the conjecture of Gunasekar et al.'17 under the restricted isometry\n",
      "property. The technique can be applied to analyzing neural networks with\n",
      "one-hidden-layer quadratic activations with some technical modifications.\n",
      "\n",
      "    \n",
      "211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for\n",
      "non-convex optimization. The algorithm performs stochastic gradient descent,\n",
      "where in each step it injects appropriately scaled Gaussian noise to the\n",
      "update. We analyze the algorithm's hitting time to an arbitrary subset of the\n",
      "parameter space. Two results follow from our general theory: First, we prove\n",
      "that for empirical risk minimization, if the empirical risk is point-wise close\n",
      "to the (smooth) population risk, then the algorithm achieves an approximate\n",
      "local minimum of the population risk in polynomial time, escaping suboptimal\n",
      "local minima that only exist in the empirical risk. Second, we show that SGLD\n",
      "improves on one of the best known learnability results for learning linear\n",
      "classifiers under the zero-one loss.\n",
      "\n",
      "    \n",
      "212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Fairness in machine learning has predominantly been studied in static\n",
      "classification settings without concern for how decisions change the underlying\n",
      "population over time. Conventional wisdom suggests that fairness criteria\n",
      "promote the long-term well-being of those groups they aim to protect.\n",
      "We study how static fairness criteria interact with temporal indicators of\n",
      "well-being, such as long-term improvement, stagnation, and decline in a\n",
      "variable of interest. We demonstrate that even in a one-step feedback model,\n",
      "common fairness criteria in general do not promote improvement over time, and\n",
      "may in fact cause harm in cases where an unconstrained objective would not.\n",
      "We completely characterize the delayed impact of three standard criteria,\n",
      "contrasting the regimes in which these exhibit qualitatively different\n",
      "behavior. In addition, we find that a natural form of measurement error\n",
      "broadens the regime in which fairness criteria perform favorably.\n",
      "Our results highlight the importance of measurement and temporal modeling in\n",
      "the evaluation of fairness criteria, suggesting a range of new challenges and\n",
      "trade-offs.\n",
      "\n",
      "    \n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ijcai.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we consider the distributed optimization of non-smooth convex\n",
      "functions using a network of computing units. We investigate this problem under\n",
      "two regularity assumptions: (1) the Lipschitz continuity of the global\n",
      "objective function, and (2) the Lipschitz continuity of local individual\n",
      "functions. Under the local regularity assumption, we provide the first optimal\n",
      "first-order decentralized algorithm called multi-step primal-dual (MSPD) and\n",
      "its corresponding optimal convergence rate. A notable aspect of this result is\n",
      "that, for non-smooth functions, while the dominant term of the error is in\n",
      "$O(1/\\sqrt{t})$, the structure of the communication network only impacts a\n",
      "second-order term in $O(1/t)$, where $t$ is time. In other words, the error due\n",
      "to limits in communication resources decreases at a fast rate even in the case\n",
      "of non-strongly-convex objective functions. Under the global regularity\n",
      "assumption, we provide a simple yet efficient algorithm called distributed\n",
      "randomized smoothing (DRS) based on a local smoothing of the objective\n",
      "function, and show that DRS is within a $d^{1/4}$ multiplicative factor of the\n",
      "optimal convergence rate, where $d$ is the underlying dimension.\n",
      "\n",
      "    \n",
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new family of deep neural network models. Instead of\n",
      "specifying a discrete sequence of hidden layers, we parameterize the derivative\n",
      "of the hidden state using a neural network. The output of the network is\n",
      "computed using a black-box differential equation solver. These continuous-depth\n",
      "models have constant memory cost, adapt their evaluation strategy to each\n",
      "input, and can explicitly trade numerical precision for speed. We demonstrate\n",
      "these properties in continuous-depth residual networks and continuous-time\n",
      "latent variable models. We also construct continuous normalizing flows, a\n",
      "generative model that can train by maximum likelihood, without partitioning or\n",
      "ordering the data dimensions. For training, we show how to scalably\n",
      "backpropagate through any ODE solver, without access to its internal\n",
      "operations. This allows end-to-end training of ODEs within larger models.\n",
      "\n",
      "    \n",
      "216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'sreal.ucf.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "217\n",
      "It is pdf\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.cse.ust.hk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.sciencedirect.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "222\n",
      "It is pdf\n",
      "223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.sciencedirect.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ri.cmu.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "234\n",
      "It is pdf\n",
      "235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.researchgate.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ucl.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.matec-conferences.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "244\n",
      "It is pdf\n",
      "245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.researchgate.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'waset.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'publications.waset.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we take a fresh look at some old and new algorithms for\n",
      "off-policy, return-based reinforcement learning. Expressing these in a common\n",
      "form, we derive a novel algorithm, Retrace($\\lambda$), with three desired\n",
      "properties: (1) it has low variance; (2) it safely uses samples collected from\n",
      "any behaviour policy, whatever its degree of \"off-policyness\"; and (3) it is\n",
      "efficient as it makes the best use of samples collected from near on-policy\n",
      "behaviour policies. We analyze the contractive nature of the related operator\n",
      "under both off-policy policy evaluation and control settings and derive online\n",
      "sample-based algorithms. We believe this is the first return-based off-policy\n",
      "control algorithm converging a.s. to $Q^*$ without the GLIE assumption (Greedy\n",
      "in the Limit with Infinite Exploration). As a corollary, we prove the\n",
      "convergence of Watkins' Q($\\lambda$), which was an open problem since 1989. We\n",
      "illustrate the benefits of Retrace($\\lambda$) on a standard suite of Atari 2600\n",
      "games.\n",
      "\n",
      "    \n",
      "247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State of the art deep reinforcement learning algorithms take many millions of\n",
      "interactions to attain human-level performance. Humans, on the other hand, can\n",
      "very quickly exploit highly rewarding nuances of an environment upon first\n",
      "discovery. In the brain, such rapid learning is thought to depend on the\n",
      "hippocampus and its capacity for episodic memory. Here we investigate whether a\n",
      "simple model of hippocampal episodic control can learn to solve difficult\n",
      "sequential decision-making tasks. We demonstrate that it not only attains a\n",
      "highly rewarding strategy significantly faster than state-of-the-art deep\n",
      "reinforcement learning algorithms, but also achieves a higher overall reward on\n",
      "some of the more challenging domains.\n",
      "\n",
      "    \n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning robust value functions given raw observations and rewards is now\n",
      "possible with model-free and model-based deep reinforcement learning\n",
      "algorithms. There is a third alternative, called Successor Representations\n",
      "(SR), which decomposes the value function into two components -- a reward\n",
      "predictor and a successor map. The successor map represents the expected future\n",
      "state occupancy from any given state and the reward predictor maps states to\n",
      "scalar rewards. The value function of a state can be computed as the inner\n",
      "product between the successor map and the reward weights. In this paper, we\n",
      "present DSR, which generalizes SR within an end-to-end deep reinforcement\n",
      "learning framework. DSR has several appealing properties including: increased\n",
      "sensitivity to distal reward changes due to factorization of reward and world\n",
      "dynamics, and the ability to extract bottleneck states (subgoals) given\n",
      "successor maps trained under a random policy. We show the efficacy of our\n",
      "approach on two diverse environments given raw pixel observations -- simple\n",
      "grid-world domains (MazeBase) and the Doom game engine.\n",
      "\n",
      "    \n",
      "249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider an agent's uncertainty about its environment and the problem of\n",
      "generalizing this uncertainty across observations. Specifically, we focus on\n",
      "the problem of exploration in non-tabular reinforcement learning. Drawing\n",
      "inspiration from the intrinsic motivation literature, we use density models to\n",
      "measure uncertainty, and propose a novel algorithm for deriving a pseudo-count\n",
      "from an arbitrary density model. This technique enables us to generalize\n",
      "count-based exploration algorithms to the non-tabular case. We apply our ideas\n",
      "to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We\n",
      "transform these pseudo-counts into intrinsic rewards and obtain significantly\n",
      "improved exploration in a number of hard games, including the infamously\n",
      "difficult Montezuma's Revenge.\n",
      "\n",
      "    \n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Partially observed control problems are a challenging aspect of reinforcement\n",
      "learning. We extend two related, model-free algorithms for continuous control\n",
      "-- deterministic policy gradient and stochastic value gradient -- to solve\n",
      "partially observed domains using recurrent neural networks trained with\n",
      "backpropagation through time.\n",
      "We demonstrate that this approach, coupled with long-short term memory is\n",
      "able to solve a variety of physical control problems exhibiting an assortment\n",
      "of memory requirements. These include the short-term integration of information\n",
      "from noisy sensors and the identification of system parameters, as well as\n",
      "long-term memory problems that require preserving information over many time\n",
      "steps. We also demonstrate success on a combined exploration and memory problem\n",
      "in the form of a simplified version of the well-known Morris water maze task.\n",
      "Finally, we show that our approach can deal with high-dimensional observations\n",
      "by learning directly from pixels.\n",
      "We find that recurrent deterministic and stochastic policies are able to\n",
      "learn similarly good solutions to these tasks, including the water maze where\n",
      "the agent must learn effective search strategies.\n",
      "\n",
      "    \n",
      "251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we introduce a new set of reinforcement learning (RL) tasks in\n",
      "Minecraft (a flexible 3D world). We then use these tasks to systematically\n",
      "compare and contrast existing deep reinforcement learning (DRL) architectures\n",
      "with our new memory-based DRL architectures. These tasks are designed to\n",
      "emphasize, in a controllable manner, issues that pose challenges for RL methods\n",
      "including partial observability (due to first-person visual observations),\n",
      "delayed rewards, high-dimensional visual observations, and the need to use\n",
      "active perception in a correct manner so as to perform well in the tasks. While\n",
      "these tasks are conceptually simple to describe, by virtue of having all of\n",
      "these challenges simultaneously they are difficult for current DRL\n",
      "architectures. Additionally, we evaluate the generalization performance of the\n",
      "architectures on environments not used during training. The experimental\n",
      "results show that our new architectures generalize to unseen environments\n",
      "better than existing DRL architectures.\n",
      "\n",
      "    \n",
      "252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Reinforcement Learning methods have achieved state of the art\n",
      "performance in learning control policies for the games in the Atari 2600\n",
      "domain. One of the important parameters in the Arcade Learning Environment\n",
      "(ALE) is the frame skip rate. It decides the granularity at which agents can\n",
      "control game play. A frame skip value of $k$ allows the agent to repeat a\n",
      "selected action $k$ number of times. The current state of the art architectures\n",
      "like Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of\n",
      "a framework with a static frame skip rate, where the action output from the\n",
      "network is repeated for a fixed number of frames regardless of the current\n",
      "state. In this paper, we propose a new architecture, Dynamic Frame skip Deep\n",
      "Q-Network (DFDQN) which makes the frame skip rate a dynamic learnable\n",
      "parameter. This allows us to choose the number of times an action is to be\n",
      "repeated based on the current state. We show empirically that such a setting\n",
      "improves the performance on relatively harder games like Seaquest.\n",
      "\n",
      "    \n",
      "253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces an automated skill acquisition framework in\n",
      "reinforcement learning which involves identifying a hierarchical description of\n",
      "the given task in terms of abstract states and extended actions between\n",
      "abstract states. Identifying such structures present in the task provides ways\n",
      "to simplify and speed up reinforcement learning algorithms. These structures\n",
      "also help to generalize such algorithms over multiple tasks without relearning\n",
      "policies from scratch. We use ideas from dynamical systems to find metastable\n",
      "regions in the state space and associate them with abstract states. The\n",
      "spectral clustering algorithm PCCA+ is used to identify suitable abstractions\n",
      "aligned to the underlying structure. Skills are defined in terms of the\n",
      "sequence of actions that lead to transitions between such abstract states. The\n",
      "connectivity information from PCCA+ is used to generate these skills or\n",
      "options. These skills are independent of the learning task and can be\n",
      "efficiently reused across a variety of tasks defined over the same model. This\n",
      "approach works well even without the exact model of the environment by using\n",
      "sample trajectories to construct an approximate estimate. We also present our\n",
      "approach to scaling the skill acquisition framework to complex tasks with large\n",
      "state spaces for which we perform state aggregation using the representation\n",
      "learned from an action conditional video prediction network and use the skill\n",
      "acquisition framework on the aggregated state space.\n",
      "\n",
      "    \n",
      "254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recently, researchers have made significant progress combining the advances\n",
      "in deep learning for learning feature representations with reinforcement\n",
      "learning. Some notable examples include training agents to play Atari games\n",
      "based on raw pixel data and to acquire advanced manipulation skills using raw\n",
      "sensory inputs. However, it has been difficult to quantify progress in the\n",
      "domain of continuous control due to the lack of a commonly adopted benchmark.\n",
      "In this work, we present a benchmark suite of continuous control tasks,\n",
      "including classic tasks like cart-pole swing-up, tasks with very high state and\n",
      "action dimensionality such as 3D humanoid locomotion, tasks with partial\n",
      "observations, and tasks with hierarchical structure. We report novel findings\n",
      "based on the systematic evaluation of a range of implemented reinforcement\n",
      "learning algorithms. Both the benchmark and reference implementations are\n",
      "released at this https URL in order to facilitate experimental\n",
      "reproducibility and to encourage adoption by other researchers.\n",
      "\n",
      "    \n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning goal-directed behavior in environments with sparse feedback is a\n",
      "major challenge for reinforcement learning algorithms. The primary difficulty\n",
      "arises due to insufficient exploration, resulting in an agent being unable to\n",
      "learn robust value functions. Intrinsically motivated agents can explore new\n",
      "behavior for its own sake rather than to directly solve problems. Such\n",
      "intrinsic behaviors could eventually help the agent solve tasks posed by the\n",
      "environment. We present hierarchical-DQN (h-DQN), a framework to integrate\n",
      "hierarchical value functions, operating at different temporal scales, with\n",
      "intrinsically motivated deep reinforcement learning. A top-level value function\n",
      "learns a policy over intrinsic goals, and a lower-level function learns a\n",
      "policy over atomic actions to satisfy the given goals. h-DQN allows for\n",
      "flexible goal specifications, such as functions over entities and relations.\n",
      "This provides an efficient space for exploration in complicated environments.\n",
      "We demonstrate the strength of our approach on two problems with very sparse,\n",
      "delayed feedback: (1) a complex discrete stochastic decision process, and (2)\n",
      "the classic ATARI game `Montezuma's Revenge'.\n",
      "\n",
      "    \n",
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a learning-based approach to hand-eye coordination for robotic\n",
      "grasping from monocular images. To learn hand-eye coordination for grasping, we\n",
      "trained a large convolutional neural network to predict the probability that\n",
      "task-space motion of the gripper will result in successful grasps, using only\n",
      "monocular camera images and independently of camera calibration or the current\n",
      "robot pose. This requires the network to observe the spatial relationship\n",
      "between the gripper and objects in the scene, thus learning hand-eye\n",
      "coordination. We then use this network to servo the gripper in real time to\n",
      "achieve successful grasps. To train our network, we collected over 800,000\n",
      "grasp attempts over the course of two months, using between 6 and 14 robotic\n",
      "manipulators at any given time, with differences in camera placement and\n",
      "hardware. Our experimental evaluation demonstrates that our method achieves\n",
      "effective real-time control, can successfully grasp novel objects, and corrects\n",
      "mistakes by continuous servoing.\n",
      "\n",
      "    \n",
      "257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Model-free reinforcement learning has been successfully applied to a range of\n",
      "challenging problems, and has recently been extended to handle large neural\n",
      "network policies and value functions. However, the sample complexity of\n",
      "model-free algorithms, particularly when using high-dimensional function\n",
      "approximators, tends to limit their applicability to physical systems. In this\n",
      "paper, we explore algorithms and representations to reduce the sample\n",
      "complexity of deep reinforcement learning for continuous control tasks. We\n",
      "propose two complementary techniques for improving the efficiency of such\n",
      "algorithms. First, we derive a continuous variant of the Q-learning algorithm,\n",
      "which we call normalized adantage functions (NAF), as an alternative to the\n",
      "more commonly used policy gradient and actor-critic methods. NAF representation\n",
      "allows us to apply Q-learning with experience replay to continuous tasks, and\n",
      "substantially improves performance on a set of simulated robotic control tasks.\n",
      "To further improve the efficiency of our approach, we explore the use of\n",
      "learned models for accelerating model-free reinforcement learning. We show that\n",
      "iteratively refitted local linear models are especially effective for this, and\n",
      "demonstrate substantially faster learning on domains where such models are\n",
      "applicable.\n",
      "\n",
      "    \n",
      "258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Reinforcement learning can acquire complex behaviors from high-level\n",
      "specifications. However, defining a cost function that can be optimized\n",
      "effectively and encodes the correct task is challenging in practice. We explore\n",
      "how inverse optimal control (IOC) can be used to learn behaviors from\n",
      "demonstrations, with applications to torque control of high-dimensional robotic\n",
      "systems. Our method addresses two key challenges in inverse optimal control:\n",
      "first, the need for informative features and effective regularization to impose\n",
      "structure on the cost, and second, the difficulty of learning the cost function\n",
      "under unknown dynamics for high-dimensional continuous systems. To address the\n",
      "former challenge, we present an algorithm capable of learning arbitrary\n",
      "nonlinear cost functions, such as neural networks, without meticulous feature\n",
      "engineering. To address the latter challenge, we formulate an efficient\n",
      "sample-based approximation for MaxEnt IOC. We evaluate our method on a series\n",
      "of simulated tasks and real-world robotic manipulation problems, demonstrating\n",
      "substantial improvement over prior methods both in terms of task complexity and\n",
      "sample efficiency.\n",
      "\n",
      "    \n",
      "259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Efficient exploration in complex environments remains a major challenge for\n",
      "reinforcement learning. We propose bootstrapped DQN, a simple algorithm that\n",
      "explores in a computationally and statistically efficient manner through use of\n",
      "randomized value functions. Unlike dithering strategies such as epsilon-greedy\n",
      "exploration, bootstrapped DQN carries out temporally-extended (or deep)\n",
      "exploration; this can lead to exponentially faster learning. We demonstrate\n",
      "these benefits in complex stochastic MDPs and in the large-scale Arcade\n",
      "Learning Environment. Bootstrapped DQN substantially improves learning times\n",
      "and performance across most Atari games.\n",
      "\n",
      "    \n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce the value iteration network (VIN): a fully differentiable neural\n",
      "network with a `planning module' embedded within. VINs can learn to plan, and\n",
      "are suitable for predicting outcomes that involve planning-based reasoning,\n",
      "such as policies for reinforcement learning. Key to our approach is a novel\n",
      "differentiable approximation of the value-iteration algorithm, which can be\n",
      "represented as a convolutional neural network, and trained end-to-end using\n",
      "standard backpropagation. We evaluate VIN based policies on discrete and\n",
      "continuous path-planning domains, and on a natural-language based search task.\n",
      "We show that by learning an explicit planning computation, VIN policies\n",
      "generalize better to new, unseen domains.\n",
      "\n",
      "    \n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose deep distributed recurrent Q-networks (DDRQN), which enable teams\n",
      "of agents to learn to solve communication-based coordination tasks. In these\n",
      "tasks, the agents are not given any pre-designed communication protocol.\n",
      "Therefore, in order to successfully communicate, they must first automatically\n",
      "develop and agree upon their own communication protocol. We present empirical\n",
      "results on two multi-agent learning problems based on well-known riddles,\n",
      "demonstrating that DDRQN can successfully solve such tasks and discover elegant\n",
      "communication protocols to do so. To our knowledge, this is the first time deep\n",
      "reinforcement learning has succeeded in learning communication protocols. In\n",
      "addition, we present ablation experiments that confirm that each of the main\n",
      "components of the DDRQN architecture are critical to its success.\n",
      "\n",
      "    \n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a conceptually simple and lightweight framework for deep\n",
      "reinforcement learning that uses asynchronous gradient descent for optimization\n",
      "of deep neural network controllers. We present asynchronous variants of four\n",
      "standard reinforcement learning algorithms and show that parallel\n",
      "actor-learners have a stabilizing effect on training allowing all four methods\n",
      "to successfully train neural network controllers. The best performing method,\n",
      "an asynchronous variant of actor-critic, surpasses the current state-of-the-art\n",
      "on the Atari domain while training for half the time on a single multi-core CPU\n",
      "instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds\n",
      "on a wide variety of continuous motor control problems as well as on a new task\n",
      "of navigating random 3D mazes using a visual input.\n",
      "\n",
      "    \n",
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.nature.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'idp.nature.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'idp.nature.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.nature.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces new optimality-preserving operators on Q-functions. We\n",
      "first describe an operator for tabular representations, the consistent Bellman\n",
      "operator, which incorporates a notion of local policy consistency. We show that\n",
      "this local consistency leads to an increase in the action gap at each state;\n",
      "increasing this gap, we argue, mitigates the undesirable effects of\n",
      "approximation and estimation errors on the induced greedy policies. This\n",
      "operator can also be applied to discretized continuous space and time problems,\n",
      "and we provide empirical results evidencing superior performance in this\n",
      "context. Extending the idea of a locally consistent operator, we then derive\n",
      "sufficient conditions for an operator to preserve optimality, leading to a\n",
      "family of operators which includes our consistent Bellman operator. As\n",
      "corollaries we provide a proof of optimality for Baird's advantage learning\n",
      "algorithm and derive other gap-increasing operators with interesting\n",
      "properties. We conclude with an empirical study on 60 Atari 2600 games\n",
      "illustrating the strong potential of these new operators.\n",
      "\n",
      "    \n",
      "265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recently, Neural Architecture Search has achieved great success in\n",
      "large-scale image classification. In contrast, there have been limited works\n",
      "focusing on architecture search for object detection, mainly because the costly\n",
      "ImageNet pre-training is always required for detectors. Training from scratch,\n",
      "as a substitute, demands more epochs to converge and brings no computation\n",
      "saving. To overcome this obstacle, we introduce a practical neural architecture\n",
      "transformation search(NATS)algorithm for object detection in this paper.\n",
      "Instead of searching and constructing an entire network, NATS explores the\n",
      "architecture space on the base of existing network and reusing its weights. We\n",
      "propose a novel neural architecture search strategy in channel-level instead of\n",
      "path-level and devise a search space specially targeting at object detection.\n",
      "With the combination of these two designs, an architecture transformation\n",
      "scheme could be discovered to adapt a network designed for image classification\n",
      "to task of object detection. Since our method is gradient-based and only\n",
      "searches for a transformation scheme, the weights of models pretrained\n",
      "inImageNet could be utilized in both searching and retraining stage, which\n",
      "makes the whole process very efficient. The transformed network requires no\n",
      "extra parameters and FLOPs, and is friendly to hardware optimization, which is\n",
      "practical to use in real-time application. In experiments, we demonstrate the\n",
      "effectiveness of NATSon networks like ResNet and ResNeXt. Our transformed\n",
      "networks, combined with various detection frameworks, achieve significant\n",
      "improvements on the COCO dataset while keeping fast.\n",
      "\n",
      "    \n",
      "301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Rendering synthetic data (e.g., 3D CAD-rendered images) to generate\n",
      "annotations for learning deep models in vision tasks has attracted increasing\n",
      "attention in recent years. However, simply applying the models learnt on\n",
      "synthetic images may lead to high generalization error on real images due to\n",
      "domain shift. To address this issue, recent progress in cross-domain\n",
      "recognition has featured the Mean Teacher, which directly simulates\n",
      "unsupervised domain adaptation as semi-supervised learning. The domain gap is\n",
      "thus naturally bridged with consistency regularization in a teacher-student\n",
      "scheme. In this work, we advance this Mean Teacher paradigm to be applicable\n",
      "for cross-domain detection. Specifically, we present Mean Teacher with Object\n",
      "Relations (MTOR) that novelly remolds Mean Teacher under the backbone of Faster\n",
      "R-CNN by integrating the object relations into the measure of consistency cost\n",
      "between teacher and student modules. Technically, MTOR firstly learns\n",
      "relational graphs that capture similarities between pairs of regions for\n",
      "teacher and student respectively. The whole architecture is then optimized with\n",
      "three consistency regularizations: 1) region-level consistency to align the\n",
      "region-level predictions between teacher and student, 2) inter-graph\n",
      "consistency for matching the graph structures between teacher and student, and\n",
      "3) intra-graph consistency to enhance the similarity between regions of same\n",
      "class within the graph of student. Extensive experiments are conducted on the\n",
      "transfers across Cityscapes, Foggy Cityscapes, and SIM10k, and superior results\n",
      "are reported when comparing to state-of-the-art approaches. More remarkably, we\n",
      "obtain a new record of single model: 22.8% of mAP on Syn2Real detection\n",
      "dataset.\n",
      "\n",
      "    \n",
      "302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Object detectors are usually equipped with backbone networks designed for\n",
      "image classification. It might be sub-optimal because of the gap between the\n",
      "tasks of image classification and object detection. In this work, we present\n",
      "DetNAS to use Neural Architecture Search (NAS) for the design of better\n",
      "backbones for object detection. It is non-trivial because detection training\n",
      "typically needs ImageNet pre-training while NAS systems require accuracies on\n",
      "the target detection task as supervisory signals. Based on the technique of\n",
      "one-shot supernet, which contains all possible networks in the search space, we\n",
      "propose a framework for backbone search on object detection. We train the\n",
      "supernet under the typical detector training schedule: ImageNet pre-training\n",
      "and detection fine-tuning. Then, the architecture search is performed on the\n",
      "trained supernet, using the detection task as the guidance. This framework\n",
      "makes NAS on backbones very efficient. In experiments, we show the\n",
      "effectiveness of DetNAS on various detectors, for instance, one-stage RetinaNet\n",
      "and the two-stage FPN. We empirically find that networks searched on object\n",
      "detection shows consistent superiority compared to those searched on ImageNet\n",
      "classification. The resulting architecture achieves superior performance than\n",
      "hand-crafted networks on COCO with much less FLOPs complexity.\n",
      "\n",
      "    \n",
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Conventional methods for object detection typically require a substantial\n",
      "amount of training data and preparing such high-quality training data is very\n",
      "labor-intensive. In this paper, we propose a novel few-shot object detection\n",
      "network that aims at detecting objects of unseen categories with only a few\n",
      "annotated examples. Central to our method are our Attention-RPN, Multi-Relation\n",
      "Detector and Contrastive Training strategy, which exploit the similarity\n",
      "between the few shot support set and query set to detect novel objects while\n",
      "suppressing false detection in the background. To train our network, we\n",
      "contribute a new dataset that contains 1000 categories of various objects with\n",
      "high-quality annotations. To the best of our knowledge, this is one of the\n",
      "first datasets specifically designed for few-shot object detection. Once our\n",
      "few-shot network is trained, it can detect objects of unseen categories without\n",
      "further training or fine-tuning. Our method is general and has a wide range of\n",
      "potential applications. We produce a new state-of-the-art performance on\n",
      "different datasets in the few-shot setting. The dataset link is\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern CNN-based object detectors assign anchors for ground-truth objects\n",
      "under the restriction of object-anchor Intersection-over-Unit (IoU). In this\n",
      "study, we propose a learning-to-match approach to break IoU restriction,\n",
      "allowing objects to match anchors in a flexible manner. Our approach, referred\n",
      "to as FreeAnchor, updates hand-crafted anchor assignment to \"free\" anchor\n",
      "matching by formulating detector training as a maximum likelihood estimation\n",
      "(MLE) procedure. FreeAnchor targets at learning features which best explain a\n",
      "class of objects in terms of both classification and localization. FreeAnchor\n",
      "is implemented by optimizing detection customized likelihood and can be fused\n",
      "with CNN-based detectors in a plug-and-play manner. Experiments on COCO\n",
      "demonstrate that FreeAnchor consistently outperforms their counterparts with\n",
      "significant margins.\n",
      "\n",
      "    \n",
      "305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The use of object detection algorithms is becoming increasingly important in\n",
      "autonomous vehicles, and object detection at high accuracy and a fast inference\n",
      "speed is essential for safe autonomous driving. A false positive (FP) from a\n",
      "false localization during autonomous driving can lead to fatal accidents and\n",
      "hinder safe and efficient driving. Therefore, a detection algorithm that can\n",
      "cope with mislocalizations is required in autonomous driving applications. This\n",
      "paper proposes a method for improving the detection accuracy while supporting a\n",
      "real-time operation by modeling the bounding box (bbox) of YOLOv3, which is the\n",
      "most representative of one-stage detectors, with a Gaussian parameter and\n",
      "redesigning the loss function. In addition, this paper proposes a method for\n",
      "predicting the localization uncertainty that indicates the reliability of bbox.\n",
      "By using the predicted localization uncertainty during the detection process,\n",
      "the proposed schemes can significantly reduce the FP and increase the true\n",
      "positive (TP), thereby improving the accuracy. Compared to a conventional\n",
      "YOLOv3, the proposed algorithm, Gaussian YOLOv3, improves the mean average\n",
      "precision (mAP) by 3.09 and 3.5 on the KITTI and Berkeley deep drive (BDD)\n",
      "datasets, respectively. Nevertheless, the proposed algorithm is capable of\n",
      "real-time detection at faster than 42 frames per second (fps) and shows a\n",
      "higher accuracy than previous approaches with a similar fps. Therefore, the\n",
      "proposed algorithm is the most suitable for autonomous driving applications.\n",
      "\n",
      "    \n",
      "306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning to localize and name object instances is a fundamental problem in\n",
      "vision, but state-of-the-art approaches rely on expensive bounding box\n",
      "supervision. While weakly supervised detection (WSOD) methods relax the need\n",
      "for boxes to that of image-level annotations, even cheaper supervision is\n",
      "naturally available in the form of unstructured textual descriptions that users\n",
      "may freely provide when uploading image content. However, straightforward\n",
      "approaches to using such data for WSOD wastefully discard captions that do not\n",
      "exactly match object names. Instead, we show how to squeeze the most\n",
      "information out of these captions by training a text-only classifier that\n",
      "generalizes beyond dataset boundaries. Our discovery provides an opportunity\n",
      "for learning detection models from noisy but more abundant and freely-available\n",
      "caption data. We also validate our model on three classic object detection\n",
      "benchmarks and achieve state-of-the-art WSOD performance. Our code is available\n",
      "at this https URL.\n",
      "\n",
      "    \n",
      "307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in deep learning greatly boost the performance of object\n",
      "detection. State-of-the-art methods such as Faster-RCNN, FPN and R-FCN have\n",
      "achieved high accuracy in challenging benchmark datasets. However, these\n",
      "methods require fully annotated object bounding boxes for training, which are\n",
      "incredibly hard to scale up due to the high annotation cost. Weakly-supervised\n",
      "methods, on the other hand, only require image-level labels for training, but\n",
      "the performance is far below their fully-supervised counterparts. In this\n",
      "paper, we propose a semi-supervised large scale fine-grained detection method,\n",
      "which only needs bounding box annotations of a smaller number of coarse-grained\n",
      "classes and image-level labels of large scale fine-grained classes, and can\n",
      "detect all classes at nearly fully-supervised accuracy. We achieve this by\n",
      "utilizing the correlations between coarse-grained and fine-grained classes with\n",
      "shared backbone, soft-attention based proposal re-ranking, and a dual-level\n",
      "memory module. Experiment results show that our methods can achieve close\n",
      "accuracy on object detection to state-of-the-art fully-supervised methods on\n",
      "two large scale datasets, ImageNet and OpenImages, with only a small fraction\n",
      "of fully annotated classes.\n",
      "\n",
      "    \n",
      "308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern object detectors rely heavily on rectangular bounding boxes, such as\n",
      "anchors, proposals and the final predictions, to represent objects at various\n",
      "recognition stages. The bounding box is convenient to use but provides only a\n",
      "coarse localization of objects and leads to a correspondingly coarse extraction\n",
      "of object features. In this paper, we present \\textbf{RepPoints}\n",
      "(representative points), a new finer representation of objects as a set of\n",
      "sample points useful for both localization and recognition. Given ground truth\n",
      "localization and recognition targets for training, RepPoints learn to\n",
      "automatically arrange themselves in a manner that bounds the spatial extent of\n",
      "an object and indicates semantically significant local areas. They furthermore\n",
      "do not require the use of anchors to sample a space of bounding boxes. We show\n",
      "that an anchor-free object detector based on RepPoints can be as effective as\n",
      "the state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4\n",
      "$AP_{50}$ on the COCO test-dev detection benchmark, using ResNet-101 model.\n",
      "Code is available at this https URL.\n",
      "\n",
      "    \n",
      "309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a fully convolutional one-stage object detector (FCOS) to solve\n",
      "object detection in a per-pixel prediction fashion, analogue to semantic\n",
      "segmentation. Almost all state-of-the-art object detectors such as RetinaNet,\n",
      "SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast,\n",
      "our proposed detector FCOS is anchor box free, as well as proposal free. By\n",
      "eliminating the predefined set of anchor boxes, FCOS completely avoids the\n",
      "complicated computation related to anchor boxes such as calculating overlapping\n",
      "during training. More importantly, we also avoid all hyper-parameters related\n",
      "to anchor boxes, which are often very sensitive to the final detection\n",
      "performance. With the only post-processing non-maximum suppression (NMS), FCOS\n",
      "with ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale\n",
      "testing, surpassing previous one-stage detectors with the advantage of being\n",
      "much simpler. For the first time, we demonstrate a much simpler and flexible\n",
      "detection framework achieving improved detection accuracy. We hope that the\n",
      "proposed FCOS framework can serve as a simple and strong alternative for many\n",
      "other instance-level tasks. Code is available at:Code is available at:\n",
      "this https URL\n",
      "\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Scale-sensitive object detection remains a challenging task, where most of\n",
      "the existing methods could not learn it explicitly and are not robust to scale\n",
      "variance. In addition, the most existing methods are less efficient during\n",
      "training or slow during inference, which are not friendly to real-time\n",
      "applications. In this paper, we propose a practical object detection method\n",
      "with scale-sensitive network.Our method first predicts a global continuous\n",
      "scale ,which is shared by all position, for each convolution filter of each\n",
      "network stage. To effectively learn the scale, we average the spatial features\n",
      "and distill the scale from channels. For fast-deployment, we propose a scale\n",
      "decomposition method that transfers the robust fractional scale into\n",
      "combination of fixed integral scales for each convolution filter, which\n",
      "exploits the dilated convolution. We demonstrate it on one-stage and two-stage\n",
      "algorithms under different configurations. For practical applications, training\n",
      "of our method is of efficiency and simplicity which gets rid of complex data\n",
      "sampling or optimize strategy. During test-ing, the proposed method requires no\n",
      "extra operation and is very supportive of hardware acceleration like TensorRT\n",
      "and TVM. On the COCO test-dev, our model could achieve a 41.5 mAP on one-stage\n",
      "detector and 42.1 mAP on two-stage detectors based on ResNet-101, outperforming\n",
      "base-lines by 2.4 and 2.1 respectively without extra FLOPS.\n",
      "\n",
      "    \n",
      "311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The labeling cost of large number of bounding boxes is one of the main\n",
      "challenges for training modern object detectors. To reduce the dependence on\n",
      "expensive bounding box annotations, we propose a new semi-supervised object\n",
      "detection formulation, in which a few seed box level annotations and a large\n",
      "scale of image level annotations are used to train the detector. We adopt a\n",
      "training-mining framework, which is widely used in weakly supervised object\n",
      "detection tasks. However, the mining process inherently introduces various\n",
      "kinds of labelling noises: false negatives, false positives and inaccurate\n",
      "boundaries, which can be harmful for training the standard object detectors\n",
      "(e.g. Faster RCNN). We propose a novel NOise Tolerant Ensemble RCNN (NOTE-RCNN)\n",
      "object detector to handle such noisy labels. Comparing to standard Faster RCNN,\n",
      "it contains three highlights: an ensemble of two classification heads and a\n",
      "distillation head to avoid overfitting on noisy labels and improve the mining\n",
      "precision, masking the negative sample loss in box predictor to avoid the harm\n",
      "of false negative labels, and training box regression head only on seed\n",
      "annotations to eliminate the harm from inaccurate boundaries of mined bounding\n",
      "boxes. We evaluate the methods on ILSVRC 2013 and MSCOCO 2017 dataset; we\n",
      "observe that the detection accuracy consistently improves as we iterate between\n",
      "mining and training steps, and state-of-the-art performance is achieved.\n",
      "\n",
      "    \n",
      "312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Video objection detection (VID) has been a rising research direction in\n",
      "recent years. A central issue of VID is the appearance degradation of video\n",
      "frames caused by fast motion. This problem is essentially ill-posed for a\n",
      "single frame. Therefore, aggregating features from other frames becomes a\n",
      "natural choice. Existing methods rely heavily on optical flow or recurrent\n",
      "neural networks for feature aggregation. However, these methods emphasize more\n",
      "on the temporally nearby frames. In this work, we argue that aggregating\n",
      "features in the full-sequence level will lead to more discriminative and robust\n",
      "features for video object detection. To achieve this goal, we devise a novel\n",
      "Sequence Level Semantics Aggregation (SELSA) module. We further demonstrate the\n",
      "close relationship between the proposed method and the classic spectral\n",
      "clustering method, providing a novel view for understanding the VID problem. We\n",
      "test the proposed method on the ImageNet VID and the EPIC KITCHENS dataset and\n",
      "achieve new state-of-the-art results. Our method does not need complicated\n",
      "postprocessing methods such as Seq-NMS or Tubelet rescoring, which keeps the\n",
      "pipeline simple and clean.\n",
      "\n",
      "    \n",
      "313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Current CNN-based solutions to salient object detection (SOD) mainly rely on\n",
      "the optimization of cross-entropy loss (CELoss). Then the quality of detected\n",
      "saliency maps is often evaluated in terms of F-measure. In this paper, we\n",
      "investigate an interesting issue: can we consistently use the F-measure\n",
      "formulation in both training and evaluation for SOD? By reformulating the\n",
      "standard F-measure we propose the relaxed F-measure which is differentiable\n",
      "w.r.t the posterior and can be easily appended to the back of CNNs as the loss\n",
      "function. Compared to the conventional cross-entropy loss of which the\n",
      "gradients decrease dramatically in the saturated area, our loss function, named\n",
      "FLoss, holds considerable gradients even when the activation approaches the\n",
      "target. Consequently, the FLoss can continuously force the network to produce\n",
      "polarized activations. Comprehensive benchmarks on several popular datasets\n",
      "show that FLoss outperforms the state-of-the-art with a considerable margin.\n",
      "More specifically, due to the polarized predictions, our method is able to\n",
      "obtain high-quality saliency maps without carefully tuning the optimal\n",
      "threshold, showing significant advantages in real-world applications.\n",
      "\n",
      "    \n",
      "314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Fully convolutional neural networks (FCNs) have shown their advantages in the\n",
      "salient object detection task. However, most existing FCNs-based methods still\n",
      "suffer from coarse object boundaries. In this paper, to solve this problem, we\n",
      "focus on the complementarity between salient edge information and salient\n",
      "object information. Accordingly, we present an edge guidance network (EGNet)\n",
      "for salient object detection with three steps to simultaneously model these two\n",
      "kinds of complementary information in a single network. In the first step, we\n",
      "extract the salient object features by a progressive fusion way. In the second\n",
      "step, we integrate the local edge information and global location information\n",
      "to obtain the salient edge features. Finally, to sufficiently leverage these\n",
      "complementary features, we couple the same salient edge features with salient\n",
      "object features at various resolutions. Benefiting from the rich edge\n",
      "information and location information in salient edge features, the fused\n",
      "features can help locate salient objects, especially their boundaries more\n",
      "accurately. Experimental results demonstrate that the proposed method performs\n",
      "favorably against the state-of-the-art methods on six widely used datasets\n",
      "without any pre-processing and post-processing. The source code is available at\n",
      "http: //mmcheng.net/egnet/.\n",
      "\n",
      "    \n",
      "315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Conventional training of a deep CNN based object detector demands a large\n",
      "number of bounding box annotations, which may be unavailable for rare\n",
      "categories. In this work we develop a few-shot object detector that can learn\n",
      "to detect novel objects from only a few annotated examples. Our proposed model\n",
      "leverages fully labeled base classes and quickly adapts to novel classes, using\n",
      "a meta feature learner and a reweighting module within a one-stage detection\n",
      "architecture. The feature learner extracts meta features that are generalizable\n",
      "to detect novel object classes, using training data from base classes with\n",
      "sufficient samples. The reweighting module transforms a few support examples\n",
      "from the novel classes to a global vector that indicates the importance or\n",
      "relevance of meta features for detecting the corresponding objects. These two\n",
      "modules, together with a detection prediction module, are trained end-to-end\n",
      "based on an episodic few-shot learning scheme and a carefully designed loss\n",
      "function. Through extensive experiments we demonstrate that our model\n",
      "outperforms well-established baselines by a large margin for few-shot object\n",
      "detection, on multiple datasets and settings. We also present analysis on\n",
      "various aspects of our proposed model, aiming to provide some inspiration for\n",
      "future few-shot detection works.\n",
      "\n",
      "    \n",
      "316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Detecting objects in aerial images is challenging for at least two reasons:\n",
      "(1) target objects like pedestrians are very small in pixels, making them\n",
      "hardly distinguished from surrounding background; and (2) targets are in\n",
      "general sparsely and non-uniformly distributed, making the detection very\n",
      "inefficient. In this paper, we address both issues inspired by observing that\n",
      "these targets are often clustered. In particular, we propose a Clustered\n",
      "Detection (ClusDet) network that unifies object clustering and detection in an\n",
      "end-to-end framework. The key components in ClusDet include a cluster proposal\n",
      "sub-network (CPNet), a scale estimation sub-network (ScaleNet), and a dedicated\n",
      "detection network (DetecNet). Given an input image, CPNet produces object\n",
      "cluster regions and ScaleNet estimates object scales for these regions. Then,\n",
      "each scale-normalized cluster region is fed into DetecNet for object detection.\n",
      "ClusDet has several advantages over previous solutions: (1) it greatly reduces\n",
      "the number of chips for final object detection and hence achieves high running\n",
      "time efficiency, (2) the cluster-based scale estimation is more accurate than\n",
      "previously used single-object based ones, hence effectively improves the\n",
      "detection for small objects, and (3) the final DetecNet is dedicated for\n",
      "clustered regions and implicitly models the prior context information so as to\n",
      "boost detection accuracy. The proposed method is tested on three popular aerial\n",
      "image datasets including VisDrone, UAVDT and DOTA. In all experiments, ClusDet\n",
      "achieves promising performance in comparison with state-of-the-art detectors.\n",
      "Code will be available in \\url{this https URL}.\n",
      "\n",
      "    \n",
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning-based video salient object detection has recently achieved\n",
      "great success with its performance significantly outperforming any other\n",
      "unsupervised methods. However, existing data-driven approaches heavily rely on\n",
      "a large quantity of pixel-wise annotated video frames to deliver such promising\n",
      "results. In this paper, we address the semi-supervised video salient object\n",
      "detection task using pseudo-labels. Specifically, we present an effective video\n",
      "saliency detector that consists of a spatial refinement network and a\n",
      "spatiotemporal module. Based on the same refinement network and motion\n",
      "information in terms of optical flow, we further propose a novel method for\n",
      "generating pixel-level pseudo-labels from sparsely annotated frames. By\n",
      "utilizing the generated pseudo-labels together with a part of manual\n",
      "annotations, our video saliency detector learns spatial and temporal cues for\n",
      "both contrast inference and coherence enhancement, thus producing accurate\n",
      "saliency maps. Experimental results demonstrate that our proposed\n",
      "semi-supervised method even greatly outperforms all the state-of-the-art fully\n",
      "supervised methods across three public benchmarks of VOS, DAVIS, and FBMS.\n",
      "\n",
      "    \n",
      "318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Video salient object detection aims at discovering the most visually\n",
      "distinctive objects in a video. How to effectively take object motion into\n",
      "consideration during video salient object detection is a critical issue.\n",
      "Existing state-of-the-art methods either do not explicitly model and harvest\n",
      "motion cues or ignore spatial contexts within optical flow images. In this\n",
      "paper, we develop a multi-task motion guided video salient object detection\n",
      "network, which learns to accomplish two sub-tasks using two sub-networks, one\n",
      "sub-network for salient object detection in still images and the other for\n",
      "motion saliency detection in optical flow images. We further introduce a series\n",
      "of novel motion guided attention modules, which utilize the motion saliency\n",
      "sub-network to attend and enhance the sub-network for still images. These two\n",
      "sub-networks learn to adapt to each other by end-to-end training. Experimental\n",
      "results demonstrate that the proposed method significantly outperforms existing\n",
      "state-of-the-art algorithms on a wide range of benchmarks. We hope our simple\n",
      "and effective approach will serve as a solid baseline and help ease future\n",
      "research in video salient object detection. Code and models will be made\n",
      "available.\n",
      "\n",
      "    \n",
      "319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural network based methods have made a significant breakthrough in\n",
      "salient object detection. However, they are typically limited to input images\n",
      "with low resolutions ($400\\times400$ pixels or less). Little effort has been\n",
      "made to train deep neural networks to directly handle salient object detection\n",
      "in very high-resolution images. This paper pushes forward high-resolution\n",
      "saliency detection, and contributes a new dataset, named High-Resolution\n",
      "Salient Object Detection (HRSOD). To our best knowledge, HRSOD is the first\n",
      "high-resolution saliency detection dataset to date. As another contribution, we\n",
      "also propose a novel approach, which incorporates both global semantic\n",
      "information and local high-resolution details, to address this challenging\n",
      "task. More specifically, our approach consists of a Global Semantic Network\n",
      "(GSN), a Local Refinement Network (LRN) and a Global-Local Fusion Network\n",
      "(GLFN). GSN extracts the global semantic information based on down-sampled\n",
      "entire image. Guided by the results of GSN, LRN focuses on some local regions\n",
      "and progressively produces high-resolution predictions. GLFN is further\n",
      "proposed to enforce spatial consistency and boost performance. Experiments\n",
      "illustrate that our method outperforms existing state-of-the-art methods on\n",
      "high-resolution saliency datasets by a large margin, and achieves comparable or\n",
      "even better performance than them on widely-used saliency benchmarks. The HRSOD\n",
      "dataset is available at this https URL.\n",
      "\n",
      "    \n",
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art named entity recognition systems rely heavily on\n",
      "hand-crafted features and domain-specific knowledge in order to learn\n",
      "effectively from the small, supervised training corpora that are available. In\n",
      "this paper, we introduce two new neural architectures---one based on\n",
      "bidirectional LSTMs and conditional random fields, and the other that\n",
      "constructs and labels segments using a transition-based approach inspired by\n",
      "shift-reduce parsers. Our models rely on two sources of information about\n",
      "words: character-based word representations learned from the supervised corpus\n",
      "and unsupervised word representations learned from unannotated corpora. Our\n",
      "models obtain state-of-the-art performance in NER in four languages without\n",
      "resorting to any language-specific knowledge or resources such as gazetteers.\n",
      "\n",
      "    \n",
      "321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work we explore recent advances in Recurrent Neural Networks for\n",
      "large scale Language Modeling, a task central to language understanding. We\n",
      "extend current models to deal with two key challenges present in this task:\n",
      "corpora and vocabulary sizes, and complex, long term structure of language. We\n",
      "perform an exhaustive study on techniques such as character Convolutional\n",
      "Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark.\n",
      "Our best single model significantly improves state-of-the-art perplexity from\n",
      "51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20),\n",
      "while an ensemble of models sets a new record by improving perplexity from 41.0\n",
      "down to 23.7. We also release these models for the NLP and ML community to\n",
      "study and improve upon.\n",
      "\n",
      "    \n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Teaching machines to read natural language documents remains an elusive\n",
      "challenge. Machine reading systems can be tested on their ability to answer\n",
      "questions posed on the contents of documents that they have seen, but until now\n",
      "large scale training and test datasets have been missing for this type of\n",
      "evaluation. In this work we define a new methodology that resolves this\n",
      "bottleneck and provides large scale supervised reading comprehension data. This\n",
      "allows us to develop a class of attention based deep neural networks that learn\n",
      "to read real documents and answer complex questions with minimal prior\n",
      "knowledge of language structure.\n",
      "\n",
      "    \n",
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  An attentional mechanism has lately been used to improve neural machine\n",
      "translation (NMT) by selectively focusing on parts of the source sentence\n",
      "during translation. However, there has been little work exploring useful\n",
      "architectures for attention-based NMT. This paper examines two simple and\n",
      "effective classes of attentional mechanism: a global approach which always\n",
      "attends to all source words and a local one that only looks at a subset of\n",
      "source words at a time. We demonstrate the effectiveness of both approaches\n",
      "over the WMT translation tasks between English and German in both directions.\n",
      "With local attention, we achieve a significant gain of 5.0 BLEU points over\n",
      "non-attentional systems which already incorporate known techniques such as\n",
      "dropout. Our ensemble model using different attention architectures has\n",
      "established a new state-of-the-art result in the WMT'15 English to German\n",
      "translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over\n",
      "the existing best system backed by NMT and an n-gram reranker.\n",
      "\n",
      "    \n",
      "324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Pixel-level labelling tasks, such as semantic segmentation, play a central\n",
      "role in image understanding. Recent approaches have attempted to harness the\n",
      "capabilities of deep learning techniques for image recognition to tackle\n",
      "pixel-level labelling tasks. One central issue in this methodology is the\n",
      "limited capacity of deep learning techniques to delineate visual objects. To\n",
      "solve this problem, we introduce a new form of convolutional neural network\n",
      "that combines the strengths of Convolutional Neural Networks (CNNs) and\n",
      "Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To\n",
      "this end, we formulate mean-field approximate inference for the Conditional\n",
      "Random Fields with Gaussian pairwise potentials as Recurrent Neural Networks.\n",
      "This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a\n",
      "deep network that has desirable properties of both CNNs and CRFs. Importantly,\n",
      "our system fully integrates CRF modelling with CNNs, making it possible to\n",
      "train the whole deep network end-to-end with the usual back-propagation\n",
      "algorithm, avoiding offline post-processing methods for object delineation. We\n",
      "apply the proposed method to the problem of semantic image segmentation,\n",
      "obtaining top results on the challenging Pascal VOC 2012 segmentation\n",
      "benchmark.\n",
      "\n",
      "    \n",
      "325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We extend the capabilities of neural networks by coupling them to external\n",
      "memory resources, which they can interact with by attentional processes. The\n",
      "combined system is analogous to a Turing Machine or Von Neumann architecture\n",
      "but is differentiable end-to-end, allowing it to be efficiently trained with\n",
      "gradient descent. Preliminary results demonstrate that Neural Turing Machines\n",
      "can infer simple algorithms such as copying, sorting, and associative recall\n",
      "from input and output examples.\n",
      "\n",
      "    \n",
      "326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a new class of learning models called memory networks. Memory\n",
      "networks reason with inference components combined with a long-term memory\n",
      "component; they learn how to use these jointly. The long-term memory can be\n",
      "read and written to, with the goal of using it for prediction. We investigate\n",
      "these models in the context of question answering (QA) where the long-term\n",
      "memory effectively acts as a (dynamic) knowledge base, and the output is a\n",
      "textual response. We evaluate them on a large-scale QA task, and a smaller, but\n",
      "more complex, toy task generated from a simulated world. In the latter, we show\n",
      "the reasoning power of such models by chaining multiple supporting sentences to\n",
      "answer questions that require understanding the intension of verbs.\n",
      "\n",
      "    \n",
      "327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural machine translation is a recently proposed approach to machine\n",
      "translation. Unlike the traditional statistical machine translation, the neural\n",
      "machine translation aims at building a single neural network that can be\n",
      "jointly tuned to maximize the translation performance. The models proposed\n",
      "recently for neural machine translation often belong to a family of\n",
      "encoder-decoders and consists of an encoder that encodes a source sentence into\n",
      "a fixed-length vector from which a decoder generates a translation. In this\n",
      "paper, we conjecture that the use of a fixed-length vector is a bottleneck in\n",
      "improving the performance of this basic encoder-decoder architecture, and\n",
      "propose to extend this by allowing a model to automatically (soft-)search for\n",
      "parts of a source sentence that are relevant to predicting a target word,\n",
      "without having to form these parts as a hard segment explicitly. With this new\n",
      "approach, we achieve a translation performance comparable to the existing\n",
      "state-of-the-art phrase-based system on the task of English-to-French\n",
      "translation. Furthermore, qualitative analysis reveals that the\n",
      "(soft-)alignments found by the model agree well with our intuition.\n",
      "\n",
      "    \n",
      "328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Neural Networks (DNNs) are powerful models that have achieved excellent\n",
      "performance on difficult learning tasks. Although DNNs work well whenever large\n",
      "labeled training sets are available, they cannot be used to map sequences to\n",
      "sequences. In this paper, we present a general end-to-end approach to sequence\n",
      "learning that makes minimal assumptions on the sequence structure. Our method\n",
      "uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to\n",
      "a vector of a fixed dimensionality, and then another deep LSTM to decode the\n",
      "target sequence from the vector. Our main result is that on an English to\n",
      "French translation task from the WMT'14 dataset, the translations produced by\n",
      "the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's\n",
      "BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did\n",
      "not have difficulty on long sentences. For comparison, a phrase-based SMT\n",
      "system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM\n",
      "to rerank the 1000 hypotheses produced by the aforementioned SMT system, its\n",
      "BLEU score increases to 36.5, which is close to the previous best result on\n",
      "this task. The LSTM also learned sensible phrase and sentence representations\n",
      "that are sensitive to word order and are relatively invariant to the active and\n",
      "the passive voice. Finally, we found that reversing the order of the words in\n",
      "all source sentences (but not target sentences) improved the LSTM's performance\n",
      "markedly, because doing so introduced many short term dependencies between the\n",
      "source and the target sentence which made the optimization problem easier.\n",
      "\n",
      "    \n",
      "329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose a novel neural network model called RNN\n",
      "Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN\n",
      "encodes a sequence of symbols into a fixed-length vector representation, and\n",
      "the other decodes the representation into another sequence of symbols. The\n",
      "encoder and decoder of the proposed model are jointly trained to maximize the\n",
      "conditional probability of a target sequence given a source sequence. The\n",
      "performance of a statistical machine translation system is empirically found to\n",
      "improve by using the conditional probabilities of phrase pairs computed by the\n",
      "RNN Encoder-Decoder as an additional feature in the existing log-linear model.\n",
      "Qualitatively, we show that the proposed model learns a semantically and\n",
      "syntactically meaningful representation of linguistic phrases.\n",
      "\n",
      "    \n",
      "330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to accurately represent sentences is central to language\n",
      "understanding. We describe a convolutional architecture dubbed the Dynamic\n",
      "Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of\n",
      "sentences. The network uses Dynamic k-Max Pooling, a global pooling operation\n",
      "over linear sequences. The network handles input sentences of varying length\n",
      "and induces a feature graph over the sentence that is capable of explicitly\n",
      "capturing short and long-range relations. The network does not rely on a parse\n",
      "tree and is easily applicable to any language. We test the DCNN in four\n",
      "experiments: small scale binary and multi-class sentiment prediction, six-way\n",
      "question classification and Twitter sentiment prediction by distant\n",
      "supervision. The network achieves excellent performance in the first three\n",
      "tasks and a greater than 25% error reduction in the last task with respect to\n",
      "the strongest baseline.\n",
      "\n",
      "    \n",
      "331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many machine learning algorithms require the input to be represented as a\n",
      "fixed-length feature vector. When it comes to texts, one of the most common\n",
      "fixed-length features is bag-of-words. Despite their popularity, bag-of-words\n",
      "features have two major weaknesses: they lose the ordering of the words and\n",
      "they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and\n",
      "\"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an\n",
      "unsupervised algorithm that learns fixed-length feature representations from\n",
      "variable-length pieces of texts, such as sentences, paragraphs, and documents.\n",
      "Our algorithm represents each document by a dense vector which is trained to\n",
      "predict words in the document. Its construction gives our algorithm the\n",
      "potential to overcome the weaknesses of bag-of-words models. Empirical results\n",
      "show that Paragraph Vectors outperform bag-of-words models as well as other\n",
      "techniques for text representations. Finally, we achieve new state-of-the-art\n",
      "results on several text classification and sentiment analysis tasks.\n",
      "\n",
      "    \n",
      "332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The recently introduced continuous Skip-gram model is an efficient method for\n",
      "learning high-quality distributed vector representations that capture a large\n",
      "number of precise syntactic and semantic word relationships. In this paper we\n",
      "present several extensions that improve both the quality of the vectors and the\n",
      "training speed. By subsampling of the frequent words we obtain significant\n",
      "speedup and also learn more regular word representations. We also describe a\n",
      "simple alternative to the hierarchical softmax called negative sampling. An\n",
      "inherent limitation of word representations is their indifference to word order\n",
      "and their inability to represent idiomatic phrases. For example, the meanings\n",
      "of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\".\n",
      "Motivated by this example, we present a simple method for finding phrases in\n",
      "text, and show that learning good vector representations for millions of\n",
      "phrases is possible.\n",
      "\n",
      "    \n",
      "333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose two novel model architectures for computing continuous vector\n",
      "representations of words from very large data sets. The quality of these\n",
      "representations is measured in a word similarity task, and the results are\n",
      "compared to the previously best performing techniques based on different types\n",
      "of neural networks. We observe large improvements in accuracy at much lower\n",
      "computational cost, i.e. it takes less than a day to learn high quality word\n",
      "vectors from a 1.6 billion words data set. Furthermore, we show that these\n",
      "vectors provide state-of-the-art performance on our test set for measuring\n",
      "syntactic and semantic word similarities.\n",
      "\n",
      "    \n",
      "334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper shows how Long Short-term Memory recurrent neural networks can be\n",
      "used to generate complex sequences with long-range structure, simply by\n",
      "predicting one data point at a time. The approach is demonstrated for text\n",
      "(where the data are discrete) and online handwriting (where the data are\n",
      "real-valued). It is then extended to handwriting synthesis by allowing the\n",
      "network to condition its predictions on a text sequence. The resulting system\n",
      "is able to generate highly realistic cursive handwriting in a wide variety of\n",
      "styles.\n",
      "\n",
      "    \n",
      "335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many of the current state-of-the-art Large Vocabulary Continuous Speech\n",
      "Recognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov\n",
      "Models (HMMs). Most of these systems contain separate components that deal with\n",
      "the acoustic modelling, language modelling and sequence decoding. We\n",
      "investigate a more direct approach in which the HMM is replaced with a\n",
      "Recurrent Neural Network (RNN) that performs sequence prediction directly at\n",
      "the character level. Alignment between the input features and the desired\n",
      "character sequence is learned automatically by an attention mechanism built\n",
      "into the RNN. For each predicted character, the attention mechanism scans the\n",
      "input sequence and chooses relevant frames. We propose two methods to speed up\n",
      "this operation: limiting the scan to a subset of most promising frames and\n",
      "pooling over time the information contained in neighboring frames, thereby\n",
      "reducing source sequence length. Integrating an n-gram language model into the\n",
      "decoding process yields recognition accuracies similar to other HMM-free\n",
      "RNN-based approaches.\n",
      "\n",
      "    \n",
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We show that an end-to-end deep learning approach can be used to recognize\n",
      "either English or Mandarin Chinese speech--two vastly different languages.\n",
      "Because it replaces entire pipelines of hand-engineered components with neural\n",
      "networks, end-to-end learning allows us to handle a diverse variety of speech\n",
      "including noisy environments, accents and different languages. Key to our\n",
      "approach is our application of HPC techniques, resulting in a 7x speedup over\n",
      "our previous system. Because of this efficiency, experiments that previously\n",
      "took weeks now run in days. This enables us to iterate more quickly to identify\n",
      "superior architectures and algorithms. As a result, in several cases, our\n",
      "system is competitive with the transcription of human workers when benchmarked\n",
      "on standard datasets. Finally, using a technique called Batch Dispatch with\n",
      "GPUs in the data center, we show that our system can be inexpensively deployed\n",
      "in an online setting, delivering low latency when serving users at scale.\n",
      "\n",
      "    \n",
      "337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recurrent neural networks (RNNs) are a powerful model for sequential data.\n",
      "End-to-end training methods such as Connectionist Temporal Classification make\n",
      "it possible to train RNNs for sequence labelling problems where the\n",
      "input-output alignment is unknown. The combination of these methods with the\n",
      "Long Short-term Memory RNN architecture has proved particularly fruitful,\n",
      "delivering state-of-the-art results in cursive handwriting recognition. However\n",
      "RNN performance in speech recognition has so far been disappointing, with\n",
      "better results returned by deep feedforward networks. This paper investigates\n",
      "\\emph{deep recurrent neural networks}, which combine the multiple levels of\n",
      "representation that have proved so effective in deep networks with the flexible\n",
      "use of long range context that empowers RNNs. When trained end-to-end with\n",
      "suitable regularisation, we find that deep Long Short-term Memory RNNs achieve\n",
      "a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to\n",
      "our knowledge is the best recorded score.\n",
      "\n",
      "    \n",
      "338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Policy search methods can allow robots to learn control policies for a wide\n",
      "range of tasks, but practical applications of policy search often require\n",
      "hand-engineered components for perception, state estimation, and low-level\n",
      "control. In this paper, we aim to answer the following question: does training\n",
      "the perception and control systems jointly end-to-end provide better\n",
      "performance than training each component separately? To this end, we develop a\n",
      "method that can be used to learn policies that map raw image observations\n",
      "directly to torques at the robot's motors. The policies are represented by deep\n",
      "convolutional neural networks (CNNs) with 92,000 parameters, and are trained\n",
      "using a partially observed guided policy search method, which transforms policy\n",
      "search into supervised learning, with supervision provided by a simple\n",
      "trajectory-centric reinforcement learning method. We evaluate our method on a\n",
      "range of real-world manipulation tasks that require close coordination between\n",
      "vision and control, such as screwing a cap onto a bottle, and present simulated\n",
      "comparisons to a range of prior policy search methods.\n",
      "\n",
      "    \n",
      "341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We adapt the ideas underlying the success of Deep Q-Learning to the\n",
      "continuous action domain. We present an actor-critic, model-free algorithm\n",
      "based on the deterministic policy gradient that can operate over continuous\n",
      "action spaces. Using the same learning algorithm, network architecture and\n",
      "hyper-parameters, our algorithm robustly solves more than 20 simulated physics\n",
      "tasks, including classic problems such as cartpole swing-up, dexterous\n",
      "manipulation, legged locomotion and car driving. Our algorithm is able to find\n",
      "policies whose performance is competitive with those found by a planning\n",
      "algorithm with full access to the dynamics of the domain and its derivatives.\n",
      "We further demonstrate that for many of the tasks the algorithm can learn\n",
      "policies end-to-end: directly from raw pixel inputs.\n",
      "\n",
      "    \n",
      "342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of detecting robotic grasps in an RGB-D view of a\n",
      "scene containing objects. In this work, we apply a deep learning approach to\n",
      "solve this problem, which avoids time-consuming hand-design of features. This\n",
      "presents two main challenges. First, we need to evaluate a huge number of\n",
      "candidate grasps. In order to make detection fast, as well as robust, we\n",
      "present a two-step cascaded structure with two deep networks, where the top\n",
      "detections from the first are re-evaluated by the second. The first network has\n",
      "fewer features, is faster to run, and can effectively prune out unlikely\n",
      "candidate grasps. The second, with more features, is slower but has to run only\n",
      "on the top few detections. Second, we need to handle multimodal inputs well,\n",
      "for which we present a method to apply structured regularization on the weights\n",
      "based on multimodal group regularization. We demonstrate that our method\n",
      "outperforms the previous state-of-the-art methods in robotic grasp detection,\n",
      "and can be used to successfully execute grasps on two different robotic\n",
      "platforms.\n",
      "\n",
      "    \n",
      "343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present the first deep learning model to successfully learn control\n",
      "policies directly from high-dimensional sensory input using reinforcement\n",
      "learning. The model is a convolutional neural network, trained with a variant\n",
      "of Q-learning, whose input is raw pixels and whose output is a value function\n",
      "estimating future rewards. We apply our method to seven Atari 2600 games from\n",
      "the Arcade Learning Environment, with no adjustment of the architecture or\n",
      "learning algorithm. We find that it outperforms all previous approaches on six\n",
      "of the games and surpasses a human expert on three of them.\n",
      "\n",
      "    \n",
      "344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In fine art, especially painting, humans have mastered the skill to create\n",
      "unique visual experiences through composing a complex interplay between the\n",
      "content and style of an image. Thus far the algorithmic basis of this process\n",
      "is unknown and there exists no artificial system with similar capabilities.\n",
      "However, in other key areas of visual perception such as object and face\n",
      "recognition near-human performance was recently demonstrated by a class of\n",
      "biologically inspired vision models called Deep Neural Networks. Here we\n",
      "introduce an artificial system based on a Deep Neural Network that creates\n",
      "artistic images of high perceptual quality. The system uses neural\n",
      "representations to separate and recombine content and style of arbitrary\n",
      "images, providing a neural algorithm for the creation of artistic images.\n",
      "Moreover, in light of the striking similarities between performance-optimised\n",
      "artificial neural networks and biological vision, our work offers a path\n",
      "forward to an algorithmic understanding of how humans create and perceive\n",
      "artistic imagery.\n",
      "\n",
      "    \n",
      "346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a model that generates natural language descriptions of images and\n",
      "their regions. Our approach leverages datasets of images and their sentence\n",
      "descriptions to learn about the inter-modal correspondences between language\n",
      "and visual data. Our alignment model is based on a novel combination of\n",
      "Convolutional Neural Networks over image regions, bidirectional Recurrent\n",
      "Neural Networks over sentences, and a structured objective that aligns the two\n",
      "modalities through a multimodal embedding. We then describe a Multimodal\n",
      "Recurrent Neural Network architecture that uses the inferred alignments to\n",
      "learn to generate novel descriptions of image regions. We demonstrate that our\n",
      "alignment model produces state of the art results in retrieval experiments on\n",
      "Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated\n",
      "descriptions significantly outperform retrieval baselines on both full images\n",
      "and on a new dataset of region-level annotations.\n",
      "\n",
      "    \n",
      "347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Inspired by recent work in machine translation and object detection, we\n",
      "introduce an attention based model that automatically learns to describe the\n",
      "content of images. We describe how we can train this model in a deterministic\n",
      "manner using standard backpropagation techniques and stochastically by\n",
      "maximizing a variational lower bound. We also show through visualization how\n",
      "the model is able to automatically learn to fix its gaze on salient objects\n",
      "while generating the corresponding words in the output sequence. We validate\n",
      "the use of attention with state-of-the-art performance on three benchmark\n",
      "datasets: Flickr8k, Flickr30k and MS COCO.\n",
      "\n",
      "    \n",
      "348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automatically describing the content of an image is a fundamental problem in\n",
      "artificial intelligence that connects computer vision and natural language\n",
      "processing. In this paper, we present a generative model based on a deep\n",
      "recurrent architecture that combines recent advances in computer vision and\n",
      "machine translation and that can be used to generate natural sentences\n",
      "describing an image. The model is trained to maximize the likelihood of the\n",
      "target description sentence given the training image. Experiments on several\n",
      "datasets show the accuracy of the model and the fluency of the language it\n",
      "learns solely from image descriptions. Our model is often quite accurate, which\n",
      "we verify both qualitatively and quantitatively. For instance, while the\n",
      "current state-of-the-art BLEU-1 score (the higher the better) on the Pascal\n",
      "dataset is 25, our approach yields 59, to be compared to human performance\n",
      "around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66,\n",
      "and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we\n",
      "achieve a BLEU-4 of 27.7, which is the current state-of-the-art.\n",
      "\n",
      "    \n",
      "349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose the task of free-form and open-ended Visual Question Answering\n",
      "(VQA). Given an image and a natural language question about the image, the task\n",
      "is to provide an accurate natural language answer. Mirroring real-world\n",
      "scenarios, such as helping the visually impaired, both the questions and\n",
      "answers are open-ended. Visual questions selectively target different areas of\n",
      "an image, including background details and underlying context. As a result, a\n",
      "system that succeeds at VQA typically needs a more detailed understanding of\n",
      "the image and complex reasoning than a system producing generic image captions.\n",
      "Moreover, VQA is amenable to automatic evaluation, since many open-ended\n",
      "answers contain only a few words or a closed set of answers that can be\n",
      "provided in a multiple-choice format. We provide a dataset containing ~0.25M\n",
      "images, ~0.76M questions, and ~10M answers (this http URL), and discuss the\n",
      "information it provides. Numerous baselines and methods for VQA are provided\n",
      "and compared with human performance. Our VQA demo is available on CloudCV\n",
      "(this http URL).\n",
      "\n",
      "    \n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We investigate architectures of discriminatively trained deep Convolutional\n",
      "Networks (ConvNets) for action recognition in video. The challenge is to\n",
      "capture the complementary information on appearance from still frames and\n",
      "motion between frames. We also aim to generalise the best performing\n",
      "hand-crafted features within a data-driven learning framework.\n",
      "Our contribution is three-fold. First, we propose a two-stream ConvNet\n",
      "architecture which incorporates spatial and temporal networks. Second, we\n",
      "demonstrate that a ConvNet trained on multi-frame dense optical flow is able to\n",
      "achieve very good performance in spite of limited training data. Finally, we\n",
      "show that multi-task learning, applied to two different action classification\n",
      "datasets, can be used to increase the amount of training data and improve the\n",
      "performance on both.\n",
      "Our architecture is trained and evaluated on the standard video actions\n",
      "benchmarks of UCF-101 and HMDB-51, where it is competitive with the state of\n",
      "the art. It also exceeds by a large margin previous attempts to use deep nets\n",
      "for video classification.\n",
      "\n",
      "    \n",
      "353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional networks are powerful visual models that yield hierarchies of\n",
      "features. We show that convolutional networks by themselves, trained\n",
      "end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic\n",
      "segmentation. Our key insight is to build \"fully convolutional\" networks that\n",
      "take input of arbitrary size and produce correspondingly-sized output with\n",
      "efficient inference and learning. We define and detail the space of fully\n",
      "convolutional networks, explain their application to spatially dense prediction\n",
      "tasks, and draw connections to prior models. We adapt contemporary\n",
      "classification networks (AlexNet, the VGG net, and GoogLeNet) into fully\n",
      "convolutional networks and transfer their learned representations by\n",
      "fine-tuning to the segmentation task. We then define a novel architecture that\n",
      "combines semantic information from a deep, coarse layer with appearance\n",
      "information from a shallow, fine layer to produce accurate and detailed\n",
      "segmentations. Our fully convolutional network achieves state-of-the-art\n",
      "segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012),\n",
      "NYUDv2, and SIFT Flow, while inference takes one third of a second for a\n",
      "typical image.\n",
      "\n",
      "    \n",
      "355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art object detection networks depend on region proposal\n",
      "algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN\n",
      "have reduced the running time of these detection networks, exposing region\n",
      "proposal computation as a bottleneck. In this work, we introduce a Region\n",
      "Proposal Network (RPN) that shares full-image convolutional features with the\n",
      "detection network, thus enabling nearly cost-free region proposals. An RPN is a\n",
      "fully convolutional network that simultaneously predicts object bounds and\n",
      "objectness scores at each position. The RPN is trained end-to-end to generate\n",
      "high-quality region proposals, which are used by Fast R-CNN for detection. We\n",
      "further merge RPN and Fast R-CNN into a single network by sharing their\n",
      "convolutional features---using the recently popular terminology of neural\n",
      "networks with 'attention' mechanisms, the RPN component tells the unified\n",
      "network where to look. For the very deep VGG-16 model, our detection system has\n",
      "a frame rate of 5fps (including all steps) on a GPU, while achieving\n",
      "state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS\n",
      "COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015\n",
      "competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning\n",
      "entries in several tracks. Code has been made publicly available.\n",
      "\n",
      "    \n",
      "356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Object detection performance, as measured on the canonical PASCAL VOC\n",
      "dataset, has plateaued in the last few years. The best-performing methods are\n",
      "complex ensemble systems that typically combine multiple low-level image\n",
      "features with high-level context. In this paper, we propose a simple and\n",
      "scalable detection algorithm that improves mean average precision (mAP) by more\n",
      "than 30% relative to the previous best result on VOC 2012---achieving a mAP of\n",
      "53.3%. Our approach combines two key insights: (1) one can apply high-capacity\n",
      "convolutional neural networks (CNNs) to bottom-up region proposals in order to\n",
      "localize and segment objects and (2) when labeled training data is scarce,\n",
      "supervised pre-training for an auxiliary task, followed by domain-specific\n",
      "fine-tuning, yields a significant performance boost. Since we combine region\n",
      "proposals with CNNs, we call our method R-CNN: Regions with CNN features. We\n",
      "also compare R-CNN to OverFeat, a recently proposed sliding-window detector\n",
      "based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by\n",
      "a large margin on the 200-class ILSVRC2013 detection dataset. Source code for\n",
      "the complete system is available at this http URL.\n",
      "\n",
      "    \n",
      "357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Existing deep convolutional neural networks (CNNs) require a fixed-size\n",
      "(e.g., 224x224) input image. This requirement is \"artificial\" and may reduce\n",
      "the recognition accuracy for the images or sub-images of an arbitrary\n",
      "size/scale. In this work, we equip the networks with another pooling strategy,\n",
      "\"spatial pyramid pooling\", to eliminate the above requirement. The new network\n",
      "structure, called SPP-net, can generate a fixed-length representation\n",
      "regardless of image size/scale. Pyramid pooling is also robust to object\n",
      "deformations. With these advantages, SPP-net should in general improve all\n",
      "CNN-based image classification methods. On the ImageNet 2012 dataset, we\n",
      "demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures\n",
      "despite their different designs. On the Pascal VOC 2007 and Caltech101\n",
      "datasets, SPP-net achieves state-of-the-art classification results using a\n",
      "single full-image representation and no fine-tuning.\n",
      "The power of SPP-net is also significant in object detection. Using SPP-net,\n",
      "we compute the feature maps from the entire image only once, and then pool\n",
      "features in arbitrary regions (sub-images) to generate fixed-length\n",
      "representations for training the detectors. This method avoids repeatedly\n",
      "computing the convolutional features. In processing test images, our method is\n",
      "24-102x faster than the R-CNN method, while achieving better or comparable\n",
      "accuracy on Pascal VOC 2007.\n",
      "In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our\n",
      "methods rank #2 in object detection and #3 in image classification among all 38\n",
      "teams. This manuscript also introduces the improvement made for this\n",
      "competition.\n",
      "\n",
      "    \n",
      "358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Convolutional Neural Networks (DCNNs) have recently shown state of the\n",
      "art performance in high level vision tasks, such as image classification and\n",
      "object detection. This work brings together methods from DCNNs and\n",
      "probabilistic graphical models for addressing the task of pixel-level\n",
      "classification (also called \"semantic image segmentation\"). We show that\n",
      "responses at the final layer of DCNNs are not sufficiently localized for\n",
      "accurate object segmentation. This is due to the very invariance properties\n",
      "that make DCNNs good for high level tasks. We overcome this poor localization\n",
      "property of deep networks by combining the responses at the final DCNN layer\n",
      "with a fully connected Conditional Random Field (CRF). Qualitatively, our\n",
      "\"DeepLab\" system is able to localize segment boundaries at a level of accuracy\n",
      "which is beyond previous methods. Quantitatively, our method sets the new\n",
      "state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching\n",
      "71.6% IOU accuracy in the test set. We show how these results can be obtained\n",
      "efficiently: Careful network re-purposing and a novel application of the 'hole'\n",
      "algorithm from the wavelet community allow dense computation of neural net\n",
      "responses at 8 frames per second on a modern GPU.\n",
      "\n",
      "    \n",
      "359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional networks are at the core of most state-of-the-art computer\n",
      "vision solutions for a wide variety of tasks. Since 2014 very deep\n",
      "convolutional networks started to become mainstream, yielding substantial gains\n",
      "in various benchmarks. Although increased model size and computational cost\n",
      "tend to translate to immediate quality gains for most tasks (as long as enough\n",
      "labeled data is provided for training), computational efficiency and low\n",
      "parameter count are still enabling factors for various use cases such as mobile\n",
      "vision and big-data scenarios. Here we explore ways to scale up networks in\n",
      "ways that aim at utilizing the added computation as efficiently as possible by\n",
      "suitably factorized convolutions and aggressive regularization. We benchmark\n",
      "our methods on the ILSVRC 2012 classification challenge validation set\n",
      "demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%\n",
      "top-5 error for single frame evaluation using a network with a computational\n",
      "cost of 5 billion multiply-adds per inference and with using less than 25\n",
      "million parameters. With an ensemble of 4 models and multi-crop evaluation, we\n",
      "report 3.5% top-5 error on the validation set (3.6% error on the test set) and\n",
      "17.3% top-1 error on the validation set.\n",
      "\n",
      "    \n",
      "361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Very deep convolutional networks have been central to the largest advances in\n",
      "image recognition performance in recent years. One example is the Inception\n",
      "architecture that has been shown to achieve very good performance at relatively\n",
      "low computational cost. Recently, the introduction of residual connections in\n",
      "conjunction with a more traditional architecture has yielded state-of-the-art\n",
      "performance in the 2015 ILSVRC challenge; its performance was similar to the\n",
      "latest generation Inception-v3 network. This raises the question of whether\n",
      "there are any benefit in combining the Inception architecture with residual\n",
      "connections. Here we give clear empirical evidence that training with residual\n",
      "connections accelerates the training of Inception networks significantly. There\n",
      "is also some evidence of residual Inception networks outperforming similarly\n",
      "expensive Inception networks without residual connections by a thin margin. We\n",
      "also present several new streamlined architectures for both residual and\n",
      "non-residual Inception networks. These variations improve the single-frame\n",
      "recognition performance on the ILSVRC 2012 classification task significantly.\n",
      "We further demonstrate how proper activation scaling stabilizes the training of\n",
      "very wide residual Inception networks. With an ensemble of three residual and\n",
      "one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the\n",
      "ImageNet classification (CLS) challenge\n",
      "\n",
      "    \n",
      "362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep residual networks have emerged as a family of extremely deep\n",
      "architectures showing compelling accuracy and nice convergence behaviors. In\n",
      "this paper, we analyze the propagation formulations behind the residual\n",
      "building blocks, which suggest that the forward and backward signals can be\n",
      "directly propagated from one block to any other block, when using identity\n",
      "mappings as the skip connections and after-addition activation. A series of\n",
      "ablation experiments support the importance of these identity mappings. This\n",
      "motivates us to propose a new residual unit, which makes training easier and\n",
      "improves generalization. We report improved results using a 1001-layer ResNet\n",
      "on CIFAR-10 (4.62% error) and CIFAR-100, and a 200-layer ResNet on ImageNet.\n",
      "Code is available at: this https URL\n",
      "\n",
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deeper neural networks are more difficult to train. We present a residual\n",
      "learning framework to ease the training of networks that are substantially\n",
      "deeper than those used previously. We explicitly reformulate the layers as\n",
      "learning residual functions with reference to the layer inputs, instead of\n",
      "learning unreferenced functions. We provide comprehensive empirical evidence\n",
      "showing that these residual networks are easier to optimize, and can gain\n",
      "accuracy from considerably increased depth. On the ImageNet dataset we evaluate\n",
      "residual nets with a depth of up to 152 layers---8x deeper than VGG nets but\n",
      "still having lower complexity. An ensemble of these residual nets achieves\n",
      "3.57% error on the ImageNet test set. This result won the 1st place on the\n",
      "ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\n",
      "and 1000 layers.\n",
      "The depth of representations is of central importance for many visual\n",
      "recognition tasks. Solely due to our extremely deep representations, we obtain\n",
      "a 28% relative improvement on the COCO object detection dataset. Deep residual\n",
      "nets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\n",
      "where we also won the 1st places on the tasks of ImageNet detection, ImageNet\n",
      "localization, COCO detection, and COCO segmentation.\n",
      "\n",
      "    \n",
      "364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks define an exceptionally powerful class of\n",
      "models, but are still limited by the lack of ability to be spatially invariant\n",
      "to the input data in a computationally and parameter efficient manner. In this\n",
      "work we introduce a new learnable module, the Spatial Transformer, which\n",
      "explicitly allows the spatial manipulation of data within the network. This\n",
      "differentiable module can be inserted into existing convolutional\n",
      "architectures, giving neural networks the ability to actively spatially\n",
      "transform feature maps, conditional on the feature map itself, without any\n",
      "extra training supervision or modification to the optimisation process. We show\n",
      "that the use of spatial transformers results in models which learn invariance\n",
      "to translation, scale, rotation and more generic warping, resulting in\n",
      "state-of-the-art performance on several benchmarks, and for a number of classes\n",
      "of transformations.\n",
      "\n",
      "    \n",
      "365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a deep convolutional neural network architecture codenamed\n",
      "\"Inception\", which was responsible for setting the new state of the art for\n",
      "classification and detection in the ImageNet Large-Scale Visual Recognition\n",
      "Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the\n",
      "improved utilization of the computing resources inside the network. This was\n",
      "achieved by a carefully crafted design that allows for increasing the depth and\n",
      "width of the network while keeping the computational budget constant. To\n",
      "optimize quality, the architectural decisions were based on the Hebbian\n",
      "principle and the intuition of multi-scale processing. One particular\n",
      "incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22\n",
      "layers deep network, the quality of which is assessed in the context of\n",
      "classification and detection.\n",
      "\n",
      "    \n",
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work we investigate the effect of the convolutional network depth on\n",
      "its accuracy in the large-scale image recognition setting. Our main\n",
      "contribution is a thorough evaluation of networks of increasing depth using an\n",
      "architecture with very small (3x3) convolution filters, which shows that a\n",
      "significant improvement on the prior-art configurations can be achieved by\n",
      "pushing the depth to 16-19 weight layers. These findings were the basis of our\n",
      "ImageNet Challenge 2014 submission, where our team secured the first and the\n",
      "second places in the localisation and classification tracks respectively. We\n",
      "also show that our representations generalise well to other datasets, where\n",
      "they achieve state-of-the-art results. We have made our two best-performing\n",
      "ConvNet models publicly available to facilitate further research on the use of\n",
      "deep visual representations in computer vision.\n",
      "\n",
      "    \n",
      "367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The latest generation of Convolutional Neural Networks (CNN) have achieved\n",
      "impressive results in challenging benchmarks on image recognition and object\n",
      "detection, significantly raising the interest of the community in these\n",
      "methods. Nevertheless, it is still unclear how different CNN methods compare\n",
      "with each other and with previous state-of-the-art shallow representations such\n",
      "as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts\n",
      "a rigorous evaluation of these new techniques, exploring different deep\n",
      "architectures and comparing them on a common ground, identifying and disclosing\n",
      "important implementation details. We identify several useful properties of\n",
      "CNN-based representations, including the fact that the dimensionality of the\n",
      "CNN output layer can be reduced significantly without having an adverse effect\n",
      "on performance. We also identify aspects of deep and shallow methods that can\n",
      "be successfully shared. In particular, we show that the data augmentation\n",
      "techniques commonly applied to CNN-based methods can also be applied to shallow\n",
      "methods, and result in an analogous performance boost. Source code and models\n",
      "to reproduce the experiments in the paper is made publicly available.\n",
      "\n",
      "    \n",
      "368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an integrated framework for using Convolutional Networks for\n",
      "classification, localization and detection. We show how a multiscale and\n",
      "sliding window approach can be efficiently implemented within a ConvNet. We\n",
      "also introduce a novel deep learning approach to localization by learning to\n",
      "predict object boundaries. Bounding boxes are then accumulated rather than\n",
      "suppressed in order to increase detection confidence. We show that different\n",
      "tasks can be learned simultaneously using a single shared network. This\n",
      "integrated framework is the winner of the localization task of the ImageNet\n",
      "Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very\n",
      "competitive results for the detection and classifications tasks. In\n",
      "post-competition work, we establish a new state of the art for the detection\n",
      "task. Finally, we release a feature extractor from our best model called\n",
      "OverFeat.\n",
      "\n",
      "    \n",
      "369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of designing models to leverage a recently introduced\n",
      "approximate model averaging technique called dropout. We define a simple new\n",
      "model called maxout (so named because its output is the max of a set of inputs,\n",
      "and because it is a natural companion to dropout) designed to both facilitate\n",
      "optimization by dropout and improve the accuracy of dropout's fast approximate\n",
      "model averaging technique. We empirically verify that the model successfully\n",
      "accomplishes both of these tasks. We use maxout and dropout to demonstrate\n",
      "state of the art classification performance on four benchmark datasets: MNIST,\n",
      "CIFAR-10, CIFAR-100, and SVHN.\n",
      "\n",
      "    \n",
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a novel deep network structure called \"Network In Network\" (NIN)\n",
      "to enhance model discriminability for local patches within the receptive field.\n",
      "The conventional convolutional layer uses linear filters followed by a\n",
      "nonlinear activation function to scan the input. Instead, we build micro neural\n",
      "networks with more complex structures to abstract the data within the receptive\n",
      "field. We instantiate the micro neural network with a multilayer perceptron,\n",
      "which is a potent function approximator. The feature maps are obtained by\n",
      "sliding the micro networks over the input in a similar manner as CNN; they are\n",
      "then fed into the next layer. Deep NIN can be implemented by stacking mutiple\n",
      "of the above described structure. With enhanced local modeling via the micro\n",
      "network, we are able to utilize global average pooling over feature maps in the\n",
      "classification layer, which is easier to interpret and less prone to\n",
      "overfitting than traditional fully connected layers. We demonstrated the\n",
      "state-of-the-art classification performances with NIN on CIFAR-10 and\n",
      "CIFAR-100, and reasonable performances on SVHN and MNIST datasets.\n",
      "\n",
      "    \n",
      "371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modeling the distribution of natural images is a landmark problem in\n",
      "unsupervised learning. This task requires an image model that is at once\n",
      "expressive, tractable and scalable. We present a deep neural network that\n",
      "sequentially predicts the pixels in an image along the two spatial dimensions.\n",
      "Our method models the discrete probability of the raw pixel values and encodes\n",
      "the complete set of dependencies in the image. Architectural novelties include\n",
      "fast two-dimensional recurrent layers and an effective use of residual\n",
      "connections in deep recurrent networks. We achieve log-likelihood scores on\n",
      "natural images that are considerably better than the previous state of the art.\n",
      "Our main results also provide benchmarks on the diverse ImageNet dataset.\n",
      "Samples generated from the model appear crisp, varied and globally coherent.\n",
      "\n",
      "    \n",
      "372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a variety of new architectural features and training procedures\n",
      "that we apply to the generative adversarial networks (GANs) framework. We focus\n",
      "on two applications of GANs: semi-supervised learning, and the generation of\n",
      "images that humans find visually realistic. Unlike most work on generative\n",
      "models, our primary goal is not to train a model that assigns high likelihood\n",
      "to test data, nor do we require the model to be able to learn well without\n",
      "using any labels. Using our new techniques, we achieve state-of-the-art results\n",
      "in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated\n",
      "images are of high quality as confirmed by a visual Turing test: our model\n",
      "generates MNIST samples that humans cannot distinguish from real data, and\n",
      "CIFAR-10 samples that yield a human error rate of 21.3%. We also present\n",
      "ImageNet samples with unprecedented resolution and show that our methods enable\n",
      "the model to learn recognizable features of ImageNet classes.\n",
      "\n",
      "    \n",
      "373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In recent years, supervised learning with convolutional networks (CNNs) has\n",
      "seen huge adoption in computer vision applications. Comparatively, unsupervised\n",
      "learning with CNNs has received less attention. In this work we hope to help\n",
      "bridge the gap between the success of CNNs for supervised learning and\n",
      "unsupervised learning. We introduce a class of CNNs called deep convolutional\n",
      "generative adversarial networks (DCGANs), that have certain architectural\n",
      "constraints, and demonstrate that they are a strong candidate for unsupervised\n",
      "learning. Training on various image datasets, we show convincing evidence that\n",
      "our deep convolutional adversarial pair learns a hierarchy of representations\n",
      "from object parts to scenes in both the generator and discriminator.\n",
      "Additionally, we use the learned features for novel tasks - demonstrating their\n",
      "applicability as general image representations.\n",
      "\n",
      "    \n",
      "374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural\n",
      "network architecture for image generation. DRAW networks combine a novel\n",
      "spatial attention mechanism that mimics the foveation of the human eye, with a\n",
      "sequential variational auto-encoding framework that allows for the iterative\n",
      "construction of complex images. The system substantially improves on the state\n",
      "of the art for generative models on MNIST, and, when trained on the Street View\n",
      "House Numbers dataset, it generates images that cannot be distinguished from\n",
      "real data with the naked eye.\n",
      "\n",
      "    \n",
      "375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a new framework for estimating generative models via an\n",
      "adversarial process, in which we simultaneously train two models: a generative\n",
      "model G that captures the data distribution, and a discriminative model D that\n",
      "estimates the probability that a sample came from the training data rather than\n",
      "G. The training procedure for G is to maximize the probability of D making a\n",
      "mistake. This framework corresponds to a minimax two-player game. In the space\n",
      "of arbitrary functions G and D, a unique solution exists, with G recovering the\n",
      "training data distribution and D equal to 1/2 everywhere. In the case where G\n",
      "and D are defined by multilayer perceptrons, the entire system can be trained\n",
      "with backpropagation. There is no need for any Markov chains or unrolled\n",
      "approximate inference networks during either training or generation of samples.\n",
      "Experiments demonstrate the potential of the framework through qualitative and\n",
      "quantitative evaluation of the generated samples.\n",
      "\n",
      "    \n",
      "376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  How can we perform efficient inference and learning in directed probabilistic\n",
      "models, in the presence of continuous latent variables with intractable\n",
      "posterior distributions, and large datasets? We introduce a stochastic\n",
      "variational inference and learning algorithm that scales to large datasets and,\n",
      "under some mild differentiability conditions, even works in the intractable\n",
      "case. Our contributions is two-fold. First, we show that a reparameterization\n",
      "of the variational lower bound yields a lower bound estimator that can be\n",
      "straightforwardly optimized using standard stochastic gradient methods. Second,\n",
      "we show that for i.i.d. datasets with continuous latent variables per\n",
      "datapoint, posterior inference can be made especially efficient by fitting an\n",
      "approximate inference model (also called a recognition model) to the\n",
      "intractable posterior using the proposed lower bound estimator. Theoretical\n",
      "advantages are reflected in experimental results.\n",
      "\n",
      "    \n",
      "377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of building high-level, class-specific feature\n",
      "detectors from only unlabeled data. For example, is it possible to learn a face\n",
      "detector using only unlabeled images? To answer this, we train a 9-layered\n",
      "locally connected sparse autoencoder with pooling and local contrast\n",
      "normalization on a large dataset of images (the model has 1 billion\n",
      "connections, the dataset has 10 million 200x200 pixel images downloaded from\n",
      "the Internet). We train this network using model parallelism and asynchronous\n",
      "SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to\n",
      "what appears to be a widely-held intuition, our experimental results reveal\n",
      "that it is possible to train a face detector without having to label images as\n",
      "containing a face or not. Control experiments show that this feature detector\n",
      "is robust not only to translation but also to scaling and out-of-plane\n",
      "rotation. We also find that the same network is sensitive to other high-level\n",
      "concepts such as cat faces and human bodies. Starting with these learned\n",
      "features, we trained our network to obtain 15.8% accuracy in recognizing 20,000\n",
      "object categories from ImageNet, a leap of 70% relative improvement over the\n",
      "previous state-of-the-art.\n",
      "\n",
      "    \n",
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Theoretical and empirical evidence indicates that the depth of neural\n",
      "networks is crucial for their success. However, training becomes more difficult\n",
      "as depth increases, and training of very deep networks remains an open problem.\n",
      "Here we introduce a new architecture designed to overcome this. Our so-called\n",
      "highway networks allow unimpeded information flow across many layers on\n",
      "information highways. They are inspired by Long Short-Term Memory recurrent\n",
      "networks and use adaptive gating units to regulate the information flow. Even\n",
      "with hundreds of layers, highway networks can be trained directly through\n",
      "simple gradient descent. This enables the study of extremely deep and efficient\n",
      "architectures.\n",
      "\n",
      "    \n",
      "379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training Deep Neural Networks is complicated by the fact that the\n",
      "distribution of each layer's inputs changes during training, as the parameters\n",
      "of the previous layers change. This slows down the training by requiring lower\n",
      "learning rates and careful parameter initialization, and makes it notoriously\n",
      "hard to train models with saturating nonlinearities. We refer to this\n",
      "phenomenon as internal covariate shift, and address the problem by normalizing\n",
      "layer inputs. Our method draws its strength from making normalization a part of\n",
      "the model architecture and performing the normalization for each training\n",
      "mini-batch. Batch Normalization allows us to use much higher learning rates and\n",
      "be less careful about initialization. It also acts as a regularizer, in some\n",
      "cases eliminating the need for Dropout. Applied to a state-of-the-art image\n",
      "classification model, Batch Normalization achieves the same accuracy with 14\n",
      "times fewer training steps, and beats the original model by a significant\n",
      "margin. Using an ensemble of batch-normalized networks, we improve upon the\n",
      "best published result on ImageNet classification: reaching 4.9% top-5\n",
      "validation error (and 4.8% test error), exceeding the accuracy of human raters.\n",
      "\n",
      "    \n",
      "380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Rectified activation units (rectifiers) are essential for state-of-the-art\n",
      "neural networks. In this work, we study rectifier neural networks for image\n",
      "classification from two aspects. First, we propose a Parametric Rectified\n",
      "Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU\n",
      "improves model fitting with nearly zero extra computational cost and little\n",
      "overfitting risk. Second, we derive a robust initialization method that\n",
      "particularly considers the rectifier nonlinearities. This method enables us to\n",
      "train extremely deep rectified models directly from scratch and to investigate\n",
      "deeper or wider network architectures. Based on our PReLU networks\n",
      "(PReLU-nets), we achieve 4.94% top-5 test error on the ImageNet 2012\n",
      "classification dataset. This is a 26% relative improvement over the ILSVRC 2014\n",
      "winner (GoogLeNet, 6.66%). To our knowledge, our result is the first to surpass\n",
      "human-level performance (5.1%, Russakovsky et al.) on this visual recognition\n",
      "challenge.\n",
      "\n",
      "    \n",
      "381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce Adam, an algorithm for first-order gradient-based optimization\n",
      "of stochastic objective functions, based on adaptive estimates of lower-order\n",
      "moments. The method is straightforward to implement, is computationally\n",
      "efficient, has little memory requirements, is invariant to diagonal rescaling\n",
      "of the gradients, and is well suited for problems that are large in terms of\n",
      "data and/or parameters. The method is also appropriate for non-stationary\n",
      "objectives and problems with very noisy and/or sparse gradients. The\n",
      "hyper-parameters have intuitive interpretations and typically require little\n",
      "tuning. Some connections to related algorithms, on which Adam was inspired, are\n",
      "discussed. We also analyze the theoretical convergence properties of the\n",
      "algorithm and provide a regret bound on the convergence rate that is comparable\n",
      "to the best known results under the online convex optimization framework.\n",
      "Empirical results demonstrate that Adam works well in practice and compares\n",
      "favorably to other stochastic optimization methods. Finally, we discuss AdaMax,\n",
      "a variant of Adam based on the infinity norm.\n",
      "\n",
      "    \n",
      "382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  When a large feedforward neural network is trained on a small training set,\n",
      "it typically performs poorly on held-out test data. This \"overfitting\" is\n",
      "greatly reduced by randomly omitting half of the feature detectors on each\n",
      "training case. This prevents complex co-adaptations in which a feature detector\n",
      "is only helpful in the context of several other specific feature detectors.\n",
      "Instead, each neuron learns to detect a feature that is generally helpful for\n",
      "producing the correct answer given the combinatorially large variety of\n",
      "internal contexts in which it must operate. Random \"dropout\" gives big\n",
      "improvements on many benchmark tasks and sets new records for speech and object\n",
      "recognition.\n",
      "\n",
      "    \n",
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training state-of-the-art, deep neural networks is computationally expensive.\n",
      "One way to reduce the training time is to normalize the activities of the\n",
      "neurons. A recently introduced technique called batch normalization uses the\n",
      "distribution of the summed input to a neuron over a mini-batch of training\n",
      "cases to compute a mean and variance which are then used to normalize the\n",
      "summed input to that neuron on each training case. This significantly reduces\n",
      "the training time in feed-forward neural networks. However, the effect of batch\n",
      "normalization is dependent on the mini-batch size and it is not obvious how to\n",
      "apply it to recurrent neural networks. In this paper, we transpose batch\n",
      "normalization into layer normalization by computing the mean and variance used\n",
      "for normalization from all of the summed inputs to the neurons in a layer on a\n",
      "single training case. Like batch normalization, we also give each neuron its\n",
      "own adaptive bias and gain which are applied after the normalization but before\n",
      "the non-linearity. Unlike batch normalization, layer normalization performs\n",
      "exactly the same computation at training and test times. It is also\n",
      "straightforward to apply to recurrent neural networks by computing the\n",
      "normalization statistics separately at each time step. Layer normalization is\n",
      "very effective at stabilizing the hidden state dynamics in recurrent networks.\n",
      "Empirically, we show that layer normalization can substantially reduce the\n",
      "training time compared with previously published techniques.\n",
      "\n",
      "    \n",
      "384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The move from hand-designed features to learned features in machine learning\n",
      "has been wildly successful. In spite of this, optimization algorithms are still\n",
      "designed by hand. In this paper we show how the design of an optimization\n",
      "algorithm can be cast as a learning problem, allowing the algorithm to learn to\n",
      "exploit structure in the problems of interest in an automatic way. Our learned\n",
      "algorithms, implemented by LSTMs, outperform generic, hand-designed competitors\n",
      "on the tasks for which they are trained, and also generalize well to new tasks\n",
      "with similar structure. We demonstrate this on a number of tasks, including\n",
      "simple convex problems, training neural networks, and styling images with\n",
      "neural art.\n",
      "\n",
      "    \n",
      "385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Given a grayscale photograph as input, this paper attacks the problem of\n",
      "hallucinating a plausible color version of the photograph. This problem is\n",
      "clearly underconstrained, so previous approaches have either relied on\n",
      "significant user interaction or resulted in desaturated colorizations. We\n",
      "propose a fully automatic approach that produces vibrant and realistic\n",
      "colorizations. We embrace the underlying uncertainty of the problem by posing\n",
      "it as a classification task and use class-rebalancing at training time to\n",
      "increase the diversity of colors in the result. The system is implemented as a\n",
      "feed-forward pass in a CNN at test time and is trained on over a million color\n",
      "images. We evaluate our algorithm using a \"colorization Turing test,\" asking\n",
      "human participants to choose between a generated and ground truth color image.\n",
      "Our method successfully fools humans on 32% of the trials, significantly higher\n",
      "than previous methods. Moreover, we show that colorization can be a powerful\n",
      "pretext task for self-supervised feature learning, acting as a cross-channel\n",
      "encoder. This approach results in state-of-the-art performance on several\n",
      "feature learning benchmarks.\n",
      "\n",
      "    \n",
      "386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Realistic image manipulation is challenging because it requires modifying the\n",
      "image appearance in a user-controlled way, while preserving the realism of the\n",
      "result. Unless the user has considerable artistic skill, it is easy to \"fall\n",
      "off\" the manifold of natural images while editing. In this paper, we propose to\n",
      "learn the natural image manifold directly from data using a generative\n",
      "adversarial neural network. We then define a class of image editing operations,\n",
      "and constrain their output to lie on that learned manifold at all times. The\n",
      "model automatically adjusts the output keeping all edits as realistic as\n",
      "possible. All our manipulations are expressed in terms of constrained\n",
      "optimization and are applied in near-real time. We evaluate our algorithm on\n",
      "the task of realistic photo manipulation of shape and color. The presented\n",
      "method can further be used for changing one image to look like the other, as\n",
      "well as generating novel imagery from scratch based on user's scribbles.\n",
      "\n",
      "    \n",
      "387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Gatys et al. recently demonstrated that deep networks can generate beautiful\n",
      "textures and stylized images from a single texture example. However, their\n",
      "methods requires a slow and memory-consuming optimization process. We propose\n",
      "here an alternative approach that moves the computational burden to a learning\n",
      "stage. Given a single example of a texture, our approach trains compact\n",
      "feed-forward convolutional networks to generate multiple samples of the same\n",
      "texture of arbitrary size and to transfer artistic style from a given image to\n",
      "any other image. The resulting networks are remarkably light-weight and can\n",
      "generate textures of quality comparable to Gatys~et~al., but hundreds of times\n",
      "faster. More generally, our approach highlights the power and flexibility of\n",
      "generative feed-forward models trained with complex and expressive loss\n",
      "functions.\n",
      "\n",
      "    \n",
      "388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent research on deep neural networks has focused primarily on improving\n",
      "accuracy. For a given accuracy level, it is typically possible to identify\n",
      "multiple DNN architectures that achieve that accuracy level. With equivalent\n",
      "accuracy, smaller DNN architectures offer at least three advantages: (1)\n",
      "Smaller DNNs require less communication across servers during distributed\n",
      "training. (2) Smaller DNNs require less bandwidth to export a new model from\n",
      "the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on\n",
      "FPGAs and other hardware with limited memory. To provide all of these\n",
      "advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet\n",
      "achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.\n",
      "Additionally, with model compression techniques we are able to compress\n",
      "SqueezeNet to less than 0.5MB (510x smaller than AlexNet).\n",
      "The SqueezeNet architecture is available for download here:\n",
      "this https URL\n",
      "\n",
      "389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art deep neural networks (DNNs) have hundreds of millions of\n",
      "connections and are both computationally and memory intensive, making them\n",
      "difficult to deploy on embedded systems with limited hardware resources and\n",
      "power budgets. While custom hardware helps the computation, fetching weights\n",
      "from DRAM is two orders of magnitude more expensive than ALU operations, and\n",
      "dominates the required power.\n",
      "Previously proposed 'Deep Compression' makes it possible to fit large DNNs\n",
      "(AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by\n",
      "pruning the redundant connections and having multiple connections share the\n",
      "same weight. We propose an energy efficient inference engine (EIE) that\n",
      "performs inference on this compressed network model and accelerates the\n",
      "resulting sparse matrix-vector multiplication with weight sharing. Going from\n",
      "DRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x;\n",
      "Weight sharing gives 8x; Skipping zero activations from ReLU saves another 3x.\n",
      "Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to\n",
      "CPU and GPU implementations of the same DNN without compression. EIE has a\n",
      "processing power of 102GOPS/s working directly on a compressed network,\n",
      "corresponding to 3TOPS/s on an uncompressed network, and processes FC layers of\n",
      "AlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is\n",
      "24,000x and 3,400x more energy efficient than a CPU and GPU respectively.\n",
      "Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy\n",
      "efficiency and area efficiency.\n",
      "\n",
      "    \n",
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a method to train Binarized Neural Networks (BNNs) - neural\n",
      "networks with binary weights and activations at run-time. At training-time the\n",
      "binary weights and activations are used for computing the parameters gradients.\n",
      "During the forward pass, BNNs drastically reduce memory size and accesses, and\n",
      "replace most arithmetic operations with bit-wise operations, which is expected\n",
      "to substantially improve power-efficiency. To validate the effectiveness of\n",
      "BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On\n",
      "both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10\n",
      "and SVHN datasets. Last but not least, we wrote a binary matrix multiplication\n",
      "GPU kernel with which it is possible to run our MNIST BNN 7 times faster than\n",
      "with an unoptimized GPU kernel, without suffering any loss in classification\n",
      "accuracy. The code for training and running our BNNs is available on-line.\n",
      "\n",
      "    \n",
      "391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural network architectures with memory and attention mechanisms exhibit\n",
      "certain reasoning capabilities required for question answering. One such\n",
      "architecture, the dynamic memory network (DMN), obtained high accuracy on a\n",
      "variety of language tasks. However, it was not shown whether the architecture\n",
      "achieves strong results for question answering when supporting facts are not\n",
      "marked during training or whether it could be applied to other modalities such\n",
      "as images. Based on an analysis of the DMN, we propose several improvements to\n",
      "its memory and input modules. Together with these changes we introduce a novel\n",
      "input module for images in order to be able to answer visual questions. Our new\n",
      "DMN+ model improves the state of the art on both the Visual Question Answering\n",
      "dataset and the \\babi-10k text question-answering dataset without supporting\n",
      "fact supervision.\n",
      "\n",
      "    \n",
      "392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents stacked attention networks (SANs) that learn to answer\n",
      "natural language questions from images. SANs use semantic representation of a\n",
      "question as query to search for the regions in an image that are related to the\n",
      "answer. We argue that image question answering (QA) often requires multiple\n",
      "steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\n",
      "image multiple times to infer the answer progressively. Experiments conducted\n",
      "on four image QA data sets demonstrate that the proposed SANs significantly\n",
      "outperform previous state-of-the-art approaches. The visualization of the\n",
      "attention layers illustrates the progress that the SAN locates the relevant\n",
      "visual clues that lead to the answer of the question layer-by-layer.\n",
      "\n",
      "    \n",
      "393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural Machine Translation (NMT) is an end-to-end learning approach for\n",
      "automated translation, with the potential to overcome many of the weaknesses of\n",
      "conventional phrase-based translation systems. Unfortunately, NMT systems are\n",
      "known to be computationally expensive both in training and in translation\n",
      "inference. Also, most NMT systems have difficulty with rare words. These issues\n",
      "have hindered NMT's use in practical deployments and services, where both\n",
      "accuracy and speed are essential. In this work, we present GNMT, Google's\n",
      "Neural Machine Translation system, which attempts to address many of these\n",
      "issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder\n",
      "layers using attention and residual connections. To improve parallelism and\n",
      "therefore decrease training time, our attention mechanism connects the bottom\n",
      "layer of the decoder to the top layer of the encoder. To accelerate the final\n",
      "translation speed, we employ low-precision arithmetic during inference\n",
      "computations. To improve handling of rare words, we divide words into a limited\n",
      "set of common sub-word units (\"wordpieces\") for both input and output. This\n",
      "method provides a good balance between the flexibility of \"character\"-delimited\n",
      "models and the efficiency of \"word\"-delimited models, naturally handles\n",
      "translation of rare words, and ultimately improves the overall accuracy of the\n",
      "system. Our beam search technique employs a length-normalization procedure and\n",
      "uses a coverage penalty, which encourages generation of an output sentence that\n",
      "is most likely to cover all the words in the source sentence. On the WMT'14\n",
      "English-to-French and English-to-German benchmarks, GNMT achieves competitive\n",
      "results to state-of-the-art. Using a human side-by-side evaluation on a set of\n",
      "isolated simple sentences, it reduces translation errors by an average of 60%\n",
      "compared to Google's phrase-based production system.\n",
      "\n",
      "    \n",
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a class of efficient models called MobileNets for mobile and\n",
      "embedded vision applications. MobileNets are based on a streamlined\n",
      "architecture that uses depth-wise separable convolutions to build light weight\n",
      "deep neural networks. We introduce two simple global hyper-parameters that\n",
      "efficiently trade off between latency and accuracy. These hyper-parameters\n",
      "allow the model builder to choose the right sized model for their application\n",
      "based on the constraints of the problem. We present extensive experiments on\n",
      "resource and accuracy tradeoffs and show strong performance compared to other\n",
      "popular models on ImageNet classification. We then demonstrate the\n",
      "effectiveness of MobileNets across a wide range of applications and use cases\n",
      "including object detection, finegrain classification, face attributes and large\n",
      "scale geo-localization.\n",
      "\n",
      "    \n",
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The prevalent approach to sequence to sequence learning maps an input\n",
      "sequence to a variable length output sequence via recurrent neural networks. We\n",
      "introduce an architecture based entirely on convolutional neural networks.\n",
      "Compared to recurrent models, computations over all elements can be fully\n",
      "parallelized during training and optimization is easier since the number of\n",
      "non-linearities is fixed and independent of the input length. Our use of gated\n",
      "linear units eases gradient propagation and we equip each decoder layer with a\n",
      "separate attention module. We outperform the accuracy of the deep LSTM setup of\n",
      "Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French\n",
      "translation at an order of magnitude faster speed, both on GPU and CPU.\n",
      "\n",
      "    \n",
      "396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural network models are capable of generating extremely natural sounding\n",
      "conversational interactions. Nevertheless, these models have yet to demonstrate\n",
      "that they can incorporate content in the form of factual information or\n",
      "entity-grounded opinion that would enable them to serve in more task-oriented\n",
      "conversational applications. This paper presents a novel, fully data-driven,\n",
      "and knowledge-grounded neural conversation model aimed at producing more\n",
      "contentful responses without slot filling. We generalize the widely-used\n",
      "Seq2Seq approach by conditioning responses on both conversation history and\n",
      "external \"facts\", allowing the model to be versatile and applicable in an\n",
      "open-domain setting. Our approach yields significant improvements over a\n",
      "competitive Seq2Seq baseline. Human judges found that our outputs are\n",
      "significantly more informative.\n",
      "\n",
      "    \n",
      "397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Transfer learning, where a model is first pre-trained on a data-rich task\n",
      "before being fine-tuned on a downstream task, has emerged as a powerful\n",
      "technique in natural language processing (NLP). The effectiveness of transfer\n",
      "learning has given rise to a diversity of approaches, methodology, and\n",
      "practice. In this paper, we explore the landscape of transfer learning\n",
      "techniques for NLP by introducing a unified framework that converts every\n",
      "language problem into a text-to-text format. Our systematic study compares\n",
      "pre-training objectives, architectures, unlabeled datasets, transfer\n",
      "approaches, and other factors on dozens of language understanding tasks. By\n",
      "combining the insights from our exploration with scale and our new \"Colossal\n",
      "Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks\n",
      "covering summarization, question answering, text classification, and more. To\n",
      "facilitate future work on transfer learning for NLP, we release our dataset,\n",
      "pre-trained models, and code.\n",
      "\n",
      "    \n",
      "398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A text-to-speech synthesis system typically consists of multiple stages, such\n",
      "as a text analysis frontend, an acoustic model and an audio synthesis module.\n",
      "Building these components often requires extensive domain expertise and may\n",
      "contain brittle design choices. In this paper, we present Tacotron, an\n",
      "end-to-end generative text-to-speech model that synthesizes speech directly\n",
      "from characters. Given <text, audio> pairs, the model can be trained completely\n",
      "from scratch with random initialization. We present several key techniques to\n",
      "make the sequence-to-sequence framework perform well for this challenging task.\n",
      "Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\n",
      "outperforming a production parametric system in terms of naturalness. In\n",
      "addition, since Tacotron generates speech at the frame level, it's\n",
      "substantially faster than sample-level autoregressive methods.\n",
      "\n",
      "    \n",
      "399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces a deep-learning approach to photographic style transfer\n",
      "that handles a large variety of image content while faithfully transferring the\n",
      "reference style. Our approach builds upon the recent work on painterly transfer\n",
      "that separates style from the content of an image by considering different\n",
      "layers of a neural network. However, as is, this approach is not suitable for\n",
      "photorealistic style transfer. Even when both the input and reference images\n",
      "are photographs, the output still exhibits distortions reminiscent of a\n",
      "painting. Our contribution is to constrain the transformation from the input to\n",
      "the output to be locally affine in colorspace, and to express this constraint\n",
      "as a custom fully differentiable energy term. We show that this approach\n",
      "successfully suppresses distortion and yields satisfying photorealistic style\n",
      "transfers in a broad variety of scenarios, including transfer of the time of\n",
      "day, weather, season, and artistic edits.\n",
      "\n",
      "    \n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore the use of Evolution Strategies (ES), a class of black box\n",
      "optimization algorithms, as an alternative to popular MDP-based RL techniques\n",
      "such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\n",
      "that ES is a viable solution strategy that scales extremely well with the\n",
      "number of CPUs available: By using a novel communication strategy based on\n",
      "common random numbers, our ES implementation only needs to communicate scalars,\n",
      "making it possible to scale to over a thousand parallel workers. This allows us\n",
      "to solve 3D humanoid walking in 10 minutes and obtain competitive results on\n",
      "most Atari games after one hour of training. In addition, we highlight several\n",
      "advantages of ES as a black box optimization technique: it is invariant to\n",
      "action frequency and delayed rewards, tolerant of extremely long horizons, and\n",
      "does not need temporal discounting or value function approximation.\n",
      "\n",
      "    \n",
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional neural networks (CNNs) are inherently limited to model\n",
      "geometric transformations due to the fixed geometric structures in its building\n",
      "modules. In this work, we introduce two new modules to enhance the\n",
      "transformation modeling capacity of CNNs, namely, deformable convolution and\n",
      "deformable RoI pooling. Both are based on the idea of augmenting the spatial\n",
      "sampling locations in the modules with additional offsets and learning the\n",
      "offsets from target tasks, without additional supervision. The new modules can\n",
      "readily replace their plain counterparts in existing CNNs and can be easily\n",
      "trained end-to-end by standard back-propagation, giving rise to deformable\n",
      "convolutional networks. Extensive experiments validate the effectiveness of our\n",
      "approach on sophisticated vision tasks of object detection and semantic\n",
      "segmentation. The code would be released.\n",
      "\n",
      "    \n",
      "402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While humans easily recognize relations between data from different domains\n",
      "without any supervision, learning to automatically discover them is in general\n",
      "very challenging and needs many ground-truth pairs that illustrate the\n",
      "relations. To avoid costly pairing, we address the task of discovering\n",
      "cross-domain relations given unpaired data. We propose a method based on\n",
      "generative adversarial networks that learns to discover relations between\n",
      "different domains (DiscoGAN). Using the discovered relations, our proposed\n",
      "network successfully transfers style from one domain to another while\n",
      "preserving key attributes such as orientation and face identity. Source code\n",
      "for official implementation is publicly available\n",
      "this https URL\n",
      "\n",
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Deep Voice, a production-quality text-to-speech system constructed\n",
      "entirely from deep neural networks. Deep Voice lays the groundwork for truly\n",
      "end-to-end neural speech synthesis. The system comprises five major building\n",
      "blocks: a segmentation model for locating phoneme boundaries, a\n",
      "grapheme-to-phoneme conversion model, a phoneme duration prediction model, a\n",
      "fundamental frequency prediction model, and an audio synthesis model. For the\n",
      "segmentation model, we propose a novel way of performing phoneme boundary\n",
      "detection with deep neural networks using connectionist temporal classification\n",
      "(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet\n",
      "that requires fewer parameters and trains faster than the original. By using a\n",
      "neural network for each component, our system is simpler and more flexible than\n",
      "traditional text-to-speech systems, where each component requires laborious\n",
      "feature engineering and extensive domain expertise. Finally, we show that\n",
      "inference with our system can be performed faster than real time and describe\n",
      "optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x\n",
      "speedups over existing implementations.\n",
      "\n",
      "    \n",
      "404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore design principles for general pixel-level prediction problems,\n",
      "from low-level edge detection to mid-level surface normal estimation to\n",
      "high-level semantic segmentation. Convolutional predictors, such as the\n",
      "fully-convolutional network (FCN), have achieved remarkable success by\n",
      "exploiting the spatial redundancy of neighboring pixels through convolutional\n",
      "processing. Though computationally efficient, we point out that such approaches\n",
      "are not statistically efficient during learning precisely because spatial\n",
      "redundancy limits the information learned from neighboring pixels. We\n",
      "demonstrate that stratified sampling of pixels allows one to (1) add diversity\n",
      "during batch updates, speeding up learning; (2) explore complex nonlinear\n",
      "predictors, improving accuracy; and (3) efficiently train state-of-the-art\n",
      "models tabula rasa (i.e., \"from scratch\") for diverse pixel-labeling tasks. Our\n",
      "single architecture produces state-of-the-art results for semantic segmentation\n",
      "on PASCAL-Context dataset, surface normal estimation on NYUDv2 depth dataset,\n",
      "and edge detection on BSDS.\n",
      "\n",
      "    \n",
      "405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Batch Normalization is quite effective at accelerating and improving the\n",
      "training of deep models. However, its effectiveness diminishes when the\n",
      "training minibatches are small, or do not consist of independent samples. We\n",
      "hypothesize that this is due to the dependence of model layer inputs on all the\n",
      "examples in the minibatch, and different activations being produced between\n",
      "training and inference. We propose Batch Renormalization, a simple and\n",
      "effective extension to ensure that the training and inference models generate\n",
      "the same outputs that depend on individual examples rather than the entire\n",
      "minibatch. Models trained with Batch Renormalization perform substantially\n",
      "better than batchnorm when training with small or non-i.i.d. minibatches. At\n",
      "the same time, Batch Renormalization retains the benefits of batchnorm such as\n",
      "insensitivity to initialization and training efficiency.\n",
      "\n",
      "    \n",
      "406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite their massive size, successful deep artificial neural networks can\n",
      "exhibit a remarkably small difference between training and test performance.\n",
      "Conventional wisdom attributes small generalization error either to properties\n",
      "of the model family, or to the regularization techniques used during training.\n",
      "Through extensive systematic experiments, we show how these traditional\n",
      "approaches fail to explain why large neural networks generalize well in\n",
      "practice. Specifically, our experiments establish that state-of-the-art\n",
      "convolutional networks for image classification trained with stochastic\n",
      "gradient methods easily fit a random labeling of the training data. This\n",
      "phenomenon is qualitatively unaffected by explicit regularization, and occurs\n",
      "even if we replace the true images by completely unstructured random noise. We\n",
      "corroborate these experimental findings with a theoretical construction showing\n",
      "that simple depth two neural networks already have perfect finite sample\n",
      "expressivity as soon as the number of parameters exceeds the number of data\n",
      "points as it usually does in practice.\n",
      "We interpret our experimental findings by comparison with traditional models.\n",
      "\n",
      "    \n",
      "407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Scale variation is one of the key challenges in object detection. In this\n",
      "work, we first present a controlled experiment to investigate the effect of\n",
      "receptive fields for scale variation in object detection. Based on the findings\n",
      "from the exploration experiments, we propose a novel Trident Network\n",
      "(TridentNet) aiming to generate scale-specific feature maps with a uniform\n",
      "representational power. We construct a parallel multi-branch architecture in\n",
      "which each branch shares the same transformation parameters but with different\n",
      "receptive fields. Then, we adopt a scale-aware training scheme to specialize\n",
      "each branch by sampling object instances of proper scales for training. As a\n",
      "bonus, a fast approximation version of TridentNet could achieve significant\n",
      "improvements without any additional parameters and computational cost compared\n",
      "with the vanilla detector. On the COCO dataset, our TridentNet with ResNet-101\n",
      "backbone achieves state-of-the-art single-model results of 48.4 mAP. Codes are\n",
      "available at this https URL.\n",
      "\n",
      "    \n",
      "408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Unsupervised learning with generative adversarial networks (GANs) has proven\n",
      "hugely successful. Regular GANs hypothesize the discriminator as a classifier\n",
      "with the sigmoid cross entropy loss function. However, we found that this loss\n",
      "function may lead to the vanishing gradients problem during the learning\n",
      "process. To overcome such a problem, we propose in this paper the Least Squares\n",
      "Generative Adversarial Networks (LSGANs) which adopt the least squares loss\n",
      "function for the discriminator. We show that minimizing the objective function\n",
      "of LSGAN yields minimizing the Pearson $\\chi^2$ divergence. There are two\n",
      "benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher\n",
      "quality images than regular GANs. Second, LSGANs perform more stable during the\n",
      "learning process. We evaluate LSGANs on five scene datasets and the\n",
      "experimental results show that the images generated by LSGANs are of better\n",
      "quality than the ones generated by regular GANs. We also conduct two comparison\n",
      "experiments between LSGANs and regular GANs to illustrate the stability of\n",
      "LSGANs.\n",
      "\n",
      "    \n",
      "409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present the Stanford Question Answering Dataset (SQuAD), a new reading\n",
      "comprehension dataset consisting of 100,000+ questions posed by crowdworkers on\n",
      "a set of Wikipedia articles, where the answer to each question is a segment of\n",
      "text from the corresponding reading passage. We analyze the dataset to\n",
      "understand the types of reasoning required to answer the questions, leaning\n",
      "heavily on dependency and constituency trees. We build a strong logistic\n",
      "regression model, which achieves an F1 score of 51.0%, a significant\n",
      "improvement over a simple baseline (20%). However, human performance (86.8%) is\n",
      "much higher, indicating that the dataset presents a good challenge problem for\n",
      "future research.\n",
      "The dataset is freely available at this https URL\n",
      "\n",
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The existing machine translation systems, whether phrase-based or neural,\n",
      "have relied almost exclusively on word-level modelling with explicit\n",
      "segmentation. In this paper, we ask a fundamental question: can neural machine\n",
      "translation generate a character sequence without any explicit segmentation? To\n",
      "answer this question, we evaluate an attention-based encoder-decoder with a\n",
      "subword-level encoder and a character-level decoder on four language\n",
      "pairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15.\n",
      "Our experiments show that the models with a character-level decoder outperform\n",
      "the ones with a subword-level decoder on all of the four language pairs.\n",
      "Furthermore, the ensembles of neural models with a character-level decoder\n",
      "outperform the state-of-the-art non-neural machine translation systems on\n",
      "En-Cs, En-De and En-Fi and perform comparably on En-Ru.\n",
      "\n",
      "    \n",
      "411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Object category localization is a challenging problem in computer vision.\n",
      "Standard supervised training requires bounding box annotations of object\n",
      "instances. This time-consuming annotation process is sidestepped in weakly\n",
      "supervised learning. In this case, the supervised information is restricted to\n",
      "binary labels that indicate the absence/presence of object instances in the\n",
      "image, without their locations. We follow a multiple-instance learning approach\n",
      "that iteratively trains the detector and infers the object locations in the\n",
      "positive training images. Our main contribution is a multi-fold multiple\n",
      "instance learning procedure, which prevents training from prematurely locking\n",
      "onto erroneous object locations. This procedure is particularly important when\n",
      "using high-dimensional representations, such as Fisher vectors and\n",
      "convolutional neural network features. We also propose a window refinement\n",
      "method, which improves the localization accuracy by incorporating an objectness\n",
      "prior. We present a detailed experimental evaluation using the PASCAL VOC 2007\n",
      "dataset, which verifies the effectiveness of our approach.\n",
      "\n",
      "    \n",
      "412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we present a fully automatic brain tumor segmentation method\n",
      "based on Deep Neural Networks (DNNs). The proposed networks are tailored to\n",
      "glioblastomas (both low and high grade) pictured in MR images. By their very\n",
      "nature, these tumors can appear anywhere in the brain and have almost any kind\n",
      "of shape, size, and contrast. These reasons motivate our exploration of a\n",
      "machine learning solution that exploits a flexible, high capacity DNN while\n",
      "being extremely efficient. Here, we give a description of different model\n",
      "choices that we've found to be necessary for obtaining competitive performance.\n",
      "We explore in particular different architectures based on Convolutional Neural\n",
      "Networks (CNN), i.e. DNNs specifically adapted to image data.\n",
      "We present a novel CNN architecture which differs from those traditionally\n",
      "used in computer vision. Our CNN exploits both local features as well as more\n",
      "global contextual features simultaneously. Also, different from most\n",
      "traditional uses of CNNs, our networks use a final layer that is a\n",
      "convolutional implementation of a fully connected layer which allows a 40 fold\n",
      "speed up. We also describe a 2-phase training procedure that allows us to\n",
      "tackle difficulties related to the imbalance of tumor labels. Finally, we\n",
      "explore a cascade architecture in which the output of a basic CNN is treated as\n",
      "an additional source of information for a subsequent CNN. Results reported on\n",
      "the 2013 BRATS test dataset reveal that our architecture improves over the\n",
      "currently published state-of-the-art while being over 30 times faster.\n",
      "\n",
      "    \n",
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The Teacher Forcing algorithm trains recurrent networks by supplying observed\n",
      "sequence values as inputs during training and using the network's own\n",
      "one-step-ahead predictions to do multi-step sampling. We introduce the\n",
      "Professor Forcing algorithm, which uses adversarial domain adaptation to\n",
      "encourage the dynamics of the recurrent network to be the same when training\n",
      "the network and when sampling from the network over multiple time steps. We\n",
      "apply Professor Forcing to language modeling, vocal synthesis on raw waveforms,\n",
      "handwriting generation, and image generation. Empirically we find that\n",
      "Professor Forcing acts as a regularizer, improving test likelihood on character\n",
      "level Penn Treebank and sequential MNIST. We also find that the model\n",
      "qualitatively improves samples, especially when sampling for a large number of\n",
      "time steps. This is supported by human evaluation of sample quality. Trade-offs\n",
      "between Professor Forcing and Scheduled Sampling are discussed. We produce\n",
      "T-SNEs showing that Professor Forcing successfully makes the dynamics of the\n",
      "network during training and sampling more similar.\n",
      "\n",
      "    \n",
      "414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The matrix-based Renyi's \\alpha-entropy functional and its multivariate\n",
      "extension were recently developed in terms of the normalized eigenspectrum of a\n",
      "Hermitian matrix of the projected data in a reproducing kernel Hilbert space\n",
      "(RKHS). However, the utility and possible applications of these new estimators\n",
      "are rather new and mostly unknown to practitioners. In this paper, we first\n",
      "show that our estimators enable straightforward measurement of information flow\n",
      "in realistic convolutional neural networks (CNN) without any approximation.\n",
      "Then, we introduce the partial information decomposition (PID) framework and\n",
      "develop three quantities to analyze the synergy and redundancy in convolutional\n",
      "layer representations. Our results validate two fundamental data processing\n",
      "inequalities and reveal some fundamental properties concerning the training of\n",
      "CNN.\n",
      "\n",
      "    \n",
      "415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces Adaptive Computation Time (ACT), an algorithm that\n",
      "allows recurrent neural networks to learn how many computational steps to take\n",
      "between receiving an input and emitting an output. ACT requires minimal changes\n",
      "to the network architecture, is deterministic and differentiable, and does not\n",
      "add any noise to the parameter gradients. Experimental results are provided for\n",
      "four synthetic problems: determining the parity of binary vectors, applying\n",
      "binary logic operations, adding integers, and sorting real numbers. Overall,\n",
      "performance is dramatically improved by the use of ACT, which successfully\n",
      "adapts the number of computational steps to the requirements of the problem. We\n",
      "also present character-level language modelling results on the Hutter prize\n",
      "Wikipedia dataset. In this case ACT does not yield large gains in performance;\n",
      "however it does provide intriguing insight into the structure of the data, with\n",
      "more computation allocated to harder-to-predict transitions, such as spaces\n",
      "between words and ends of sentences. This suggests that ACT or other adaptive\n",
      "computation methods could provide a generic method for inferring segment\n",
      "boundaries in sequence data.\n",
      "\n",
      "    \n",
      "417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has shown that convolutional networks can be substantially\n",
      "deeper, more accurate, and efficient to train if they contain shorter\n",
      "connections between layers close to the input and those close to the output. In\n",
      "this paper, we embrace this observation and introduce the Dense Convolutional\n",
      "Network (DenseNet), which connects each layer to every other layer in a\n",
      "feed-forward fashion. Whereas traditional convolutional networks with L layers\n",
      "have L connections - one between each layer and its subsequent layer - our\n",
      "network has L(L+1)/2 direct connections. For each layer, the feature-maps of\n",
      "all preceding layers are used as inputs, and its own feature-maps are used as\n",
      "inputs into all subsequent layers. DenseNets have several compelling\n",
      "advantages: they alleviate the vanishing-gradient problem, strengthen feature\n",
      "propagation, encourage feature reuse, and substantially reduce the number of\n",
      "parameters. We evaluate our proposed architecture on four highly competitive\n",
      "object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).\n",
      "DenseNets obtain significant improvements over the state-of-the-art on most of\n",
      "them, whilst requiring less computation to achieve high performance. Code and\n",
      "pre-trained models are available at this https URL .\n",
      "\n",
      "    \n",
      "418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ieeexplore.ieee.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce the adversarially learned inference (ALI) model, which jointly\n",
      "learns a generation network and an inference network using an adversarial\n",
      "process. The generation network maps samples from stochastic latent variables\n",
      "to the data space while the inference network maps training examples in data\n",
      "space to the space of latent variables. An adversarial game is cast between\n",
      "these two networks and a discriminative network is trained to distinguish\n",
      "between joint latent/data-space samples from the generative network and joint\n",
      "samples from the inference network. We illustrate the ability of the model to\n",
      "learn mutually coherent inference and generation networks through the\n",
      "inspections of model samples and reconstructions and confirm the usefulness of\n",
      "the learned representations by obtaining a performance competitive with\n",
      "state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.\n",
      "\n",
      "    \n",
      "420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training recurrent neural networks to model long term dependencies is\n",
      "difficult. Hence, we propose to use external linguistic knowledge as an\n",
      "explicit signal to inform the model which memories it should utilize.\n",
      "Specifically, external knowledge is used to augment a sequence with typed edges\n",
      "between arbitrarily distant elements, and the resulting graph is decomposed\n",
      "into directed acyclic subgraphs. We introduce a model that encodes such graphs\n",
      "as explicit memory in recurrent neural networks, and use it to model\n",
      "coreference relations in text. We apply our model to several text comprehension\n",
      "tasks and achieve new state-of-the-art results on all considered benchmarks,\n",
      "including CNN, bAbi, and LAMBADA. On the bAbi QA tasks, our model solves 15 out\n",
      "of the 20 tasks with only 1000 training examples per task. Analysis of the\n",
      "learned representations further demonstrates the ability of our model to encode\n",
      "fine-grained entity information across a document.\n",
      "\n",
      "    \n",
      "421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Human pose estimation plays an important role in many computer vision tasks\n",
      "and has been studied for many decades. However, due to complex appearance\n",
      "variations from poses, illuminations, occlusions and low resolutions, it still\n",
      "remains a challenging problem. Taking the advantage of high-level semantic\n",
      "information from deep convolutional neural networks is an effective way to\n",
      "improve the accuracy of human pose estimation. In this paper, we propose a\n",
      "novel Cascade Feature Aggregation (CFA) method, which cascades several\n",
      "hourglass networks for robust human pose estimation. Features from different\n",
      "stages are aggregated to obtain abundant contextual information, leading to\n",
      "robustness to poses, partial occlusions and low resolution. Moreover, results\n",
      "from different stages are fused to further improve the localization accuracy.\n",
      "The extensive experiments on MPII datasets and LIP datasets demonstrate that\n",
      "our proposed CFA outperforms the state-of-the-art and achieves the best\n",
      "performance on the state-of-the-art benchmark MPII.\n",
      "\n",
      "    \n",
      "422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Random data augmentation is a critical technique to avoid overfitting in\n",
      "training deep neural network models. However, data augmentation and network\n",
      "training are usually treated as two isolated processes, limiting the\n",
      "effectiveness of network training. Why not jointly optimize the two? We propose\n",
      "adversarial data augmentation to address this limitation. The main idea is to\n",
      "design an augmentation network (generator) that competes against a target\n",
      "network (discriminator) by generating `hard' augmentation operations online.\n",
      "The augmentation network explores the weaknesses of the target network, while\n",
      "the latter learns from `hard' augmentations to achieve better performance. We\n",
      "also design a reward/penalty strategy for effective joint training. We\n",
      "demonstrate our approach on the problem of human pose estimation and carry out\n",
      "a comprehensive experimental analysis, showing that our method can\n",
      "significantly improve state-of-the-art models without additional data efforts.\n",
      "\n",
      "    \n",
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most of the existing deep learning-based methods for 3D hand and human pose\n",
      "estimation from a single depth map are based on a common framework that takes a\n",
      "2D depth map and directly regresses the 3D coordinates of keypoints, such as\n",
      "hand or human body joints, via 2D convolutional neural networks (CNNs). The\n",
      "first weakness of this approach is the presence of perspective distortion in\n",
      "the 2D depth map. While the depth map is intrinsically 3D data, many previous\n",
      "methods treat depth maps as 2D images that can distort the shape of the actual\n",
      "object through projection from 3D to 2D space. This compels the network to\n",
      "perform perspective distortion-invariant estimation. The second weakness of the\n",
      "conventional approach is that directly regressing 3D coordinates from a 2D\n",
      "image is a highly non-linear mapping, which causes difficulty in the learning\n",
      "procedure. To overcome these weaknesses, we firstly cast the 3D hand and human\n",
      "pose estimation problem from a single depth map into a voxel-to-voxel\n",
      "prediction that uses a 3D voxelized grid and estimates the per-voxel likelihood\n",
      "for each keypoint. We design our model as a 3D CNN that provides accurate\n",
      "estimates while running in real-time. Our system outperforms previous methods\n",
      "in almost all publicly available 3D hand and human pose estimation datasets and\n",
      "placed first in the HANDS 2017 frame-based 3D hand pose estimation challenge.\n",
      "The code is available in this https URL.\n",
      "\n",
      "    \n",
      "424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This is an official pytorch implementation of Deep High-Resolution\n",
      "Representation Learning for Human Pose Estimation. In this work, we are\n",
      "interested in the human pose estimation problem with a focus on learning\n",
      "reliable high-resolution representations. Most existing methods recover\n",
      "high-resolution representations from low-resolution representations produced by\n",
      "a high-to-low resolution network. Instead, our proposed network maintains\n",
      "high-resolution representations through the whole process. We start from a\n",
      "high-resolution subnetwork as the first stage, gradually add high-to-low\n",
      "resolution subnetworks one by one to form more stages, and connect the\n",
      "mutli-resolution subnetworks in parallel. We conduct repeated multi-scale\n",
      "fusions such that each of the high-to-low resolution representations receives\n",
      "information from other parallel representations over and over, leading to rich\n",
      "high-resolution representations. As a result, the predicted keypoint heatmap is\n",
      "potentially more accurate and spatially more precise. We empirically\n",
      "demonstrate the effectiveness of our network through the superior pose\n",
      "estimation results over two benchmark datasets: the COCO keypoint detection\n",
      "dataset and the MPII Human Pose dataset. The code and models have been publicly\n",
      "available at\n",
      "\\url{this https URL}.\n",
      "\n",
      "    \n",
      "425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Instance-level human analysis is common in real-life scenarios and has\n",
      "multiple manifestations, such as human part segmentation, dense pose\n",
      "estimation, human-object interactions, etc. Models need to distinguish\n",
      "different human instances in the image panel and learn rich features to\n",
      "represent the details of each instance. In this paper, we present an end-to-end\n",
      "pipeline for solving the instance-level human analysis, named Parsing R-CNN. It\n",
      "processes a set of human instances simultaneously through comprehensive\n",
      "considering the characteristics of region-based approach and the appearance of\n",
      "a human, thus allowing representing the details of instances. Parsing R-CNN is\n",
      "very flexible and efficient, which is applicable to many issues in human\n",
      "instance analysis. Our approach outperforms all state-of-the-art methods on\n",
      "CIHP (Crowd Instance-level Human Parsing), MHP v2.0 (Multi-Human Parsing) and\n",
      "DensePose-COCO datasets. Based on the proposed Parsing R-CNN, we reach the 1st\n",
      "place in the COCO 2018 Challenge DensePose Estimation task. Code and models are\n",
      "public available.\n",
      "\n",
      "    \n",
      "426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This work introduces a novel convolutional network architecture for the task\n",
      "of human pose estimation. Features are processed across all scales and\n",
      "consolidated to best capture the various spatial relationships associated with\n",
      "the body. We show how repeated bottom-up, top-down processing used in\n",
      "conjunction with intermediate supervision is critical to improving the\n",
      "performance of the network. We refer to the architecture as a \"stacked\n",
      "hourglass\" network based on the successive steps of pooling and upsampling that\n",
      "are done to produce a final set of predictions. State-of-the-art results are\n",
      "achieved on the FLIC and MPII benchmarks outcompeting all recent methods.\n",
      "\n",
      "    \n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  For 3D hand and body pose estimation task in depth image, a novel\n",
      "anchor-based approach termed Anchor-to-Joint regression network (A2J) with the\n",
      "end-to-end learning ability is proposed. Within A2J, anchor points able to\n",
      "capture global-local spatial context information are densely set on depth image\n",
      "as local regressors for the joints. They contribute to predict the positions of\n",
      "the joints in ensemble way to enhance generalization ability. The proposed 3D\n",
      "articulated pose estimation paradigm is different from the state-of-the-art\n",
      "encoder-decoder based FCN, 3D CNN and point-set based manners. To discover\n",
      "informative anchor points towards certain joint, anchor proposal procedure is\n",
      "also proposed for A2J. Meanwhile 2D CNN (i.e., ResNet-50) is used as backbone\n",
      "network to drive A2J, without using time-consuming 3D convolutional or\n",
      "deconvolutional layers. The experiments on 3 hand datasets and 2 body datasets\n",
      "verify A2J's superiority. Meanwhile, A2J is of high running speed around 100\n",
      "FPS on single NVIDIA 1080Ti GPU.\n",
      "\n",
      "    \n",
      "428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new generative model where samples are produced via Langevin\n",
      "dynamics using gradients of the data distribution estimated with score\n",
      "matching. Because gradients might be ill-defined when the data resides on\n",
      "low-dimensional manifolds, we perturb the data with different levels of\n",
      "Gaussian noise and jointly estimate the corresponding scores, i.e., the vector\n",
      "fields of gradients of the perturbed data distribution for all noise levels.\n",
      "For sampling, we propose an annealed Langevin dynamics where we use gradients\n",
      "corresponding to gradually decreasing noise levels as the sampling process gets\n",
      "closer to the data manifold. Our framework allows flexible model architectures,\n",
      "requires no sampling during training or the use of adversarial methods, and\n",
      "provides a learning objective that can be used for principled model\n",
      "comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and\n",
      "CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.91 on\n",
      "CIFAR-10. Additionally, we demonstrate that our models learn effective\n",
      "representations via image inpainting experiments.\n",
      "\n",
      "    \n",
      "429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openai.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Humans can only interact with part of the surrounding environment due to\n",
      "biological restrictions. Therefore, we learn to reason the spatial\n",
      "relationships across a series of observations to piece together the surrounding\n",
      "environment. Inspired by such behavior and the fact that machines also have\n",
      "computational constraints, we propose \\underline{CO}nditional\n",
      "\\underline{CO}ordinate GAN (COCO-GAN) of which the generator generates images\n",
      "by parts based on their spatial coordinates as the condition. On the other\n",
      "hand, the discriminator learns to justify realism across multiple assembled\n",
      "patches by global coherence, local appearance, and edge-crossing continuity.\n",
      "Despite the full images are never generated during training, we show that\n",
      "COCO-GAN can produce \\textbf{state-of-the-art-quality} full images during\n",
      "inference. We further demonstrate a variety of novel applications enabled by\n",
      "teaching the network to be aware of coordinates. First, we perform\n",
      "extrapolation to the learned coordinate manifold and generate off-the-boundary\n",
      "patches. Combining with the originally generated full image, COCO-GAN can\n",
      "produce images that are larger than training samples, which we called\n",
      "\"beyond-boundary generation\". We then showcase panorama generation within a\n",
      "cylindrical coordinate system that inherently preserves horizontally cyclic\n",
      "topology. On the computation side, COCO-GAN has a built-in divide-and-conquer\n",
      "paradigm that reduces memory requisition during training and inference,\n",
      "provides high-parallelism, and can generate parts of images on-demand.\n",
      "\n",
      "    \n",
      "431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Flow-based generative models parameterize probability distributions through\n",
      "an invertible transformation and can be trained by maximum likelihood.\n",
      "Invertible residual networks provide a flexible family of transformations where\n",
      "only Lipschitz conditions rather than strict architectural constraints are\n",
      "needed for enforcing invertibility. However, prior work trained invertible\n",
      "residual networks for density estimation by relying on biased log-density\n",
      "estimates whose bias increased with the network's expressiveness. We give a\n",
      "tractable unbiased estimate of the log density using a \"Russian roulette\"\n",
      "estimator, and reduce the memory required during training by using an\n",
      "alternative infinite series for the gradient. Furthermore, we improve\n",
      "invertible residual blocks by proposing the use of activation functions that\n",
      "avoid derivative saturation and generalizing the Lipschitz condition to induced\n",
      "mixed norms. The resulting approach, called Residual Flows, achieves\n",
      "state-of-the-art performance on density estimation amongst flow-based models,\n",
      "and outperforms networks that use coupling blocks at joint generative and\n",
      "discriminative modeling.\n",
      "\n",
      "    \n",
      "432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to automatically estimate the quality and coverage of the samples\n",
      "produced by a generative model is a vital requirement for driving algorithm\n",
      "research. We present an evaluation metric that can separately and reliably\n",
      "measure both of these aspects in image generation tasks by forming explicit,\n",
      "non-parametric representations of the manifolds of real and generated data. We\n",
      "demonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing\n",
      "several illustrative examples where existing metrics yield uninformative or\n",
      "contradictory results. Furthermore, we analyze multiple design variants of\n",
      "StyleGAN to better understand the relationships between the model architecture,\n",
      "training methods, and the properties of the resulting sample distribution. In\n",
      "the process, we identify new variants that improve the state-of-the-art. We\n",
      "also perform the first principled analysis of truncation methods and identify\n",
      "an improved method. Finally, we extend our metric to estimate the perceptual\n",
      "quality of individual samples, and use this to study latent space\n",
      "interpolations.\n",
      "\n",
      "    \n",
      "433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In standard generative adversarial network (SGAN), the discriminator\n",
      "estimates the probability that the input data is real. The generator is trained\n",
      "to increase the probability that fake data is real. We argue that it should\n",
      "also simultaneously decrease the probability that real data is real because 1)\n",
      "this would account for a priori knowledge that half of the data in the\n",
      "mini-batch is fake, 2) this would be observed with divergence minimization, and\n",
      "3) in optimal settings, SGAN would be equivalent to integral probability metric\n",
      "(IPM) GANs.\n",
      "We show that this property can be induced by using a relativistic\n",
      "discriminator which estimate the probability that the given real data is more\n",
      "realistic than a randomly sampled fake data. We also present a variant in which\n",
      "the discriminator estimate the probability that the given real data is more\n",
      "realistic than fake data, on average. We generalize both approaches to\n",
      "non-standard GAN loss functions and we refer to them respectively as\n",
      "Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that\n",
      "IPM-based GANs are a subset of RGANs which use the identity function.\n",
      "Empirically, we observe that 1) RGANs and RaGANs are significantly more\n",
      "stable and generate higher quality data samples than their non-relativistic\n",
      "counterparts, 2) Standard RaGAN with gradient penalty generate data of better\n",
      "quality than WGAN-GP while only requiring a single discriminator update per\n",
      "generator update (reducing the time taken for reaching the state-of-the-art by\n",
      "400%), and 3) RaGANs are able to generate plausible high resolutions images\n",
      "(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these\n",
      "images are of significantly better quality than the ones generated by WGAN-GP\n",
      "and SGAN with spectral normalization.\n",
      "\n",
      "    \n",
      "434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  TorchBeast is a platform for reinforcement learning (RL) research in PyTorch.\n",
      "It implements a version of the popular IMPALA algorithm for fast, asynchronous,\n",
      "parallel training of RL agents. Additionally, TorchBeast has simplicity as an\n",
      "explicit design goal: We provide both a pure-Python implementation\n",
      "(\"MonoBeast\") as well as a multi-machine high-performance version\n",
      "(\"PolyBeast\"). In the latter, parts of the implementation are written in C++,\n",
      "but all parts pertaining to machine learning are kept in simple Python using\n",
      "PyTorch, with the environments provided using the OpenAI Gym interface. This\n",
      "enables researchers to conduct scalable RL research using TorchBeast without\n",
      "any programming knowledge beyond Python and PyTorch. In this paper, we describe\n",
      "the TorchBeast design principles and implementation and demonstrate that it\n",
      "performs on-par with IMPALA on Atari. TorchBeast is released as an open-source\n",
      "package under the Apache 2.0 license and is available at\n",
      "\\url{this https URL}.\n",
      "\n",
      "    \n",
      "435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present two novel solutions for multi-view 3D human pose estimation based\n",
      "on new learnable triangulation methods that combine 3D information from\n",
      "multiple 2D views. The first (baseline) solution is a basic differentiable\n",
      "algebraic triangulation with an addition of confidence weights estimated from\n",
      "the input images. The second solution is based on a novel method of volumetric\n",
      "aggregation from intermediate 2D backbone feature maps. The aggregated volume\n",
      "is then refined via 3D convolutions that produce final 3D joint heatmaps and\n",
      "allow modelling a human pose prior. Crucially, both approaches are end-to-end\n",
      "differentiable, which allows us to directly optimize the target metric. We\n",
      "demonstrate transferability of the solutions across datasets and considerably\n",
      "improve the multi-view state of the art on the Human3.6M dataset. Video\n",
      "demonstration, annotations and additional materials will be posted on our\n",
      "project page (this https URL).\n",
      "\n",
      "    \n",
      "436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automatically determining three-dimensional human pose from monocular RGB\n",
      "image data is a challenging problem. The two-dimensional nature of the input\n",
      "results in intrinsic ambiguities which make inferring depth particularly\n",
      "difficult. Recently, researchers have demonstrated that the flexible\n",
      "statistical modelling capabilities of deep neural networks are sufficient to\n",
      "make such inferences with reasonable accuracy. However, many of these models\n",
      "use coordinate output techniques which are memory-intensive, not\n",
      "differentiable, and/or do not spatially generalise well. We propose\n",
      "improvements to 3D coordinate prediction which avoid the aforementioned\n",
      "undesirable traits by predicting 2D marginal heatmaps under an augmented\n",
      "soft-argmax scheme. Our resulting model, MargiPose, produces visually coherent\n",
      "heatmaps whilst maintaining differentiability. We are also able to achieve\n",
      "state-of-the-art accuracy on publicly available 3D human pose estimation data.\n",
      "\n",
      "    \n",
      "437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an approach to recover absolute 3D human poses from multi-view\n",
      "images by incorporating multi-view geometric priors in our model. It consists\n",
      "of two separate steps: (1) estimating the 2D poses in multi-view images and (2)\n",
      "recovering the 3D poses from the multi-view 2D poses. First, we introduce a\n",
      "cross-view fusion scheme into CNN to jointly estimate 2D poses for multiple\n",
      "views. Consequently, the 2D pose estimation for each view already benefits from\n",
      "other views. Second, we present a recursive Pictorial Structure Model to\n",
      "recover the 3D pose from the multi-view 2D poses. It gradually improves the\n",
      "accuracy of 3D pose with affordable computational cost. We test our method on\n",
      "two public datasets H36M and Total Capture. The Mean Per Joint Position Errors\n",
      "on the two datasets are 26mm and 29mm, which outperforms the state-of-the-arts\n",
      "remarkably (26mm vs 52mm, 29mm vs 35mm). Our code is released at\n",
      "\\url{this https URL}.\n",
      "\n",
      "    \n",
      "439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Following the success of deep convolutional networks, state-of-the-art\n",
      "methods for 3d human pose estimation have focused on deep end-to-end systems\n",
      "that predict 3d joint locations given raw image pixels. Despite their excellent\n",
      "performance, it is often not easy to understand whether their remaining error\n",
      "stems from a limited 2d pose (visual) understanding, or from a failure to map\n",
      "2d poses into 3-dimensional positions. With the goal of understanding these\n",
      "sources of error, we set out to build a system that given 2d joint locations\n",
      "predicts 3d positions. Much to our surprise, we have found that, with current\n",
      "technology, \"lifting\" ground truth 2d joint locations to 3d space is a task\n",
      "that can be solved with a remarkably low error rate: a relatively simple deep\n",
      "feed-forward network outperforms the best reported result by about 30\\% on\n",
      "Human3.6M, the largest publicly available 3d pose estimation benchmark.\n",
      "Furthermore, training our system on the output of an off-the-shelf\n",
      "state-of-the-art 2d detector (\\ie, using images as input) yields state of the\n",
      "art results -- this includes an array of systems that have been trained\n",
      "end-to-end specifically for this task. Our results indicate that a large\n",
      "portion of the error of modern deep 3d pose estimation systems stems from their\n",
      "visual analysis, and suggests directions to further advance the state of the\n",
      "art in 3d human pose estimation.\n",
      "\n",
      "    \n",
      "440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Model-based human pose estimation is currently approached through two\n",
      "different paradigms. Optimization-based methods fit a parametric body model to\n",
      "2D observations in an iterative manner, leading to accurate image-model\n",
      "alignments, but are often slow and sensitive to the initialization. In\n",
      "contrast, regression-based methods, that use a deep network to directly\n",
      "estimate the model parameters from pixels, tend to provide reasonable, but not\n",
      "pixel accurate, results while requiring huge amounts of supervision. In this\n",
      "work, instead of investigating which approach is better, our key insight is\n",
      "that the two paradigms can form a strong collaboration. A reasonable, directly\n",
      "regressed estimate from the network can initialize the iterative optimization\n",
      "making the fitting faster and more accurate. Similarly, a pixel accurate fit\n",
      "from iterative optimization can act as strong supervision for the network. This\n",
      "is the core of our proposed approach SPIN (SMPL oPtimization IN the loop). The\n",
      "deep network initializes an iterative optimization routine that fits the body\n",
      "model to 2D joints within the training loop, and the fitted estimate is\n",
      "subsequently used to supervise the network. Our approach is self-improving by\n",
      "nature, since better network estimates can lead the optimization to better\n",
      "solutions, while more accurate optimization fits provide better supervision for\n",
      "the network. We demonstrate the effectiveness of our approach in different\n",
      "settings, where 3D ground truth is scarce, or not available, and we\n",
      "consistently outperform the state-of-the-art model-based pose estimation\n",
      "approaches by significant margins. The project website with videos, results,\n",
      "and code can be found at this https URL.\n",
      "\n",
      "    \n",
      "441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  For the ECCV 2018 PoseTrack Challenge, we present a 3D human pose estimation\n",
      "system based mainly on the integral human pose regression method. We show a\n",
      "comprehensive ablation study to examine the key performance factors of the\n",
      "proposed system. Our system obtains 47mm MPJPE on the CHALL_H80K test dataset,\n",
      "placing second in the ECCV2018 3D human pose estimation challenge. Code will be\n",
      "released to facilitate future work.\n",
      "\n",
      "    \n",
      "442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper addresses the problem of 3D human pose estimation from a single\n",
      "image. We follow a standard two-step pipeline by first detecting the 2D\n",
      "position of the $N$ body joints, and then using these observations to infer 3D\n",
      "pose. For the first step, we use a recent CNN-based detector. For the second\n",
      "step, most existing approaches perform 2$N$-to-3$N$ regression of the Cartesian\n",
      "joint coordinates. We show that more precise pose estimates can be obtained by\n",
      "representing both the 2D and 3D human poses using $N\\times N$ distance\n",
      "matrices, and formulating the problem as a 2D-to-3D distance matrix regression.\n",
      "For learning such a regressor we leverage on simple Neural Network\n",
      "architectures, which by construction, enforce positivity and symmetry of the\n",
      "predicted matrices. The approach has also the advantage to naturally handle\n",
      "missing observations and allowing to hypothesize the position of non-observed\n",
      "joints. Quantitative results on Humaneva and Human3.6M datasets demonstrate\n",
      "consistent performance gains over state-of-the-art. Qualitative evaluation on\n",
      "the images in-the-wild of the LSP dataset, using the regressor learned on\n",
      "Human3.6M, reveals very promising generalization results.\n",
      "\n",
      "    \n",
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multi-person pose estimation from a 2D image is an essential technique for\n",
      "human behavior understanding. In this paper, we propose a human pose refinement\n",
      "network that estimates a refined pose from a tuple of an input image and input\n",
      "pose. The pose refinement was performed mainly through an end-to-end trainable\n",
      "multi-stage architecture in previous methods. However, they are highly\n",
      "dependent on pose estimation models and require careful model design. By\n",
      "contrast, we propose a model-agnostic pose refinement method. According to a\n",
      "recent study, state-of-the-art 2D human pose estimation methods have similar\n",
      "error distributions. We use this error statistics as prior information to\n",
      "generate synthetic poses and use the synthesized poses to train our model. In\n",
      "the testing stage, pose estimation results of any other methods can be input to\n",
      "the proposed method. Moreover, the proposed model does not require code or\n",
      "knowledge about other methods, which allows it to be easily used in the\n",
      "post-processing step. We show that the proposed approach achieves better\n",
      "performance than the conventional multi-stage refinement models and\n",
      "consistently improves the performance of various state-of-the-art pose\n",
      "estimation methods on the commonly used benchmark. The code is available in\n",
      "this https URL\\footnote{\\url{this https URL}}.\n",
      "\n",
      "    \n",
      "444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents a novel approach to estimating the continuous six degree\n",
      "of freedom (6-DoF) pose (3D translation and rotation) of an object from a\n",
      "single RGB image. The approach combines semantic keypoints predicted by a\n",
      "convolutional network (convnet) with a deformable shape model. Unlike prior\n",
      "work, we are agnostic to whether the object is textured or textureless, as the\n",
      "convnet learns the optimal representation from the available training image\n",
      "data. Furthermore, the approach can be applied to instance- and class-based\n",
      "pose recovery. Empirically, we show that the proposed approach can accurately\n",
      "recover the 6-DoF object pose for both instance- and class-based scenarios with\n",
      "a cluttered background. For class-based object pose estimation,\n",
      "state-of-the-art accuracy is shown on the large-scale PASCAL3D+ dataset.\n",
      "\n",
      "    \n",
      "445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a simple and effective method for 3D hand pose estimation from a\n",
      "single depth frame. As opposed to previous state-of-the-art methods based on\n",
      "holistic 3D regression, our method works on dense pixel-wise estimation. This\n",
      "is achieved by careful design choices in pose parameterization, which leverages\n",
      "both 2D and 3D properties of depth map. Specifically, we decompose the pose\n",
      "parameters into a set of per-pixel estimations, i.e., 2D heat maps, 3D heat\n",
      "maps and unit 3D directional vector fields. The 2D/3D joint heat maps and 3D\n",
      "joint offsets are estimated via multi-task network cascades, which is trained\n",
      "end-to-end. The pixel-wise estimations can be directly translated into a vote\n",
      "casting scheme. A variant of mean shift is then used to aggregate local votes\n",
      "while enforcing consensus between the the estimated 3D pose and the pixel-wise\n",
      "2D and 3D estimations by design. Our method is efficient and highly accurate.\n",
      "On MSRA and NYU hand dataset, our method outperforms all previous\n",
      "state-of-the-art approaches by a large margin. On the ICVL hand dataset, our\n",
      "method achieves similar accuracy compared to the currently proposed nearly\n",
      "saturated result and outperforms various other proposed methods. Code is\n",
      "available $\\href{\"this https URL\"}{\\text{online}}$.\n",
      "\n",
      "    \n",
      "446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents KeypointNet, an end-to-end geometric reasoning framework\n",
      "to learn an optimal set of category-specific 3D keypoints, along with their\n",
      "detectors. Given a single image, KeypointNet extracts 3D keypoints that are\n",
      "optimized for a downstream task. We demonstrate this framework on 3D pose\n",
      "estimation by proposing a differentiable objective that seeks the optimal set\n",
      "of keypoints for recovering the relative pose between two views of an object.\n",
      "Our model discovers geometrically and semantically consistent keypoints across\n",
      "viewing angles and instances of an object category. Importantly, we find that\n",
      "our end-to-end framework using no ground-truth keypoint annotations outperforms\n",
      "a fully supervised baseline using the same neural network architecture on the\n",
      "task of pose estimation. The discovered 3D keypoints on the car, chair, and\n",
      "plane categories of ShapeNet are visualized at this http URL.\n",
      "\n",
      "    \n",
      "447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multi-person pose estimation in the wild is challenging. Although\n",
      "state-of-the-art human detectors have demonstrated good performance, small\n",
      "errors in localization and recognition are inevitable. These errors can cause\n",
      "failures for a single-person pose estimator (SPPE), especially for methods that\n",
      "solely depend on human detection results. In this paper, we propose a novel\n",
      "regional multi-person pose estimation (RMPE) framework to facilitate pose\n",
      "estimation in the presence of inaccurate human bounding boxes. Our framework\n",
      "consists of three components: Symmetric Spatial Transformer Network (SSTN),\n",
      "Parametric Pose Non-Maximum-Suppression (NMS), and Pose-Guided Proposals\n",
      "Generator (PGPG). Our method is able to handle inaccurate bounding boxes and\n",
      "redundant detections, allowing it to achieve a 17% increase in mAP over the\n",
      "state-of-the-art methods on the MPII (multi person) dataset.Our model and\n",
      "source codes are publicly available.\n",
      "\n",
      "    \n",
      "448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  TensorFlow is an interface for expressing machine learning algorithms, and an\n",
      "implementation for executing such algorithms. A computation expressed using\n",
      "TensorFlow can be executed with little or no change on a wide variety of\n",
      "heterogeneous systems, ranging from mobile devices such as phones and tablets\n",
      "up to large-scale distributed systems of hundreds of machines and thousands of\n",
      "computational devices such as GPU cards. The system is flexible and can be used\n",
      "to express a wide variety of algorithms, including training and inference\n",
      "algorithms for deep neural network models, and it has been used for conducting\n",
      "research and for deploying machine learning systems into production across more\n",
      "than a dozen areas of computer science and other fields, including speech\n",
      "recognition, computer vision, robotics, information retrieval, natural language\n",
      "processing, geographic information extraction, and computational drug\n",
      "discovery. This paper describes the TensorFlow interface and an implementation\n",
      "of that interface that we have built at Google. The TensorFlow API and a\n",
      "reference implementation were released as an open-source package under the\n",
      "Apache 2.0 license in November, 2015 and are available at this http URL.\n",
      "\n",
      "    \n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The goal of this paper is to advance the state-of-the-art of articulated pose\n",
      "estimation in scenes with multiple people. To that end we contribute on three\n",
      "fronts. We propose (1) improved body part detectors that generate effective\n",
      "bottom-up proposals for body parts; (2) novel image-conditioned pairwise terms\n",
      "that allow to assemble the proposals into a variable number of consistent body\n",
      "part configurations; and (3) an incremental optimization strategy that explores\n",
      "the search space more efficiently thus leading both to better performance and\n",
      "significant speed-up factors. Evaluation is done on two single-person and two\n",
      "multi-person pose estimation benchmarks. The proposed approach significantly\n",
      "outperforms best known multi-person pose estimation results while demonstrating\n",
      "competitive performance on the task of single person pose estimation. Models\n",
      "and code available at this http URL\n",
      "\n",
      "450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multi-person pose estimation is fundamental to many computer vision tasks and\n",
      "has made significant progress in recent years. However, few previous methods\n",
      "explored the problem of pose estimation in crowded scenes while it remains\n",
      "challenging and inevitable in many scenarios. Moreover, current benchmarks\n",
      "cannot provide an appropriate evaluation for such cases. In this paper, we\n",
      "propose a novel and efficient method to tackle the problem of pose estimation\n",
      "in the crowd and a new dataset to better evaluate algorithms. Our model\n",
      "consists of two key components: joint-candidate single person pose estimation\n",
      "(SPPE) and global maximum joints association. With multi-peak prediction for\n",
      "each joint and global association using graph model, our method is robust to\n",
      "inevitable interference in crowded scenes and very efficient in inference. The\n",
      "proposed method surpasses the state-of-the-art methods on CrowdPose dataset by\n",
      "5.2 mAP and results on MSCOCO dataset demonstrate the generalization ability of\n",
      "our method. Source code and dataset will be made publicly available.\n",
      "\n",
      "    \n",
      "451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a new training methodology for generative adversarial networks.\n",
      "The key idea is to grow both the generator and discriminator progressively:\n",
      "starting from a low resolution, we add new layers that model increasingly fine\n",
      "details as training progresses. This both speeds the training up and greatly\n",
      "stabilizes it, allowing us to produce images of unprecedented quality, e.g.,\n",
      "CelebA images at 1024^2. We also propose a simple way to increase the variation\n",
      "in generated images, and achieve a record inception score of 8.80 in\n",
      "unsupervised CIFAR10. Additionally, we describe several implementation details\n",
      "that are important for discouraging unhealthy competition between the generator\n",
      "and discriminator. Finally, we suggest a new metric for evaluating GAN results,\n",
      "both in terms of image quality and variation. As an additional contribution, we\n",
      "construct a higher-quality version of the CelebA dataset.\n",
      "\n",
      "    \n",
      "452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in Generative Adversarial Networks (GANs) have shown\n",
      "impressive results for task of facial expression synthesis. The most successful\n",
      "architecture is StarGAN, that conditions GANs generation process with images of\n",
      "a specific domain, namely a set of images of persons sharing the same\n",
      "expression. While effective, this approach can only generate a discrete number\n",
      "of expressions, determined by the content of the dataset. To address this\n",
      "limitation, in this paper, we introduce a novel GAN conditioning scheme based\n",
      "on Action Units (AU) annotations, which describes in a continuous manifold the\n",
      "anatomical facial movements defining a human expression. Our approach allows\n",
      "controlling the magnitude of activation of each AU and combine several of them.\n",
      "Additionally, we propose a fully unsupervised strategy to train the model, that\n",
      "only requires images annotated with their activated AUs, and exploit attention\n",
      "mechanisms that make our network robust to changing backgrounds and lighting\n",
      "conditions. Extensive evaluation show that our approach goes beyond competing\n",
      "conditional generators both in the capability to synthesize a much wider range\n",
      "of expressions ruled by anatomically feasible muscle movements, as in the\n",
      "capacity of dealing with images in the wild.\n",
      "\n",
      "    \n",
      "453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes InfoGAN, an information-theoretic extension to the\n",
      "Generative Adversarial Network that is able to learn disentangled\n",
      "representations in a completely unsupervised manner. InfoGAN is a generative\n",
      "adversarial network that also maximizes the mutual information between a small\n",
      "subset of the latent variables and the observation. We derive a lower bound to\n",
      "the mutual information objective that can be optimized efficiently, and show\n",
      "that our training procedure can be interpreted as a variation of the Wake-Sleep\n",
      "algorithm. Specifically, InfoGAN successfully disentangles writing styles from\n",
      "digit shapes on the MNIST dataset, pose from lighting of 3D rendered images,\n",
      "and background digits from the central digit on the SVHN dataset. It also\n",
      "discovers visual concepts that include hair styles, presence/absence of\n",
      "eyeglasses, and emotions on the CelebA face dataset. Experiments show that\n",
      "InfoGAN learns interpretable representations that are competitive with\n",
      "representations learned by existing fully supervised methods.\n",
      "\n",
      "    \n",
      "454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we tackle the problem of unsupervised domain adaptation for the\n",
      "task of semantic segmentation, where we attempt to transfer the knowledge\n",
      "learned upon synthetic datasets with ground-truth labels to real-world images\n",
      "without any annotation. With the hypothesis that the structural content of\n",
      "images is the most informative and decisive factor to semantic segmentation and\n",
      "can be readily shared across domains, we propose a Domain Invariant Structure\n",
      "Extraction (DISE) framework to disentangle images into domain-invariant\n",
      "structure and domain-specific texture representations, which can further\n",
      "realize image-translation across domains and enable label transfer to improve\n",
      "segmentation performance. Extensive experiments verify the effectiveness of our\n",
      "proposed DISE model and demonstrate its superiority over several\n",
      "state-of-the-art approaches.\n",
      "\n",
      "    \n",
      "455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Self-attention is a useful mechanism to build generative models for language\n",
      "and images. It determines the importance of context elements by comparing each\n",
      "element to the current time step. In this paper, we show that a very\n",
      "lightweight convolution can perform competitively to the best reported\n",
      "self-attention results. Next, we introduce dynamic convolutions which are\n",
      "simpler and more efficient than self-attention. We predict separate convolution\n",
      "kernels based solely on the current time-step in order to determine the\n",
      "importance of context elements. The number of operations required by this\n",
      "approach scales linearly in the input length, whereas self-attention is\n",
      "quadratic. Experiments on large-scale machine translation, language modeling\n",
      "and abstractive summarization show that dynamic convolutions improve over\n",
      "strong self-attention models. On the WMT'14 English-German test set dynamic\n",
      "convolutions achieve a new state of the art of 29.7 BLEU.\n",
      "\n",
      "    \n",
      "456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Domain adaptation is critical for success in new, unseen environments.\n",
      "Adversarial adaptation models applied in feature spaces discover domain\n",
      "invariant representations, but are difficult to visualize and sometimes fail to\n",
      "capture pixel-level and low-level domain shifts. Recent work has shown that\n",
      "generative adversarial networks combined with cycle-consistency constraints are\n",
      "surprisingly effective at mapping images between domains, even without the use\n",
      "of aligned image pairs. We propose a novel discriminatively-trained\n",
      "Cycle-Consistent Adversarial Domain Adaptation model. CyCADA adapts\n",
      "representations at both the pixel-level and feature-level, enforces\n",
      "cycle-consistency while leveraging a task loss, and does not require aligned\n",
      "pairs. Our model can be applied in a variety of visual recognition and\n",
      "prediction settings. We show new state-of-the-art results across multiple\n",
      "adaptation tasks, including digit classification and semantic segmentation of\n",
      "road scenes demonstrating transfer from synthetic to real world domains.\n",
      "\n",
      "    \n",
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We investigate conditional adversarial networks as a general-purpose solution\n",
      "to image-to-image translation problems. These networks not only learn the\n",
      "mapping from input image to output image, but also learn a loss function to\n",
      "train this mapping. This makes it possible to apply the same generic approach\n",
      "to problems that traditionally would require very different loss formulations.\n",
      "We demonstrate that this approach is effective at synthesizing photos from\n",
      "label maps, reconstructing objects from edge maps, and colorizing images, among\n",
      "other tasks. Indeed, since the release of the pix2pix software associated with\n",
      "this paper, a large number of internet users (many of them artists) have posted\n",
      "their own experiments with our system, further demonstrating its wide\n",
      "applicability and ease of adoption without the need for parameter tweaking. As\n",
      "a community, we no longer hand-engineer our mapping functions, and this work\n",
      "suggests we can achieve reasonable results without hand-engineering our loss\n",
      "functions either.\n",
      "\n",
      "    \n",
      "458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a novel method for unsupervised image-to-image translation, which\n",
      "incorporates a new attention module and a new learnable normalization function\n",
      "in an end-to-end manner. The attention module guides our model to focus on more\n",
      "important regions distinguishing between source and target domains based on the\n",
      "attention map obtained by the auxiliary classifier. Unlike previous\n",
      "attention-based methods which cannot handle the geometric changes between\n",
      "domains, our model can translate both images requiring holistic changes and\n",
      "images requiring large shape changes. Moreover, our new AdaLIN (Adaptive\n",
      "Layer-Instance Normalization) function helps our attention-guided model to\n",
      "flexibly control the amount of change in shape and texture by learned\n",
      "parameters depending on datasets. Experimental results show the superiority of\n",
      "the proposed method compared to the existing state-of-the-art models with a\n",
      "fixed network architecture and hyper-parameters.\n",
      "\n",
      "    \n",
      "459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite recent progress in generative image modeling, successfully generating\n",
      "high-resolution, diverse samples from complex datasets such as ImageNet remains\n",
      "an elusive goal. To this end, we train Generative Adversarial Networks at the\n",
      "largest scale yet attempted, and study the instabilities specific to such\n",
      "scale. We find that applying orthogonal regularization to the generator renders\n",
      "it amenable to a simple \"truncation trick,\" allowing fine control over the\n",
      "trade-off between sample fidelity and variety by reducing the variance of the\n",
      "Generator's input. Our modifications lead to models which set the new state of\n",
      "the art in class-conditional image synthesis. When trained on ImageNet at\n",
      "128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of\n",
      "166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous\n",
      "best IS of 52.52 and FID of 18.6.\n",
      "\n",
      "    \n",
      "460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaccess.thecvf.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We evaluate whether features extracted from the activation of a deep\n",
      "convolutional network trained in a fully supervised fashion on a large, fixed\n",
      "set of object recognition tasks can be re-purposed to novel generic tasks. Our\n",
      "generic tasks may differ significantly from the originally trained tasks and\n",
      "there may be insufficient labeled or unlabeled data to conventionally train or\n",
      "adapt a deep architecture to the new tasks. We investigate and visualize the\n",
      "semantic clustering of deep convolutional features with respect to a variety of\n",
      "such tasks, including scene recognition, domain adaptation, and fine-grained\n",
      "recognition challenges. We compare the efficacy of relying on various network\n",
      "levels to define a fixed feature, and report novel results that significantly\n",
      "outperform the state-of-the-art on several important vision challenges. We are\n",
      "releasing DeCAF, an open-source implementation of these deep convolutional\n",
      "activation features, along with all associated network parameters to enable\n",
      "vision researchers to be able to conduct experimentation with deep\n",
      "representations across a range of visual concept learning paradigms.\n",
      "\n",
      "    \n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Although various image-based domain adaptation (DA) techniques have been\n",
      "proposed in recent years, domain shift in videos is still not well-explored.\n",
      "Most previous works only evaluate performance on small-scale datasets which are\n",
      "saturated. Therefore, we first propose two large-scale video DA datasets with\n",
      "much larger domain discrepancy: UCF-HMDB_full and Kinetics-Gameplay. Second, we\n",
      "investigate different DA integration methods for videos, and show that\n",
      "simultaneously aligning and learning temporal dynamics achieves effective\n",
      "alignment even without sophisticated DA methods. Finally, we propose Temporal\n",
      "Attentive Adversarial Adaptation Network (TA3N), which explicitly attends to\n",
      "the temporal dynamics using domain discrepancy for more effective domain\n",
      "alignment, achieving state-of-the-art performance on four video DA datasets\n",
      "(e.g. 7.9% accuracy gain over \"Source only\" from 73.9% to 81.8% on \"HMDB -->\n",
      "UCF\", and 10.3% gain on \"Kinetics --> Gameplay\"). The code and data are\n",
      "released at this http URL.\n",
      "\n",
      "    \n",
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Visual domain adaptation aims to learn robust classifiers for the target\n",
      "domain by leveraging knowledge from a source domain. Existing methods either\n",
      "attempt to align the cross-domain distributions, or perform manifold subspace\n",
      "learning. However, there are two significant challenges: (1) degenerated\n",
      "feature transformation, which means that distribution alignment is often\n",
      "performed in the original feature space, where feature distortions are hard to\n",
      "overcome. On the other hand, subspace learning is not sufficient to reduce the\n",
      "distribution divergence. (2) unevaluated distribution alignment, which means\n",
      "that existing distribution alignment methods only align the marginal and\n",
      "conditional distributions with equal importance, while they fail to evaluate\n",
      "the different importance of these two distributions in real applications. In\n",
      "this paper, we propose a Manifold Embedded Distribution Alignment (MEDA)\n",
      "approach to address these challenges. MEDA learns a domain-invariant classifier\n",
      "in Grassmann manifold with structural risk minimization, while performing\n",
      "dynamic distribution alignment to quantitatively account for the relative\n",
      "importance of marginal and conditional distributions. To the best of our\n",
      "knowledge, MEDA is the first attempt to perform dynamic distribution alignment\n",
      "for manifold domain adaptation. Extensive experiments demonstrate that MEDA\n",
      "shows significant improvements in classification accuracy compared to\n",
      "state-of-the-art traditional and deep methods.\n",
      "\n",
      "    \n",
      "464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work, we connect two distinct concepts for unsupervised domain\n",
      "adaptation: feature distribution alignment between domains by utilizing the\n",
      "task-specific decision boundary and the Wasserstein metric. Our proposed sliced\n",
      "Wasserstein discrepancy (SWD) is designed to capture the natural notion of\n",
      "dissimilarity between the outputs of task-specific classifiers. It provides a\n",
      "geometrically meaningful guidance to detect target samples that are far from\n",
      "the support of the source and enables efficient distribution alignment in an\n",
      "end-to-end trainable fashion. In the experiments, we validate the effectiveness\n",
      "and genericness of our method on digit and sign recognition, image\n",
      "classification, semantic segmentation, and object detection.\n",
      "\n",
      "    \n",
      "465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we aim to solve for unsupervised domain adaptation of\n",
      "classifiers where we have access to label information for the source domain\n",
      "while these are not available for a target domain. While various methods have\n",
      "been proposed for solving these including adversarial discriminator based\n",
      "methods, most approaches have focused on the entire image based domain\n",
      "adaptation. In an image, there would be regions that can be adapted better, for\n",
      "instance, the foreground object may be similar in nature. To obtain such\n",
      "regions, we propose methods that consider the probabilistic certainty estimate\n",
      "of various regions and specify focus on these during classification for\n",
      "adaptation. We observe that just by incorporating the probabilistic certainty\n",
      "of the discriminator while training the classifier, we are able to obtain state\n",
      "of the art results on various datasets as compared against all the recent\n",
      "methods. We provide a thorough empirical analysis of the method by providing\n",
      "ablation analysis, statistical significance test, and visualization of the\n",
      "attention maps and t-SNE embeddings. These evaluations convincingly demonstrate\n",
      "the effectiveness of the proposed approach.\n",
      "\n",
      "    \n",
      "466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep convolutional neural networks demonstrate impressive results in the\n",
      "super-resolution domain. A series of studies concentrate on improving peak\n",
      "signal noise ratio (PSNR) by using much deeper layers, which are not friendly\n",
      "to constrained resources. Pursuing a trade-off between the restoration capacity\n",
      "and the simplicity of models is still non-trivial. Recent contributions are\n",
      "struggling to manually maximize this balance, while our work achieves the same\n",
      "goal automatically with neural architecture search. Specifically, we handle\n",
      "super-resolution with a multi-objective approach. We also propose an elastic\n",
      "search tactic at both micro and macro level, based on a hybrid controller that\n",
      "profits from evolutionary computation and reinforcement learning. Quantitative\n",
      "experiments help us to draw a conclusion that our generated models dominate\n",
      "most of the state-of-the-art methods with respect to the individual FLOPS.\n",
      "\n",
      "    \n",
      "467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a simple, interpretable framework for solving a wide range of\n",
      "image reconstruction problems such as denoising and deconvolution. Given a\n",
      "corrupted input image, the model synthesizes a spatially varying linear filter\n",
      "which, when applied to the input image, reconstructs the desired output. The\n",
      "model parameters are learned using supervised or self-supervised training. We\n",
      "test this model on three tasks: non-uniform motion blur removal,\n",
      "lossy-compression artifact reduction and single image super resolution. We\n",
      "demonstrate that our model substantially outperforms state-of-the-art methods\n",
      "on all these tasks and is significantly faster than optimization-based\n",
      "approaches to deconvolution. Unlike models that directly predict output pixel\n",
      "values, the predicted filter flow is controllable and interpretable, which we\n",
      "demonstrate by visualizing the space of predicted filters for different tasks.\n",
      "\n",
      "    \n",
      "468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaccess.thecvf.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The recent increase in the extensive use of digital imaging technologies has\n",
      "brought with it a simultaneous demand for higher-resolution images. We develop\n",
      "a novel edge-informed approach to single image super-resolution (SISR). The\n",
      "SISR problem is reformulated as an image inpainting task. We use a two-stage\n",
      "inpainting model as a baseline for super-resolution and show its effectiveness\n",
      "for different scale factors (x2, x4, x8) compared to basic interpolation\n",
      "schemes. This model is trained using a joint optimization of image contents\n",
      "(texture and color) and structures (edges). Quantitative and qualitative\n",
      "comparisons are included and the proposed model is compared with current\n",
      "state-of-the-art techniques. We show that our method of decoupling structure\n",
      "and texture reconstruction improves the quality of the final reconstructed\n",
      "high-resolution image. Code and models available at:\n",
      "this https URL\n",
      "\n",
      "470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Video restoration tasks, including super-resolution, deblurring, etc, are\n",
      "drawing increasing attention in the computer vision community. A challenging\n",
      "benchmark named REDS is released in the NTIRE19 Challenge. This new benchmark\n",
      "challenges existing methods from two aspects: (1) how to align multiple frames\n",
      "given large motions, and (2) how to effectively fuse different frames with\n",
      "diverse motion and blur. In this work, we propose a novel Video Restoration\n",
      "framework with Enhanced Deformable networks, termed EDVR, to address these\n",
      "challenges. First, to handle large motions, we devise a Pyramid, Cascading and\n",
      "Deformable (PCD) alignment module, in which frame alignment is done at the\n",
      "feature level using deformable convolutions in a coarse-to-fine manner. Second,\n",
      "we propose a Temporal and Spatial Attention (TSA) fusion module, in which\n",
      "attention is applied both temporally and spatially, so as to emphasize\n",
      "important features for subsequent restoration. Thanks to these modules, our\n",
      "EDVR wins the champions and outperforms the second place by a large margin in\n",
      "all four tracks in the NTIRE19 video restoration and enhancement challenges.\n",
      "EDVR also demonstrates superior performance to state-of-the-art published\n",
      "methods on video super-resolution and deblurring. The code is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recently, several models based on deep neural networks have achieved great\n",
      "success in terms of both reconstruction accuracy and computational performance\n",
      "for single image super-resolution. In these methods, the low resolution (LR)\n",
      "input image is upscaled to the high resolution (HR) space using a single\n",
      "filter, commonly bicubic interpolation, before reconstruction. This means that\n",
      "the super-resolution (SR) operation is performed in HR space. We demonstrate\n",
      "that this is sub-optimal and adds computational complexity. In this paper, we\n",
      "present the first convolutional neural network (CNN) capable of real-time SR of\n",
      "1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN\n",
      "architecture where the feature maps are extracted in the LR space. In addition,\n",
      "we introduce an efficient sub-pixel convolution layer which learns an array of\n",
      "upscaling filters to upscale the final LR feature maps into the HR output. By\n",
      "doing so, we effectively replace the handcrafted bicubic filter in the SR\n",
      "pipeline with more complex upscaling filters specifically trained for each\n",
      "feature map, whilst also reducing the computational complexity of the overall\n",
      "SR operation. We evaluate the proposed approach using images and videos from\n",
      "publicly available datasets and show that it performs significantly better\n",
      "(+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster\n",
      "than previous CNN-based methods.\n",
      "\n",
      "    \n",
      "472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite the breakthroughs in accuracy and speed of single image\n",
      "super-resolution using faster and deeper convolutional neural networks, one\n",
      "central problem remains largely unsolved: how do we recover the finer texture\n",
      "details when we super-resolve at large upscaling factors? The behavior of\n",
      "optimization-based super-resolution methods is principally driven by the choice\n",
      "of the objective function. Recent work has largely focused on minimizing the\n",
      "mean squared reconstruction error. The resulting estimates have high peak\n",
      "signal-to-noise ratios, but they are often lacking high-frequency details and\n",
      "are perceptually unsatisfying in the sense that they fail to match the fidelity\n",
      "expected at the higher resolution. In this paper, we present SRGAN, a\n",
      "generative adversarial network (GAN) for image super-resolution (SR). To our\n",
      "knowledge, it is the first framework capable of inferring photo-realistic\n",
      "natural images for 4x upscaling factors. To achieve this, we propose a\n",
      "perceptual loss function which consists of an adversarial loss and a content\n",
      "loss. The adversarial loss pushes our solution to the natural image manifold\n",
      "using a discriminator network that is trained to differentiate between the\n",
      "super-resolved images and original photo-realistic images. In addition, we use\n",
      "a content loss motivated by perceptual similarity instead of similarity in\n",
      "pixel space. Our deep residual network is able to recover photo-realistic\n",
      "textures from heavily downsampled images on public benchmarks. An extensive\n",
      "mean-opinion-score (MOS) test shows hugely significant gains in perceptual\n",
      "quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\n",
      "the original high-resolution images than to those obtained with any\n",
      "state-of-the-art method.\n",
      "\n",
      "    \n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose an image super-resolution method (SR) using a deeply-recursive\n",
      "convolutional network (DRCN). Our network has a very deep recursive layer (up\n",
      "to 16 recursions). Increasing recursion depth can improve performance without\n",
      "introducing new parameters for additional convolutions. Albeit advantages,\n",
      "learning a DRCN is very hard with a standard gradient descent method due to\n",
      "exploding/vanishing gradients. To ease the difficulty of training, we propose\n",
      "two extensions: recursive-supervision and skip-connection. Our method\n",
      "outperforms previous methods by a large margin.\n",
      "\n",
      "    \n",
      "474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work\n",
      "that is capable of generating realistic textures during single image\n",
      "super-resolution. However, the hallucinated details are often accompanied with\n",
      "unpleasant artifacts. To further enhance the visual quality, we thoroughly\n",
      "study three key components of SRGAN - network architecture, adversarial loss\n",
      "and perceptual loss, and improve each of them to derive an Enhanced SRGAN\n",
      "(ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block\n",
      "(RRDB) without batch normalization as the basic network building unit.\n",
      "Moreover, we borrow the idea from relativistic GAN to let the discriminator\n",
      "predict relative realness instead of the absolute value. Finally, we improve\n",
      "the perceptual loss by using the features before activation, which could\n",
      "provide stronger supervision for brightness consistency and texture recovery.\n",
      "Benefiting from these improvements, the proposed ESRGAN achieves consistently\n",
      "better visual quality with more realistic and natural textures than SRGAN and\n",
      "won the first place in the PIRM2018-SR Challenge. The code is available at\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Video restoration tasks, including super-resolution, deblurring, etc, are\n",
      "drawing increasing attention in the computer vision community. A challenging\n",
      "benchmark named REDS is released in the NTIRE19 Challenge. This new benchmark\n",
      "challenges existing methods from two aspects: (1) how to align multiple frames\n",
      "given large motions, and (2) how to effectively fuse different frames with\n",
      "diverse motion and blur. In this work, we propose a novel Video Restoration\n",
      "framework with Enhanced Deformable networks, termed EDVR, to address these\n",
      "challenges. First, to handle large motions, we devise a Pyramid, Cascading and\n",
      "Deformable (PCD) alignment module, in which frame alignment is done at the\n",
      "feature level using deformable convolutions in a coarse-to-fine manner. Second,\n",
      "we propose a Temporal and Spatial Attention (TSA) fusion module, in which\n",
      "attention is applied both temporally and spatially, so as to emphasize\n",
      "important features for subsequent restoration. Thanks to these modules, our\n",
      "EDVR wins the champions and outperforms the second place by a large margin in\n",
      "all four tracks in the NTIRE19 video restoration and enhancement challenges.\n",
      "EDVR also demonstrates superior performance to state-of-the-art published\n",
      "methods on video super-resolution and deblurring. The code is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The tradeoff between receptive field size and efficiency is a crucial issue\n",
      "in low level vision. Plain convolutional networks (CNNs) generally enlarge the\n",
      "receptive field at the expense of computational cost. Recently, dilated\n",
      "filtering has been adopted to address this issue. But it suffers from gridding\n",
      "effect, and the resulting receptive field is only a sparse sampling of input\n",
      "image with checkerboard patterns. In this paper, we present a novel multi-level\n",
      "wavelet CNN (MWCNN) model for better tradeoff between receptive field size and\n",
      "computational efficiency. With the modified U-Net architecture, wavelet\n",
      "transform is introduced to reduce the size of feature maps in the contracting\n",
      "subnetwork. Furthermore, another convolutional layer is further used to\n",
      "decrease the channels of feature maps. In the expanding subnetwork, inverse\n",
      "wavelet transform is then deployed to reconstruct the high resolution feature\n",
      "maps. Our MWCNN can also be explained as the generalization of dilated\n",
      "filtering and subsampling, and can be applied to many image restoration tasks.\n",
      "The experimental results clearly show the effectiveness of MWCNN for image\n",
      "denoising, single image super-resolution, and JPEG image artifacts removal.\n",
      "\n",
      "    \n",
      "477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many classic methods have shown non-local self-similarity in natural images\n",
      "to be an effective prior for image restoration. However, it remains unclear and\n",
      "challenging to make use of this intrinsic property via deep networks. In this\n",
      "paper, we propose a non-local recurrent network (NLRN) as the first attempt to\n",
      "incorporate non-local operations into a recurrent neural network (RNN) for\n",
      "image restoration. The main contributions of this work are: (1) Unlike existing\n",
      "methods that measure self-similarity in an isolated manner, the proposed\n",
      "non-local module can be flexibly integrated into existing deep networks for\n",
      "end-to-end training to capture deep feature correlation between each location\n",
      "and its neighborhood. (2) We fully employ the RNN structure for its parameter\n",
      "efficiency and allow deep feature correlation to be propagated along adjacent\n",
      "recurrent states. This new design boosts robustness against inaccurate\n",
      "correlation estimation due to severely degraded images. (3) We show that it is\n",
      "essential to maintain a confined neighborhood for computing deep feature\n",
      "correlation given degraded images. This is in contrast to existing practice\n",
      "that deploys the whole image. Extensive experiments on both image denoising and\n",
      "super-resolution tasks are conducted. Thanks to the recurrent non-local\n",
      "operations and correlation propagation, the proposed NLRN achieves superior\n",
      "results to state-of-the-art methods with much fewer parameters.\n",
      "\n",
      "    \n",
      "478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional neural network has recently achieved great success for image\n",
      "restoration (IR) and also offered hierarchical features. However, most deep CNN\n",
      "based IR models do not make full use of the hierarchical features from the\n",
      "original low-quality images, thereby achieving relatively-low performance. In\n",
      "this paper, we propose a novel residual dense network (RDN) to address this\n",
      "problem in IR. We fully exploit the hierarchical features from all the\n",
      "convolutional layers. Specifically, we propose residual dense block (RDB) to\n",
      "extract abundant local features via densely connected convolutional layers. RDB\n",
      "further allows direct connections from the state of preceding RDB to all the\n",
      "layers of current RDB, leading to a contiguous memory mechanism. To adaptively\n",
      "learn more effective features from preceding and current local features and\n",
      "stabilize the training of wider network, we proposed local feature fusion in\n",
      "RDB. After fully obtaining dense local features, we use global feature fusion\n",
      "to jointly and adaptively learn global hierarchical features in a holistic way.\n",
      "We demonstrate the effectiveness of RDN with three representative IR\n",
      "applications, single image super-resolution, Gaussian image denoising, and\n",
      "image compression artifact reduction. Experiments on benchmark datasets show\n",
      "that our RDN achieves favorable performance against state-of-the-art methods\n",
      "for each IR task.\n",
      "\n",
      "    \n",
      "479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Non-local self-similarity is well-known to be an effective prior for the\n",
      "image denoising problem. However, little work has been done to incorporate it\n",
      "in convolutional neural networks, which surpass non-local model-based methods\n",
      "despite only exploiting local information. In this paper, we propose a novel\n",
      "end-to-end trainable neural network architecture employing layers based on\n",
      "graph convolution operations, thereby creating neurons with non-local receptive\n",
      "fields. The graph convolution operation generalizes the classic convolution to\n",
      "arbitrary graphs. In this work, the graph is dynamically computed from\n",
      "similarities among the hidden features of the network, so that the powerful\n",
      "representation learning capabilities of the network are exploited to uncover\n",
      "self-similar patterns. We introduce a lightweight Edge-Conditioned Convolution\n",
      "which addresses vanishing gradient and over-parameterization issues of this\n",
      "particular graph convolution. Extensive experiments show state-of-the-art\n",
      "performance with improved qualitative and quantitative results on both\n",
      "synthetic Gaussian noise and real noise.\n",
      "\n",
      "    \n",
      "480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Image restoration, including image denoising, super resolution, inpainting,\n",
      "and so on, is a well-studied problem in computer vision and image processing,\n",
      "as well as a test bed for low-level image modeling algorithms. In this work, we\n",
      "propose a very deep fully convolutional auto-encoder network for image\n",
      "restoration, which is a encoding-decoding framework with symmetric\n",
      "convolutional-deconvolutional layers. In other words, the network is composed\n",
      "of multiple layers of convolution and de-convolution operators, learning\n",
      "end-to-end mappings from corrupted images to the original ones. The\n",
      "convolutional layers capture the abstraction of image contents while\n",
      "eliminating corruptions. Deconvolutional layers have the capability to upsample\n",
      "the feature maps and recover the image details. To deal with the problem that\n",
      "deeper networks tend to be more difficult to train, we propose to symmetrically\n",
      "link convolutional and deconvolutional layers with skip-layer connections, with\n",
      "which the training converges much faster and attains better results.\n",
      "\n",
      "    \n",
      "481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Object detection and instance recognition play a central role in many AI\n",
      "applications like autonomous driving, video surveillance and medical image\n",
      "analysis. However, training object detection models on large scale datasets\n",
      "remains computationally expensive and time consuming. This paper presents an\n",
      "efficient and open source object detection framework called SimpleDet which\n",
      "enables the training of state-of-the-art detection models on consumer grade\n",
      "hardware at large scale. SimpleDet supports up-to-date detection models with\n",
      "best practice. SimpleDet also supports distributed training with near linear\n",
      "scaling out of box. Codes, examples and documents of SimpleDet can be found at\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Accurate state estimation is a fundamental module for various intelligent\n",
      "applications, such as robot navigation, autonomous driving, virtual and\n",
      "augmented reality. Visual and inertial fusion is a popular technology for 6-DOF\n",
      "state estimation in recent years. Time instants at which different sensors'\n",
      "measurements are recorded are of crucial importance to the system's robustness\n",
      "and accuracy. In practice, timestamps of each sensor typically suffer from\n",
      "triggering and transmission delays, leading to temporal misalignment (time\n",
      "offsets) among different sensors. Such temporal offset dramatically influences\n",
      "the performance of sensor fusion. To this end, we propose an online approach\n",
      "for calibrating temporal offset between visual and inertial measurements. Our\n",
      "approach achieves temporal offset calibration by jointly optimizing time\n",
      "offset, camera and IMU states, as well as feature locations in a SLAM system.\n",
      "Furthermore, the approach is a general model, which can be easily employed in\n",
      "several feature-based optimization frameworks. Simulation and experimental\n",
      "results demonstrate the high accuracy of our calibration approach even compared\n",
      "with other state-of-art offline tools. The VIO comparison against other methods\n",
      "proves that the online temporal calibration significantly benefits\n",
      "visual-inertial systems. The source code of temporal calibration is integrated\n",
      "into our public project, VINS-Mono.\n",
      "\n",
      "    \n",
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a traffic simulation named DeepTraffic where the planning systems\n",
      "for a subset of the vehicles are handled by a neural network as part of a\n",
      "model-free, off-policy reinforcement learning process. The primary goal of\n",
      "DeepTraffic is to make the hands-on study of deep reinforcement learning\n",
      "accessible to thousands of students, educators, and researchers in order to\n",
      "inspire and fuel the exploration and evaluation of deep Q-learning network\n",
      "variants and hyperparameter configurations through large-scale, open\n",
      "competition. This paper investigates the crowd-sourced hyperparameter tuning of\n",
      "the policy network that resulted from the first iteration of the DeepTraffic\n",
      "competition where thousands of participants actively searched through the\n",
      "hyperparameter space.\n",
      "\n",
      "    \n",
      "484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Developing and testing algorithms for autonomous vehicles in real world is an\n",
      "expensive and time consuming process. Also, in order to utilize recent advances\n",
      "in machine intelligence and deep learning we need to collect a large amount of\n",
      "annotated training data in a variety of conditions and environments. We present\n",
      "a new simulator built on Unreal Engine that offers physically and visually\n",
      "realistic simulations for both of these goals. Our simulator includes a physics\n",
      "engine that can operate at a high frequency for real-time hardware-in-the-loop\n",
      "(HITL) simulations with support for popular protocols (e.g. MavLink). The\n",
      "simulator is designed from the ground up to be extensible to accommodate new\n",
      "types of vehicles, hardware platforms and software protocols. In addition, the\n",
      "modular design enables various components to be easily usable independently in\n",
      "other projects. We demonstrate the simulator by first implementing a quadrotor\n",
      "as an autonomous vehicle and then experimentally comparing the software\n",
      "components with real-world flights.\n",
      "\n",
      "    \n",
      "485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract: this http URL's approach to Artificial Intelligence for self-driving cars is based\n",
      "on an agent that learns to clone driver behaviors and plans maneuvers by\n",
      "simulating future events in the road. This paper illustrates one of our\n",
      "research approaches for driving simulation. One where we learn to simulate.\n",
      "Here we investigate variational autoencoders with classical and learned cost\n",
      "functions using generative adversarial networks for embedding road frames.\n",
      "Afterwards, we learn a transition model in the embedded space using action\n",
      "conditioned Recurrent Neural Networks. We show that our approach can keep\n",
      "predicting realistic looking video for several frames despite the transition\n",
      "model being optimized without a cost function in the pixel space.\n",
      "\n",
      "    \n",
      "486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Human detection has witnessed impressive progress in recent years. However,\n",
      "the occlusion issue of detecting human in highly crowded environments is far\n",
      "from solved. To make matters worse, crowd scenarios are still under-represented\n",
      "in current human detection benchmarks. In this paper, we introduce a new\n",
      "dataset, called CrowdHuman, to better evaluate detectors in crowd scenarios.\n",
      "The CrowdHuman dataset is large, rich-annotated and contains high diversity.\n",
      "There are a total of $470K$ human instances from the train and validation\n",
      "subsets, and $~22.6$ persons per image, with various kinds of occlusions in the\n",
      "dataset. Each human instance is annotated with a head bounding-box, human\n",
      "visible-region bounding-box and human full-body bounding-box. Baseline\n",
      "performance of state-of-the-art detection frameworks on CrowdHuman is\n",
      "presented. The cross-dataset generalization results of CrowdHuman dataset\n",
      "demonstrate state-of-the-art performance on previous dataset including\n",
      "Caltech-USA, CityPersons, and Brainwash without bells and whistles. We hope our\n",
      "dataset will serve as a solid baseline and help promote future research in\n",
      "human detection tasks.\n",
      "\n",
      "    \n",
      "487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep convolutional neural networks take GPU days of compute time to train on\n",
      "large data sets. Pedestrian detection for self driving cars requires very low\n",
      "latency. Image recognition for mobile phones is constrained by limited\n",
      "processing resources. The success of convolutional neural networks in these\n",
      "situations is limited by how fast we can compute them. Conventional FFT based\n",
      "convolution is fast for large filters, but state of the art convolutional\n",
      "neural networks use small, 3x3 filters. We introduce a new class of fast\n",
      "algorithms for convolutional neural networks using Winograd's minimal filtering\n",
      "algorithms. The algorithms compute minimal complexity convolution over small\n",
      "tiles, which makes them fast with small filters and small batch sizes. We\n",
      "benchmark a GPU implementation of our algorithm with the VGG network and show\n",
      "state of the art throughput at batch sizes from 1 to 64.\n",
      "\n",
      "    \n",
      "488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  One of the most difficult speech recognition tasks is accurate recognition of\n",
      "human to human communication. Advances in deep learning over the last few years\n",
      "have produced major speech recognition improvements on the representative\n",
      "Switchboard conversational corpus. Word error rates that just a few years ago\n",
      "were 14% have dropped to 8.0%, then 6.6% and most recently 5.8%, and are now\n",
      "believed to be within striking range of human performance. This then raises two\n",
      "issues - what IS human performance, and how far down can we still drive speech\n",
      "recognition error rates? A recent paper by Microsoft suggests that we have\n",
      "already achieved human performance. In trying to verify this statement, we\n",
      "performed an independent set of human performance measurements on two\n",
      "conversational tasks and found that human performance may be considerably\n",
      "better than what was earlier reported, giving the community a significantly\n",
      "harder goal to achieve. We also report on our own efforts in this area,\n",
      "presenting a set of acoustic and language modeling techniques that lowered the\n",
      "word error rate of our own English conversational telephone LVCSR system to the\n",
      "level of 5.5%/10.3% on the Switchboard/CallHome subsets of the Hub5 2000\n",
      "evaluation, which - at least at the writing of this paper - is a new\n",
      "performance milestone (albeit not at what we measure to be human performance!).\n",
      "On the acoustic side, we use a score fusion of three models: one LSTM with\n",
      "multiple feature inputs, a second LSTM trained with speaker-adversarial\n",
      "multi-task learning and a third residual net (ResNet) with 25 convolutional\n",
      "layers and time-dilated convolutions. On the language modeling side, we use\n",
      "word and character LSTMs and convolutional WaveNet-style language models.\n",
      "\n",
      "    \n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Self-attention has been a huge success for many downstream tasks in NLP,\n",
      "which led to exploration of applying self-attention to speech problems as well.\n",
      "The efficacy of self-attention in speech applications, however, seems not fully\n",
      "blown yet since it is challenging to handle highly correlated speech frames in\n",
      "the context of self-attention. In this paper we propose a new neural network\n",
      "model architecture, namely multi-stream self-attention, to address the issue\n",
      "thus make the self-attention mechanism more effective for speech recognition.\n",
      "The proposed model architecture consists of parallel streams of self-attention\n",
      "encoders, and each stream has layers of 1D convolutions with dilated kernels\n",
      "whose dilation rates are unique given stream, followed by a self-attention\n",
      "layer. The self-attention mechanism in each stream pays attention to only one\n",
      "resolution of input speech frames and the attentive computation can be more\n",
      "efficient. In a later stage, outputs from all the streams are concatenated then\n",
      "linearly projected to the final embedding. By stacking the proposed\n",
      "multi-stream self-attention encoder blocks and rescoring the resultant lattices\n",
      "with neural network language models, we achieve the word error rate of 2.2% on\n",
      "the test-clean dataset of the LibriSpeech corpus, the best number reported thus\n",
      "far on the dataset.\n",
      "\n",
      "    \n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The availability of open-source software is playing a remarkable role in the\n",
      "popularization of speech recognition and deep learning. Kaldi, for instance, is\n",
      "nowadays an established framework used to develop state-of-the-art speech\n",
      "recognizers. PyTorch is used to build neural networks with the Python language\n",
      "and has recently spawn tremendous interest within the machine learning\n",
      "community thanks to its simplicity and flexibility.\n",
      "The PyTorch-Kaldi project aims to bridge the gap between these popular\n",
      "toolkits, trying to inherit the efficiency of Kaldi and the flexibility of\n",
      "PyTorch. PyTorch-Kaldi is not only a simple interface between these software,\n",
      "but it embeds several useful features for developing modern speech recognizers.\n",
      "For instance, the code is specifically designed to naturally plug-in\n",
      "user-defined acoustic models. As an alternative, users can exploit several\n",
      "pre-implemented neural networks that can be customized using intuitive\n",
      "configuration files. PyTorch-Kaldi supports multiple feature and label streams\n",
      "as well as combinations of neural networks, enabling the use of complex neural\n",
      "architectures. The toolkit is publicly-released along with a rich documentation\n",
      "and is designed to properly work locally or on HPC clusters.\n",
      "Experiments, that are conducted on several datasets and tasks, show that\n",
      "PyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech\n",
      "recognizers.\n",
      "\n",
      "    \n",
      "491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present state-of-the-art automatic speech recognition (ASR) systems\n",
      "employing a standard hybrid DNN/HMM architecture compared to an attention-based\n",
      "encoder-decoder design for the LibriSpeech task. Detailed descriptions of the\n",
      "system development, including model design, pretraining schemes, training\n",
      "schedules, and optimization approaches are provided for both system\n",
      "architectures. Both hybrid DNN/HMM and attention-based systems employ\n",
      "bi-directional LSTMs for acoustic modeling/encoding. For language modeling, we\n",
      "employ both LSTM and Transformer based architectures. All our systems are built\n",
      "using RWTHs open-source toolkits RASR and RETURNN. To the best knowledge of the\n",
      "authors, the results obtained when training on the full LibriSpeech training\n",
      "set, are the best published currently, both for the hybrid DNN/HMM and the\n",
      "attention-based systems. Our single hybrid system even outperforms previous\n",
      "results obtained from combining eight single systems. Our comparison shows that\n",
      "on the LibriSpeech 960h task, the hybrid DNN/HMM system outperforms the\n",
      "attention-based system by 15% relative on the clean and 40% relative on the\n",
      "other test sets in terms of word error rate. Moreover, experiments on a reduced\n",
      "100h-subset of the LibriSpeech training corpus even show a more pronounced\n",
      "margin between the hybrid DNN/HMM and attention-based architectures.\n",
      "\n",
      "    \n",
      "492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.danielpovey.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.isca-speech.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present SpecAugment, a simple data augmentation method for speech\n",
      "recognition. SpecAugment is applied directly to the feature inputs of a neural\n",
      "network (i.e., filter bank coefficients). The augmentation policy consists of\n",
      "warping the features, masking blocks of frequency channels, and masking blocks\n",
      "of time steps. We apply SpecAugment on Listen, Attend and Spell networks for\n",
      "end-to-end speech recognition tasks. We achieve state-of-the-art performance on\n",
      "the LibriSpeech 960h and Swichboard 300h tasks, outperforming all prior work.\n",
      "On LibriSpeech, we achieve 6.8% WER on test-other without the use of a language\n",
      "model, and 5.8% WER with shallow fusion with a language model. This compares to\n",
      "the previous state-of-the-art hybrid system of 7.5% WER. For Switchboard, we\n",
      "achieve 7.2%/14.6% on the Switchboard/CallHome portion of the Hub5'00 test set\n",
      "without the use of a language model, and 6.8%/14.1% with shallow fusion, which\n",
      "compares to the previous state-of-the-art hybrid system at 8.3%/17.3% WER.\n",
      "\n",
      "    \n",
      "495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a state-of-the-art speech recognition system developed using\n",
      "end-to-end deep learning. Our architecture is significantly simpler than\n",
      "traditional speech systems, which rely on laboriously engineered processing\n",
      "pipelines; these traditional systems also tend to perform poorly when used in\n",
      "noisy environments. In contrast, our system does not need hand-designed\n",
      "components to model background noise, reverberation, or speaker variation, but\n",
      "instead directly learns a function that is robust to such effects. We do not\n",
      "need a phoneme dictionary, nor even the concept of a \"phoneme.\" Key to our\n",
      "approach is a well-optimized RNN training system that uses multiple GPUs, as\n",
      "well as a set of novel data synthesis techniques that allow us to efficiently\n",
      "obtain a large amount of varied data for training. Our system, called Deep\n",
      "Speech, outperforms previously published results on the widely studied\n",
      "Switchboard Hub5'00, achieving 16.0% error on the full test set. Deep Speech\n",
      "also handles challenging noisy environments better than widely used,\n",
      "state-of-the-art commercial speech systems.\n",
      "\n",
      "    \n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a deep learning based method for estimating 3D facial expression\n",
      "coefficients. Unlike previous work, our process does not relay on facial\n",
      "landmark detection methods as a proxy step. Recent methods have shown that a\n",
      "CNN can be trained to regress accurate and discriminative 3D morphable model\n",
      "(3DMM) representations, directly from image intensities. By foregoing facial\n",
      "landmark detection, these methods were able to estimate shapes for occluded\n",
      "faces appearing in unprecedented in-the-wild viewing conditions. We build on\n",
      "those methods by showing that facial expressions can also be estimated by a\n",
      "robust, deep, landmark-free approach. Our ExpNet CNN is applied directly to the\n",
      "intensities of a face image and regresses a 29D vector of 3D expression\n",
      "coefficients. We propose a unique method for collecting data to train this\n",
      "network, leveraging on the robustness of deep networks to training label noise.\n",
      "We further offer a novel means of evaluating the accuracy of estimated\n",
      "expression coefficients: by measuring how well they capture facial emotions on\n",
      "the CK+ and EmotiW-17 emotion recognition benchmarks. We show that our ExpNet\n",
      "produces expression coefficients which better discriminate between facial\n",
      "emotions than those obtained using state of the art, facial landmark detection\n",
      "techniques. Moreover, this advantage grows as image scales drop, demonstrating\n",
      "that our ExpNet is more robust to scale changes than landmark detection\n",
      "methods. Finally, at the same level of accuracy, our ExpNet is orders of\n",
      "magnitude faster than its alternatives.\n",
      "\n",
      "    \n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multimodal sentiment analysis is a very actively growing field of research. A\n",
      "promising area of opportunity in this field is to improve the multimodal fusion\n",
      "mechanism. We present a novel feature fusion strategy that proceeds in a\n",
      "hierarchical fashion, first fusing the modalities two in two and only then\n",
      "fusing all three modalities. On multimodal sentiment analysis of individual\n",
      "utterances, our strategy outperforms conventional concatenation of features by\n",
      "1%, which amounts to 5% reduction in error rate. On utterance-level multimodal\n",
      "sentiment analysis of multi-utterance video clips, for which current\n",
      "state-of-the-art techniques incorporate contextual information from other\n",
      "utterances of the same clip, our hierarchical fusion gives up to 2.4% (almost\n",
      "10% error rate reduction) over currently used concatenation. The implementation\n",
      "of our method is publicly available in the form of open-source code.\n",
      "\n",
      "    \n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractMultimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Emotion recognition has become an important field of research in Human\n",
      "Computer Interactions as we improve upon the techniques for modelling the\n",
      "various aspects of behaviour. With the advancement of technology our\n",
      "understanding of emotions are advancing, there is a growing need for automatic\n",
      "emotion recognition systems. One of the directions the research is heading is\n",
      "the use of Neural Networks which are adept at estimating complex functions that\n",
      "depend on a large number and diverse source of input data. In this paper we\n",
      "attempt to exploit this effectiveness of Neural networks to enable us to\n",
      "perform multimodal Emotion recognition on IEMOCAP dataset using data from\n",
      "Speech, Text, and Motion capture data from face expressions, rotation and hand\n",
      "movements. Prior research has concentrated on Emotion detection from Speech on\n",
      "the IEMOCAP dataset, but our approach is the first that uses the multiple modes\n",
      "of data offered by IEMOCAP for a more robust and accurate emotion detection.\n",
      "\n",
      "    \n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Emotion detection in conversations is a necessary step for a number of\n",
      "applications, including opinion mining over chat history, social media threads,\n",
      "debates, argumentation mining, understanding consumer feedback in live\n",
      "conversations, etc. Currently, systems do not treat the parties in the\n",
      "conversation individually by adapting to the speaker of each utterance. In this\n",
      "paper, we describe a new method based on recurrent neural networks that keeps\n",
      "track of the individual party states throughout the conversation and uses this\n",
      "information for emotion classification. Our model outperforms the state of the\n",
      "art by a significant margin on two different datasets.\n",
      "\n",
      "    \n",
      "501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes Tacotron 2, a neural network architecture for speech\n",
      "synthesis directly from text. The system is composed of a recurrent\n",
      "sequence-to-sequence feature prediction network that maps character embeddings\n",
      "to mel-scale spectrograms, followed by a modified WaveNet model acting as a\n",
      "vocoder to synthesize timedomain waveforms from those spectrograms. Our model\n",
      "achieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\n",
      "professionally recorded speech. To validate our design choices, we present\n",
      "ablation studies of key components of our system and evaluate the impact of\n",
      "using mel spectrograms as the input to WaveNet instead of linguistic, duration,\n",
      "and $F_0$ features. We further demonstrate that using a compact acoustic\n",
      "intermediate representation enables significant simplification of the WaveNet\n",
      "architecture.\n",
      "\n",
      "    \n",
      "502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we address the problem of enhancing the speech of a speaker of\n",
      "interest in a cocktail party scenario when visual information of the speaker of\n",
      "interest is available. Contrary to most previous studies, we do not learn\n",
      "visual features on the typically small audio-visual datasets, but use an\n",
      "already available face landmark detector (trained on a separate image dataset).\n",
      "The landmarks are used by LSTM-based models to generate time-frequency masks\n",
      "which are applied to the acoustic mixed-speech spectrogram. Results show that:\n",
      "(i) landmark motion features are very effective features for this task, (ii)\n",
      "similarly to previous work, reconstruction of the target speaker's spectrogram\n",
      "mediated by masking is significantly more accurate than direct spectrogram\n",
      "reconstruction, and (iii) the best masks depend on both motion landmark\n",
      "features and the input mixed-speech spectrogram. To the best of our knowledge,\n",
      "our proposed models are the first models trained and evaluated on the limited\n",
      "size GRID and TCD-TIMIT datasets, that achieve speaker-independent speech\n",
      "enhancement in a multi-talker setting.\n",
      "\n",
      "    \n",
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Grapheme-to-phoneme (G2P) conversion is an important task in automatic speech\n",
      "recognition and text-to-speech systems. Recently, G2P conversion is viewed as a\n",
      "sequence to sequence task and modeled by RNN or CNN based encoder-decoder\n",
      "framework. However, previous works do not consider the practical issues when\n",
      "deploying G2P model in the production system, such as how to leverage\n",
      "additional unlabeled data to boost the accuracy, as well as reduce model size\n",
      "for online deployment. In this work, we propose token-level ensemble\n",
      "distillation for G2P conversion, which can (1) boost the accuracy by distilling\n",
      "the knowledge from additional unlabeled data, and (2) reduce the model size but\n",
      "maintain the high accuracy, both of which are very practical and helpful in the\n",
      "online production system. We use token-level knowledge distillation, which\n",
      "results in better accuracy than the sequence-level counterpart. What is more,\n",
      "we adopt the Transformer instead of RNN or CNN based models to further boost\n",
      "the accuracy of G2P conversion. Experiments on the publicly available CMUDict\n",
      "dataset and an internal English dataset demonstrate the effectiveness of our\n",
      "proposed method. Particularly, our method achieves 19.88% WER on CMUDict\n",
      "dataset, outperforming the previous works by more than 4.22% WER, and setting\n",
      "the new state-of-the-art results.\n",
      "\n",
      "    \n",
      "504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Time series with non-uniform intervals occur in many applications, and are\n",
      "difficult to model using standard recurrent neural networks (RNNs). We\n",
      "generalize RNNs to have continuous-time hidden dynamics defined by ordinary\n",
      "differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use\n",
      "ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE\n",
      "model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps\n",
      "between observations, and can explicitly model the probability of observation\n",
      "times using Poisson processes. We show experimentally that these ODE-based\n",
      "models outperform their RNN-based counterparts on irregularly-sampled data.\n",
      "\n",
      "    \n",
      "505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning compressed representations of multivariate time series (MTS)\n",
      "facilitates data analysis in the presence of noise and redundant information,\n",
      "and for a large number of variates and time steps. However, classical\n",
      "dimensionality reduction approaches are designed for vectorial data and cannot\n",
      "deal explicitly with missing values. In this work, we propose a novel\n",
      "autoencoder architecture based on recurrent neural networks to generate\n",
      "compressed representations of MTS. The proposed model can process inputs\n",
      "characterized by variable lengths and it is specifically designed to handle\n",
      "missing data. Our autoencoder learns fixed-length vectorial representations,\n",
      "whose pairwise similarities are aligned to a kernel function that operates in\n",
      "input space and that handles missing values. This allows to learn good\n",
      "representations, even in the presence of a significant amount of missing data.\n",
      "To show the effectiveness of the proposed approach, we evaluate the quality of\n",
      "the learned representations in several classification tasks, including those\n",
      "involving medical data, and we compare to other methods for dimensionality\n",
      "reduction. Successively, we design two frameworks based on the proposed\n",
      "architecture: one for imputing missing data and another for one-class\n",
      "classification. Finally, we analyze under what circumstances an autoencoder\n",
      "with recurrent layers can learn better compressed representations of MTS than\n",
      "feed-forward architectures.\n",
      "\n",
      "    \n",
      "506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The all-relevant problem of feature selection is the identification of all\n",
      "strongly and weakly relevant attributes. This problem is especially hard to\n",
      "solve for time series classification and regression in industrial applications\n",
      "such as predictive maintenance or production line optimization, for which each\n",
      "label or regression target is associated with several time series and\n",
      "meta-information simultaneously. Here, we are proposing an efficient, scalable\n",
      "feature extraction algorithm for time series, which filters the available\n",
      "features in an early stage of the machine learning pipeline with respect to\n",
      "their significance for the classification or regression task, while controlling\n",
      "the expected percentage of selected but irrelevant features. The proposed\n",
      "algorithm combines established feature extraction methods with a feature\n",
      "importance filter. It has a low computational complexity, allows to start on a\n",
      "problem with only limited domain knowledge available, can be trivially\n",
      "parallelized, is highly scalable and based on well studied non-parametric\n",
      "hypothesis tests. We benchmark our proposed algorithm on all binary\n",
      "classification problems of the UCR time series classification archive as well\n",
      "as time series from a production line optimization project and simulated\n",
      "stochastic processes with underlying qualitative change of dynamics.\n",
      "\n",
      "    \n",
      "507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce Gluon Time Series (GluonTS, available at\n",
      "this https URL), a library for deep-learning-based time series\n",
      "modeling. GluonTS simplifies the development of and experimentation with time\n",
      "series models for common tasks such as forecasting or anomaly detection. It\n",
      "provides all necessary components and tools that scientists need for quickly\n",
      "building new models, for efficiently running and analyzing experiments and for\n",
      "evaluating model accuracy.\n",
      "\n",
      "    \n",
      "508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural sequence models are widely used to model time-series data. Equally\n",
      "ubiquitous is the usage of beam search (BS) as an approximate inference\n",
      "algorithm to decode output sequences from these models. BS explores the search\n",
      "space in a greedy left-right fashion retaining only the top-B candidates -\n",
      "resulting in sequences that differ only slightly from each other. Producing\n",
      "lists of nearly identical sequences is not only computationally wasteful but\n",
      "also typically fails to capture the inherent ambiguity of complex AI tasks. To\n",
      "overcome this problem, we propose Diverse Beam Search (DBS), an alternative to\n",
      "BS that decodes a list of diverse outputs by optimizing for a\n",
      "diversity-augmented objective. We observe that our method finds better top-1\n",
      "solutions by controlling for the exploration and exploitation of the search\n",
      "space - implying that DBS is a better search algorithm. Moreover, these gains\n",
      "are achieved with minimal computational or memory over- head as compared to\n",
      "beam search. To demonstrate the broad applicability of our method, we present\n",
      "results on image captioning, machine translation and visual question generation\n",
      "using both standard quantitative metrics and qualitative human studies.\n",
      "Further, we study the role of diversity for image-grounded language generation\n",
      "tasks as the complexity of the image changes. We observe that our method\n",
      "consistently outperforms BS and previously proposed techniques for diverse\n",
      "decoding from neural sequence models.\n",
      "\n",
      "    \n",
      "509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The spatio-temporal graph learning is becoming an increasingly important\n",
      "object of graph study. Many application domains involve highly dynamic graphs\n",
      "where temporal information is crucial, e.g. traffic networks and financial\n",
      "transaction graphs. Despite the constant progress made on learning structured\n",
      "data, there is still a lack of effective means to extract dynamic complex\n",
      "features from spatio-temporal structures. Particularly, conventional models\n",
      "such as convolutional networks or recurrent neural networks are incapable of\n",
      "revealing the temporal patterns in short or long terms and exploring the\n",
      "spatial properties in local or global scope from spatio-temporal graphs\n",
      "simultaneously. To tackle this problem, we design a novel multi-scale\n",
      "architecture, Spatio-Temporal U-Net (ST-UNet), for graph-structured time series\n",
      "modeling. In this U-shaped network, a paired sampling operation is proposed in\n",
      "spacetime domain accordingly: the pooling (ST-Pool) coarsens the input graph in\n",
      "spatial from its deterministic partition while abstracts multi-resolution\n",
      "temporal dependencies through dilated recurrent skip connections; based on\n",
      "previous settings in the downsampling, the unpooling (ST-Unpool) restores the\n",
      "original structure of spatio-temporal graphs and resumes regular intervals\n",
      "within graph sequences. Experiments on spatio-temporal prediction tasks\n",
      "demonstrate that our model effectively captures comprehensive features in\n",
      "multiple scales and achieves substantial improvements over mainstream methods\n",
      "on several real-world datasets.\n",
      "\n",
      "    \n",
      "510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Increasing model size when pretraining natural language representations often\n",
      "results in improved performance on downstream tasks. However, at some point\n",
      "further model increases become harder due to GPU/TPU memory limitations, longer\n",
      "training times, and unexpected model degradation. To address these problems, we\n",
      "present two parameter-reduction techniques to lower memory consumption and\n",
      "increase the training speed of BERT. Comprehensive empirical evidence shows\n",
      "that our proposed methods lead to models that scale much better compared to the\n",
      "original BERT. We also use a self-supervised loss that focuses on modeling\n",
      "inter-sentence coherence, and show it consistently helps downstream tasks with\n",
      "multi-sentence inputs. As a result, our best model establishes new\n",
      "state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having\n",
      "fewer parameters compared to BERT-large.\n",
      "\n",
      "    \n",
      "511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present the design and implementation of a visual search system for real\n",
      "time image retrieval on this http URL, the world's third largest and China's largest\n",
      "e-commerce site. We demonstrate that our system can support real time visual\n",
      "search with hundreds of billions of product images at sub-second timescales and\n",
      "handle frequent image updates through distributed hierarchical architecture and\n",
      "efficient indexing methods. We hope that sharing our practice with our real\n",
      "production system will inspire the middleware community's interest and\n",
      "appreciation for building practical large scale systems for emerging\n",
      "applications, such as ecommerce visual search.\n",
      "\n",
      "    \n",
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Localization of salient facial landmark points, such as eye corners or the\n",
      "tip of the nose, is still considered a challenging computer vision problem\n",
      "despite recent efforts. This is especially evident in unconstrained\n",
      "environments, i.e., in the presence of background clutter and large head pose\n",
      "variations. Most methods that achieve state-of-the-art accuracy are slow, and,\n",
      "thus, have limited applications. We describe a method that can accurately\n",
      "estimate the positions of relevant facial landmarks in real-time even on\n",
      "hardware with limited processing power, such as mobile devices. This is\n",
      "achieved with a sequence of estimators based on ensembles of regression trees.\n",
      "The trees use simple pixel intensity comparisons in their internal nodes and\n",
      "this makes them able to process image regions very fast. We test the developed\n",
      "system on several publicly available datasets and analyse its processing speed\n",
      "on various devices. Experimental results show that our method has practical\n",
      "value.\n",
      "\n",
      "    \n",
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe a method for visual object detection based on an ensemble of\n",
      "optimized decision trees organized in a cascade of rejectors. The trees use\n",
      "pixel intensity comparisons in their internal nodes and this makes them able to\n",
      "process image regions very fast. Experimental analysis is provided through a\n",
      "face detection problem. The obtained results are encouraging and demonstrate\n",
      "that the method has practical value. Additionally, we analyse its sensitivity\n",
      "to noise and show how to perform fast rotation invariant object detection.\n",
      "Complete source code is provided at this https URL.\n",
      "\n",
      "    \n",
      "514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Bayesian optimization provides sample-efficient global optimization for a\n",
      "broad range of applications, including automatic machine learning, molecular\n",
      "chemistry, and experimental design. We introduce BoTorch, a modern programming\n",
      "framework for Bayesian optimization. Enabled by Monte-Carlo (MC) acquisition\n",
      "functions and auto-differentiation, BoTorch's modular design facilitates\n",
      "flexible specification and optimization of probabilistic models written in\n",
      "PyTorch, radically simplifying implementation of novel acquisition functions.\n",
      "Our MC approach is made practical by a distinctive algorithmic foundation that\n",
      "leverages fast predictive distributions and hardware acceleration. In\n",
      "experiments, we demonstrate the improved sample efficiency of BoTorch relative\n",
      "to other popular libraries. BoTorch is open source and available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Binary neural networks have attracted numerous attention in recent years.\n",
      "However, mainly due to the information loss stemming from the biased\n",
      "binarization, how to preserve the accuracy of networks still remains a critical\n",
      "issue. In this paper, we attempt to maintain the information propagated in the\n",
      "forward process and propose a Balanced Binary Neural Networks with Gated\n",
      "Residual (BBG for short). First, a weight balanced binarization is introduced\n",
      "to maximize information entropy of binary weights, and thus the informative\n",
      "binary weights can capture more information contained in the activations.\n",
      "Second, for binary activations, a gated residual is further appended to\n",
      "compensate their information loss during the forward process, with a slight\n",
      "overhead. Both techniques can be wrapped as a generic network module that\n",
      "supports various network architectures for different tasks including\n",
      "classification and detection. We evaluate our BBG on image classification tasks\n",
      "over CIFAR-10/100 and ImageNet and on detection task over Pascal VOC. The\n",
      "experimental results show that BBG-Net performs remarkably well across various\n",
      "network architectures such as VGG, ResNet and SSD with the superior performance\n",
      "over state-of-the-art methods in terms of memory consumption, inference speed\n",
      "and accuracy.\n",
      "\n",
      "    \n",
      "516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Chinese word segmentation (CWS) is a fundamental step of Chinese natural\n",
      "language processing. In this paper, we build a new toolkit, named PKUSEG, for\n",
      "multi-domain word segmentation. Unlike existing single-model toolkits, PKUSEG\n",
      "targets at multi-domain word segmentation and provides separate models for\n",
      "different domains, such as web, medicine, and tourism. The new toolkit also\n",
      "supports POS tagging and model training to adapt to various application\n",
      "scenarios. Experiments show that PKUSEG achieves high performance on multiple\n",
      "domains. The toolkit is now freely and publicly available for the usage of\n",
      "research and industry.\n",
      "\n",
      "    \n",
      "517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Data augmentation is a commonly used technique for increasing both the size\n",
      "and the diversity of labeled training sets by leveraging input transformations\n",
      "that preserve output labels. In computer vision domain, image augmentations\n",
      "have become a common implicit regularization technique to combat overfitting in\n",
      "deep convolutional neural networks and are ubiquitously used to improve\n",
      "performance. While most deep learning frameworks implement basic image\n",
      "transformations, the list is typically limited to some variations and\n",
      "combinations of flipping, rotating, scaling, and cropping. Moreover, the image\n",
      "processing speed varies in existing tools for image augmentation. We present\n",
      "Albumentations, a fast and flexible library for image augmentations with many\n",
      "various image transform operations available, that is also an easy-to-use\n",
      "wrapper around other augmentation libraries. We provide examples of image\n",
      "augmentations for different computer vision tasks and show that Albumentations\n",
      "is faster than other commonly used image augmentation tools on the most of\n",
      "commonly used image transformations. The source code for Albumentations is made\n",
      "publicly available online at this https URL\n",
      "\n",
      "518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openreview.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dl.acm.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Caffe provides multimedia scientists and practitioners with a clean and\n",
      "modifiable framework for state-of-the-art deep learning algorithms and a\n",
      "collection of reference models. The framework is a BSD-licensed C++ library\n",
      "with Python and MATLAB bindings for training and deploying general-purpose\n",
      "convolutional neural networks and other deep models efficiently on commodity\n",
      "architectures. Caffe fits industry and internet-scale media needs by CUDA GPU\n",
      "computation, processing over 40 million images a day on a single K40 or Titan\n",
      "GPU ($\\approx$ 2.5 ms per image). By separating model representation from\n",
      "actual implementation, Caffe allows experimentation and seamless switching\n",
      "among platforms for ease of development and deployment from prototyping\n",
      "machines to cloud environments. Caffe is maintained and developed by the\n",
      "Berkeley Vision and Learning Center (BVLC) with the help of an active community\n",
      "of contributors on GitHub. It powers ongoing research projects, large-scale\n",
      "industrial applications, and startup prototypes in vision, speech, and\n",
      "multimedia.\n",
      "\n",
      "    \n",
      "521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The highest accuracy object detectors to date are based on a two-stage\n",
      "approach popularized by R-CNN, where a classifier is applied to a sparse set of\n",
      "candidate object locations. In contrast, one-stage detectors that are applied\n",
      "over a regular, dense sampling of possible object locations have the potential\n",
      "to be faster and simpler, but have trailed the accuracy of two-stage detectors\n",
      "thus far. In this paper, we investigate why this is the case. We discover that\n",
      "the extreme foreground-background class imbalance encountered during training\n",
      "of dense detectors is the central cause. We propose to address this class\n",
      "imbalance by reshaping the standard cross entropy loss such that it\n",
      "down-weights the loss assigned to well-classified examples. Our novel Focal\n",
      "Loss focuses training on a sparse set of hard examples and prevents the vast\n",
      "number of easy negatives from overwhelming the detector during training. To\n",
      "evaluate the effectiveness of our loss, we design and train a simple dense\n",
      "detector we call RetinaNet. Our results show that when trained with the focal\n",
      "loss, RetinaNet is able to match the speed of previous one-stage detectors\n",
      "while surpassing the accuracy of all existing state-of-the-art two-stage\n",
      "detectors. Code is at: this https URL.\n",
      "\n",
      "    \n",
      "522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We investigate omni-supervised learning, a special regime of semi-supervised\n",
      "learning in which the learner exploits all available labeled data plus\n",
      "internet-scale sources of unlabeled data. Omni-supervised learning is\n",
      "lower-bounded by performance on existing labeled datasets, offering the\n",
      "potential to surpass state-of-the-art fully supervised methods. To exploit the\n",
      "omni-supervised setting, we propose data distillation, a method that ensembles\n",
      "predictions from multiple transformations of unlabeled data, using a single\n",
      "model, to automatically generate new training annotations. We argue that visual\n",
      "recognition models have recently become accurate enough that it is now possible\n",
      "to apply classic ideas about self-training to challenging real-world data. Our\n",
      "experimental results show that in the cases of human keypoint detection and\n",
      "general object detection, state-of-the-art models trained with data\n",
      "distillation surpass the performance of using labeled data from the COCO\n",
      "dataset alone.\n",
      "\n",
      "    \n",
      "523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most methods for object instance segmentation require all training examples\n",
      "to be labeled with segmentation masks. This requirement makes it expensive to\n",
      "annotate new categories and has restricted instance segmentation models to ~100\n",
      "well-annotated classes. The goal of this paper is to propose a new partially\n",
      "supervised training paradigm, together with a novel weight transfer function,\n",
      "that enables training instance segmentation models on a large set of categories\n",
      "all of which have box annotations, but only a small fraction of which have mask\n",
      "annotations. These contributions allow us to train Mask R-CNN to detect and\n",
      "segment 3000 visual concepts using box annotations from the Visual Genome\n",
      "dataset and mask annotations from the 80 classes in the COCO dataset. We\n",
      "evaluate our approach in a controlled study on the COCO dataset. This work is a\n",
      "first step towards instance segmentation models that have broad comprehension\n",
      "of the visual world.\n",
      "\n",
      "    \n",
      "524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Batch Normalization (BN) is a milestone technique in the development of deep\n",
      "learning, enabling various networks to train. However, normalizing along the\n",
      "batch dimension introduces problems --- BN's error increases rapidly when the\n",
      "batch size becomes smaller, caused by inaccurate batch statistics estimation.\n",
      "This limits BN's usage for training larger models and transferring features to\n",
      "computer vision tasks including detection, segmentation, and video, which\n",
      "require small batches constrained by memory consumption. In this paper, we\n",
      "present Group Normalization (GN) as a simple alternative to BN. GN divides the\n",
      "channels into groups and computes within each group the mean and variance for\n",
      "normalization. GN's computation is independent of batch sizes, and its accuracy\n",
      "is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN\n",
      "has 10.6% lower error than its BN counterpart when using a batch size of 2;\n",
      "when using typical batch sizes, GN is comparably good with BN and outperforms\n",
      "other normalization variants. Moreover, GN can be naturally transferred from\n",
      "pre-training to fine-tuning. GN can outperform its BN-based counterparts for\n",
      "object detection and segmentation in COCO, and for video classification in\n",
      "Kinetics, showing that GN can effectively replace the powerful BN in a variety\n",
      "of tasks. GN can be easily implemented by a few lines of code in modern\n",
      "libraries.\n",
      "\n",
      "    \n",
      "525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  To understand the visual world, a machine must not only recognize individual\n",
      "object instances but also how they interact. Humans are often at the center of\n",
      "such interactions and detecting human-object interactions is an important\n",
      "practical and scientific problem. In this paper, we address the task of\n",
      "detecting <human, verb, object> triplets in challenging everyday photos. We\n",
      "propose a novel model that is driven by a human-centric approach. Our\n",
      "hypothesis is that the appearance of a person -- their pose, clothing, action\n",
      "-- is a powerful cue for localizing the objects they are interacting with. To\n",
      "exploit this cue, our model learns to predict an action-specific density over\n",
      "target object locations based on the appearance of a detected person. Our model\n",
      "also jointly learns to detect people and objects, and by fusing these\n",
      "predictions it efficiently infers interaction triplets in a clean, jointly\n",
      "trained end-to-end system we call InteractNet. We validate our approach on the\n",
      "recently introduced Verbs in COCO (V-COCO) and HICO-DET datasets, where we show\n",
      "quantitatively compelling results.\n",
      "\n",
      "    \n",
      "526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Both convolutional and recurrent operations are building blocks that process\n",
      "one local neighborhood at a time. In this paper, we present non-local\n",
      "operations as a generic family of building blocks for capturing long-range\n",
      "dependencies. Inspired by the classical non-local means method in computer\n",
      "vision, our non-local operation computes the response at a position as a\n",
      "weighted sum of the features at all positions. This building block can be\n",
      "plugged into many computer vision architectures. On the task of video\n",
      "classification, even without any bells and whistles, our non-local models can\n",
      "compete or outperform current competition winners on both Kinetics and Charades\n",
      "datasets. In static image recognition, our non-local models improve object\n",
      "detection/segmentation and pose estimation on the COCO suite of tasks. Code is\n",
      "available at this https URL .\n",
      "\n",
      "    \n",
      "527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  OpenAI Gym is a toolkit for reinforcement learning research. It includes a\n",
      "growing collection of benchmark problems that expose a common interface, and a\n",
      "website where people can share their results and compare the performance of\n",
      "algorithms. This whitepaper discusses the components of OpenAI Gym and the\n",
      "design decisions that went into the software.\n",
      "\n",
      "    \n",
      "528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  MXNet is a multi-language machine learning (ML) library to ease the\n",
      "development of ML algorithms, especially for deep neural networks. Embedded in\n",
      "the host language, it blends declarative symbolic expression with imperative\n",
      "tensor computation. It offers auto differentiation to derive gradients. MXNet\n",
      "is computation and memory efficient and runs on various heterogeneous systems,\n",
      "ranging from mobile devices to distributed GPU clusters.\n",
      "This paper describes both the API design and the system implementation of\n",
      "MXNet, and explains how embedding of both symbolic expression and tensor\n",
      "operation is handled in a unified fashion. Our preliminary experiments reveal\n",
      "promising results on large scale deep neural network applications using\n",
      "multiple GPU machines.\n",
      "\n",
      "    \n",
      "529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Tree boosting is a highly effective and widely used machine learning method.\n",
      "In this paper, we describe a scalable end-to-end tree boosting system called\n",
      "XGBoost, which is used widely by data scientists to achieve state-of-the-art\n",
      "results on many machine learning challenges. We propose a novel sparsity-aware\n",
      "algorithm for sparse data and weighted quantile sketch for approximate tree\n",
      "learning. More importantly, we provide insights on cache access patterns, data\n",
      "compression and sharding to build a scalable tree boosting system. By combining\n",
      "these insights, XGBoost scales beyond billions of examples using far fewer\n",
      "resources than existing systems.\n",
      "\n",
      "    \n",
      "530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose an approximate strategy to efficiently train neural network based\n",
      "language models over very large vocabularies. Our approach, called adaptive\n",
      "softmax, circumvents the linear dependency on the vocabulary size by exploiting\n",
      "the unbalanced word distribution to form clusters that explicitly minimize the\n",
      "expectation of computation time. Our approach further reduces the computational\n",
      "time by exploiting the specificities of modern architectures and matrix-matrix\n",
      "vector operations, making it particularly suited for graphical processing\n",
      "units. Our experiments carried out on standard benchmarks, such as EuroParl and\n",
      "One Billion Word, show that our approach brings a large gain in efficiency over\n",
      "standard approximations while achieving an accuracy close to that of the full\n",
      "softmax. The code of our method is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in modern Natural Language Processing (NLP) research have\n",
      "been dominated by the combination of Transfer Learning methods with large-scale\n",
      "language models, in particular based on the Transformer architecture. With them\n",
      "came a paradigm shift in NLP with the starting point for training a model on a\n",
      "downstream task moving from a blank specific model to a general-purpose\n",
      "pretrained architecture. Still, creating these general-purpose models remains\n",
      "an expensive and time-consuming process restricting the use of these methods to\n",
      "a small sub-set of the wider NLP community. In this paper, we present\n",
      "HuggingFace's Transformers library, a library for state-of-the-art NLP, making\n",
      "these developments available to the community by gathering state-of-the-art\n",
      "general-purpose pretrained models under a unified API together with an\n",
      "ecosystem of libraries, examples, tutorials and scripts targeting many\n",
      "downstream NLP tasks. HuggingFace's Transformers library features carefully\n",
      "crafted model implementations and high-performance pretrained weights for two\n",
      "main deep learning frameworks, PyTorch and TensorFlow, while supporting all the\n",
      "necessary tools to analyze, evaluate and use these models in downstream tasks\n",
      "such as text/token classification, questions answering and language generation\n",
      "among others. The library has gained significant organic traction and adoption\n",
      "among both the researcher and practitioner communities. We are committed at\n",
      "HuggingFace to pursue the efforts to develop this toolkit with the ambition of\n",
      "creating the standard library for building NLP systems.\n",
      "\n",
      "    \n",
      "533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  As Transfer Learning from large-scale pre-trained models becomes more\n",
      "prevalent in Natural Language Processing (NLP), operating these large models in\n",
      "on-the-edge and/or under constrained computational training or inference\n",
      "budgets remains challenging. In this work, we propose a method to pre-train a\n",
      "smaller general-purpose language representation model, called DistilBERT, which\n",
      "can then be fine-tuned with good performances on a wide range of tasks like its\n",
      "larger counterparts. While most prior work investigated the use of distillation\n",
      "for building task-specific models, we leverage knowledge distillation during\n",
      "the pre-training phase and show that it is possible to reduce the size of a\n",
      "BERT model by 40%, while retaining 97% of its language understanding\n",
      "capabilities and being 60% faster. To leverage the inductive biases learned by\n",
      "larger models during pre-training, we introduce a triple loss combining\n",
      "language modeling, distillation and cosine-distance losses. Our smaller, faster\n",
      "and lighter model is cheaper to pre-train and we demonstrate its capabilities\n",
      "for on-device computations in a proof-of-concept experiment and a comparative\n",
      "on-device study.\n",
      "\n",
      "    \n",
      "534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an approach that uses a multi-camera system to train fine-grained\n",
      "detectors for keypoints that are prone to occlusion, such as the joints of a\n",
      "hand. We call this procedure multiview bootstrapping: first, an initial\n",
      "keypoint detector is used to produce noisy labels in multiple views of the\n",
      "hand. The noisy detections are then triangulated in 3D using multiview geometry\n",
      "or marked as outliers. Finally, the reprojected triangulations are used as new\n",
      "labeled training data to improve the detector. We repeat this process,\n",
      "generating more labeled data in each iteration. We derive a result analytically\n",
      "relating the minimum number of views to achieve target true and false positive\n",
      "rates for a given detector. The method is used to train a hand keypoint\n",
      "detector for single images. The resulting keypoint detector runs in realtime on\n",
      "RGB images and has accuracy comparable to methods that use depth sensors. The\n",
      "single view detector, triangulated over multiple views, enables 3D markerless\n",
      "hand motion capture with complex object interactions.\n",
      "\n",
      "    \n",
      "535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an approach to efficiently detect the 2D pose of multiple people\n",
      "in an image. The approach uses a nonparametric representation, which we refer\n",
      "to as Part Affinity Fields (PAFs), to learn to associate body parts with\n",
      "individuals in the image. The architecture encodes global context, allowing a\n",
      "greedy bottom-up parsing step that maintains high accuracy while achieving\n",
      "realtime performance, irrespective of the number of people in the image. The\n",
      "architecture is designed to jointly learn part locations and their association\n",
      "via two branches of the same sequential prediction process. Our method placed\n",
      "first in the inaugural COCO 2016 keypoints challenge, and significantly exceeds\n",
      "the previous state-of-the-art result on the MPII Multi-Person benchmark, both\n",
      "in performance and efficiency.\n",
      "\n",
      "    \n",
      "536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Realtime multi-person 2D pose estimation is a key component in enabling\n",
      "machines to have an understanding of people in images and videos. In this work,\n",
      "we present a realtime approach to detect the 2D pose of multiple people in an\n",
      "image. The proposed method uses a nonparametric representation, which we refer\n",
      "to as Part Affinity Fields (PAFs), to learn to associate body parts with\n",
      "individuals in the image. This bottom-up system achieves high accuracy and\n",
      "realtime performance, regardless of the number of people in the image. In\n",
      "previous work, PAFs and body part location estimation were refined\n",
      "simultaneously across training stages. We demonstrate that a PAF-only\n",
      "refinement rather than both PAF and body part location refinement results in a\n",
      "substantial increase in both runtime performance and accuracy. We also present\n",
      "the first combined body and foot keypoint detector, based on an internal\n",
      "annotated foot dataset that we have publicly released. We show that the\n",
      "combined detector not only reduces the inference time compared to running them\n",
      "sequentially, but also maintains the accuracy of each component individually.\n",
      "This work has culminated in the release of OpenPose, the first open-source\n",
      "realtime system for multi-person 2D pose detection, including body, foot, hand,\n",
      "and facial keypoints.\n",
      "\n",
      "    \n",
      "537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Pose Machines provide a sequential prediction framework for learning rich\n",
      "implicit spatial models. In this work we show a systematic design for how\n",
      "convolutional networks can be incorporated into the pose machine framework for\n",
      "learning image features and image-dependent spatial models for the task of pose\n",
      "estimation. The contribution of this paper is to implicitly model long-range\n",
      "dependencies between variables in structured prediction tasks such as\n",
      "articulated pose estimation. We achieve this by designing a sequential\n",
      "architecture composed of convolutional networks that directly operate on belief\n",
      "maps from previous stages, producing increasingly refined estimates for part\n",
      "locations, without the need for explicit graphical model-style inference. Our\n",
      "approach addresses the characteristic difficulty of vanishing gradients during\n",
      "training by providing a natural learning objective function that enforces\n",
      "intermediate supervision, thereby replenishing back-propagated gradients and\n",
      "conditioning the learning procedure. We demonstrate state-of-the-art\n",
      "performance and outperform competing methods on standard benchmarks including\n",
      "the MPII, LSP, and FLIC datasets.\n",
      "\n",
      "    \n",
      "538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of producing compact architectures for text\n",
      "classification, such that the full model fits in a limited amount of memory.\n",
      "After considering different solutions inspired by the hashing literature, we\n",
      "propose a method built upon product quantization to store word embeddings.\n",
      "While the original technique leads to a loss in accuracy, we adapt this method\n",
      "to circumvent quantization artefacts. Our experiments carried out on several\n",
      "benchmarks show that our approach typically requires two orders of magnitude\n",
      "less memory than fastText while being only slightly inferior with respect to\n",
      "accuracy. As a result, it outperforms the state of the art by a good margin in\n",
      "terms of the compromise between memory usage and accuracy.\n",
      "\n",
      "    \n",
      "539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Continuous word representations, trained on large unlabeled corpora are\n",
      "useful for many natural language processing tasks. Popular models that learn\n",
      "such representations ignore the morphology of words, by assigning a distinct\n",
      "vector to each word. This is a limitation, especially for languages with large\n",
      "vocabularies and many rare words. In this paper, we propose a new approach\n",
      "based on the skipgram model, where each word is represented as a bag of\n",
      "character $n$-grams. A vector representation is associated to each character\n",
      "$n$-gram; words being represented as the sum of these representations. Our\n",
      "method is fast, allowing to train models on large corpora quickly and allows us\n",
      "to compute word representations for words that did not appear in the training\n",
      "data. We evaluate our word representations on nine different languages, both on\n",
      "word similarity and analogy tasks. By comparing to recently proposed\n",
      "morphological word representations, we show that our vectors achieve\n",
      "state-of-the-art performance on these tasks.\n",
      "\n",
      "    \n",
      "540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Transforming a graphical user interface screenshot created by a designer into\n",
      "computer code is a typical task conducted by a developer in order to build\n",
      "customized software, websites, and mobile applications. In this paper, we show\n",
      "that deep learning methods can be leveraged to train a model end-to-end to\n",
      "automatically generate code from a single input image with over 77% of accuracy\n",
      "for three different platforms (i.e. iOS, Android and web-based technologies).\n",
      "\n",
      "    \n",
      "541\n",
      "It is pdf\n",
      "542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Photorealistic image stylization concerns transferring style of a reference\n",
      "photo to a content photo with the constraint that the stylized photo should\n",
      "remain photorealistic. While several photorealistic image stylization methods\n",
      "exist, they tend to generate spatially inconsistent stylizations with\n",
      "noticeable artifacts. In this paper, we propose a method to address these\n",
      "issues. The proposed method consists of a stylization step and a smoothing\n",
      "step. While the stylization step transfers the style of the reference photo to\n",
      "the content photo, the smoothing step ensures spatially consistent\n",
      "stylizations. Each of the steps has a closed-form solution and can be computed\n",
      "efficiently. We conduct extensive experimental validations. The results show\n",
      "that the proposed method generates photorealistic stylization outputs that are\n",
      "more preferred by human subjects as compared to those by the competing methods\n",
      "while running much faster. Source code and additional results are available at\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "543\n",
      "It is pdf\n",
      "544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This article describes our experiments in neural machine translation using\n",
      "the recent Tensor2Tensor framework and the Transformer sequence-to-sequence\n",
      "model (Vaswani et al., 2017). We examine some of the critical parameters that\n",
      "affect the final translation quality, memory usage, training stability and\n",
      "training time, concluding each experiment with a set of recommendations for\n",
      "fellow researchers. In addition to confirming the general mantra \"more data and\n",
      "larger models\", we address scaling to multiple GPUs and provide practical tips\n",
      "for improved training regarding batch size, learning rate, warmup steps,\n",
      "maximum sentence length and checkpoint averaging. We hope that our observations\n",
      "will allow others to get better results given their particular hardware and\n",
      "data constraints.\n",
      "\n",
      "    \n",
      "545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent works have highlighted the strength of the Transformer architecture on\n",
      "sequence tasks while, at the same time, neural architecture search (NAS) has\n",
      "begun to outperform human-designed models. Our goal is to apply NAS to search\n",
      "for a better alternative to the Transformer. We first construct a large search\n",
      "space inspired by the recent advances in feed-forward sequence models and then\n",
      "run evolutionary architecture search with warm starting by seeding our initial\n",
      "population with the Transformer. To directly search on the computationally\n",
      "expensive WMT 2014 English-German translation task, we develop the Progressive\n",
      "Dynamic Hurdles method, which allows us to dynamically allocate more resources\n",
      "to more promising candidate models. The architecture found in our experiments\n",
      "-- the Evolved Transformer -- demonstrates consistent improvement over the\n",
      "Transformer on four well-established language tasks: WMT 2014 English-German,\n",
      "WMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,\n",
      "the Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8\n",
      "on WMT'14 English-German; at smaller sizes, it achieves the same quality as the\n",
      "original \"big\" Transformer with 37.6% less parameters and outperforms the\n",
      "Transformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.\n",
      "\n",
      "    \n",
      "546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We show that generating English Wikipedia articles can be approached as a\n",
      "multi- document summarization of source documents. We use extractive\n",
      "summarization to coarsely identify salient information and a neural abstractive\n",
      "model to generate the article. For the abstractive model, we introduce a\n",
      "decoder-only architecture that can scalably attend to very long sequences, much\n",
      "longer than typical encoder- decoder architectures used in sequence\n",
      "transduction. We show that this model can generate fluent, coherent\n",
      "multi-sentence paragraphs and even whole Wikipedia articles. When given\n",
      "reference documents, we show it can extract relevant factual information as\n",
      "reflected in perplexity, ROUGE scores and human evaluations.\n",
      "\n",
      "    \n",
      "547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recurrent neural networks (RNNs) sequentially process data by updating their\n",
      "state with each new data point, and have long been the de facto choice for\n",
      "sequence modeling tasks. However, their inherently sequential computation makes\n",
      "them slow to train. Feed-forward and convolutional architectures have recently\n",
      "been shown to achieve superior results on some sequence modeling tasks such as\n",
      "machine translation, with the added advantage that they concurrently process\n",
      "all inputs in the sequence, leading to easy parallelization and faster training\n",
      "times. Despite these successes, however, popular feed-forward sequence models\n",
      "like the Transformer fail to generalize in many simple tasks that recurrent\n",
      "models handle with ease, e.g. copying strings or even simple logical inference\n",
      "when the string or formula lengths exceed those observed at training time. We\n",
      "propose the Universal Transformer (UT), a parallel-in-time self-attentive\n",
      "recurrent sequence model which can be cast as a generalization of the\n",
      "Transformer model and which addresses these issues. UTs combine the\n",
      "parallelizability and global receptive field of feed-forward sequence models\n",
      "like the Transformer with the recurrent inductive bias of RNNs. We also add a\n",
      "dynamic per-position halting mechanism and find that it improves accuracy on\n",
      "several tasks. In contrast to the standard Transformer, under certain\n",
      "assumptions, UTs can be shown to be Turing-complete. Our experiments show that\n",
      "UTs outperform standard Transformers on a wide range of algorithmic and\n",
      "language understanding tasks, including the challenging LAMBADA language\n",
      "modeling task where UTs achieve a new state of the art, and machine translation\n",
      "where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De\n",
      "dataset.\n",
      "\n",
      "    \n",
      "548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Relying entirely on an attention mechanism, the Transformer introduced by\n",
      "Vaswani et al. (2017) achieves state-of-the-art results for machine\n",
      "translation. In contrast to recurrent and convolutional neural networks, it\n",
      "does not explicitly model relative or absolute position information in its\n",
      "structure. Instead, it requires adding representations of absolute positions to\n",
      "its inputs. In this work we present an alternative approach, extending the\n",
      "self-attention mechanism to efficiently consider representations of the\n",
      "relative positions, or distances between sequence elements. On the WMT 2014\n",
      "English-to-German and English-to-French translation tasks, this approach yields\n",
      "improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations,\n",
      "respectively. Notably, we observe that combining relative and absolute position\n",
      "representations yields no further improvement in translation quality. We\n",
      "describe an efficient implementation of our method and cast it as an instance\n",
      "of relation-aware self-attention mechanisms that can generalize to arbitrary\n",
      "graph-labeled inputs.\n",
      "\n",
      "    \n",
      "549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Mathematical expressions were generated, evaluated and used to train neural\n",
      "network models based on the transformer architecture. The expressions and their\n",
      "targets were analyzed as a character-level sequence transduction task in which\n",
      "the encoder and decoder are built on attention mechanisms. Three models were\n",
      "trained to understand and evaluate symbolic variables and expressions in\n",
      "mathematics: (1) the self-attentive and feed-forward transformer without\n",
      "recurrence or convolution, (2) the universal transformer with recurrence, and\n",
      "(3) the adaptive universal transformer with recurrence and adaptive computation\n",
      "time. The models respectively achieved test accuracies as high as 76.1%, 78.8%\n",
      "and 84.9% in evaluating the expressions to match the target values. For the\n",
      "cases inferred incorrectly, the results differed from the targets by only one\n",
      "or two characters. The models notably learned to add, subtract and multiply\n",
      "both positive and negative decimal numbers of variable digits assigned to\n",
      "symbolic variables.\n",
      "\n",
      "    \n",
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Depthwise separable convolutions reduce the number of parameters and\n",
      "computation used in convolutional operations while increasing representational\n",
      "efficiency. They have been shown to be successful in image classification\n",
      "models, both in obtaining better models than previously possible for a given\n",
      "parameter count (the Xception architecture) and considerably reducing the\n",
      "number of parameters required to perform at a given level (the MobileNets\n",
      "family of architectures). Recently, convolutional sequence-to-sequence networks\n",
      "have been applied to machine translation tasks with good results. In this work,\n",
      "we study how depthwise separable convolutions can be applied to neural machine\n",
      "translation. We introduce a new architecture inspired by Xception and ByteNet,\n",
      "called SliceNet, which enables a significant reduction of the parameter count\n",
      "and amount of computation needed to obtain results like ByteNet, and, with a\n",
      "similar parameter count, achieves new state-of-the-art results. In addition to\n",
      "showing that depthwise separable convolutions perform well for machine\n",
      "translation, we investigate the architectural changes that they enable: we\n",
      "observe that thanks to depthwise separability, we can increase the length of\n",
      "convolution windows, removing the need for filter dilation. We also introduce a\n",
      "new \"super-separable\" convolution operation that further reduces the number of\n",
      "parameters and computational cost for obtaining state-of-the-art results.\n",
      "\n",
      "    \n",
      "551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern machine learning algorithms are increasingly computationally\n",
      "demanding, requiring specialized hardware and distributed computation to\n",
      "achieve high performance in a reasonable time frame. Many hyperparameter search\n",
      "algorithms have been proposed for improving the efficiency of model selection,\n",
      "however their adaptation to the distributed compute environment is often\n",
      "ad-hoc. We propose Tune, a unified framework for model selection and training\n",
      "that provides a narrow-waist interface between training scripts and search\n",
      "algorithms. We show that this interface meets the requirements for a broad\n",
      "range of hyperparameter search algorithms, allows straightforward scaling of\n",
      "search to large clusters, and simplifies algorithm implementation. We\n",
      "demonstrate the implementation of several state-of-the-art hyperparameter\n",
      "search algorithms in Tune. Tune is available at\n",
      "this http URL.\n",
      "\n",
      "    \n",
      "552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose the Self-Attention Generative Adversarial Network\n",
      "(SAGAN) which allows attention-driven, long-range dependency modeling for image\n",
      "generation tasks. Traditional convolutional GANs generate high-resolution\n",
      "details as a function of only spatially local points in lower-resolution\n",
      "feature maps. In SAGAN, details can be generated using cues from all feature\n",
      "locations. Moreover, the discriminator can check that highly detailed features\n",
      "in distant portions of the image are consistent with each other. Furthermore,\n",
      "recent work has shown that generator conditioning affects GAN performance.\n",
      "Leveraging this insight, we apply spectral normalization to the GAN generator\n",
      "and find that this improves training dynamics. The proposed SAGAN achieves the\n",
      "state-of-the-art results, boosting the best published Inception score from 36.8\n",
      "to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the\n",
      "challenging ImageNet dataset. Visualization of the attention layers shows that\n",
      "the generator leverages neighborhoods that correspond to object shapes rather\n",
      "than local regions of fixed shape.\n",
      "\n",
      "    \n",
      "553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  It this paper we revisit the fast stylization method introduced in Ulyanov\n",
      "et. al. (2016). We show how a small change in the stylization architecture\n",
      "results in a significant qualitative improvement in the generated images. The\n",
      "change is limited to swapping batch normalization with instance normalization,\n",
      "and to apply the latter both at training and testing times. The resulting\n",
      "method can be used to train high-performance architectures for real-time image\n",
      "generation. The code will is made available on github at\n",
      "this https URL. Full paper can be found at\n",
      "arXiv:1701.02096.\n",
      "\n",
      "    \n",
      "554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generative Adversarial Networks (GANs) excel at creating realistic images\n",
      "with complex models for which maximum likelihood is infeasible. However, the\n",
      "convergence of GAN training has still not been proved. We propose a two\n",
      "time-scale update rule (TTUR) for training GANs with stochastic gradient\n",
      "descent on arbitrary GAN loss functions. TTUR has an individual learning rate\n",
      "for both the discriminator and the generator. Using the theory of stochastic\n",
      "approximation, we prove that the TTUR converges under mild assumptions to a\n",
      "stationary local Nash equilibrium. The convergence carries over to the popular\n",
      "Adam optimization, for which we prove that it follows the dynamics of a heavy\n",
      "ball with friction and thus prefers flat minima in the objective landscape. For\n",
      "the evaluation of the performance of GANs at image generation, we introduce the\n",
      "\"Fréchet Inception Distance\" (FID) which captures the similarity of generated\n",
      "images to real ones better than the Inception Score. In experiments, TTUR\n",
      "improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)\n",
      "outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN\n",
      "Bedrooms, and the One Billion Word Benchmark.\n",
      "\n",
      "    \n",
      "555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE)\n",
      "models for large scale image generation. To this end, we scale and enhance the\n",
      "autoregressive priors used in VQ-VAE to generate synthetic samples of much\n",
      "higher coherence and fidelity than possible before. We use simple feed-forward\n",
      "encoder and decoder networks, making our model an attractive candidate for\n",
      "applications where the encoding and/or decoding speed is critical.\n",
      "Additionally, VQ-VAE requires sampling an autoregressive model only in the\n",
      "compressed latent space, which is an order of magnitude faster than sampling in\n",
      "the pixel space, especially for large images. We demonstrate that a multi-scale\n",
      "hierarchical organization of VQ-VAE, augmented with powerful priors over the\n",
      "latent codes, is able to generate samples with quality that rivals that of\n",
      "state of the art Generative Adversarial Networks on multifaceted datasets such\n",
      "as ImageNet, while not suffering from GAN's known shortcomings such as mode\n",
      "collapse and lack of diversity.\n",
      "\n",
      "    \n",
      "556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Similarity search approaches based on graph walks have recently attained\n",
      "outstanding speed-accuracy trade-offs, taking aside the memory requirements. In\n",
      "this paper, we revisit these approaches by considering, additionally, the\n",
      "memory constraint required to index billions of images on a single server. This\n",
      "leads us to propose a method based both on graph traversal and compact\n",
      "representations. We encode the indexed vectors using quantization and exploit\n",
      "the graph structure to refine the similarity estimation.\n",
      "In essence, our method takes the best of these two worlds: the search\n",
      "strategy is based on nested graphs, thereby providing high precision with a\n",
      "relatively small set of comparisons. At the same time it offers a significant\n",
      "memory compression. As a result, our approach outperforms the state of the art\n",
      "on operating points considering 64-128 bytes per vector, as demonstrated by our\n",
      "results on two billion-scale public benchmarks.\n",
      "\n",
      "    \n",
      "557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Similarity search finds application in specialized database systems handling\n",
      "complex data such as images or videos, which are typically represented by\n",
      "high-dimensional features and require specific indexing structures. This paper\n",
      "tackles the problem of better utilizing GPUs for this task. While GPUs excel at\n",
      "data-parallel tasks, prior approaches are bottlenecked by algorithms that\n",
      "expose less parallelism, such as k-min selection, or make poor use of the\n",
      "memory hierarchy.\n",
      "We propose a design for k-selection that operates at up to 55% of theoretical\n",
      "peak performance, enabling a nearest neighbor implementation that is 8.5x\n",
      "faster than prior GPU state of the art. We apply it in different similarity\n",
      "search scenarios, by proposing optimized design for brute-force, approximate\n",
      "and compressed-domain search based on product quantization. In all these\n",
      "setups, we outperform the state of the art by large margins. Our implementation\n",
      "enables the construction of a high accuracy k-NN graph on 95 million images\n",
      "from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion\n",
      "vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced\n",
      "our approach for the sake of comparison and reproducibility.\n",
      "\n",
      "    \n",
      "558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a guide to help deep learning practitioners understand and\n",
      "manipulate convolutional neural network architectures. The guide clarifies the\n",
      "relationship between various properties (input shape, kernel shape, zero\n",
      "padding, strides and output shape) of convolutional, pooling and transposed\n",
      "convolutional layers, as well as the relationship between convolutional and\n",
      "transposed convolutional layers. Relationships are derived for various cases,\n",
      "and are illustrated in order to make them intuitive.\n",
      "\n",
      "    \n",
      "559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in Deep Reinforcement Learning and Robotics have been driven\n",
      "by the presence of increasingly realistic and complex simulation environments.\n",
      "Many of the existing platforms, however, provide either unrealistic visuals,\n",
      "inaccurate physics, low task complexity, or a limited capacity for interaction\n",
      "among artificial agents. Furthermore, many platforms lack the ability to\n",
      "flexibly configure the simulation, hence turning the simulation environment\n",
      "into a black-box from the perspective of the learning system. Here we describe\n",
      "a new open source toolkit for creating and interacting with simulation\n",
      "environments using the Unity platform: Unity ML-Agents Toolkit. By taking\n",
      "advantage of Unity as a simulation platform, the toolkit enables the\n",
      "development of learning environments which are rich in sensory and physical\n",
      "complexity, provide compelling cognitive challenges, and support dynamic\n",
      "multi-agent interaction. We detail the platform design, communication protocol,\n",
      "set of example environments, and variety of training scenarios made possible\n",
      "via the toolkit.\n",
      "\n",
      "    \n",
      "560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Hierarchical reinforcement learning (HRL) is a promising approach to extend\n",
      "traditional reinforcement learning (RL) methods to solve more complex tasks.\n",
      "Yet, the majority of current HRL methods require careful task-specific design\n",
      "and on-policy training, making them difficult to apply in real-world scenarios.\n",
      "In this paper, we study how we can develop HRL algorithms that are general, in\n",
      "that they do not make onerous additional assumptions beyond standard RL\n",
      "algorithms, and efficient, in the sense that they can be used with modest\n",
      "numbers of interaction samples, making them suitable for real-world problems\n",
      "such as robotic control. For generality, we develop a scheme where lower-level\n",
      "controllers are supervised with goals that are learned and proposed\n",
      "automatically by the higher-level controllers. To address efficiency, we\n",
      "propose to use off-policy experience for both higher and lower-level training.\n",
      "This poses a considerable challenge, since changes to the lower-level behaviors\n",
      "change the action space for the higher-level policy, and we introduce an\n",
      "off-policy correction to remedy this challenge. This allows us to take\n",
      "advantage of recent advances in off-policy model-free RL to learn both higher-\n",
      "and lower-level policies using substantially fewer environment interactions\n",
      "than on-policy algorithms. We term the resulting HRL agent HIRO and find that\n",
      "it is generally applicable and highly sample-efficient. Our experiments show\n",
      "that HIRO can be used to learn highly complex behaviors for simulated robots,\n",
      "such as pushing objects and utilizing them to reach target locations, learning\n",
      "from only a few million samples, equivalent to a few days of real-time\n",
      "interaction. In comparisons with a number of prior HRL methods, we find that\n",
      "our approach substantially outperforms previous state-of-the-art techniques.\n",
      "\n",
      "    \n",
      "561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a tutorial on Bayesian optimization, a method of finding the\n",
      "maximum of expensive cost functions. Bayesian optimization employs the Bayesian\n",
      "technique of setting a prior over the objective function and combining it with\n",
      "evidence to get a posterior function. This permits a utility-based selection of\n",
      "the next observation to make on the objective function, which must take into\n",
      "account both exploration (sampling from areas of high uncertainty) and\n",
      "exploitation (sampling areas likely to offer improvement over the current best\n",
      "observation). We also present two detailed extensions of Bayesian optimization,\n",
      "with experiments---active user modelling with preferences, and hierarchical\n",
      "reinforcement learning---and a discussion of the pros and cons of Bayesian\n",
      "optimization based on our experiences.\n",
      "\n",
      "    \n",
      "562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In many real-world scenarios, an autonomous agent often encounters various\n",
      "tasks within a single complex environment. We propose to build a graph\n",
      "abstraction over the environment structure to accelerate the learning of these\n",
      "tasks. Here, nodes are important points of interest (pivotal states) and edges\n",
      "represent feasible traversals between them. Our approach has two stages. First,\n",
      "we jointly train a latent pivotal state model and a curiosity-driven\n",
      "goal-conditioned policy in a task-agnostic manner. Second, provided with the\n",
      "information from the world graph, a high-level Manager quickly finds solution\n",
      "to new tasks and expresses subgoals in reference to pivotal states to a\n",
      "low-level Worker. The Worker can then also leverage the graph to easily\n",
      "traverse to the pivotal states of interest, even across long distance, and\n",
      "explore non-locally. We perform a thorough ablation study to evaluate our\n",
      "approach on a suite of challenging maze tasks, demonstrating significant\n",
      "advantages from the proposed framework over baselines that lack world graph\n",
      "knowledge in terms of performance and efficiency.\n",
      "\n",
      "    \n",
      "563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most existing methods determine relation types only after all the entities\n",
      "have been recognized, thus the interaction between relation types and entity\n",
      "mentions is not fully modeled. This paper presents a novel paradigm to deal\n",
      "with relation extraction by regarding the related entities as the arguments of\n",
      "a relation. We apply a hierarchical reinforcement learning (HRL) framework in\n",
      "this paradigm to enhance the interaction between entity mentions and relation\n",
      "types. The whole extraction process is decomposed into a hierarchy of two-level\n",
      "RL policies for relation detection and entity extraction respectively, so that\n",
      "it is more feasible and natural to deal with overlapping relations. Our model\n",
      "was evaluated on public datasets collected via distant supervision, and results\n",
      "show that it gains better performance than existing methods and is more\n",
      "powerful for extracting overlapping relations.\n",
      "\n",
      "    \n",
      "564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep reinforcement learning has achieved many impressive results in recent\n",
      "years. However, tasks with sparse rewards or long horizons continue to pose\n",
      "significant challenges. To tackle these important problems, we propose a\n",
      "general framework that first learns useful skills in a pre-training\n",
      "environment, and then leverages the acquired skills for learning faster in\n",
      "downstream tasks. Our approach brings together some of the strengths of\n",
      "intrinsic motivation and hierarchical methods: the learning of useful skill is\n",
      "guided by a single proxy reward, the design of which requires very minimal\n",
      "domain knowledge about the downstream tasks. Then a high-level policy is\n",
      "trained on top of these skills, providing a significant improvement of the\n",
      "exploration and allowing to tackle sparse rewards in the downstream tasks. To\n",
      "efficiently pre-train a large span of skills, we use Stochastic Neural Networks\n",
      "combined with an information-theoretic regularizer. Our experiments show that\n",
      "this combination is effective in learning a wide span of interpretable skills\n",
      "in a sample-efficient way, and can significantly boost the learning performance\n",
      "uniformly across a wide range of downstream tasks.\n",
      "\n",
      "    \n",
      "565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Hierarchical agents have the potential to solve sequential decision making\n",
      "tasks with greater sample efficiency than their non-hierarchical counterparts\n",
      "because hierarchical agents can break down tasks into sets of subtasks that\n",
      "only require short sequences of decisions. In order to realize this potential\n",
      "of faster learning, hierarchical agents need to be able to learn their multiple\n",
      "levels of policies in parallel so these simpler subproblems can be solved\n",
      "simultaneously. Yet, learning multiple levels of policies in parallel is hard\n",
      "because it is inherently unstable: changes in a policy at one level of the\n",
      "hierarchy may cause changes in the transition and reward functions at higher\n",
      "levels in the hierarchy, making it difficult to jointly learn multiple levels\n",
      "of policies. In this paper, we introduce a new Hierarchical Reinforcement\n",
      "Learning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome\n",
      "the instability issues that arise when agents try to jointly learn multiple\n",
      "levels of policies. The main idea behind HAC is to train each level of the\n",
      "hierarchy independently of the lower levels by training each level as if the\n",
      "lower level policies are already optimal. We demonstrate experimentally in both\n",
      "grid world and simulated robotics domains that our approach can significantly\n",
      "accelerate learning relative to other non-hierarchical and hierarchical\n",
      "methods. Indeed, our framework is the first to successfully learn 3-level\n",
      "hierarchies in parallel in tasks with continuous state and action spaces.\n",
      "\n",
      "    \n",
      "566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Open-domain dialog generation is a challenging problem; maximum likelihood\n",
      "training can lead to repetitive outputs, models have difficulty tracking\n",
      "long-term conversational goals, and training on standard movie or online\n",
      "datasets may lead to the generation of inappropriate, biased, or offensive\n",
      "text. Reinforcement Learning (RL) is a powerful framework that could\n",
      "potentially address these issues, for example by allowing a dialog model to\n",
      "optimize for reducing toxicity and repetitiveness. However, previous approaches\n",
      "which apply RL to open-domain dialog generation do so at the word level, making\n",
      "it difficult for the model to learn proper credit assignment for long-term\n",
      "conversational rewards. In this paper, we propose a novel approach to\n",
      "hierarchical reinforcement learning, VHRL, which uses policy gradients to tune\n",
      "the utterance-level embedding of a variational sequence model. This\n",
      "hierarchical approach provides greater flexibility for learning long-term,\n",
      "conversational rewards. We use self-play and RL to optimize for a set of\n",
      "human-centered conversation metrics, and show that our approach provides\n",
      "significant improvements -- in terms of both human evaluation and automatic\n",
      "metrics -- over state-of-the-art dialog models, including Transformers.\n",
      "\n",
      "    \n",
      "567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Hierarchical reinforcement learning (HRL) has recently shown promising\n",
      "advances on speeding up learning, improving the exploration, and discovering\n",
      "intertask transferable skills. Most recent works focus on HRL with two levels,\n",
      "i.e., a master policy manipulates subpolicies, which in turn manipulate\n",
      "primitive actions. However, HRL with multiple levels is usually needed in many\n",
      "real-world scenarios, whose ultimate goals are highly abstract, while their\n",
      "actions are very primitive. Therefore, in this paper, we propose a\n",
      "diversity-driven extensible HRL (DEHRL), where an extensible and scalable\n",
      "framework is built and learned levelwise to realize HRL with multiple levels.\n",
      "DEHRL follows a popular assumption: diverse subpolicies are useful, i.e.,\n",
      "subpolicies are believed to be more useful if they are more diverse. However,\n",
      "existing implementations of this diversity assumption usually have their own\n",
      "drawbacks, which makes them inapplicable to HRL with multiple levels.\n",
      "Consequently, we further propose a novel diversity-driven solution to achieve\n",
      "this assumption in DEHRL. Experimental studies evaluate DEHRL with five\n",
      "baselines from four perspectives in two domains; the results show that DEHRL\n",
      "outperforms the state-of-the-art baselines in all four aspects.\n",
      "\n",
      "    \n",
      "568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Given a text description, most existing semantic parsers synthesize a program\n",
      "in one shot. However, it is quite challenging to produce a correct program\n",
      "solely based on the description, which in reality is often ambiguous or\n",
      "incomplete. In this paper, we investigate interactive semantic parsing, where\n",
      "the agent can ask the user clarification questions to resolve ambiguities via a\n",
      "multi-turn dialogue, on an important type of programs called \"If-Then recipes.\"\n",
      "We develop a hierarchical reinforcement learning (HRL) based agent that\n",
      "significantly improves the parsing performance with minimal questions to the\n",
      "user. Results under both simulation and human evaluation show that our agent\n",
      "substantially outperforms non-interactive semantic parsers and rule-based\n",
      "agents.\n",
      "\n",
      "    \n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In hierarchical reinforcement learning a major challenge is determining\n",
      "appropriate low-level policies. We propose an unsupervised learning scheme,\n",
      "based on asymmetric self-play from Sukhbaatar et al. (2018), that automatically\n",
      "learns a good representation of sub-goals in the environment and a low-level\n",
      "policy that can execute them. A high-level policy can then direct the lower one\n",
      "by generating a sequence of continuous sub-goal vectors. We evaluate our model\n",
      "using Mazebase and Mujoco environments, including the challenging AntGather\n",
      "task. Visualizations of the sub-goal embeddings reveal a logical decomposition\n",
      "of tasks within the environment. Quantitatively, our approach obtains\n",
      "compelling performance gains over non-hierarchical approaches.\n",
      "\n",
      "    \n",
      "570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Designing hierarchical reinforcement learning algorithms that induce a notion\n",
      "of safety is not only vital for safety-critical applications, but also, brings\n",
      "better understanding of an artificially intelligent agent's decisions. While\n",
      "learning end-to-end options automatically has been fully realized recently, we\n",
      "propose a solution to learning safe options. We introduce the idea of\n",
      "controllability of states based on the temporal difference errors in the\n",
      "option-critic framework. We then derive the policy-gradient theorem with\n",
      "controllability and propose a novel framework called safe option-critic. We\n",
      "demonstrate the effectiveness of our approach in the four-rooms grid-world,\n",
      "cartpole, and three games in the Arcade Learning Environment (ALE): MsPacman,\n",
      "Amidar and Q*Bert. Learning of end-to-end options with the proposed notion of\n",
      "safety achieves reduction in the variance of return and boosts the performance\n",
      "in environments with intrinsic variability in the reward structure. More\n",
      "importantly, the proposed algorithm outperforms the vanilla options in all the\n",
      "environments and primitive actions in two out of three ALE games.\n",
      "\n",
      "    \n",
      "571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep reinforcement learning can match and exceed human performance, but if\n",
      "even minor changes are introduced to the environment artificial networks often\n",
      "can't adapt. Humans meanwhile are quite adaptable. We hypothesize that this is\n",
      "partly because of how humans use heuristics, and partly because humans can\n",
      "imagine new and more challenging environments to learn from. We've developed a\n",
      "model of hierarchical reinforcement learning that combines both these elements\n",
      "into a stumbler-strategist network. We test transfer performance of this\n",
      "network using Wythoff's game, a gridworld environment with a known optimal\n",
      "strategy. We show that combining imagined play with a heuristic--labeling each\n",
      "position as \"good\" or \"bad\"'--both accelerates learning and promotes transfer\n",
      "to novel games, while also improving model interpretability.\n",
      "\n",
      "    \n",
      "572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical\n",
      "reinforcement learning. Our approach is inspired by the feudal reinforcement\n",
      "learning proposal of Dayan and Hinton, and gains power and efficacy by\n",
      "decoupling end-to-end learning across multiple levels -- allowing it to utilise\n",
      "different resolutions of time. Our framework employs a Manager module and a\n",
      "Worker module. The Manager operates at a lower temporal resolution and sets\n",
      "abstract goals which are conveyed to and enacted by the Worker. The Worker\n",
      "generates primitive actions at every tick of the environment. The decoupled\n",
      "structure of FuN conveys several benefits -- in addition to facilitating very\n",
      "long timescale credit assignment it also encourages the emergence of\n",
      "sub-policies associated with different goals set by the Manager. These\n",
      "properties allow FuN to dramatically outperform a strong baseline agent on\n",
      "tasks that involve long-term credit assignment or memorisation. We demonstrate\n",
      "the performance of our proposed system on a range of tasks from the ATARI suite\n",
      "and also from a 3D DeepMind Lab environment.\n",
      "\n",
      "    \n",
      "573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new RL problem where the agent is required to generalize to a\n",
      "previously-unseen environment characterized by a subtask graph which describes\n",
      "a set of subtasks and their dependencies. Unlike existing hierarchical\n",
      "multitask RL approaches that explicitly describe what the agent should do at a\n",
      "high level, our problem only describes properties of subtasks and relationships\n",
      "among them, which requires the agent to perform complex reasoning to find the\n",
      "optimal subtask to execute. To solve this problem, we propose a neural subtask\n",
      "graph solver (NSGS) which encodes the subtask graph using a recursive neural\n",
      "network embedding. To overcome the difficulty of training, we propose a novel\n",
      "non-parametric gradient-based policy, graph reward propagation, to pre-train\n",
      "our NSGS agent and further finetune it through actor-critic method. The\n",
      "experimental results on two 2D visual domains show that our agent can perform\n",
      "complex reasoning to find a near-optimal way of executing the subtask graph and\n",
      "generalize well to the unseen subtask graphs. In addition, we compare our agent\n",
      "with a Monte-Carlo tree search (MCTS) method showing that our method is much\n",
      "more efficient than MCTS, and the performance of NSGS can be further improved\n",
      "by combining it with MCTS.\n",
      "\n",
      "    \n",
      "574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents the Crossmodal Attentive Skill Learner (CASL), integrated\n",
      "with the recently-introduced Asynchronous Advantage Option-Critic (A2OC)\n",
      "architecture [Harb et al., 2017] to enable hierarchical reinforcement learning\n",
      "across multiple sensory inputs. We provide concrete examples where the approach\n",
      "not only improves performance in a single task, but accelerates transfer to new\n",
      "tasks. We demonstrate the attention mechanism anticipates and identifies useful\n",
      "latent features, while filtering irrelevant sensor modalities during execution.\n",
      "We modify the Arcade Learning Environment [Bellemare et al., 2013] to support\n",
      "audio queries, and conduct evaluations of crossmodal learning in the Atari 2600\n",
      "game Amidar. Finally, building on the recent work of Babaeizadeh et al. [2017],\n",
      "we open-source a fast hybrid CPU-GPU implementation of CASL.\n",
      "\n",
      "    \n",
      "575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A common strategy to deal with the expensive reinforcement learning (RL) of\n",
      "complex tasks is to decompose them into a collection of subtasks that are\n",
      "usually simpler to learn as well as reusable for new problems. However, when a\n",
      "robot learns the policies for these subtasks, common approaches treat every\n",
      "policy learning process separately. Therefore, all these individual\n",
      "(composable) policies need to be learned before tackling the learning process\n",
      "of the complex task through policies composition. Moreover, such composition of\n",
      "individual policies is usually performed sequentially, which is not suitable\n",
      "for tasks that require to perform the subtasks concurrently. In this paper, we\n",
      "propose to combine a set of composable Gaussian policies corresponding to these\n",
      "subtasks using a set of activation vectors, resulting in a complex Gaussian\n",
      "policy that is a function of the means and covariances matrices of the\n",
      "composable policies. Moreover, we propose an algorithm for learning both\n",
      "compound and composable policies within the same learning process by exploiting\n",
      "the off-policy data generated from the compound policy. The algorithm is built\n",
      "on a maximum entropy RL approach to favor exploration during the learning\n",
      "process. The results of the experiments show that the experience collected with\n",
      "the compound policy permits not only to solve the complex task but also to\n",
      "obtain useful composable policies that successfully perform in their\n",
      "corresponding subtasks.\n",
      "\n",
      "    \n",
      "576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning interpretable and transferable subpolicies and performing task\n",
      "decomposition from a single, complex task is difficult. Some traditional\n",
      "hierarchical reinforcement learning techniques enforce this decomposition in a\n",
      "top-down manner, while meta-learning techniques require a task distribution at\n",
      "hand to learn such decompositions. This paper presents a framework for using\n",
      "diverse suboptimal world models to decompose complex task solutions into\n",
      "simpler modular subpolicies. This framework performs automatic decomposition of\n",
      "a single source task in a bottom up manner, concurrently learning the required\n",
      "modular subpolicies as well as a controller to coordinate them. We perform a\n",
      "series of experiments on high dimensional continuous action control tasks to\n",
      "demonstrate the effectiveness of this approach at both complex single task\n",
      "learning and lifelong learning. Finally, we perform ablation studies to\n",
      "understand the importance and robustness of different elements in the framework\n",
      "and limitations to this approach.\n",
      "\n",
      "    \n",
      "577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Real-world tasks are often highly structured. Hierarchical reinforcement\n",
      "learning (HRL) has attracted research interest as an approach for leveraging\n",
      "the hierarchical structure of a given task in reinforcement learning (RL).\n",
      "However, identifying the hierarchical policy structure that enhances the\n",
      "performance of RL is not a trivial task. In this paper, we propose an HRL\n",
      "method that learns a latent variable of a hierarchical policy using mutual\n",
      "information maximization. Our approach can be interpreted as a way to learn a\n",
      "discrete and latent representation of the state-action space. To learn option\n",
      "policies that correspond to modes of the advantage function, we introduce\n",
      "advantage-weighted importance sampling. In our HRL method, the gating policy\n",
      "learns to select option policies based on an option-value function, and these\n",
      "option policies are optimized based on the deterministic policy gradient\n",
      "method. This framework is derived by leveraging the analogy between a\n",
      "monolithic policy in standard RL and a hierarchical policy in HRL by using a\n",
      "deterministic option policy. Experimental results indicate that our HRL\n",
      "approach can learn a diversity of options and that it can enhance the\n",
      "performance of RL in continuous control tasks.\n",
      "\n",
      "    \n",
      "578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents the MAXQ approach to hierarchical reinforcement learning\n",
      "based on decomposing the target Markov decision process (MDP) into a hierarchy\n",
      "of smaller MDPs and decomposing the value function of the target MDP into an\n",
      "additive combination of the value functions of the smaller MDPs. The paper\n",
      "defines the MAXQ hierarchy, proves formal results on its representational\n",
      "power, and establishes five conditions for the safe use of state abstractions.\n",
      "The paper presents an online model-free learning algorithm, MAXQ-Q, and proves\n",
      "that it converges wih probability 1 to a kind of locally-optimal policy known\n",
      "as a recursively optimal policy, even in the presence of the five kinds of\n",
      "state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\n",
      "through a series of experiments in three domains and shows experimentally that\n",
      "MAXQ-Q (with state abstractions) converges to a recursively optimal policy much\n",
      "faster than flat Q learning. The fact that MAXQ learns a representation of the\n",
      "value function has an important benefit: it makes it possible to compute and\n",
      "execute an improved, non-hierarchical policy via a procedure similar to the\n",
      "policy improvement step of policy iteration. The paper demonstrates the\n",
      "effectiveness of this non-hierarchical execution experimentally. Finally, the\n",
      "paper concludes with a comparison to related work and a discussion of the\n",
      "design tradeoffs in hierarchical reinforcement learning.\n",
      "\n",
      "    \n",
      "579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present the first massively distributed architecture for deep\n",
      "reinforcement learning. This architecture uses four main components: parallel\n",
      "actors that generate new behaviour; parallel learners that are trained from\n",
      "stored experience; a distributed neural network to represent the value function\n",
      "or behaviour policy; and a distributed store of experience. We used our\n",
      "architecture to implement the Deep Q-Network algorithm (DQN). Our distributed\n",
      "algorithm was applied to 49 games from Atari 2600 games from the Arcade\n",
      "Learning Environment, using identical hyperparameters. Our performance\n",
      "surpassed non-distributed DQN in 41 of the 49 games and also reduced the\n",
      "wall-time required to achieve these results by an order of magnitude on most\n",
      "games.\n",
      "\n",
      "    \n",
      "580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we consider the task of learning control policies for\n",
      "text-based games. In these games, all interactions in the virtual world are\n",
      "through text and the underlying state is not observed. The resulting language\n",
      "barrier makes such environments challenging for automatic game players. We\n",
      "employ a deep reinforcement learning framework to jointly learn state\n",
      "representations and action policies using game rewards as feedback. This\n",
      "framework enables us to map text descriptions into vector representations that\n",
      "capture the semantics of the game states. We evaluate our approach on two game\n",
      "worlds, comparing against baselines using bag-of-words and bag-of-bigrams for\n",
      "state representations. Our algorithm outperforms the baselines on both worlds\n",
      "demonstrating the importance of learning expressive representations.\n",
      "\n",
      "    \n",
      "581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Reinforcement Learning has yielded proficient controllers for complex\n",
      "tasks. However, these controllers have limited memory and rely on being able to\n",
      "perceive the complete game screen at each decision point. To address these\n",
      "shortcomings, this article investigates the effects of adding recurrency to a\n",
      "Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected\n",
      "layer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network}\n",
      "(DRQN), although capable of seeing only a single frame at each timestep,\n",
      "successfully integrates information through time and replicates DQN's\n",
      "performance on standard Atari games and partially observed equivalents\n",
      "featuring flickering game screens. Additionally, when trained with partial\n",
      "observations and evaluated with incrementally more complete observations,\n",
      "DRQN's performance scales as a function of observability. Conversely, when\n",
      "trained with full observations and evaluated with partial observations, DRQN's\n",
      "performance degrades less than DQN's. Thus, given the same length of history,\n",
      "recurrency is a viable alternative to stacking a history of frames in the DQN's\n",
      "input layer and while recurrency confers no systematic advantage when learning\n",
      "to play the game, the recurrent net can better adapt at evaluation time if the\n",
      "quality of observations changes.\n",
      "\n",
      "    \n",
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This report presents Giraffe, a chess engine that uses self-play to discover\n",
      "all its domain-specific knowledge, with minimal hand-crafted knowledge given by\n",
      "the programmer. Unlike previous attempts using machine learning only to perform\n",
      "parameter-tuning on hand-crafted evaluation functions, Giraffe's learning\n",
      "system also performs automatic feature extraction and pattern recognition. The\n",
      "trained evaluation function performs comparably to the evaluation functions of\n",
      "state-of-the-art chess engines - all of which containing thousands of lines of\n",
      "carefully hand-crafted pattern recognizers, tuned over many years by both\n",
      "computer chess experts and human chess masters. Giraffe is the most successful\n",
      "attempt thus far at using end-to-end machine learning to play chess.\n",
      "\n",
      "    \n",
      "583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The popular Q-learning algorithm is known to overestimate action values under\n",
      "certain conditions. It was not previously known whether, in practice, such\n",
      "overestimations are common, whether they harm performance, and whether they can\n",
      "generally be prevented. In this paper, we answer all these questions\n",
      "affirmatively. In particular, we first show that the recent DQN algorithm,\n",
      "which combines Q-learning with a deep neural network, suffers from substantial\n",
      "overestimations in some games in the Atari 2600 domain. We then show that the\n",
      "idea behind the Double Q-learning algorithm, which was introduced in a tabular\n",
      "setting, can be generalized to work with large-scale function approximation. We\n",
      "propose a specific adaptation to the DQN algorithm and show that the resulting\n",
      "algorithm not only reduces the observed overestimations, as hypothesized, but\n",
      "that this also leads to much better performance on several games.\n",
      "\n",
      "    \n",
      "584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces a machine learning based system for controlling a\n",
      "robotic manipulator with visual perception only. The capability to autonomously\n",
      "learn robot controllers solely from raw-pixel images and without any prior\n",
      "knowledge of configuration is shown for the first time. We build upon the\n",
      "success of recent deep reinforcement learning and develop a system for learning\n",
      "target reaching with a three-joint robot manipulator using external visual\n",
      "observation. A Deep Q Network (DQN) was demonstrated to perform target reaching\n",
      "after training in simulation. Transferring the network to real hardware and\n",
      "real observation in a naive approach failed, but experiments show that the\n",
      "network works when replacing camera images with synthetic images.\n",
      "\n",
      "    \n",
      "585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Experience replay lets online reinforcement learning agents remember and\n",
      "reuse experiences from the past. In prior work, experience transitions were\n",
      "uniformly sampled from a replay memory. However, this approach simply replays\n",
      "transitions at the same frequency that they were originally experienced,\n",
      "regardless of their significance. In this paper we develop a framework for\n",
      "prioritizing experience, so as to replay important transitions more frequently,\n",
      "and therefore learn more efficiently. We use prioritized experience replay in\n",
      "Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved\n",
      "human-level performance across many Atari games. DQN with prioritized\n",
      "experience replay achieves a new state-of-the-art, outperforming DQN with\n",
      "uniform replay on 41 out of 49 games.\n",
      "\n",
      "    \n",
      "586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In recent years there have been many successes of using deep representations\n",
      "in reinforcement learning. Still, many of these applications use conventional\n",
      "architectures, such as convolutional networks, LSTMs, or auto-encoders. In this\n",
      "paper, we present a new neural network architecture for model-free\n",
      "reinforcement learning. Our dueling network represents two separate estimators:\n",
      "one for the state value function and one for the state-dependent action\n",
      "advantage function. The main benefit of this factoring is to generalize\n",
      "learning across actions without imposing any change to the underlying\n",
      "reinforcement learning algorithm. Our results show that this architecture leads\n",
      "to better policy evaluation in the presence of many similar-valued actions.\n",
      "Moreover, the dueling architecture enables our RL agent to outperform the\n",
      "state-of-the-art on the Atari 2600 domain.\n",
      "\n",
      "    \n",
      "587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Using deep neural nets as function approximator for reinforcement learning\n",
      "tasks have recently been shown to be very powerful for solving problems\n",
      "approaching real-world complexity. Using these results as a benchmark, we\n",
      "discuss the role that the discount factor may play in the quality of the\n",
      "learning process of a deep Q-network (DQN). When the discount factor\n",
      "progressively increases up to its final value, we empirically show that it is\n",
      "possible to significantly reduce the number of learning steps. When used in\n",
      "conjunction with a varying learning rate, we empirically show that it\n",
      "outperforms original DQN on several experiments. We relate this phenomenon with\n",
      "the instabilities of neural networks when they are used in an approximate\n",
      "Dynamic Programming setting. We also describe the possibility to fall within a\n",
      "local optimum during the learning process, thus connecting our discussion with\n",
      "the exploration/exploitation dilemma.\n",
      "\n",
      "    \n",
      "588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A deep learning approach to reinforcement learning led to a general learner\n",
      "able to train on visual input to play a variety of arcade games at the human\n",
      "and superhuman levels. Its creators at the Google DeepMind's team called the\n",
      "approach: Deep Q-Network (DQN). We present an extension of DQN by \"soft\" and\n",
      "\"hard\" attention mechanisms. Tests of the proposed Deep Attention Recurrent\n",
      "Q-Network (DARQN) algorithm on multiple Atari 2600 games show level of\n",
      "performance superior to that of DQN. Moreover, built-in attention mechanisms\n",
      "allow a direct online monitoring of the training process by highlighting the\n",
      "regions of the game screen the agent is focusing on when making decisions.\n",
      "\n",
      "    \n",
      "589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Policies for complex visual tasks have been successfully learned with deep\n",
      "reinforcement learning, using an approach called deep Q-networks (DQN), but\n",
      "relatively large (task-specific) networks and extensive training are needed to\n",
      "achieve good performance. In this work, we present a novel method called policy\n",
      "distillation that can be used to extract the policy of a reinforcement learning\n",
      "agent and train a new network that performs at the expert level while being\n",
      "dramatically smaller and more efficient. Furthermore, the same method can be\n",
      "used to consolidate multiple task-specific policies into a single policy. We\n",
      "demonstrate these claims using the Atari domain and show that the multi-task\n",
      "distilled agent outperforms the single-task teachers as well as a\n",
      "jointly-trained DQN agent.\n",
      "\n",
      "    \n",
      "590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In recent years there is a growing interest in using deep representations for\n",
      "reinforcement learning. In this paper, we present a methodology and tools to\n",
      "analyze Deep Q-networks (DQNs) in a non-blind matter. Moreover, we propose a\n",
      "new model, the Semi Aggregated Markov Decision Process (SAMDP), and an\n",
      "algorithm that learns it automatically. The SAMDP model allows us to identify\n",
      "spatio-temporal abstractions directly from features and may be used as a\n",
      "sub-goal detector in future work. Using our tools we reveal that the features\n",
      "learned by DQNs aggregate the state space in a hierarchical fashion, explaining\n",
      "its success. Moreover, we are able to understand and describe the policies\n",
      "learned by DQNs for three different Atari2600 games and suggest ways to\n",
      "interpret, debug and optimize deep neural networks in reinforcement learning.\n",
      "\n",
      "    \n",
      "591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many real-world applications can be described as large-scale games of\n",
      "imperfect information. To deal with these challenging domains, prior work has\n",
      "focused on computing Nash equilibria in a handcrafted abstraction of the\n",
      "domain. In this paper we introduce the first scalable end-to-end approach to\n",
      "learning approximate Nash equilibria without prior domain knowledge. Our method\n",
      "combines fictitious self-play with deep reinforcement learning. When applied to\n",
      "Leduc poker, Neural Fictitious Self-Play (NFSP) approached a Nash equilibrium,\n",
      "whereas common reinforcement learning methods diverged. In Limit Texas Holdem,\n",
      "a poker game of real-world scale, NFSP learnt a strategy that approached the\n",
      "performance of state-of-the-art, superhuman algorithms based on significant\n",
      "domain expertise.\n",
      "\n",
      "    \n",
      "592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We describe an iterative procedure for optimizing policies, with guaranteed\n",
      "monotonic improvement. By making several approximations to the\n",
      "theoretically-justified procedure, we develop a practical algorithm, called\n",
      "Trust Region Policy Optimization (TRPO). This algorithm is similar to natural\n",
      "policy gradient methods and is effective for optimizing large nonlinear\n",
      "policies such as neural networks. Our experiments demonstrate its robust\n",
      "performance on a wide variety of tasks: learning simulated robotic swimming,\n",
      "hopping, and walking gaits; and playing Atari games using images of the screen\n",
      "as input. Despite its approximations that deviate from the theory, TRPO tends\n",
      "to give monotonic improvement, with little tuning of hyperparameters.\n",
      "\n",
      "    \n",
      "593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Model predictive control (MPC) is an effective method for controlling robotic\n",
      "systems, particularly autonomous aerial vehicles such as quadcopters. However,\n",
      "application of MPC can be computationally demanding, and typically requires\n",
      "estimating the state of the system, which can be challenging in complex,\n",
      "unstructured environments. Reinforcement learning can in principle forego the\n",
      "need for explicit state estimation and acquire a policy that directly maps\n",
      "sensor readings to actions, but is difficult to apply to unstable systems that\n",
      "are liable to fail catastrophically during training before an effective policy\n",
      "has been found. We propose to combine MPC with reinforcement learning in the\n",
      "framework of guided policy search, where MPC is used to generate data at\n",
      "training time, under full state observations provided by an instrumented\n",
      "training environment. This data is used to train a deep neural network policy,\n",
      "which is allowed to access only the raw observations from the vehicle's onboard\n",
      "sensors. After training, the neural network policy can successfully control the\n",
      "robot without knowledge of the full state, and at a fraction of the\n",
      "computational cost of MPC. We evaluate our method by learning obstacle\n",
      "avoidance policies for a simulated quadrotor, using simulated onboard sensors\n",
      "and no explicit state estimation at test time.\n",
      "\n",
      "    \n",
      "594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Policy gradient methods are an appealing approach in reinforcement learning\n",
      "because they directly optimize the cumulative reward and can straightforwardly\n",
      "be used with nonlinear function approximators such as neural networks. The two\n",
      "main challenges are the large number of samples typically required, and the\n",
      "difficulty of obtaining stable and steady improvement despite the\n",
      "nonstationarity of the incoming data. We address the first challenge by using\n",
      "value functions to substantially reduce the variance of policy gradient\n",
      "estimates at the cost of some bias, with an exponentially-weighted estimator of\n",
      "the advantage function that is analogous to TD(lambda). We address the second\n",
      "challenge by using trust region optimization procedure for both the policy and\n",
      "the value function, which are represented by neural networks.\n",
      "Our approach yields strong empirical results on highly challenging 3D\n",
      "locomotion tasks, learning running gaits for bipedal and quadrupedal simulated\n",
      "robots, and learning a policy for getting the biped to stand up from starting\n",
      "out lying on the ground. In contrast to a body of prior work that uses\n",
      "hand-crafted policy representations, our neural network policies map directly\n",
      "from raw kinematics to joint torques. Our algorithm is fully model-free, and\n",
      "the amount of simulated experience required for the learning tasks on 3D bipeds\n",
      "corresponds to 1-2 weeks of real time.\n",
      "\n",
      "    \n",
      "595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes GProp, a deep reinforcement learning algorithm for\n",
      "continuous policies with compatible function approximation. The algorithm is\n",
      "based on two innovations. Firstly, we present a temporal-difference based\n",
      "method for learning the gradient of the value-function. Secondly, we present\n",
      "the deviator-actor-critic (DAC) model, which comprises three neural networks\n",
      "that estimate the value function, its gradient, and determine the actor's\n",
      "policy respectively. We evaluate GProp on two challenging tasks: a contextual\n",
      "bandit problem constructed from nonparametric regression datasets that is\n",
      "designed to probe the ability of reinforcement learning algorithms to\n",
      "accurately estimate gradients; and the octopus arm, a challenging reinforcement\n",
      "learning benchmark. GProp is competitive with fully supervised methods on the\n",
      "bandit task and achieves the best performance to date on the octopus arm.\n",
      "\n",
      "    \n",
      "596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has shown that deep neural networks are capable of approximating\n",
      "both value functions and policies in reinforcement learning domains featuring\n",
      "continuous state and action spaces. However, to the best of our knowledge no\n",
      "previous work has succeeded at using deep neural networks in structured\n",
      "(parameterized) continuous action spaces. To fill this gap, this paper focuses\n",
      "on learning within the domain of simulated RoboCup soccer, which features a\n",
      "small set of discrete action types, each of which is parameterized with\n",
      "continuous variables. The best learned agent can score goals more reliably than\n",
      "the 2012 RoboCup champion agent. As such, this paper represents a successful\n",
      "extension of deep reinforcement learning to the class of parameterized action\n",
      "space MDPs.\n",
      "\n",
      "    \n",
      "597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Achieving efficient and scalable exploration in complex domains poses a major\n",
      "challenge in reinforcement learning. While Bayesian and PAC-MDP approaches to\n",
      "the exploration problem offer strong formal guarantees, they are often\n",
      "impractical in higher dimensions due to their reliance on enumerating the\n",
      "state-action space. Hence, exploration in complex domains is often performed\n",
      "with simple epsilon-greedy methods. In this paper, we consider the challenging\n",
      "Atari games domain, which requires processing raw pixel inputs and delayed\n",
      "rewards. We evaluate several more sophisticated exploration strategies,\n",
      "including Thompson sampling and Boltzman exploration, and propose a new\n",
      "exploration method based on assigning exploration bonuses from a concurrently\n",
      "learned model of the system dynamics. By parameterizing our learned model with\n",
      "a neural network, we are able to develop a scalable and efficient approach to\n",
      "exploration bonuses that can be applied to tasks with complex, high-dimensional\n",
      "state spaces. In the Atari domain, our method provides the most consistent\n",
      "improvement across a range of games that pose a major challenge for prior\n",
      "methods. In addition to raw game-scores, we also develop an AUC-100 metric for\n",
      "the Atari Learning domain to evaluate the impact of exploration on this\n",
      "benchmark.\n",
      "\n",
      "    \n",
      "598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Motivated by vision-based reinforcement learning (RL) problems, in particular\n",
      "Atari games from the recent benchmark Aracade Learning Environment (ALE), we\n",
      "consider spatio-temporal prediction problems where future (image-)frames are\n",
      "dependent on control variables or actions as well as previous frames. While not\n",
      "composed of natural scenes, frames in Atari games are high-dimensional in size,\n",
      "can involve tens of objects with one or more objects being controlled by the\n",
      "actions directly and many other objects being influenced indirectly, can\n",
      "involve entry and departure of objects, and can involve deep partial\n",
      "observability. We propose and evaluate two deep neural network architectures\n",
      "that consist of encoding, action-conditional transformation, and decoding\n",
      "layers based on convolutional neural networks and recurrent neural networks.\n",
      "Experimental results show that the proposed architectures are able to generate\n",
      "visually-realistic frames that are also useful for control over approximately\n",
      "100-step action-conditional futures in some games. To the best of our\n",
      "knowledge, this paper is the first to make and evaluate long-term predictions\n",
      "on high-dimensional video conditioned by control inputs.\n",
      "\n",
      "    \n",
      "599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Data-efficient reinforcement learning (RL) in continuous state-action spaces\n",
      "using very high-dimensional observations remains a key challenge in developing\n",
      "fully autonomous systems. We consider a particularly important instance of this\n",
      "challenge, the pixels-to-torques problem, where an RL agent learns a\n",
      "closed-loop control policy (\"torques\") from pixel information only. We\n",
      "introduce a data-efficient, model-based reinforcement learning algorithm that\n",
      "learns such a closed-loop policy directly from pixel information. The key\n",
      "ingredient is a deep dynamical model for learning a low-dimensional feature\n",
      "embedding of images jointly with a predictive model in this low-dimensional\n",
      "feature space. Joint learning is crucial for long-term predictions, which lie\n",
      "at the core of the adaptive nonlinear model predictive control strategy that we\n",
      "use for closed-loop control. Compared to state-of-the-art RL methods for\n",
      "continuous states and actions, our approach learns quickly, scales to\n",
      "high-dimensional state spaces, is lightweight and an important step toward\n",
      "fully autonomous end-to-end learning from pixels to torques.\n",
      "\n",
      "    \n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a unified framework for learning continuous control policies using\n",
      "backpropagation. It supports stochastic control by treating stochasticity in\n",
      "the Bellman equation as a deterministic function of exogenous noise. The\n",
      "product is a spectrum of general policy gradient algorithms that range from\n",
      "model-free methods with value functions to model-based methods without value\n",
      "functions. We use learned models but only require observations from the\n",
      "environment in- stead of observations from model-predicted trajectories,\n",
      "minimizing the impact of compounded model errors. We apply these algorithms\n",
      "first to a toy stochastic control problem and then to several physics-based\n",
      "control problems in simulation. One of these variants, SVG(1), shows the\n",
      "effectiveness of learning models, value functions, and policies simultaneously\n",
      "in continuous domains.\n",
      "\n",
      "    \n",
      "601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper addresses the general problem of reinforcement learning (RL) in\n",
      "partially observable environments. In 2013, our large RL recurrent neural\n",
      "networks (RNNs) learned from scratch to drive simulated cars from\n",
      "high-dimensional video input. However, real brains are more powerful in many\n",
      "ways. In particular, they learn a predictive model of their initially unknown\n",
      "environment, and somehow use it for abstract (e.g., hierarchical) planning and\n",
      "reasoning. Guided by algorithmic information theory, we describe RNN-based AIs\n",
      "(RNNAIs) designed to do the same. Such an RNNAI can be trained on never-ending\n",
      "sequences of tasks, some of them provided by the user, others invented by the\n",
      "RNNAI itself in a curious, playful fashion, to improve its RNN-based world\n",
      "model. Unlike our previous model-building RNN-based RL machines dating back to\n",
      "1990, the RNNAI learns to actively query its model for abstract reasoning and\n",
      "planning and decision making, essentially \"learning to think.\" The basic ideas\n",
      "of this report can be applied to many other cases where one RNN-like system\n",
      "exploits the algorithmic information content of another. They are taken from a\n",
      "grant proposal submitted in Fall 2014, and also explain concepts such as\n",
      "\"mirror neurons.\" Experimental results will be described in separate papers.\n",
      "\n",
      "    \n",
      "602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to plan and execute goal specific actions in varied, unexpected\n",
      "settings is a central requirement of intelligent agents. In this paper, we\n",
      "explore how an agent can be equipped with an internal model of the dynamics of\n",
      "the external world, and how it can use this model to plan novel actions by\n",
      "running multiple internal simulations (\"visual imagination\"). Our models\n",
      "directly process raw visual input, and use a novel object-centric prediction\n",
      "formulation based on visual glimpses centered on objects (fixations) to enforce\n",
      "translational invariance of the learned physical laws. The agent gathers\n",
      "training data through random interaction with a collection of different\n",
      "environments, and the resulting model can then be used to plan goal-directed\n",
      "actions in novel environments that the agent has not seen before. We\n",
      "demonstrate that our agent can accurately plan actions for playing a simulated\n",
      "billiards game, which requires pushing a ball into a target position or into\n",
      "collision with another ball.\n",
      "\n",
      "    \n",
      "603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an active detection model for localizing objects in scenes. The\n",
      "model is class-specific and allows an agent to focus attention on candidate\n",
      "regions for identifying the correct location of a target object. This agent\n",
      "learns to deform a bounding box using simple transformation actions, with the\n",
      "goal of determining the most specific location of target objects following\n",
      "top-down reasoning. The proposed localization agent is trained using deep\n",
      "reinforcement learning, and evaluated on the Pascal VOC 2007 dataset. We show\n",
      "that agents guided by the proposed model are able to localize a single instance\n",
      "of an object after analyzing only between 11 and 25 regions in an image, and\n",
      "obtain the best detection results among systems that do not use object\n",
      "proposals for object localization.\n",
      "\n",
      "    \n",
      "604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a novel schema for sequence to sequence learning with a Deep\n",
      "Q-Network (DQN), which decodes the output sequence iteratively. The aim here is\n",
      "to enable the decoder to first tackle easier portions of the sequences, and\n",
      "then turn to cope with difficult parts. Specifically, in each iteration, an\n",
      "encoder-decoder Long Short-Term Memory (LSTM) network is employed to, from the\n",
      "input sequence, automatically create features to represent the internal states\n",
      "of and formulate a list of potential actions for the DQN. Take rephrasing a\n",
      "natural sentence as an example. This list can contain ranked potential words.\n",
      "Next, the DQN learns to make decision on which action (e.g., word) will be\n",
      "selected from the list to modify the current decoded sequence. The newly\n",
      "modified output sequence is subsequently used as the input to the DQN for the\n",
      "next decoding iteration. In each iteration, we also bias the reinforcement\n",
      "learning's attention to explore sequence portions which are previously\n",
      "difficult to be decoded. For evaluation, the proposed strategy was trained to\n",
      "decode ten thousands natural sentences. Our experiments indicate that, when\n",
      "compared to a left-to-right greedy beam search LSTM decoder, the proposed\n",
      "method performed competitively well when decoding sentences from the training\n",
      "set, but significantly outperformed the baseline when decoding unseen\n",
      "sentences, in terms of BLEU score obtained.\n",
      "\n",
      "    \n",
      "605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a novel definition of the reinforcement learning state, actions\n",
      "and reward function that allows a deep Q-network (DQN) to learn to control an\n",
      "optimization hyperparameter. Using Q-learning with experience replay, we train\n",
      "two DQNs to accept a state representation of an objective function as input and\n",
      "output the expected discounted return of rewards, or q-values, connected to the\n",
      "actions of either adjusting the learning rate or leaving it unchanged. The two\n",
      "DQNs learn a policy similar to a line search, but differ in the number of\n",
      "allowed actions. The trained DQNs in combination with a gradient-based update\n",
      "routine form the basis of the Q-gradient descent algorithms. To demonstrate the\n",
      "viability of this framework, we show that the DQN's q-values associated with\n",
      "optimal action converge and that the Q-gradient descent algorithms outperform\n",
      "gradient descent with an Armijo or nonmonotone line search. Unlike traditional\n",
      "optimization methods, Q-gradient descent can incorporate any objective\n",
      "statistic and by varying the actions we gain insight into the type of learning\n",
      "rate adjustment strategies that are successful for neural network optimization.\n",
      "\n",
      "    \n",
      "606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The mutual information is a core statistical quantity that has applications\n",
      "in all areas of machine learning, whether this is in training of density models\n",
      "over multiple data modalities, in maximising the efficiency of noisy\n",
      "transmission channels, or when learning behaviour policies for exploration by\n",
      "artificial agents. Most learning algorithms that involve optimisation of the\n",
      "mutual information rely on the Blahut-Arimoto algorithm --- an enumerative\n",
      "algorithm with exponential complexity that is not suitable for modern machine\n",
      "learning applications. This paper provides a new approach for scalable\n",
      "optimisation of the mutual information by merging techniques from variational\n",
      "inference and deep learning. We develop our approach by focusing on the problem\n",
      "of intrinsically-motivated learning, where the mutual information forms the\n",
      "definition of a well-known internal drive known as empowerment. Using a\n",
      "variational lower bound on the mutual information, combined with convolutional\n",
      "networks for handling visual input streams, we develop a stochastic\n",
      "optimisation algorithm that allows for scalable information maximisation and\n",
      "empowerment-based reasoning directly from pixels to actions.\n",
      "\n",
      "    \n",
      "607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The recently introduced Deep Q-Networks (DQN) algorithm has gained attention\n",
      "as one of the first successful combinations of deep neural networks and\n",
      "reinforcement learning. Its promise was demonstrated in the Arcade Learning\n",
      "Environment (ALE), a challenging framework composed of dozens of Atari 2600\n",
      "games used to evaluate general competency in AI. It achieved dramatically\n",
      "better results than earlier approaches, showing that its ability to learn good\n",
      "representations is quite robust and general. This paper attempts to understand\n",
      "the principles that underlie DQN's impressive performance and to better\n",
      "contextualize its success. We systematically evaluate the importance of key\n",
      "representational biases encoded by DQN's network by proposing simple linear\n",
      "representations that make use of these concepts. Incorporating these\n",
      "characteristics, we obtain a computationally practical feature set that\n",
      "achieves competitive performance to DQN in the ALE. Besides offering insight\n",
      "into the strengths and weaknesses of DQN, we provide a generic representation\n",
      "for the ALE, significantly reducing the burden of learning a representation for\n",
      "each game. Moreover, we also provide a simple, reproducible benchmark for the\n",
      "sake of comparison to future work in the ALE.\n",
      "\n",
      "    \n",
      "608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State of the art deep reinforcement learning algorithms take many millions of\n",
      "interactions to attain human-level performance. Humans, on the other hand, can\n",
      "very quickly exploit highly rewarding nuances of an environment upon first\n",
      "discovery. In the brain, such rapid learning is thought to depend on the\n",
      "hippocampus and its capacity for episodic memory. Here we investigate whether a\n",
      "simple model of hippocampal episodic control can learn to solve difficult\n",
      "sequential decision-making tasks. We demonstrate that it not only attains a\n",
      "highly rewarding strategy significantly faster than state-of-the-art deep\n",
      "reinforcement learning algorithms, but also achieves a higher overall reward on\n",
      "some of the more challenging domains.\n",
      "\n",
      "    \n",
      "609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Intelligent creatures can explore their environments and learn useful skills\n",
      "without supervision. In this paper, we propose DIAYN ('Diversity is All You\n",
      "Need'), a method for learning useful skills without a reward function. Our\n",
      "proposed method learns skills by maximizing an information theoretic objective\n",
      "using a maximum entropy policy. On a variety of simulated robotic tasks, we\n",
      "show that this simple objective results in the unsupervised emergence of\n",
      "diverse skills, such as walking and jumping. In a number of reinforcement\n",
      "learning benchmark environments, our method is able to learn a skill that\n",
      "solves the benchmark task despite never receiving the true task reward. We show\n",
      "how pretrained skills can provide a good parameter initialization for\n",
      "downstream tasks, and can be composed hierarchically to solve complex, sparse\n",
      "reward tasks. Our results suggest that unsupervised discovery of skills can\n",
      "serve as an effective pretraining mechanism for overcoming challenges of\n",
      "exploration and data efficiency in reinforcement learning.\n",
      "\n",
      "    \n",
      "610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes AllenNLP, a platform for research on deep learning\n",
      "methods in natural language understanding. AllenNLP is designed to support\n",
      "researchers who want to build novel language understanding models quickly and\n",
      "easily. It is built on top of PyTorch, allowing for dynamic computation graphs,\n",
      "and provides (1) a flexible data API that handles intelligent batching and\n",
      "padding, (2) high-level abstractions for common operations in working with\n",
      "text, and (3) a modular and extensible experiment framework that makes doing\n",
      "good science easy. It also includes reference implementations of high quality\n",
      "approaches for both core semantic problems (e.g. semantic role labeling (Palmer\n",
      "et al., 2005)) and language understanding applications (e.g. machine\n",
      "comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source\n",
      "effort maintained by engineers and researchers at the Allen Institute for\n",
      "Artificial Intelligence.\n",
      "\n",
      "    \n",
      "611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images\n",
      "of 70,000 fashion products from 10 categories, with 7,000 images per category.\n",
      "The training set has 60,000 images and the test set has 10,000 images.\n",
      "Fashion-MNIST is intended to serve as a direct drop-in replacement for the\n",
      "original MNIST dataset for benchmarking machine learning algorithms, as it\n",
      "shares the same image size, data format and the structure of training and\n",
      "testing splits. The dataset is freely available at\n",
      "this https URL\n",
      "\n",
      "612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a new algorithm for the contextual bandit learning problem, where\n",
      "the learner repeatedly takes one of $K$ actions in response to the observed\n",
      "context, and observes the reward only for that chosen action. Our method\n",
      "assumes access to an oracle for solving fully supervised cost-sensitive\n",
      "classification problems and achieves the statistically optimal regret guarantee\n",
      "with only $\\tilde{O}(\\sqrt{KT/\\log N})$ oracle calls across all $T$ rounds,\n",
      "where $N$ is the number of policies in the policy class we compete against. By\n",
      "doing so, we obtain the most practical contextual bandit learning algorithm\n",
      "amongst approaches that work for general policy classes. We further conduct a\n",
      "proof-of-concept experiment which demonstrates the excellent computational and\n",
      "prediction performance of (an online variant of) our algorithm relative to\n",
      "several baselines.\n",
      "\n",
      "    \n",
      "613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.aclweb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite widespread adoption, machine learning models remain mostly black\n",
      "boxes. Understanding the reasons behind predictions is, however, quite\n",
      "important in assessing trust, which is fundamental if one plans to take action\n",
      "based on a prediction, or when choosing whether to deploy a new model. Such\n",
      "understanding also provides insights into the model, which can be used to\n",
      "transform an untrustworthy model or prediction into a trustworthy one. In this\n",
      "work, we propose LIME, a novel explanation technique that explains the\n",
      "predictions of any classifier in an interpretable and faithful manner, by\n",
      "learning an interpretable model locally around the prediction. We also propose\n",
      "a method to explain models by presenting representative individual predictions\n",
      "and their explanations in a non-redundant way, framing the task as a submodular\n",
      "optimization problem. We demonstrate the flexibility of these methods by\n",
      "explaining different models for text (e.g. random forests) and image\n",
      "classification (e.g. neural networks). We show the utility of explanations via\n",
      "novel experiments, both simulated and with human subjects, on various scenarios\n",
      "that require trust: deciding if one should trust a prediction, choosing between\n",
      "models, improving an untrustworthy classifier, and identifying why a classifier\n",
      "should not be trusted.\n",
      "\n",
      "    \n",
      "615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of how a teacher algorithm can enable an unknown Deep\n",
      "Reinforcement Learning (DRL) student to become good at a skill over a wide\n",
      "range of diverse environments. To do so, we study how a teacher algorithm can\n",
      "learn to generate a learning curriculum, whereby it sequentially samples\n",
      "parameters controlling a stochastic procedural generation of environments.\n",
      "Because it does not initially know the capacities of its student, a key\n",
      "challenge for the teacher is to discover which environments are easy, difficult\n",
      "or unlearnable, and in what order to propose them to maximize the efficiency of\n",
      "learning over the learnable ones. To achieve this, this problem is transformed\n",
      "into a surrogate continuous bandit problem where the teacher samples\n",
      "environments in order to maximize absolute learning progress of its student. We\n",
      "present a new algorithm modeling absolute learning progress with Gaussian\n",
      "mixture models (ALP-GMM). We also adapt existing algorithms and provide a\n",
      "complete study in the context of DRL. Using parameterized variants of the\n",
      "BipedalWalker environment, we study their efficiency to personalize a learning\n",
      "curriculum for different learners (embodiments), their robustness to the ratio\n",
      "of learnable/unlearnable environments, and their scalability to non-linear and\n",
      "high-dimensional parameter spaces. Videos and code are available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Soft Actor-Critic is a state-of-the-art reinforcement learning algorithm for\n",
      "continuous action settings that is not applicable to discrete action settings.\n",
      "Many important settings involve discrete actions, however, and so here we\n",
      "derive an alternative version of the Soft Actor-Critic algorithm that is\n",
      "applicable to discrete action settings. We then show that, even without any\n",
      "hyperparameter tuning, it is competitive with the tuned model-free\n",
      "state-of-the-art on a selection of games from the Atari suite.\n",
      "\n",
      "    \n",
      "617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art computer vision approaches rely on huge amounts of annotated\n",
      "data. The collection of such data is a time consuming process since it is\n",
      "mainly performed by humans. The literature shows that semi-automatic annotation\n",
      "approaches can significantly speed up the annotation process by the automatic\n",
      "generation of annotation proposals to support the annotator. In this paper we\n",
      "present a framework that allows for a quick and flexible design of\n",
      "semi-automatic annotation pipelines. We show that a good design of the process\n",
      "will speed up the collection of annotations. Our contribution is a new approach\n",
      "to image annotation that allows for the combination of different annotation\n",
      "tools and machine learning algorithms in one process. We further present\n",
      "potential applications of our approach. The source code of our framework called\n",
      "LOST (Label Objects and Save Time) is available at:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes an upgraded electro-magnetic side-channel attack that\n",
      "automatically reconstructs the intercepted data. A novel system is introduced,\n",
      "running in parallel with leakage signal interception and catching compromising\n",
      "data in real-time. Based on deep learning and character recognition the\n",
      "proposed system retrieves more than 57% of characters present in intercepted\n",
      "signals regardless of signal type: analog or digital. The approach is also\n",
      "extended to a protection system that triggers an alarm if the system is\n",
      "compromised, demonstrating a success rate over 95%. Based on software-defined\n",
      "radio and graphics processing unit architectures, this solution can be easily\n",
      "deployed onto existing information systems where information shall be kept\n",
      "secret.\n",
      "\n",
      "    \n",
      "619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Question answering (QA) models have shown rapid progress enabled by the\n",
      "availability of large, high-quality benchmark datasets. Such annotated datasets\n",
      "are difficult and costly to collect, and rarely exist in languages other than\n",
      "English, making training QA systems in other languages challenging. An\n",
      "alternative to building large monolingual training datasets is to develop\n",
      "cross-lingual systems which can transfer to a target language without requiring\n",
      "training data in that language. In order to develop such systems, it is crucial\n",
      "to invest in high quality multilingual evaluation benchmarks to measure\n",
      "progress. We present MLQA, a multi-way aligned extractive QA evaluation\n",
      "benchmark intended to spur research in this area. MLQA contains QA instances in\n",
      "7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and\n",
      "Simplified Chinese. It consists of over 12K QA instances in English and 5K in\n",
      "each other language, with each QA instance being parallel between 4 languages\n",
      "on average. MLQA is built using a novel alignment context strategy on Wikipedia\n",
      "articles, and serves as a cross-lingual extension to existing extractive QA\n",
      "datasets. We evaluate current state-of-the-art cross-lingual representations on\n",
      "MLQA, and also provide machine-translation-based baselines. In all cases,\n",
      "transfer results are shown to be significantly behind training-language\n",
      "performance.\n",
      "\n",
      "    \n",
      "620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Layer normalization (LayerNorm) has been successfully applied to various deep\n",
      "neural networks to help stabilize training and boost model convergence because\n",
      "of its capability in handling re-centering and re-scaling of both inputs and\n",
      "weight matrix. However, the computational overhead introduced by LayerNorm\n",
      "makes these improvements expensive and significantly slows the underlying\n",
      "network, e.g. RNN in particular. In this paper, we hypothesize that\n",
      "re-centering invariance in LayerNorm is dispensable and propose root mean\n",
      "square layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs\n",
      "to a neuron in one layer according to root mean square (RMS), giving the model\n",
      "re-scaling invariance property and implicit learning rate adaptation ability.\n",
      "RMSNorm is computationally simpler and thus more efficient than LayerNorm. We\n",
      "also present partial RMSNorm, or pRMSNorm where the RMS is estimated from p% of\n",
      "the summed inputs without breaking the above properties. Extensive experiments\n",
      "on several tasks using diverse network architectures show that RMSNorm achieves\n",
      "comparable performance against LayerNorm but reduces the running time by 7%~64%\n",
      "on different models. Source code is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore the impact of learning paradigms on training deep neural networks\n",
      "for the Travelling Salesman Problem. We design controlled experiments to train\n",
      "supervised learning (SL) and reinforcement learning (RL) models on fixed graph\n",
      "sizes up to 100 nodes, and evaluate them on variable sized graphs up to 500\n",
      "nodes. Beyond not needing labelled data, out results reveal favorable\n",
      "properties of RL over SL: RL training leads to better emergent generalization\n",
      "to variable graph sizes and is a key component for learning scale-invariant\n",
      "solvers for novel combinatorial problems.\n",
      "\n",
      "    \n",
      "622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We generalize the concept of maximum-margin classifiers (MMCs) to arbitrary\n",
      "norms and non-linear functions. Support Vector Machines (SVMs) are a special\n",
      "case of MMC. We find that MMCs can be formulated as Integral Probability\n",
      "Metrics (IPMs) or classifiers with some form of gradient norm penalty. This\n",
      "implies a direct link to a class of Generative adversarial networks (GANs)\n",
      "which penalize a gradient norm. We show that the Discriminator in Wasserstein,\n",
      "Standard, Least-Squares, and Hinge GAN with Gradient Penalty is an MMC. We\n",
      "explain why maximizing a margin may be helpful in GANs. We hypothesize and\n",
      "confirm experimentally that $L^\\infty$-norm penalties with Hinge loss produce\n",
      "better GANs than $L^2$-norm penalties (based on common evaluation metrics). We\n",
      "derive the margins of Relativistic paired (Rp) and average (Ra) GANs.\n",
      "\n",
      "    \n",
      "623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Modern applications of machine learning (ML) deal with increasingly\n",
      "heterogeneous datasets comprised of data collected from overlapping latent\n",
      "subpopulations. As a result, traditional models trained over large datasets may\n",
      "fail to recognize highly predictive localized effects in favour of weakly\n",
      "predictive global patterns. This is a problem because localized effects are\n",
      "critical to developing individualized policies and treatment plans in\n",
      "applications ranging from precision medicine to advertising. To address this\n",
      "challenge, we propose to estimate sample-specific models that tailor inference\n",
      "and prediction at the individual level. In contrast to classical ML models that\n",
      "estimate a single, complex model (or only a few complex models), our approach\n",
      "produces a model personalized to each sample. These sample-specific models can\n",
      "be studied to understand subgroup dynamics that go beyond coarse-grained class\n",
      "labels. Crucially, our approach does not assume that relationships between\n",
      "samples (e.g. a similarity network) are known a priori. Instead, we use\n",
      "unmodeled covariates to learn a latent distance metric over the samples. We\n",
      "apply this approach to financial, biomedical, and electoral data as well as\n",
      "simulated data and show that sample-specific models provide fine-grained\n",
      "interpretations of complicated phenomena without sacrificing predictive\n",
      "accuracy compared to state-of-the-art models such as deep neural networks.\n",
      "\n",
      "    \n",
      "624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNNs) have been very successful at solving a\n",
      "variety of computer vision tasks such as object classification and detection,\n",
      "semantic segmentation, activity understanding, to name just a few. One key\n",
      "enabling factor for their great performance has been the ability to train very\n",
      "deep CNNs. Despite their huge success in many tasks, CNNs do not work well with\n",
      "non-Euclidean data which is prevalent in many real-world applications. Graph\n",
      "Convolutional Networks (GCNs) offer an alternative that allows for\n",
      "non-Eucledian data as input to a neural network similar to CNNs. While GCNs\n",
      "already achieve encouraging results, they are currently limited to shallow\n",
      "architectures with 2-4 layers due to vanishing gradients during training. This\n",
      "work transfers concepts such as residual/dense connections and dilated\n",
      "convolutions from CNNs to GCNs in order to successfully train very deep GCNs.\n",
      "We show the benefit of deep GCNs with as many as 112 layers experimentally\n",
      "across various datasets and tasks. Specifically, we achieve state-of-the-art\n",
      "performance in part segmentation and semantic segmentation on point clouds and\n",
      "in node classification of protein functions across biological protein-protein\n",
      "interaction (PPI) graphs. We believe that the insights in this work will open a\n",
      "lot of avenues for future research on GCNs and transfer to further tasks not\n",
      "explored in this work. The source code for this work is available for Pytorch\n",
      "and Tensorflow at this https URL and\n",
      "this https URL respectively.\n",
      "\n",
      "    \n",
      "625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  It is challenging for current one-step retrieve-and-read question answering\n",
      "(QA) systems to answer questions like \"Which novel by the author of 'Armada'\n",
      "will be adapted as a feature film by Steven Spielberg?\" because the question\n",
      "seldom contains retrievable clues about the missing entity (here, the author).\n",
      "Answering such a question requires multi-hop reasoning where one must gather\n",
      "information about the missing entity (or facts) to proceed with further\n",
      "reasoning. We present GoldEn (Gold Entity) Retriever, which iterates between\n",
      "reading context and retrieving more supporting documents to answer open-domain\n",
      "multi-hop questions. Instead of using opaque and computationally expensive\n",
      "neural retrieval models, GoldEn Retriever generates natural language search\n",
      "queries given the question and available context, and leverages off-the-shelf\n",
      "information retrieval systems to query for missing entities. This allows GoldEn\n",
      "Retriever to scale up efficiently for open-domain multi-hop reasoning while\n",
      "maintaining interpretability. We evaluate GoldEn Retriever on the recently\n",
      "proposed open-domain multi-hop QA dataset, HotpotQA, and demonstrate that it\n",
      "outperforms the best previously published model despite not using pretrained\n",
      "language models such as BERT.\n",
      "\n",
      "    \n",
      "626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Nodes performing different functions in a network have different roles, and\n",
      "these roles can be gleaned from the structure of the network. Learning latent\n",
      "representations for the roles of nodes helps to understand the network and to\n",
      "transfer knowledge across networks. However, most existing structural embedding\n",
      "approaches suffer from high computation and space cost or rely on heuristic\n",
      "feature engineering. Here we propose RiWalk, a flexible paradigm for learning\n",
      "structural node representations. It decouples the structural embedding problem\n",
      "into a role identification procedure and a network embedding procedure. Through\n",
      "role identification, rooted kernels with structural dependencies kept are built\n",
      "to better integrate network embedding methods. To demonstrate the effectiveness\n",
      "of RiWalk, we develop two different role identification methods named RiWalk-SP\n",
      "and RiWalk-WL respectively and employ random walk based network embedding\n",
      "methods. Experiments on within-network classification tasks show that our\n",
      "proposed algorithms achieve comparable performance with other baselines while\n",
      "being an order of magnitude more efficient. Besides, we also conduct\n",
      "across-network role classification tasks. The results show potential of\n",
      "structural embeddings in transfer learning. RiWalk is also scalable, making it\n",
      "capable of capturing structural roles in massive networks.\n",
      "\n",
      "    \n",
      "627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Developing a differentially private deep learning algorithm is challenging,\n",
      "due to the difficulty in analyzing the sensitivity of objective functions that\n",
      "are typically used to train deep neural networks. Many existing methods resort\n",
      "to the stochastic gradient descent algorithm and apply a pre-defined\n",
      "sensitivity to the gradients for privatizing weights. However, their slow\n",
      "convergence typically yields a high cumulative privacy loss. Here, we take a\n",
      "different route by employing the method of auxiliary coordinates, which allows\n",
      "us to independently update the weights per layer by optimizing a per-layer\n",
      "objective function. This objective function can be well approximated by a\n",
      "low-order Taylor's expansion, in which sensitivity analysis becomes tractable.\n",
      "We perturb the coefficients of the expansion for privacy, which we optimize\n",
      "using more advanced optimization routines than SGD for faster convergence. We\n",
      "empirically show that our algorithm provides a decent trained model quality\n",
      "under a modest privacy budget.\n",
      "\n",
      "    \n",
      "628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Application of discrete-time survival methods for continuous-time survival\n",
      "prediction is considered. For this purpose, a scheme for discretization of\n",
      "continuous-time data is proposed by considering the quantiles of the estimated\n",
      "event-time distribution, and, for smaller data sets, it is found to be\n",
      "preferable over the commonly used equidistant scheme. Furthermore, two\n",
      "interpolation schemes for continuous-time survival estimates are explored, both\n",
      "of which are shown to yield improved performance compared to the discrete-time\n",
      "estimates. The survival methods considered are based on the likelihood for\n",
      "right-censored survival data, and parameterize either the probability mass\n",
      "function (PMF) or the discrete-time hazard rate, both with neural networks.\n",
      "Through simulations and study of real-world data, the hazard rate\n",
      "parametrization is found to perform slightly better than the parametrization of\n",
      "the PMF. Inspired by these investigations, a continuous-time method is proposed\n",
      "by assuming that the continuous-time hazard rate is piecewise constant. The\n",
      "method, named PC-Hazard, is found to be highly competitive with the\n",
      "aforementioned methods in addition to other methods for survival prediction\n",
      "found in the literature.\n",
      "\n",
      "    \n",
      "629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Semantic image synthesis aims at generating photorealistic images from\n",
      "semantic layouts. Previous approaches with conditional generative adversarial\n",
      "networks (GAN) show state-of-the-art performance on this task, which either\n",
      "feed the semantic label maps as inputs to the generator, or use them to\n",
      "modulate the activations in normalization layers via affine transformations. We\n",
      "argue that convolutional kernels in the generator should be aware of the\n",
      "distinct semantic labels at different locations when generating images. In\n",
      "order to better exploit the semantic layout for the image generator, we propose\n",
      "to predict convolutional kernels conditioned on the semantic label map to\n",
      "generate the intermediate feature maps from the noise maps and eventually\n",
      "generate the images. Moreover, we propose a feature pyramid semantics-embedding\n",
      "discriminator, which is more effective in enhancing fine details and semantic\n",
      "alignments between the generated images and the input semantic layouts than\n",
      "previous multi-scale discriminators. We achieve state-of-the-art results on\n",
      "both quantitative metrics and subjective evaluation on various semantic\n",
      "segmentation datasets, demonstrating the effectiveness of our approach.\n",
      "\n",
      "    \n",
      "630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural Machine Translation (NMT) models generally perform translation using a\n",
      "fixed-size lexical vocabulary, which is an important bottleneck on their\n",
      "generalization capability and overall translation quality. The standard\n",
      "approach to overcome this limitation is to segment words into subword units,\n",
      "typically using some external tools with arbitrary heuristics, resulting in\n",
      "vocabulary units not optimized for the translation task. Recent studies have\n",
      "shown that the same approach can be extended to perform NMT directly at the\n",
      "level of characters, which can deliver translation accuracy on-par with\n",
      "subword-based models, on the other hand, this requires relatively deeper\n",
      "networks. In this paper, we propose a more computationally-efficient solution\n",
      "for character-level NMT which implements a hierarchical decoding architecture\n",
      "where translations are subsequently generated at the level of words and\n",
      "characters. We evaluate different methods for open-vocabulary NMT in the\n",
      "machine translation task from English into five languages with distinct\n",
      "morphological typology, and show that the hierarchical decoding model can reach\n",
      "higher translation accuracy than the subword-level NMT model using\n",
      "significantly fewer parameters, while demonstrating better capacity in learning\n",
      "longer-distance contextual and grammatical dependencies than the standard\n",
      "character-level NMT model.\n",
      "\n",
      "    \n",
      "631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  With the demand for machine learning increasing, so does the demand for tools\n",
      "which make it easier to use. Automated machine learning (AutoML) tools have\n",
      "been developed to address this need, such as the Tree-Based Pipeline\n",
      "Optimization Tool (TPOT) which uses genetic programming to build optimal\n",
      "pipelines. We introduce Layered TPOT, a modification to TPOT which aims to\n",
      "create pipelines equally good as the original, but in significantly less time.\n",
      "This approach evaluates candidate pipelines on increasingly large subsets of\n",
      "the data according to their fitness, using a modified evolutionary algorithm to\n",
      "allow for separate competition between pipelines trained on different sample\n",
      "sizes. Empirical evaluation shows that, on sufficiently large datasets, Layered\n",
      "TPOT indeed finds better models faster.\n",
      "\n",
      "    \n",
      "632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  As the field of data science continues to grow, there will be an\n",
      "ever-increasing demand for tools that make machine learning accessible to\n",
      "non-experts. In this paper, we introduce the concept of tree-based pipeline\n",
      "optimization for automating one of the most tedious parts of machine\n",
      "learning---pipeline design. We implement an open source Tree-based Pipeline\n",
      "Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a\n",
      "series of simulated and real-world benchmark data sets. In particular, we show\n",
      "that TPOT can design machine learning pipelines that provide a significant\n",
      "improvement over a basic machine learning analysis while requiring little to no\n",
      "input nor prior knowledge from the user. We also address the tendency for TPOT\n",
      "to design overly complex pipelines by integrating Pareto optimization, which\n",
      "produces compact pipelines without sacrificing classification accuracy. As\n",
      "such, this work represents an important step toward fully automating machine\n",
      "learning pipeline design.\n",
      "\n",
      "    \n",
      "633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Over the past decade, data science and machine learning has grown from a\n",
      "mysterious art form to a staple tool across a variety of fields in academia,\n",
      "business, and government. In this paper, we introduce the concept of tree-based\n",
      "pipeline optimization for automating one of the most tedious parts of machine\n",
      "learning---pipeline design. We implement a Tree-based Pipeline Optimization\n",
      "Tool (TPOT) and demonstrate its effectiveness on a series of simulated and\n",
      "real-world genetic data sets. In particular, we show that TPOT can build\n",
      "machine learning pipelines that achieve competitive classification accuracy and\n",
      "discover novel pipeline operators---such as synthetic feature\n",
      "constructors---that significantly improve classification accuracy on these data\n",
      "sets. We also highlight the current challenges to pipeline optimization, such\n",
      "as the tendency to produce pipelines that overfit the data, and suggest future\n",
      "research paths to overcome these challenges. As such, this work represents an\n",
      "early step toward fully automating machine learning pipeline design.\n",
      "\n",
      "    \n",
      "634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural architecture search (NAS) has been proposed to automatically tune deep\n",
      "neural networks, but existing search algorithms, e.g., NASNet, PNAS, usually\n",
      "suffer from expensive computational cost. Network morphism, which keeps the\n",
      "functionality of a neural network while changing its neural architecture, could\n",
      "be helpful for NAS by enabling more efficient training during the search. In\n",
      "this paper, we propose a novel framework enabling Bayesian optimization to\n",
      "guide the network morphism for efficient neural architecture search. The\n",
      "framework develops a neural network kernel and a tree-structured acquisition\n",
      "function optimization algorithm to efficiently explores the search space.\n",
      "Intensive experiments on real-world benchmark datasets have been done to\n",
      "demonstrate the superior performance of the developed framework over the\n",
      "state-of-the-art methods. Moreover, we build an open-source AutoML system based\n",
      "on our method, namely Auto-Keras. The system runs in parallel on CPU and GPU,\n",
      "with an adaptive search strategy for different GPU memory limits.\n",
      "\n",
      "    \n",
      "635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  DeepMind Lab is a first-person 3D game platform designed for research and\n",
      "development of general artificial intelligence and machine learning systems.\n",
      "DeepMind Lab can be used to study how autonomous artificial agents may learn\n",
      "complex tasks in large, partially observed, and visually diverse worlds.\n",
      "DeepMind Lab has a simple and flexible API enabling creative task-designs and\n",
      "novel AI-designs to be explored and quickly iterated upon. It is powered by a\n",
      "fast and widely recognised game engine, and tailored for effective use by the\n",
      "research community.\n",
      "\n",
      "    \n",
      "636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Analogical reasoning is effective in capturing linguistic regularities. This\n",
      "paper proposes an analogical reasoning task on Chinese. After delving into\n",
      "Chinese lexical knowledge, we sketch 68 implicit morphological relations and 28\n",
      "explicit semantic relations. A big and balanced dataset CA8 is then built for\n",
      "this task, including 17813 questions. Furthermore, we systematically explore\n",
      "the influences of vector representations, context features, and corpora on\n",
      "analogical reasoning. With the experiments, CA8 is proved to be a reliable\n",
      "benchmark for evaluating Chinese word embeddings.\n",
      "\n",
      "    \n",
      "637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generative Adversarial Networks (GANs) are powerful generative models, but\n",
      "suffer from training instability. The recently proposed Wasserstein GAN (WGAN)\n",
      "makes progress toward stable training of GANs, but sometimes can still generate\n",
      "only low-quality samples or fail to converge. We find that these problems are\n",
      "often due to the use of weight clipping in WGAN to enforce a Lipschitz\n",
      "constraint on the critic, which can lead to undesired behavior. We propose an\n",
      "alternative to clipping weights: penalize the norm of gradient of the critic\n",
      "with respect to its input. Our proposed method performs better than standard\n",
      "WGAN and enables stable training of a wide variety of GAN architectures with\n",
      "almost no hyperparameter tuning, including 101-layer ResNets and language\n",
      "models over discrete data. We also achieve high quality generations on CIFAR-10\n",
      "and LSUN bedrooms.\n",
      "\n",
      "    \n",
      "638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We extend Generative Adversarial Networks (GANs) to the semi-supervised\n",
      "context by forcing the discriminator network to output class labels. We train a\n",
      "generative model G and a discriminator D on a dataset with inputs belonging to\n",
      "one of N classes. At training time, D is made to predict which of N+1 classes\n",
      "the input belongs to, where an extra class is added to correspond to the\n",
      "outputs of G. We show that this method can be used to create a more\n",
      "data-efficient classifier and that it allows for generating higher quality\n",
      "samples than a regular GAN.\n",
      "\n",
      "    \n",
      "639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Collecting well-annotated image datasets to train modern machine learning\n",
      "algorithms is prohibitively expensive for many tasks. One appealing alternative\n",
      "is rendering synthetic data where ground-truth annotations are generated\n",
      "automatically. Unfortunately, models trained purely on rendered images often\n",
      "fail to generalize to real images. To address this shortcoming, prior work\n",
      "introduced unsupervised domain adaptation algorithms that attempt to map\n",
      "representations between the two domains or learn to extract features that are\n",
      "domain-invariant. In this work, we present a new approach that learns, in an\n",
      "unsupervised manner, a transformation in the pixel space from one domain to the\n",
      "other. Our generative adversarial network (GAN)-based method adapts\n",
      "source-domain images to appear as if drawn from the target domain. Our approach\n",
      "not only produces plausible samples, but also outperforms the state-of-the-art\n",
      "on a number of unsupervised domain adaptation scenarios by large margins.\n",
      "Finally, we demonstrate that the adaptation process generalizes to object\n",
      "classes unseen during training.\n",
      "\n",
      "    \n",
      "640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Conditional Generative Adversarial Networks (GANs) for cross-domain\n",
      "image-to-image translation have made much progress recently. Depending on the\n",
      "task complexity, thousands to millions of labeled image pairs are needed to\n",
      "train a conditional GAN. However, human labeling is expensive, even\n",
      "impractical, and large quantities of data may not always be available. Inspired\n",
      "by dual learning from natural language translation, we develop a novel dual-GAN\n",
      "mechanism, which enables image translators to be trained from two sets of\n",
      "unlabeled images from two domains. In our architecture, the primal GAN learns\n",
      "to translate images from domain U to those in domain V, while the dual GAN\n",
      "learns to invert the task. The closed loop made by the primal and dual tasks\n",
      "allows images from either domain to be translated and then reconstructed. Hence\n",
      "a loss function that accounts for the reconstruction error of images can be\n",
      "used to train the translators. Experiments on multiple image translation tasks\n",
      "with unlabeled data show considerable performance gain of DualGAN over a single\n",
      "GAN. For some tasks, DualGAN can even achieve comparable or slightly better\n",
      "results than conditional GAN trained on fully labeled data.\n",
      "\n",
      "    \n",
      "641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Adaptive Instance Selection network architecture for\n",
      "class-agnostic instance segmentation. Given an input image and a point $(x,\n",
      "y)$, it generates a mask for the object located at $(x, y)$. The network adapts\n",
      "to the input point with a help of AdaIN layers, thus producing different masks\n",
      "for different objects on the same image. AdaptIS generates pixel-accurate\n",
      "object masks, therefore it accurately segments objects of complex shape or\n",
      "severely occluded ones. AdaptIS can be easily combined with standard semantic\n",
      "segmentation pipeline to perform panoptic segmentation. To illustrate the idea,\n",
      "we perform experiments on a challenging toy problem with difficult occlusions.\n",
      "Then we extensively evaluate the method on panoptic segmentation benchmarks. We\n",
      "obtain state-of-the-art results on Cityscapes and Mapillary even without\n",
      "pretraining on COCO, and show competitive results on a challenging COCO\n",
      "dataset. The source code of the method and the trained models are available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We provide an open-source C++ library for real-time metric-semantic\n",
      "visual-inertial Simultaneous Localization And Mapping (SLAM). The library goes\n",
      "beyond existing visual and visual-inertial SLAM libraries (e.g., ORB-SLAM,\n",
      "VINS- Mono, OKVIS, ROVIO) by enabling mesh reconstruction and semantic labeling\n",
      "in 3D. Kimera is designed with modularity in mind and has four key components:\n",
      "a visual-inertial odometry (VIO) module for fast and accurate state estimation,\n",
      "a robust pose graph optimizer for global trajectory estimation, a lightweight\n",
      "3D mesher module for fast mesh reconstruction, and a dense 3D metric-semantic\n",
      "reconstruction module. The modules can be run in isolation or in combination,\n",
      "hence Kimera can easily fall back to a state-of-the-art VIO or a full SLAM\n",
      "system. Kimera runs in real-time on a CPU and produces a 3D metric-semantic\n",
      "mesh from semantically labeled images, which can be obtained by modern deep\n",
      "learning methods. We hope that the flexibility, computational efficiency,\n",
      "robustness, and accuracy afforded by Kimera will build a solid basis for future\n",
      "metric-semantic SLAM and perception research, and will allow researchers across\n",
      "multiple areas (e.g., VIO, SLAM, 3D reconstruction, segmentation) to benchmark\n",
      "and prototype their own efforts without having to start from scratch.\n",
      "\n",
      "    \n",
      "643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent studies have demonstrated the efficiency of generative pretraining for\n",
      "English natural language understanding. In this work, we extend this approach\n",
      "to multiple languages and show the effectiveness of cross-lingual pretraining.\n",
      "We propose two methods to learn cross-lingual language models (XLMs): one\n",
      "unsupervised that only relies on monolingual data, and one supervised that\n",
      "leverages parallel data with a new cross-lingual language model objective. We\n",
      "obtain state-of-the-art results on cross-lingual classification, unsupervised\n",
      "and supervised machine translation. On XNLI, our approach pushes the state of\n",
      "the art by an absolute gain of 4.9% accuracy. On unsupervised machine\n",
      "translation, we obtain 34.3 BLEU on WMT'16 German-English, improving the\n",
      "previous state of the art by more than 9 BLEU. On supervised machine\n",
      "translation, we obtain a new state of the art of 38.5 BLEU on WMT'16\n",
      "Romanian-English, outperforming the previous best approach by more than 4 BLEU.\n",
      "Our code and pretrained models will be made publicly available.\n",
      "\n",
      "    \n",
      "644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNNs) achieve impressive performance in a wide\n",
      "variety of fields. Their success benefited from a massive boost when very deep\n",
      "CNN models were able to be reliably trained. Despite their merits, CNNs fail to\n",
      "properly address problems with non-Euclidean data. To overcome this challenge,\n",
      "Graph Convolutional Networks (GCNs) build graphs to represent non-Euclidean\n",
      "data, borrow concepts from CNNs, and apply them in training. GCNs show\n",
      "promising results, but they are usually limited to very shallow models due to\n",
      "the vanishing gradient problem. As a result, most state-of-the-art GCN models\n",
      "are no deeper than 3 or 4 layers. In this work, we present new ways to\n",
      "successfully train very deep GCNs. We do this by borrowing concepts from CNNs,\n",
      "specifically residual/dense connections and dilated convolutions, and adapting\n",
      "them to GCN architectures. Extensive experiments show the positive effect of\n",
      "these deep GCN frameworks. Finally, we use these new concepts to build a very\n",
      "deep 56-layer GCN, and show how it significantly boosts performance (+3.7% mIoU\n",
      "over state-of-the-art) in the task of point cloud semantic segmentation. We\n",
      "believe that the community can greatly benefit from this work, as it opens up\n",
      "many opportunities for advancing GCN-based research.\n",
      "\n",
      "    \n",
      "645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The concept of non-linearity in a Neural Network is introduced by an\n",
      "activation function which serves an integral role in the training and\n",
      "performance evaluation of the network. Over the years of theoretical research,\n",
      "many activation functions have been proposed, however, only a few are widely\n",
      "used in mostly all applications which include ReLU (Rectified Linear Unit),\n",
      "TanH (Tan Hyperbolic), Sigmoid, Leaky ReLU and Swish. In this work, a novel\n",
      "neural activation function called as Mish is proposed. The experiments show\n",
      "that Mish tends to work better than both ReLU and Swish along with other\n",
      "standard activation functions in many deep networks across challenging\n",
      "datasets. For instance, in Squeeze Excite Net- 18 for CIFAR 100 classification,\n",
      "the network with Mish had an increase in Top-1 test accuracy by 0.494% and\n",
      "1.671% as compared to the same network with Swish and ReLU respectively. The\n",
      "similarity to Swish along with providing a boost in performance and its\n",
      "simplicity in implementation makes it easier for researchers and developers to\n",
      "use Mish in their Neural Network Models.\n",
      "\n",
      "    \n",
      "646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generative adversarial networks (GANs) are capable of producing high quality\n",
      "samples, but they suffer from numerous issues such as instability and mode\n",
      "collapse during training. To combat this, we propose to model the generator and\n",
      "discriminator as agents acting under local information, uncertainty, and\n",
      "awareness of their opponent. By doing so we achieve stable convergence, even\n",
      "when the underlying game has no Nash equilibria. We call this mechanism\n",
      "implicit competitive regularization (ICR) and show that it is present in the\n",
      "recently proposed competitive gradient descent (CGD). When comparing CGD to\n",
      "Adam using a variety of loss functions and regularizers on CIFAR10, CGD shows a\n",
      "much more consistent performance, which we attribute to ICR. In our\n",
      "experiments, we achieve the highest inception score when using the WGAN loss\n",
      "(without gradient penalty or weight clipping) together with CGD. This can be\n",
      "interpreted as minimizing a form of integral probability metric based on ICR.\n",
      "\n",
      "    \n",
      "647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work we aim to solve a large collection of tasks using a single\n",
      "reinforcement learning agent with a single set of parameters. A key challenge\n",
      "is to handle the increased amount of data and extended training time. We have\n",
      "developed a new distributed agent IMPALA (Importance Weighted Actor-Learner\n",
      "Architecture) that not only uses resources more efficiently in single-machine\n",
      "training but also scales to thousands of machines without sacrificing data\n",
      "efficiency or resource utilisation. We achieve stable learning at high\n",
      "throughput by combining decoupled acting and learning with a novel off-policy\n",
      "correction method called V-trace. We demonstrate the effectiveness of IMPALA\n",
      "for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the\n",
      "DeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available\n",
      "Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our\n",
      "results show that IMPALA is able to achieve better performance than previous\n",
      "agents with less data, and crucially exhibits positive transfer between tasks\n",
      "as a result of its multi-task approach.\n",
      "\n",
      "    \n",
      "648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents a new Unified pre-trained Language Model (UniLM) that can\n",
      "be fine-tuned for both natural language understanding and generation tasks. The\n",
      "model is pre-trained using three types of language modeling tasks:\n",
      "unidirectional, bidirectional, and sequence-to-sequence prediction. The unified\n",
      "modeling is achieved by employing a shared Transformer network and utilizing\n",
      "specific self-attention masks to control what context the prediction conditions\n",
      "on. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0\n",
      "and CoQA question answering tasks. Moreover, UniLM achieves new\n",
      "state-of-the-art results on five natural language generation datasets,\n",
      "including improving the CNN/DailyMail abstractive summarization ROUGE-L to\n",
      "40.51 (2.04 absolute improvement), the Gigaword abstractive summarization\n",
      "ROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question\n",
      "answering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question\n",
      "generation BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7\n",
      "document-grounded dialog response generation NIST-4 to 2.67 (human performance\n",
      "is 2.65). The code and pre-trained models are available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in image-to-image translation have led to some ways to\n",
      "generate multiple domain images through a single network. However, there is\n",
      "still a limit in creating an image of a target domain without a dataset on it.\n",
      "We propose a method that expands the concept of `multi-domain' from data to the\n",
      "loss area and learns the combined characteristics of each domain to dynamically\n",
      "infer translations of images in mixed domains. First, we introduce\n",
      "Sym-parameter and its learning method for variously mixed losses while\n",
      "synchronizing them with input conditions. Then, we propose Sym-parameterized\n",
      "Generative Network (SGN) which is empirically confirmed of learning mixed\n",
      "characteristics of various data and losses, and translating images to any\n",
      "mixed-domain without ground truths, such as 30% Van Gogh and 20% Monet and 40%\n",
      "snowy.\n",
      "\n",
      "    \n",
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automatically learned quality assessment for images has recently become a hot\n",
      "topic due to its usefulness in a wide variety of applications such as\n",
      "evaluating image capture pipelines, storage techniques and sharing media.\n",
      "Despite the subjective nature of this problem, most existing methods only\n",
      "predict the mean opinion score provided by datasets such as AVA [1] and TID2013\n",
      "[2]. Our approach differs from others in that we predict the distribution of\n",
      "human opinion scores using a convolutional neural network. Our architecture\n",
      "also has the advantage of being significantly simpler than other methods with\n",
      "comparable performance. Our proposed approach relies on the success (and\n",
      "retraining) of proven, state-of-the-art deep object recognition networks. Our\n",
      "resulting network can be used to not only score images reliably and with high\n",
      "correlation to human perception, but also to assist with adaptation and\n",
      "optimization of photo editing/enhancement algorithms in a photographic\n",
      "pipeline. All this is done without need for a \"golden\" reference image,\n",
      "consequently allowing for single-image, semantic- and perceptually-aware,\n",
      "no-reference quality assessment.\n",
      "\n",
      "    \n",
      "651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Bidirectional Encoder Representations from Transformers (BERT) represents the\n",
      "latest incarnation of pretrained language models which have recently advanced a\n",
      "wide range of natural language processing tasks. In this paper, we showcase how\n",
      "BERT can be usefully applied in text summarization and propose a general\n",
      "framework for both extractive and abstractive models. We introduce a novel\n",
      "document-level encoder based on BERT which is able to express the semantics of\n",
      "a document and obtain representations for its sentences. Our extractive model\n",
      "is built on top of this encoder by stacking several inter-sentence Transformer\n",
      "layers. For abstractive summarization, we propose a new fine-tuning schedule\n",
      "which adopts different optimizers for the encoder and the decoder as a means of\n",
      "alleviating the mismatch between the two (the former is pretrained while the\n",
      "latter is not). We also demonstrate that a two-staged fine-tuning approach can\n",
      "further boost the quality of the generated summaries. Experiments on three\n",
      "datasets show that our model achieves state-of-the-art results across the board\n",
      "in both extractive and abstractive settings. Our code is available at\n",
      "this https URL\n",
      "\n",
      "652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Channel attention has recently demonstrated to offer great potential in\n",
      "improving the performance of deep convolutional neural networks (CNNs).\n",
      "However, most existing methods dedicate to developing more sophisticated\n",
      "attention modules to achieve better performance, inevitably increasing the\n",
      "computational burden. To overcome the paradox of performance and complexity\n",
      "trade-off, this paper makes an attempt to investigate an extremely lightweight\n",
      "attention module for boosting the performance of deep CNNs. In particular, we\n",
      "propose an Efficient Channel Attention (ECA) module, which only involves $k (k\n",
      "< 9)$ parameters but brings clear performance gain. By revisiting the channel\n",
      "attention module in SENet, we empirically show avoiding dimensionality\n",
      "reduction and appropriate cross-channel interaction are important to learn\n",
      "effective channel attention. Therefore, we propose a local cross-channel\n",
      "interaction strategy without dimension reduction, which can be efficiently\n",
      "implemented by a fast 1D convolution. Furthermore, we develop a function of\n",
      "channel dimension to adaptively determine kernel size of 1D convolution, which\n",
      "stands for coverage of local cross-channel interaction. Our ECA module can be\n",
      "flexibly incorporated into existing CNN architectures, and the resulting CNNs\n",
      "are named by ECA-Net. We extensively evaluate the proposed ECA-Net on image\n",
      "classification, object detection and instance segmentation with backbones of\n",
      "ResNets and MobileNetV2. The experimental results show our ECA-Net is more\n",
      "efficient while performing favorably against its counterparts. The source code\n",
      "and models can be available at this https URL.\n",
      "\n",
      "    \n",
      "653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This work presents Kornia -- an open source computer vision library which\n",
      "consists of a set of differentiable routines and modules to solve generic\n",
      "computer vision problems. The package uses PyTorch as its main backend both for\n",
      "efficiency and to take advantage of the reverse-mode auto-differentiation to\n",
      "define and compute the gradient of complex functions. Inspired by OpenCV,\n",
      "Kornia is composed of a set of modules containing operators that can be\n",
      "inserted inside neural networks to train models to perform image\n",
      "transformations, camera calibration, epipolar geometry, and low level image\n",
      "processing techniques, such as filtering and edge detection that operate\n",
      "directly on high dimensional tensor representations. Examples of classical\n",
      "vision problems implemented using our framework are provided including a\n",
      "benchmark comparing to existing vision libraries.\n",
      "\n",
      "    \n",
      "654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Filter pruning is one of the most effective ways to accelerate and compress\n",
      "convolutional neural networks (CNNs). In this work, we propose a global filter\n",
      "pruning algorithm called Gate Decorator, which transforms a vanilla CNN module\n",
      "by multiplying its output by the channel-wise scaling factors, i.e. gate. When\n",
      "the scaling factor is set to zero, it is equivalent to removing the\n",
      "corresponding filter. We use Taylor expansion to estimate the change in the\n",
      "loss function caused by setting the scaling factor to zero and use the\n",
      "estimation for the global filter importance ranking. Then we prune the network\n",
      "by removing those unimportant filters. After pruning, we merge all the scaling\n",
      "factors into its original module, so no special operations or structures are\n",
      "introduced. Moreover, we propose an iterative pruning framework called\n",
      "Tick-Tock to improve pruning accuracy. The extensive experiments demonstrate\n",
      "the effectiveness of our approaches. For example, we achieve the\n",
      "state-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without\n",
      "noticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with\n",
      "40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy.\n",
      "Various datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet\n",
      "ILSVRC-12 and PASCAL VOC 2011. Code is available at\n",
      "this http URL\n",
      "\n",
      "655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural architecture search (NAS) aims to automate the search procedure of\n",
      "architecture instead of manual design. Even if recent NAS approaches finish the\n",
      "search within days, lengthy training is still required for a specific\n",
      "architecture candidate to get the parameters for its accurate evaluation.\n",
      "Recently one-shot NAS methods are proposed to largely squeeze the tedious\n",
      "training process by sharing parameters across candidates. In this way, the\n",
      "parameters for each candidate can be directly extracted from the shared\n",
      "parameters instead of training them from scratch. However, they have no sense\n",
      "of which candidate will perform better until evaluation so that the candidates\n",
      "to evaluate are randomly sampled and the top-1 candidate is considered the\n",
      "best. In this paper, we propose a Self-Evaluated Template Network (SETN) to\n",
      "improve the quality of the architecture candidates for evaluation so that it is\n",
      "more likely to cover competitive candidates. SETN consists of two components:\n",
      "(1) an evaluator, which learns to indicate the probability of each individual\n",
      "architecture being likely to have a lower validation loss. The candidates for\n",
      "evaluation can thus be selectively sampled according to this evaluator. (2) a\n",
      "template network, which shares parameters among all candidates to amortize the\n",
      "training cost of generated candidates. In experiments, the architecture found\n",
      "by SETN achieves state-of-the-art performance on CIFAR and ImageNet benchmarks\n",
      "within comparable computation costs. Code is publicly available on GitHub:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Conventional neural architecture search (NAS) approaches are based on\n",
      "reinforcement learning or evolutionary strategy, which take more than 3000 GPU\n",
      "hours to find a good model on CIFAR-10. We propose an efficient NAS approach\n",
      "learning to search by gradient descent. Our approach represents the search\n",
      "space as a directed acyclic graph (DAG). This DAG contains billions of\n",
      "sub-graphs, each of which indicates a kind of neural architecture. To avoid\n",
      "traversing all the possibilities of the sub-graphs, we develop a differentiable\n",
      "sampler over the DAG. This sampler is learnable and optimized by the validation\n",
      "loss after training the sampled architecture. In this way, our approach can be\n",
      "trained in an end-to-end fashion by gradient descent, named Gradient-based\n",
      "search using Differentiable Architecture Sampler (GDAS). In experiments, we can\n",
      "finish one searching procedure in four GPU hours on CIFAR-10, and the\n",
      "discovered model obtains a test error of 2.82\\% with only 2.5M parameters,\n",
      "which is on par with the state-of-the-art. Code is publicly available on\n",
      "GitHub: this https URL.\n",
      "\n",
      "    \n",
      "657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Network pruning reduces the computation costs of an over-parameterized\n",
      "network without performance damage. Prevailing pruning algorithms pre-define\n",
      "the width and depth of the pruned networks, and then transfer parameters from\n",
      "the unpruned network to pruned networks. To break the structure limitation of\n",
      "the pruned networks, we propose to apply neural architecture search to search\n",
      "directly for a network with flexible channel and layer sizes. The number of the\n",
      "channels/layers is learned by minimizing the loss of the pruned networks. The\n",
      "feature map of the pruned network is an aggregation of K feature map fragments\n",
      "(generated by K networks of different sizes), which are sampled based on the\n",
      "probability distribution.The loss can be back-propagated not only to the\n",
      "network weights, but also to the parameterized distribution to explicitly tune\n",
      "the size of the channels/layers. Specifically, we apply channel-wise\n",
      "interpolation to keep the feature map with different channel sizes aligned in\n",
      "the aggregation procedure. The maximum probability for the size in each\n",
      "distribution serves as the width and depth of the pruned network, whose\n",
      "parameters are learned by knowledge transfer, e.g., knowledge distillation,\n",
      "from the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNet\n",
      "demonstrate the effectiveness of our new perspective of network pruning\n",
      "compared to traditional network pruning algorithms. Various searching and\n",
      "knowledge transfer approaches are conducted to show the effectiveness of the\n",
      "two components. Code is at: this https URL.\n",
      "\n",
      "    \n",
      "658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we introduce an anchor-box free and single shot instance\n",
      "segmentation method, which is conceptually simple, fully convolutional and can\n",
      "be used as a mask prediction module for instance segmentation, by easily\n",
      "embedding it into most off-the-shelf detection methods. Our method, termed\n",
      "PolarMask, formulates the instance segmentation problem as instance center\n",
      "classification and dense distance regression in a polar coordinate. Moreover,\n",
      "we propose two effective approaches to deal with sampling high-quality center\n",
      "examples and optimization for dense distance regression, respectively, which\n",
      "can significantly improve the performance and simplify the training process.\n",
      "Without any bells and whistles, PolarMask achieves 32.9% in mask mAP with\n",
      "single-model and single-scale training/testing on challenging COCO dataset. For\n",
      "the first time, we demonstrate a much simpler and flexible instance\n",
      "segmentation framework achieving competitive accuracy. We hope that the\n",
      "proposed PolarMask framework can serve as a fundamental and strong baseline for\n",
      "single shot instance segmentation tasks. Code is available at:\n",
      "this http URL.\n",
      "\n",
      "    \n",
      "659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in neural architecture search (NAS) demand tremendous\n",
      "computational resources, which makes it difficult to reproduce experiments and\n",
      "imposes a barrier-to-entry to researchers without access to large-scale\n",
      "computation. We aim to ameliorate these problems by introducing NAS-Bench-101,\n",
      "the first public architecture dataset for NAS research. To build NAS-Bench-101,\n",
      "we carefully constructed a compact, yet expressive, search space, exploiting\n",
      "graph isomorphisms to identify 423k unique convolutional architectures. We\n",
      "trained and evaluated all of these architectures multiple times on CIFAR-10 and\n",
      "compiled the results into a large dataset of over 5 million trained models.\n",
      "This allows researchers to evaluate the quality of a diverse range of models in\n",
      "milliseconds by querying the pre-computed dataset. We demonstrate its utility\n",
      "by analyzing the dataset as a whole and by benchmarking a range of architecture\n",
      "optimization algorithms.\n",
      "\n",
      "    \n",
      "660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Face detection, as a fundamental technology for various applications, is\n",
      "always deployed on edge devices which have limited memory storage and low\n",
      "computing power. This paper introduces a Light and Fast Face Detector (LFFD)\n",
      "for edge devices. The proposed method is anchor-free and belongs to the\n",
      "one-stage category. Specifically, we rethink the importance of receptive field\n",
      "(RF) and effective receptive field (ERF) in the background of face detection.\n",
      "Essentially, the RFs of neurons in a certain layer are distributed regularly in\n",
      "the input image and theses RFs are natural \"anchors\". Combining RF \"anchors\"\n",
      "and appropriate RF strides, the proposed method can detect a large range of\n",
      "continuous face scales with 100% coverage in theory. The insightful\n",
      "understanding of relations between ERF and face scales motivates an efficient\n",
      "backbone for one-stage detection. The backbone is characterized by eight\n",
      "detection branches and common layers, resulting in efficient computation.\n",
      "Comprehensive and extensive experiments on popular benchmarks: WIDER FACE and\n",
      "FDDB are conducted. A new evaluation schema is proposed for\n",
      "application-oriented scenarios. Under the new schema, the proposed method can\n",
      "achieve superior accuracy (WIDER FACE Val/Test -- Easy: 0.910/0.896, Medium:\n",
      "0.881/0.865, Hard: 0.780/0.770; FDDB -- discontinuous: 0.973, continuous:\n",
      "0.724). Multiple hardware platforms are introduced to evaluate the running\n",
      "efficiency. The proposed method can obtain fast inference speed (NVIDIA TITAN\n",
      "Xp: 131.45 FPS at 640x480; NVIDIA TX2: 136.99 PFS at 160x120; Raspberry Pi 3\n",
      "Model B+: 8.44 FPS at 160x120) with model size of 9 MB.\n",
      "\n",
      "    \n",
      "661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The superior performance of Deformable Convolutional Networks arises from its\n",
      "ability to adapt to the geometric variations of objects. Through an examination\n",
      "of its adaptive behavior, we observe that while the spatial support for its\n",
      "neural features conforms more closely than regular ConvNets to object\n",
      "structure, this support may nevertheless extend well beyond the region of\n",
      "interest, causing features to be influenced by irrelevant image content. To\n",
      "address this problem, we present a reformulation of Deformable ConvNets that\n",
      "improves its ability to focus on pertinent image regions, through increased\n",
      "modeling power and stronger training. The modeling power is enhanced through a\n",
      "more comprehensive integration of deformable convolution within the network,\n",
      "and by introducing a modulation mechanism that expands the scope of deformation\n",
      "modeling. To effectively harness this enriched modeling capability, we guide\n",
      "network training via a proposed feature mimicking scheme that helps the network\n",
      "to learn features that reflect the object focus and classification power of\n",
      "R-CNN features. With the proposed contributions, this new version of Deformable\n",
      "ConvNets yields significant performance gains over the original model and\n",
      "produces leading results on the COCO benchmark for object detection and\n",
      "instance segmentation.\n",
      "\n",
      "    \n",
      "662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Letting a deep network be aware of the quality of its own predictions is an\n",
      "interesting yet important problem. In the task of instance segmentation, the\n",
      "confidence of instance classification is used as mask quality score in most\n",
      "instance segmentation frameworks. However, the mask quality, quantified as the\n",
      "IoU between the instance mask and its ground truth, is usually not well\n",
      "correlated with classification score. In this paper, we study this problem and\n",
      "propose Mask Scoring R-CNN which contains a network block to learn the quality\n",
      "of the predicted instance masks. The proposed network block takes the instance\n",
      "feature and the corresponding predicted mask together to regress the mask IoU.\n",
      "The mask scoring strategy calibrates the misalignment between mask quality and\n",
      "mask score, and improves instance segmentation performance by prioritizing more\n",
      "accurate mask predictions during COCO AP evaluation. By extensive evaluations\n",
      "on the COCO dataset, Mask Scoring R-CNN brings consistent and noticeable gain\n",
      "with different models, and outperforms the state-of-the-art Mask R-CNN. We hope\n",
      "our simple and effective approach will provide a new direction for improving\n",
      "instance segmentation. The source code of our method is available at\n",
      "\\url{this https URL}.\n",
      "\n",
      "    \n",
      "663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Attention mechanisms have become a popular component in deep neural networks,\n",
      "yet there has been little examination of how different influencing factors and\n",
      "methods for computing attention from these factors affect performance. Toward a\n",
      "better general understanding of attention mechanisms, we present an empirical\n",
      "study that ablates various spatial attention elements within a generalized\n",
      "attention formulation, encompassing the dominant Transformer attention as well\n",
      "as the prevalent deformable convolution and dynamic convolution modules.\n",
      "Conducted on a variety of applications, the study yields significant findings\n",
      "about spatial attention in deep networks, some of which run counter to\n",
      "conventional understanding. For example, we find that the query and key content\n",
      "comparison in Transformer attention is negligible for self-attention, but vital\n",
      "for encoder-decoder attention. A proper combination of deformable convolution\n",
      "with key content only saliency achieves the best accuracy-efficiency tradeoff\n",
      "in self-attention. Our results suggest that there exists much room for\n",
      "improvement in the design of attention mechanisms.\n",
      "\n",
      "    \n",
      "664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In object detection, an intersection over union (IoU) threshold is required\n",
      "to define positives and negatives. An object detector, trained with low IoU\n",
      "threshold, e.g. 0.5, usually produces noisy detections. However, detection\n",
      "performance tends to degrade with increasing the IoU thresholds. Two main\n",
      "factors are responsible for this: 1) overfitting during training, due to\n",
      "exponentially vanishing positive samples, and 2) inference-time mismatch\n",
      "between the IoUs for which the detector is optimal and those of the input\n",
      "hypotheses. A multi-stage object detection architecture, the Cascade R-CNN, is\n",
      "proposed to address these problems. It consists of a sequence of detectors\n",
      "trained with increasing IoU thresholds, to be sequentially more selective\n",
      "against close false positives. The detectors are trained stage by stage,\n",
      "leveraging the observation that the output of a detector is a good distribution\n",
      "for training the next higher quality detector. The resampling of progressively\n",
      "improved hypotheses guarantees that all detectors have a positive set of\n",
      "examples of equivalent size, reducing the overfitting problem. The same cascade\n",
      "procedure is applied at inference, enabling a closer match between the\n",
      "hypotheses and the detector quality of each stage. A simple implementation of\n",
      "the Cascade R-CNN is shown to surpass all single-model object detectors on the\n",
      "challenging COCO dataset. Experiments also show that the Cascade R-CNN is\n",
      "widely applicable across detector architectures, achieving consistent gains\n",
      "independently of the baseline detector strength. The code will be made\n",
      "available at this https URL.\n",
      "\n",
      "    \n",
      "665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The Non-Local Network (NLNet) presents a pioneering approach for capturing\n",
      "long-range dependencies, via aggregating query-specific global context to each\n",
      "query position. However, through a rigorous empirical analysis, we have found\n",
      "that the global contexts modeled by non-local network are almost the same for\n",
      "different query positions within an image. In this paper, we take advantage of\n",
      "this finding to create a simplified network based on a query-independent\n",
      "formulation, which maintains the accuracy of NLNet but with significantly less\n",
      "computation. We further observe that this simplified design shares similar\n",
      "structure with Squeeze-Excitation Network (SENet). Hence we unify them into a\n",
      "three-step general framework for global context modeling. Within the general\n",
      "framework, we design a better instantiation, called the global context (GC)\n",
      "block, which is lightweight and can effectively model the global context. The\n",
      "lightweight property allows us to apply it for multiple layers in a backbone\n",
      "network to construct a global context network (GCNet), which generally\n",
      "outperforms both simplified NLNet and SENet on major benchmarks for various\n",
      "recognition tasks. The code and configurations are released at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite the great success of two-stage detectors, single-stage detector is\n",
      "still a more elegant and efficient way, yet suffers from the two well-known\n",
      "disharmonies during training, i.e. the huge difference in quantity between\n",
      "positive and negative examples as well as between easy and hard examples. In\n",
      "this work, we first point out that the essential effect of the two disharmonies\n",
      "can be summarized in term of the gradient. Further, we propose a novel gradient\n",
      "harmonizing mechanism (GHM) to be a hedging for the disharmonies. The\n",
      "philosophy behind GHM can be easily embedded into both classification loss\n",
      "function like cross-entropy (CE) and regression loss function like smooth-$L_1$\n",
      "($SL_1$) loss. To this end, two novel loss functions called GHM-C and GHM-R are\n",
      "designed to balancing the gradient flow for anchor classification and bounding\n",
      "box refinement, respectively. Ablation study on MS COCO demonstrates that\n",
      "without laborious hyper-parameter tuning, both GHM-C and GHM-R can bring\n",
      "substantial improvement for single-stage detector. Without any whistles and\n",
      "bells, our model achieves 41.6 mAP on COCO test-dev set which surpasses the\n",
      "state-of-the-art method, Focal Loss (FL) + $SL_1$, by 0.8.\n",
      "\n",
      "    \n",
      "667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Grid R-CNN is a well-performed objection detection framework. It transforms\n",
      "the traditional box offset regression problem into a grid point estimation\n",
      "problem. With the guidance of the grid points, it can obtain high-quality\n",
      "localization results. However, the speed of Grid R-CNN is not so satisfactory.\n",
      "In this technical report we present Grid R-CNN Plus, a better and faster\n",
      "version of Grid R-CNN. We have made several updates that significantly speed up\n",
      "the framework and simultaneously improve the accuracy. On COCO dataset, the\n",
      "Res50-FPN based Grid R-CNN Plus detector achieves an mAP of 40.4%,\n",
      "outperforming the baseline on the same model by 3.0 points with similar\n",
      "inference time. Code is available at this https URL .\n",
      "\n",
      "    \n",
      "668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes a novel object detection framework named Grid R-CNN,\n",
      "which adopts a grid guided localization mechanism for accurate object\n",
      "detection. Different from the traditional regression based methods, the Grid\n",
      "R-CNN captures the spatial information explicitly and enjoys the position\n",
      "sensitive property of fully convolutional architecture. Instead of using only\n",
      "two independent points, we design a multi-point supervision formulation to\n",
      "encode more clues in order to reduce the impact of inaccurate prediction of\n",
      "specific points. To take the full advantage of the correlation of points in a\n",
      "grid, we propose a two-stage information fusion strategy to fuse feature maps\n",
      "of neighbor grid points. The grid guided localization approach is easy to be\n",
      "extended to different state-of-the-art detection frameworks. Grid R-CNN leads\n",
      "to high quality object localization, and experiments demonstrate that it\n",
      "achieves a 4.1% AP gain at IoU=0.8 and a 10.0% AP gain at IoU=0.9 on COCO\n",
      "benchmark compared to Faster R-CNN with Res50 backbone and FPN architecture.\n",
      "\n",
      "    \n",
      "669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Compared with model architectures, the training process, which is also\n",
      "crucial to the success of detectors, has received relatively less attention in\n",
      "object detection. In this work, we carefully revisit the standard training\n",
      "practice of detectors, and find that the detection performance is often limited\n",
      "by the imbalance during the training process, which generally consists in three\n",
      "levels - sample level, feature level, and objective level. To mitigate the\n",
      "adverse effects caused thereby, we propose Libra R-CNN, a simple but effective\n",
      "framework towards balanced learning for object detection. It integrates three\n",
      "novel components: IoU-balanced sampling, balanced feature pyramid, and balanced\n",
      "L1 loss, respectively for reducing the imbalance at sample, feature, and\n",
      "objective level. Benefitted from the overall balanced design, Libra R-CNN\n",
      "significantly improves the detection performance. Without bells and whistles,\n",
      "it achieves 2.5 points and 2.0 points higher Average Precision (AP) than FPN\n",
      "Faster R-CNN and RetinaNet respectively on MSCOCO.\n",
      "\n",
      "    \n",
      "670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Region anchors are the cornerstone of modern object detection techniques.\n",
      "State-of-the-art detectors mostly rely on a dense anchoring scheme, where\n",
      "anchors are sampled uniformly over the spatial domain with a predefined set of\n",
      "scales and aspect ratios. In this paper, we revisit this foundational stage.\n",
      "Our study shows that it can be done much more effectively and efficiently.\n",
      "Specifically, we present an alternative scheme, named Guided Anchoring, which\n",
      "leverages semantic features to guide the anchoring. The proposed method jointly\n",
      "predicts the locations where the center of objects of interest are likely to\n",
      "exist as well as the scales and aspect ratios at different locations. On top of\n",
      "predicted anchor shapes, we mitigate the feature inconsistency with a feature\n",
      "adaption module. We also study the use of high-quality proposals to improve\n",
      "detection performance. The anchoring scheme can be seamlessly integrated into\n",
      "proposal methods and detectors. With Guided Anchoring, we achieve 9.1% higher\n",
      "recall on MS COCO with 90% fewer anchors than the RPN baseline. We also adopt\n",
      "Guided Anchoring in Fast R-CNN, Faster R-CNN and RetinaNet, respectively\n",
      "improving the detection mAP by 2.2%, 2.7% and 1.2%. Code will be available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automatic synthesis of realistic images from text would be interesting and\n",
      "useful, but current AI systems are still far from this goal. However, in recent\n",
      "years generic and powerful recurrent neural network architectures have been\n",
      "developed to learn discriminative text feature representations. Meanwhile, deep\n",
      "convolutional generative adversarial networks (GANs) have begun to generate\n",
      "highly compelling images of specific categories, such as faces, album covers,\n",
      "and room interiors. In this work, we develop a novel deep architecture and GAN\n",
      "formulation to effectively bridge these advances in text and image model- ing,\n",
      "translating visual concepts from characters to pixels. We demonstrate the\n",
      "capability of our model to generate plausible images of birds and flowers from\n",
      "detailed text descriptions.\n",
      "\n",
      "    \n",
      "672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Machine learning algorithms are often vulnerable to adversarial examples that\n",
      "have imperceptible alterations from the original counterparts but can fool the\n",
      "state-of-the-art models. It is helpful to evaluate or even improve the\n",
      "robustness of these models by exposing the maliciously crafted adversarial\n",
      "examples. In this paper, we present TextFooler, a simple but strong baseline to\n",
      "generate natural adversarial text. By applying it to two fundamental natural\n",
      "language tasks, text classification and textual entailment, we successfully\n",
      "attacked three target models, including the powerful pre-trained BERT, and the\n",
      "widely used convolutional and recurrent neural networks. We demonstrate the\n",
      "advantages of this framework in three ways: (1) effective---it outperforms\n",
      "state-of-the-art attacks in terms of success rate and perturbation rate, (2)\n",
      "utility-preserving---it preserves semantic content and grammaticality, and\n",
      "remains correctly classified by humans, and (3) efficient---it generates\n",
      "adversarial text with computational complexity linear to the text length.\n",
      "\n",
      "    \n",
      "673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Although various techniques have been proposed to generate adversarial\n",
      "samples for white-box attacks on text, little attention has been paid to\n",
      "black-box attacks, which are more realistic scenarios. In this paper, we\n",
      "present a novel algorithm, DeepWordBug, to effectively generate small text\n",
      "perturbations in a black-box setting that forces a deep-learning classifier to\n",
      "misclassify a text input. We employ novel scoring strategies to identify the\n",
      "critical tokens that, if modified, cause the classifier to make an incorrect\n",
      "prediction. Simple character-level transformations are applied to the\n",
      "highest-ranked tokens in order to minimize the edit distance of the\n",
      "perturbation, yet change the original classification. We evaluated DeepWordBug\n",
      "on eight real-world text datasets, including text classification, sentiment\n",
      "analysis, and spam detection. We compare the result of DeepWordBug with two\n",
      "baselines: Random (Black-box) and Gradient (White-box). Our experimental\n",
      "results indicate that DeepWordBug reduces the prediction accuracy of current\n",
      "state-of-the-art deep-learning models, including a decrease of 68\\% on average\n",
      "for a Word-LSTM model and 48\\% on average for a Char-CNN model.\n",
      "\n",
      "    \n",
      "674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Learning-based Text Understanding (DLTU) is the backbone technique\n",
      "behind various applications, including question answering, machine translation,\n",
      "and text classification. Despite its tremendous popularity, the security\n",
      "vulnerabilities of DLTU are still largely unknown, which is highly concerning\n",
      "given its increasing use in security-sensitive applications such as sentiment\n",
      "analysis and toxic content detection. In this paper, we show that DLTU is\n",
      "inherently vulnerable to adversarial text attacks, in which maliciously crafted\n",
      "texts trigger target DLTU systems and services to misbehave. Specifically, we\n",
      "present TextBugger, a general attack framework for generating adversarial\n",
      "texts. In contrast to prior works, TextBugger differs in significant ways: (i)\n",
      "effective -- it outperforms state-of-the-art attacks in terms of attack success\n",
      "rate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\% of\n",
      "the adversarial text correctly recognized by human readers; and (iii) efficient\n",
      "-- it generates adversarial text with computational complexity sub-linear to\n",
      "the text length. We empirically evaluate TextBugger on a set of real-world DLTU\n",
      "systems and services used for sentiment analysis and toxic content detection,\n",
      "demonstrating its effectiveness, evasiveness, and efficiency. For instance,\n",
      "TextBugger achieves 100\\% success rate on the IMDB dataset based on Amazon AWS\n",
      "Comprehend within 4.61 seconds and preserves 97\\% semantic similarity. We\n",
      "further discuss possible defense mechanisms to mitigate such attack and the\n",
      "adversary's potential countermeasures, which leads to promising directions for\n",
      "further research.\n",
      "\n",
      "    \n",
      "675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Machine learning models are powerful but fallible. Generating adversarial\n",
      "examples - inputs deliberately crafted to cause model misclassification or\n",
      "other errors - can yield important insight into model assumptions and\n",
      "vulnerabilities. Despite significant recent work on adversarial example\n",
      "generation targeting image classifiers, relatively little work exists exploring\n",
      "adversarial example generation for text classifiers; additionally, many\n",
      "existing adversarial example generation algorithms require full access to\n",
      "target model parameters, rendering them impractical for many real-world\n",
      "attacks. In this work, we introduce DANCin SEQ2SEQ, a GAN-inspired algorithm\n",
      "for adversarial text example generation targeting largely black-box text\n",
      "classifiers. We recast adversarial text example generation as a reinforcement\n",
      "learning problem, and demonstrate that our algorithm offers preliminary but\n",
      "promising steps towards generating semantically meaningful adversarial text\n",
      "examples in a real-world attack scenario.\n",
      "\n",
      "    \n",
      "676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  CleverHans is a software library that provides standardized reference\n",
      "implementations of adversarial example construction techniques and adversarial\n",
      "training. The library may be used to develop more robust machine learning\n",
      "models and to provide standardized benchmarks of models' performance in the\n",
      "adversarial setting. Benchmarks constructed without a standardized\n",
      "implementation of adversarial example construction are not comparable to each\n",
      "other, because a good result may indicate a robust model or it may merely\n",
      "indicate a weak implementation of the adversarial example construction\n",
      "procedure.\n",
      "This technical report is structured as follows. Section 1 provides an\n",
      "overview of adversarial examples in machine learning and of the CleverHans\n",
      "software. Section 2 presents the core functionalities of the library: namely\n",
      "the attacks based on adversarial examples and defenses to improve the\n",
      "robustness of machine learning models to these attacks. Section 3 describes how\n",
      "to report benchmark results using the library. Section 4 describes the\n",
      "versioning system.\n",
      "\n",
      "    \n",
      "677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning takes advantage of large datasets and computationally efficient\n",
      "training algorithms to outperform other approaches at various machine learning\n",
      "tasks. However, imperfections in the training phase of deep neural networks\n",
      "make them vulnerable to adversarial samples: inputs crafted by adversaries with\n",
      "the intent of causing deep neural networks to misclassify. In this work, we\n",
      "formalize the space of adversaries against deep neural networks (DNNs) and\n",
      "introduce a novel class of algorithms to craft adversarial samples based on a\n",
      "precise understanding of the mapping between inputs and outputs of DNNs. In an\n",
      "application to computer vision, we show that our algorithms can reliably\n",
      "produce samples correctly classified by human subjects but misclassified in\n",
      "specific targets by a DNN with a 97% adversarial success rate while only\n",
      "modifying on average 4.02% of the input features per sample. We then evaluate\n",
      "the vulnerability of different sample classes to adversarial perturbations by\n",
      "defining a hardness measure. Finally, we describe preliminary work outlining\n",
      "defenses against adversarial samples by defining a predictive measure of\n",
      "distance between a benign input and a target classification.\n",
      "\n",
      "    \n",
      "678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Adversarial attacks to image classification systems present challenges to\n",
      "convolutional networks and opportunities for understanding them. This study\n",
      "suggests that adversarial perturbations on images lead to noise in the features\n",
      "constructed by these networks. Motivated by this observation, we develop new\n",
      "network architectures that increase adversarial robustness by performing\n",
      "feature denoising. Specifically, our networks contain blocks that denoise the\n",
      "features using non-local means or other filters; the entire networks are\n",
      "trained end-to-end. When combined with adversarial training, our feature\n",
      "denoising networks substantially improve the state-of-the-art in adversarial\n",
      "robustness in both white-box and black-box attack settings. On ImageNet, under\n",
      "10-iteration PGD white-box attacks where prior art has 27.9% accuracy, our\n",
      "method achieves 55.7%; even under extreme 2000-iteration PGD white-box attacks,\n",
      "our method secures 42.6% accuracy. Our method was ranked first in Competition\n",
      "on Adversarial Attacks and Defenses (CAAD) 2018 --- it achieved 50.6%\n",
      "classification accuracy on a secret, ImageNet-like test dataset against 48\n",
      "unknown attackers, surpassing the runner-up approach by ~10%. Code is available\n",
      "at this https URL.\n",
      "\n",
      "    \n",
      "679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper investigates strategies that defend against adversarial-example\n",
      "attacks on image-classification systems by transforming the inputs before\n",
      "feeding them to the system. Specifically, we study applying image\n",
      "transformations such as bit-depth reduction, JPEG compression, total variance\n",
      "minimization, and image quilting before feeding the image to a convolutional\n",
      "network classifier. Our experiments on ImageNet show that total variance\n",
      "minimization and image quilting are very effective defenses in practice, in\n",
      "particular, when the network is trained on transformed images. The strength of\n",
      "those defenses lies in their non-differentiable nature and their inherent\n",
      "randomness, which makes it difficult for an adversary to circumvent the\n",
      "defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong\n",
      "black-box attacks by a variety of major attack methods\n",
      "\n",
      "    \n",
      "680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  advertorch is a toolbox for adversarial robustness research. It contains\n",
      "various implementations for attacks, defenses and robust training methods.\n",
      "advertorch is built on PyTorch (Paszke et al., 2017), and leverages the\n",
      "advantages of the dynamic computational graph to provide concise and efficient\n",
      "reference implementations. The code is licensed under the LGPL license and is\n",
      "open sourced at this https URL .\n",
      "\n",
      "    \n",
      "681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has demonstrated that deep neural networks are vulnerable to\n",
      "adversarial examples---inputs that are almost indistinguishable from natural\n",
      "data and yet classified incorrectly by the network. In fact, some of the latest\n",
      "findings suggest that the existence of adversarial attacks may be an inherent\n",
      "weakness of deep learning models. To address this problem, we study the\n",
      "adversarial robustness of neural networks through the lens of robust\n",
      "optimization. This approach provides us with a broad and unifying view on much\n",
      "of the prior work on this topic. Its principled nature also enables us to\n",
      "identify methods for both training and attacking neural networks that are\n",
      "reliable and, in a certain sense, universal. In particular, they specify a\n",
      "concrete security guarantee that would protect against any adversary. These\n",
      "methods let us train networks with significantly improved resistance to a wide\n",
      "range of adversarial attacks. They also suggest the notion of security against\n",
      "a first-order adversary as a natural and broad security guarantee. We believe\n",
      "that robustness against such well-defined classes of adversaries is an\n",
      "important stepping stone towards fully resistant deep learning models. Code and\n",
      "pre-trained models are available at this https URL\n",
      "and this https URL.\n",
      "\n",
      "    \n",
      "682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we establish rigorous benchmarks for image classifier\n",
      "robustness. Our first benchmark, ImageNet-C, standardizes and expands the\n",
      "corruption robustness topic, while showing which classifiers are preferable in\n",
      "safety-critical applications. Then we propose a new dataset called ImageNet-P\n",
      "which enables researchers to benchmark a classifier's robustness to common\n",
      "perturbations. Unlike recent robustness research, this benchmark evaluates\n",
      "performance on common corruptions and perturbations not worst-case adversarial\n",
      "perturbations. We find that there are negligible changes in relative corruption\n",
      "robustness from AlexNet classifiers to ResNet classifiers. Afterward we\n",
      "discover ways to enhance corruption and perturbation robustness. We even find\n",
      "that a bypassed adversarial defense provides substantial common perturbation\n",
      "robustness. Together our benchmarks may aid future work toward networks that\n",
      "robustly generalize.\n",
      "\n",
      "    \n",
      "683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Correctly evaluating defenses against adversarial examples has proven to be\n",
      "extremely difficult. Despite the significant amount of recent work attempting\n",
      "to design defenses that withstand adaptive attacks, few have succeeded; most\n",
      "papers that propose defenses are quickly shown to be incorrect.\n",
      "We believe a large contributing factor is the difficulty of performing\n",
      "security evaluations. In this paper, we discuss the methodological foundations,\n",
      "review commonly accepted best practices, and suggest new methods for evaluating\n",
      "defenses to adversarial examples. We hope that both researchers developing\n",
      "defenses as well as readers and reviewers who wish to understand the\n",
      "completeness of an evaluation consider our advice in order to avoid common\n",
      "pitfalls.\n",
      "\n",
      "    \n",
      "684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a training system, which can provably defend significantly larger\n",
      "neural networks than previously possible, including ResNet-34 and DenseNet-100.\n",
      "Our approach is based on differentiable abstract interpretation and introduces\n",
      "two novel concepts: (i) abstract layers for fine-tuning the precision and\n",
      "scalability of the abstraction, (ii) a flexible domain specific language (DSL)\n",
      "for describing training objectives that combine abstract and concrete losses\n",
      "with arbitrary specifications. Our training method is implemented in the DiffAI\n",
      "system.\n",
      "\n",
      "    \n",
      "685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural networks are vulnerable to adversarial examples, which poses a threat\n",
      "to their application in security sensitive systems. We propose high-level\n",
      "representation guided denoiser (HGD) as a defense for image classification.\n",
      "Standard denoiser suffers from the error amplification effect, in which small\n",
      "residual adversarial noise is progressively amplified and leads to wrong\n",
      "classifications. HGD overcomes this problem by using a loss function defined as\n",
      "the difference between the target model's outputs activated by the clean image\n",
      "and denoised image. Compared with ensemble adversarial training which is the\n",
      "state-of-the-art defending method on large images, HGD has three advantages.\n",
      "First, with HGD as a defense, the target model is more robust to either\n",
      "white-box or black-box adversarial attacks. Second, HGD can be trained on a\n",
      "small subset of the images and generalizes well to other images and unseen\n",
      "classes. Third, HGD can be transferred to defend models other than the one\n",
      "guiding it. In NIPS competition on defense against adversarial attacks, our HGD\n",
      "solution won the first place and outperformed other models by a large margin.\n",
      "\n",
      "    \n",
      "686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural architectures are the foundation for improving performance of deep\n",
      "neural networks (DNNs). This paper presents deep compositional grammatical\n",
      "architectures which harness the best of two worlds: grammar models and DNNs.\n",
      "The proposed architectures integrate compositionality and reconfigurability of\n",
      "the former and the capability of learning rich features of the latter in a\n",
      "principled way. We utilize AND-OR Grammar (AOG) as network generator in this\n",
      "paper and call the resulting networks AOGNets. An AOGNet consists of a number\n",
      "of stages each of which is composed of a number of AOG building blocks. An AOG\n",
      "building block splits its input feature map into N groups along feature\n",
      "channels and then treat it as a sentence of N words. It then jointly realizes a\n",
      "phrase structure grammar and a dependency grammar in bottom-up parsing the\n",
      "\"sentence\" for better feature exploration and reuse. It provides a unified\n",
      "framework for the best practices developed in state-of-the-art DNNs. In\n",
      "experiments, AOGNet is tested in the CIFAR-10, CIFAR-100 and ImageNet-1K\n",
      "classification benchmark and the MS-COCO object detection and segmentation\n",
      "benchmark. In CIFAR-10, CIFAR-100 and ImageNet-1K, AOGNet obtains better\n",
      "performance than ResNet and most of its variants, ResNeXt and its attention\n",
      "based variants such as SENet, DenseNet and DualPathNet. AOGNet also obtains the\n",
      "best model interpretability score using network dissection. AOGNet further\n",
      "shows better potential in adversarial defense. In MS-COCO, AOGNet obtains\n",
      "better performance than the ResNet and ResNeXt backbones in Mask R-CNN.\n",
      "\n",
      "    \n",
      "687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent works have shown the effectiveness of randomized smoothing as a\n",
      "scalable technique for building neural network-based classifiers that are\n",
      "provably robust to $\\ell_2$-norm adversarial perturbations. In this paper, we\n",
      "employ adversarial training to improve the performance of randomized smoothing.\n",
      "We design an adapted attack for smoothed classifiers, and we show how this\n",
      "attack can be used in an adversarial training setting to boost the provable\n",
      "robustness of smoothed classifiers. We demonstrate through extensive\n",
      "experimentation that our method consistently outperforms all existing provably\n",
      "$\\ell_2$-robust classifiers by a significant margin on ImageNet and CIFAR-10,\n",
      "establishing the state-of-the-art for provable $\\ell_2$-defenses. Moreover, we\n",
      "find that pre-training and semi-supervised learning boost adversarially trained\n",
      "smoothed classifiers even further. Our code and trained models are available at\n",
      "this http URL .\n",
      "\n",
      "    \n",
      "688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We identify a trade-off between robustness and accuracy that serves as a\n",
      "guiding principle in the design of defenses against adversarial examples.\n",
      "Although this problem has been widely studied empirically, much remains unknown\n",
      "concerning the theory underlying this trade-off. In this work, we decompose the\n",
      "prediction error for adversarial examples (robust error) as the sum of the\n",
      "natural (classification) error and boundary error, and provide a differentiable\n",
      "upper bound using the theory of classification-calibrated loss, which is shown\n",
      "to be the tightest possible upper bound uniform over all probability\n",
      "distributions and measurable predictors. Inspired by our theoretical analysis,\n",
      "we also design a new defense method, TRADES, to trade adversarial robustness\n",
      "off against accuracy. Our proposed algorithm performs well experimentally in\n",
      "real-world datasets. The methodology is the foundation of our entry to the\n",
      "NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of\n",
      "~2,000 submissions, surpassing the runner-up approach by $11.41\\%$ in terms of\n",
      "mean $\\ell_2$ perturbation distance.\n",
      "\n",
      "    \n",
      "689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning achieves state-of-the-art results in many tasks in computer\n",
      "vision and natural language processing. However, recent works have shown that\n",
      "deep networks can be vulnerable to adversarial perturbations, which raised a\n",
      "serious robustness issue of deep networks. Adversarial training, typically\n",
      "formulated as a robust optimization problem, is an effective way of improving\n",
      "the robustness of deep networks. A major drawback of existing adversarial\n",
      "training algorithms is the computational overhead of the generation of\n",
      "adversarial examples, typically far greater than that of the network training.\n",
      "This leads to the unbearable overall computational cost of adversarial\n",
      "training. In this paper, we show that adversarial training can be cast as a\n",
      "discrete time differential game. Through analyzing the Pontryagin's Maximal\n",
      "Principle (PMP) of the problem, we observe that the adversary update is only\n",
      "coupled with the parameters of the first layer of the network. This inspires us\n",
      "to restrict most of the forward and back propagation within the first layer of\n",
      "the network during adversary updates. This effectively reduces the total number\n",
      "of full forward and backward propagation to only one for each group of\n",
      "adversary updates. Therefore, we refer to this algorithm YOPO (You Only\n",
      "Propagate Once). Numerical experiments demonstrate that YOPO can achieve\n",
      "comparable defense accuracy with approximately 1/5 ~ 1/4 GPU time of the\n",
      "projected gradient descent (PGD) algorithm. Our codes are available at\n",
      "https://https://github.com/a1600012888/YOPO-You-Only-Propagate-Once.\n",
      "\n",
      "    \n",
      "690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Adversarial training, in which a network is trained on adversarial examples,\n",
      "is one of the few defenses against adversarial attacks that withstands strong\n",
      "attacks. Unfortunately, the high cost of generating strong adversarial examples\n",
      "makes standard adversarial training impractical on large-scale problems like\n",
      "ImageNet. We present an algorithm that eliminates the overhead cost of\n",
      "generating adversarial examples by recycling the gradient information computed\n",
      "when updating model parameters. Our \"free\" adversarial training algorithm\n",
      "achieves state-of-the-art robustness on CIFAR-10 and CIFAR-100 datasets at\n",
      "negligible additional cost compared to natural training, and can be 7 to 30\n",
      "times faster than other strong adversarial training methods. Using a single\n",
      "workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model\n",
      "for the large-scale ImageNet classification task that maintains 40% accuracy\n",
      "against PGD attacks.\n",
      "\n",
      "    \n",
      "691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'paperswithcode.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is pdf\n",
      "692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent studies have shown that attackers can force deep learning models to\n",
      "misclassify so-called \"adversarial examples\": maliciously generated images\n",
      "formed by making imperceptible modifications to pixel values. With growing\n",
      "interest in deep learning for security applications, it is important for\n",
      "security experts and users of machine learning to recognize how learning\n",
      "systems may be attacked. Due to the complex nature of deep learning, it is\n",
      "challenging to understand how deep models can be fooled by adversarial\n",
      "examples. Thus, we present a web-based visualization tool,\n",
      "Adversarial-Playground, to demonstrate the efficacy of common adversarial\n",
      "methods against a convolutional neural network (CNN) system.\n",
      "Adversarial-Playground is educational, modular and interactive. (1) It enables\n",
      "non-experts to compare examples visually and to understand why an adversarial\n",
      "example can fool a CNN-based image classifier. (2) It can help security experts\n",
      "explore more vulnerability of deep learning as a software module. (3) Building\n",
      "an interactive visualization is challenging in this domain due to the large\n",
      "feature space of image classification (generating adversarial examples is slow\n",
      "in general and visualizing images are costly). Through multiple novel design\n",
      "choices, our tool can provide fast and accurate responses to user requests.\n",
      "Empirically, we find that our client-server division strategy reduced the\n",
      "response time by an average of 1.5 seconds per sample. Our other innovation, a\n",
      "faster variant of JSMA evasion algorithm, empirically performed twice as fast\n",
      "as JSMA and yet maintains a comparable evasion rate.\n",
      "Project source code and data from our experiments available at:\n",
      "this https URL\n",
      "\n",
      "693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We show how to turn any classifier that classifies well under Gaussian noise\n",
      "into a new classifier that is certifiably robust to adversarial perturbations\n",
      "under the $\\ell_2$ norm. This \"randomized smoothing\" technique has been\n",
      "proposed recently in the literature, but existing guarantees are loose. We\n",
      "prove a tight robustness guarantee in $\\ell_2$ norm for smoothing with Gaussian\n",
      "noise. We use randomized smoothing to obtain an ImageNet classifier with e.g. a\n",
      "certified top-1 accuracy of 49% under adversarial perturbations with $\\ell_2$\n",
      "norm less than 0.5 (=127/255). No certified defense has been shown feasible on\n",
      "ImageNet except for smoothing. On smaller-scale datasets where competing\n",
      "approaches to certified $\\ell_2$ robustness are viable, smoothing delivers\n",
      "higher certified accuracies. Our strong empirical results suggest that\n",
      "randomized smoothing is a promising direction for future research into\n",
      "adversarially robust classification. Code and models are available at\n",
      "this http URL.\n",
      "\n",
      "    \n",
      "694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we establish rigorous benchmarks for image classifier\n",
      "robustness. Our first benchmark, ImageNet-C, standardizes and expands the\n",
      "corruption robustness topic, while showing which classifiers are preferable in\n",
      "safety-critical applications. Unlike recent robustness research, this benchmark\n",
      "evaluates performance on commonplace corruptions not worst-case adversarial\n",
      "corruptions. We find that there are negligible changes in relative corruption\n",
      "robustness from AlexNet to ResNet classifiers, and we discover ways to enhance\n",
      "corruption robustness. Then we propose a new dataset called Icons-50 which\n",
      "opens research on a new kind of robustness, surface variation robustness. With\n",
      "this dataset we evaluate the frailty of classifiers on new styles of known\n",
      "objects and unexpected instances of known classes. We also demonstrate two\n",
      "methods that improve surface variation robustness. Together our benchmarks may\n",
      "aid future work toward networks that learn fundamental class structure and also\n",
      "robustly generalize.\n",
      "\n",
      "    \n",
      "695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks (DNNs) are one of the most prominent technologies of our\n",
      "time, as they achieve state-of-the-art performance in many machine learning\n",
      "tasks, including but not limited to image classification, text mining, and\n",
      "speech processing. However, recent research on DNNs has indicated\n",
      "ever-increasing concern on the robustness to adversarial examples, especially\n",
      "for security-critical tasks such as traffic sign identification for autonomous\n",
      "driving. Studies have unveiled the vulnerability of a well-trained DNN by\n",
      "demonstrating the ability of generating barely noticeable (to both human and\n",
      "machines) adversarial images that lead to misclassification. Furthermore,\n",
      "researchers have shown that these adversarial images are highly transferable by\n",
      "simply training and attacking a substitute model built upon the target model,\n",
      "known as a black-box attack to DNNs.\n",
      "Similar to the setting of training substitute models, in this paper we\n",
      "propose an effective black-box attack that also only has access to the input\n",
      "(images) and the output (confidence scores) of a targeted DNN. However,\n",
      "different from leveraging attack transferability from substitute models, we\n",
      "propose zeroth order optimization (ZOO) based attacks to directly estimate the\n",
      "gradients of the targeted DNN for generating adversarial examples. We use\n",
      "zeroth order stochastic coordinate descent along with dimension reduction,\n",
      "hierarchical attack and importance sampling techniques to efficiently attack\n",
      "black-box models. By exploiting zeroth order optimization, improved attacks to\n",
      "the targeted DNN can be accomplished, sparing the need for training substitute\n",
      "models and avoiding the loss in attack transferability. Experimental results on\n",
      "MNIST, CIFAR10 and ImageNet show that the proposed ZOO attack is as effective\n",
      "as the state-of-the-art white-box attack and significantly outperforms existing\n",
      "black-box attacks via substitute models.\n",
      "\n",
      "    \n",
      "696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional neural networks have demonstrated high accuracy on various\n",
      "tasks in recent years. However, they are extremely vulnerable to adversarial\n",
      "examples. For example, imperceptible perturbations added to clean images can\n",
      "cause convolutional neural networks to fail. In this paper, we propose to\n",
      "utilize randomization at inference time to mitigate adversarial effects.\n",
      "Specifically, we use two randomization operations: random resizing, which\n",
      "resizes the input images to a random size, and random padding, which pads zeros\n",
      "around the input images in a random manner. Extensive experiments demonstrate\n",
      "that the proposed randomization method is very effective at defending against\n",
      "both single-step and iterative attacks. Our method provides the following\n",
      "advantages: 1) no additional training or fine-tuning, 2) very few additional\n",
      "computations, 3) compatible with other adversarial defense methods. By\n",
      "combining the proposed randomization method with an adversarially trained\n",
      "model, it achieves a normalized score of 0.924 (ranked No.2 among 107 defense\n",
      "teams) in the NIPS 2017 adversarial examples defense challenge, which is far\n",
      "better than using adversarial training alone with a normalized score of 0.773\n",
      "(ranked No.56). The code is public available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While neural networks have achieved high accuracy on standard image\n",
      "classification benchmarks, their accuracy drops to nearly zero in the presence\n",
      "of small adversarial perturbations to test inputs. Defenses based on\n",
      "regularization and adversarial training have been proposed, but often followed\n",
      "by new, stronger attacks that defeat these defenses. Can we somehow end this\n",
      "arms race? In this work, we study this problem for neural networks with one\n",
      "hidden layer. We first propose a method based on a semidefinite relaxation that\n",
      "outputs a certificate that for a given network and test input, no attack can\n",
      "force the error to exceed a certain value. Second, as this certificate is\n",
      "differentiable, we jointly optimize it with the network parameters, providing\n",
      "an adaptive regularizer that encourages robustness against all attacks. On\n",
      "MNIST, our approach produces a network and a certificate that no attack that\n",
      "perturbs each pixel by at most \\epsilon = 0.1 can cause more than 35% test\n",
      "error.\n",
      "\n",
      "    \n",
      "698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Neural Networks (DNNs) have recently been shown to be vulnerable against\n",
      "adversarial examples, which are carefully crafted instances that can mislead\n",
      "DNNs to make errors during prediction. To better understand such attacks, a\n",
      "characterization is needed of the properties of regions (the so-called\n",
      "'adversarial subspaces') in which adversarial examples lie. We tackle this\n",
      "challenge by characterizing the dimensional properties of adversarial regions,\n",
      "via the use of Local Intrinsic Dimensionality (LID). LID assesses the\n",
      "space-filling capability of the region surrounding a reference example, based\n",
      "on the distance distribution of the example to its neighbors. We first provide\n",
      "explanations about how adversarial perturbation can affect the LID\n",
      "characteristic of adversarial regions, and then show empirically that LID\n",
      "characteristics can facilitate the distinction of adversarial examples\n",
      "generated using state-of-the-art attacks. As a proof-of-concept, we show that a\n",
      "potential application of LID is to distinguish adversarial examples, and the\n",
      "preliminary results show that it can outperform several state-of-the-art\n",
      "detection measures by large margins for five attack strategies considered in\n",
      "this paper across three benchmark datasets. Our analysis of the LID\n",
      "characteristic for adversarial regions not only motivates new directions of\n",
      "effective adversarial defense, but also opens up more challenges for developing\n",
      "new attacks to better understand the vulnerabilities of DNNs.\n",
      "\n",
      "    \n",
      "699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A rapidly growing area of work has studied the existence of adversarial\n",
      "examples, datapoints which have been perturbed to fool a classifier, but the\n",
      "vast majority of these works have focused primarily on threat models defined by\n",
      "$\\ell_p$ norm-bounded perturbations. In this paper, we propose a new threat\n",
      "model for adversarial attacks based on the Wasserstein distance. In the image\n",
      "classification setting, such distances measure the cost of moving pixel mass,\n",
      "which naturally cover \"standard\" image manipulations such as scaling, rotation,\n",
      "translation, and distortion (and can potentially be applied to other settings\n",
      "as well). To generate Wasserstein adversarial examples, we develop a procedure\n",
      "for projecting onto the Wasserstein ball, based upon a modified version of the\n",
      "Sinkhorn iteration. The resulting algorithm can successfully attack image\n",
      "classification models, bringing traditional CIFAR10 models down to 3% accuracy\n",
      "within a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1\n",
      "pixel), and we demonstrate that PGD-based adversarial training can improve this\n",
      "adversarial accuracy to 76%. In total, this work opens up a new direction of\n",
      "study in adversarial robustness, more formally considering convex metrics that\n",
      "accurately capture the invariances that we typically believe should exist in\n",
      "classifiers. Code for all experiments in the paper is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Considerable work on adversarial defense has studied robustness to a fixed,\n",
      "known family of adversarial distortions, most frequently L_p-bounded\n",
      "distortions. In reality, the specific form of attack will rarely be known and\n",
      "adversaries are free to employ distortions outside of any fixed set. The\n",
      "present work advocates measuring robustness against this much broader range of\n",
      "unforeseen attacks---attacks whose precise form is not known when designing a\n",
      "defense.\n",
      "We propose a methodology for evaluating a defense against a diverse range of\n",
      "distortion types together with a summary metric UAR that measures the\n",
      "Unforeseen Attack Robustness against a distortion. We construct novel JPEG,\n",
      "Fog, Gabor, and Snow adversarial attacks to simulate unforeseen adversaries and\n",
      "perform a careful study of adversarial robustness against these and existing\n",
      "distortion types. We find that evaluation against existing L_p attacks yields\n",
      "highly correlated information that may not generalize to other attacks and\n",
      "identify a set of 4 attacks that yields more diverse information. We further\n",
      "find that adversarial training against either one or multiple distortions,\n",
      "including our novel ones, does not confer robustness to unforeseen distortions.\n",
      "These results underscore the need to study robustness against unforeseen\n",
      "distortions and provide a starting point for doing so.\n",
      "\n",
      "    \n",
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks have achieved significant success across\n",
      "multiple computer vision tasks. However, they are vulnerable to carefully\n",
      "crafted, human-imperceptible adversarial noise patterns which constrain their\n",
      "deployment in critical security-sensitive systems. This paper proposes a\n",
      "computationally efficient image enhancement approach that provides a strong\n",
      "defense mechanism to effectively mitigate the effect of such adversarial\n",
      "perturbations. We show that deep image restoration networks learn mapping\n",
      "functions that can bring off-the-manifold adversarial samples onto the natural\n",
      "image manifold, thus restoring classification towards correct classes. A\n",
      "distinguishing feature of our approach is that, in addition to providing\n",
      "robustness against attacks, it simultaneously enhances image quality and\n",
      "retains models performance on clean images. Furthermore, the proposed method\n",
      "does not modify the classifier or requires a separate mechanism to detect\n",
      "adversarial images. The effectiveness of the scheme has been demonstrated\n",
      "through extensive experiments, where it has proven a strong defense in gray-box\n",
      "settings. The proposed scheme is simple and has the following advantages: (1)\n",
      "it does not require any model training or parameter optimization, (2) it\n",
      "complements other existing defense mechanisms, (3) it is agnostic to the\n",
      "attacked model and attack type and (4) it provides superior performance across\n",
      "all popular attack algorithms. Our codes are publicly available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks have achieved impressive experimental results in image\n",
      "classification, but can surprisingly be unstable with respect to adversarial\n",
      "perturbations, that is, minimal changes to the input image that cause the\n",
      "network to misclassify it. With potential applications including perception\n",
      "modules and end-to-end controllers for self-driving cars, this raises concerns\n",
      "about their safety. We develop a novel automated verification framework for\n",
      "feed-forward multi-layer neural networks based on Satisfiability Modulo Theory\n",
      "(SMT). We focus on safety of image classification decisions with respect to\n",
      "image manipulations, such as scratches or changes to camera angle or lighting\n",
      "conditions that would result in the same class being assigned by a human, and\n",
      "define safety for an individual decision in terms of invariance of the\n",
      "classification within a small neighbourhood of the original image. We enable\n",
      "exhaustive search of the region by employing discretisation, and propagate the\n",
      "analysis layer by layer. Our method works directly with the network code and,\n",
      "in contrast to existing methods, can guarantee that adversarial examples, if\n",
      "they exist, are found for the given region and family of manipulations. If\n",
      "found, adversarial examples can be shown to human testers and/or used to\n",
      "fine-tune the network. We implement the techniques using Z3 and evaluate them\n",
      "on state-of-the-art networks, including regularised and deep learning networks.\n",
      "We also compare against existing techniques to search for adversarial examples\n",
      "and estimate network robustness.\n",
      "\n",
      "    \n",
      "703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  An intriguing property of deep neural networks is the existence of\n",
      "adversarial examples, which can transfer among different architectures. These\n",
      "transferable adversarial examples may severely hinder deep neural network-based\n",
      "applications. Previous works mostly study the transferability using small scale\n",
      "datasets. In this work, we are the first to conduct an extensive study of the\n",
      "transferability over large models and a large scale dataset, and we are also\n",
      "the first to study the transferability of targeted adversarial examples with\n",
      "their target labels. We study both non-targeted and targeted adversarial\n",
      "examples, and show that while transferable non-targeted adversarial examples\n",
      "are easy to find, targeted adversarial examples generated using existing\n",
      "approaches almost never transfer with their target labels. Therefore, we\n",
      "propose novel ensemble-based approaches to generating transferable adversarial\n",
      "examples. Using such approaches, we observe a large proportion of targeted\n",
      "adversarial examples that are able to transfer with their target labels for the\n",
      "first time. We also present some geometric studies to help understanding the\n",
      "transferable adversarial examples. Finally, we show that the adversarial\n",
      "examples generated using ensemble-based approaches can successfully attack\n",
      "this http URL, which is a black-box image classification system.\n",
      "\n",
      "    \n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Adversarial robustness has emerged as an important topic in deep learning as\n",
      "carefully crafted attack samples can significantly disturb the performance of a\n",
      "model. Many recent methods have proposed to improve adversarial robustness by\n",
      "utilizing adversarial training or model distillation, which adds additional\n",
      "procedures to model training. In this paper, we propose a new training paradigm\n",
      "called Guided Complement Entropy (GCE) that is capable of achieving\n",
      "\"adversarial defense for free,\" which involves no additional procedures in the\n",
      "process of improving adversarial robustness. In addition to maximizing model\n",
      "probabilities on the ground-truth class like cross-entropy, we neutralize its\n",
      "probabilities on the incorrect classes along with a \"guided\" term to balance\n",
      "between these two terms. We show in the experiments that our method achieves\n",
      "better model robustness with even better performance compared to the commonly\n",
      "used cross-entropy training objective. We also show that our method can be used\n",
      "orthogonal to adversarial training across well-known methods with noticeable\n",
      "robustness gain. To the best of our knowledge, our approach is the first one\n",
      "that improves model robustness without compromising performance.\n",
      "\n",
      "    \n",
      "705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Although adversarial examples and model robustness have been extensively\n",
      "studied in the context of linear models and neural networks, research on this\n",
      "issue in tree-based models and how to make tree-based models robust against\n",
      "adversarial examples is still limited. In this paper, we show that tree based\n",
      "models are also vulnerable to adversarial examples and develop a novel\n",
      "algorithm to learn robust trees. At its core, our method aims to optimize the\n",
      "performance under the worst-case perturbation of input features, which leads to\n",
      "a max-min saddle point problem. Incorporating this saddle point objective into\n",
      "the decision tree building procedure is non-trivial due to the discrete nature\n",
      "of trees --- a naive approach to finding the best split according to this\n",
      "saddle point objective will take exponential time. To make our approach\n",
      "practical and scalable, we propose efficient tree building algorithms by\n",
      "approximating the inner minimizer in this saddle point problem, and present\n",
      "efficient implementations for classical information gain based trees as well as\n",
      "state-of-the-art tree boosting models such as XGBoost. Experimental results on\n",
      "real world datasets demonstrate that the proposed algorithms can substantially\n",
      "improve the robustness of tree-based models against adversarial examples.\n",
      "\n",
      "    \n",
      "706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural networks are increasingly deployed in real-world safety-critical\n",
      "domains such as autonomous driving, aircraft collision avoidance, and malware\n",
      "detection. However, these networks have been shown to often mispredict on\n",
      "inputs with minor adversarial or even accidental perturbations. Consequences of\n",
      "such errors can be disastrous and even potentially fatal as shown by the recent\n",
      "Tesla autopilot crash. Thus, there is an urgent need for formal analysis\n",
      "systems that can rigorously check neural networks for violations of different\n",
      "safety properties such as robustness against adversarial perturbations within a\n",
      "certain $L$-norm of a given image. An effective safety analysis system for a\n",
      "neural network must be able to either ensure that a safety property is\n",
      "satisfied by the network or find a counterexample, i.e., an input for which the\n",
      "network will violate the property. Unfortunately, most existing techniques for\n",
      "performing such analysis struggle to scale beyond very small networks and the\n",
      "ones that can scale to larger networks suffer from high false positives and\n",
      "cannot produce concrete counterexamples in case of a property violation. In\n",
      "this paper, we present a new efficient approach for rigorously checking\n",
      "different safety properties of neural networks that significantly outperforms\n",
      "existing approaches by multiple orders of magnitude. Our approach can check\n",
      "different safety properties and find concrete counterexamples for networks that\n",
      "are 10$\\times$ larger than the ones supported by existing analysis techniques.\n",
      "We believe that our approach to estimating tight output bounds of a network for\n",
      "a given input range can also help improve the explainability of neural networks\n",
      "and guide the training process of more robust neural networks.\n",
      "\n",
      "    \n",
      "707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks are vulnerable to adversarial attacks, which can fool\n",
      "them by adding minuscule perturbations to the input images. The robustness of\n",
      "existing defenses suffers greatly under white-box attack settings, where an\n",
      "adversary has full knowledge about the network and can iterate several times to\n",
      "find strong perturbations. We observe that the main reason for the existence of\n",
      "such perturbations is the close proximity of different class samples in the\n",
      "learned feature space. This allows model decisions to be totally changed by\n",
      "adding an imperceptible perturbation in the inputs. To counter this, we propose\n",
      "to class-wise disentangle the intermediate feature representations of deep\n",
      "networks. Specifically, we force the features for each class to lie inside a\n",
      "convex polytope that is maximally separated from the polytopes of other\n",
      "classes. In this manner, the network is forced to learn distinct and distant\n",
      "decision regions for each class. We observe that this simple constraint on the\n",
      "features greatly enhances the robustness of learned models, even against the\n",
      "strongest white-box attacks, without degrading the classification performance\n",
      "on clean images. We report extensive evaluations in both black-box and\n",
      "white-box attack scenarios and show significant gains in comparison to\n",
      "state-of-the art defenses.\n",
      "\n",
      "    \n",
      "708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this work we revisit gradient regularization for adversarial robustness\n",
      "with some new ingredients. First, we derive new per-image theoretical\n",
      "robustness bounds based on local gradient information. These bounds strongly\n",
      "motivate input gradient regularization. Second, we implement a scaleable\n",
      "version of input gradient regularization which avoids double backpropagation:\n",
      "adversarially robust ImageNet models are trained in 33 hours on four consumer\n",
      "grade GPUs. Finally, we show experimentally and through theoretical\n",
      "certification that input gradient regularization is competitive with\n",
      "adversarial training. Moreover we demonstrate that gradient regularization does\n",
      "not lead to gradient obfuscation or gradient masking.\n",
      "\n",
      "    \n",
      "709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Adversarial examples have received a great deal of recent attention because\n",
      "of their potential to uncover security flaws in machine learning systems.\n",
      "However, most prior work on adversarial examples has been on parametric\n",
      "classifiers, for which generic attack and defense methods are known;\n",
      "non-parametric methods have been only considered on an ad-hoc or\n",
      "classifier-specific basis. In this work, we take a holistic look at adversarial\n",
      "examples for non-parametric methods. We first provide a general region-based\n",
      "attack that applies to a wide range of classifiers, including nearest\n",
      "neighbors, decision trees, and random forests. Motivated by the close\n",
      "connection between non-parametric methods and the Bayes Optimal classifier, we\n",
      "next exhibit a robust analogue to the Bayes Optimal, and we use it to motivate\n",
      "a novel and generic defense that we call adversarial pruning. We empirically\n",
      "show that the region-based attack and adversarial pruning defense are either\n",
      "better than or competitive with existing attacks and defenses for\n",
      "non-parametric methods, while being considerably more generally applicable.\n",
      "\n",
      "    \n",
      "710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent works show that deep neural networks trained on image classification\n",
      "dataset bias towards textures. Those models are easily fooled by applying small\n",
      "high-frequency perturbations to clean images. In this paper, we learn robust\n",
      "image classification models by removing high-frequency components.\n",
      "Specifically, we develop a differentiable high-frequency suppression module\n",
      "based on discrete Fourier transform (DFT). Combining with adversarial training,\n",
      "we won the 5th place in the IJCAI-2019 Alibaba Adversarial AI Challenge. Our\n",
      "code is available online.\n",
      "\n",
      "    \n",
      "711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The arms race between attacks and defenses for machine learning models has\n",
      "come to a forefront in recent years, in both the security community and the\n",
      "privacy community. However, one big limitation of previous research is that the\n",
      "security domain and the privacy domain have typically been considered\n",
      "separately. It is thus unclear whether the defense methods in one domain will\n",
      "have any unexpected impact on the other domain.\n",
      "In this paper, we take a step towards resolving this limitation by combining\n",
      "the two domains. In particular, we measure the success of membership inference\n",
      "attacks against six state-of-the-art defense methods that mitigate the risk of\n",
      "adversarial examples (i.e., evasion attacks). Membership inference attacks\n",
      "determine whether or not an individual data record has been part of a model's\n",
      "training set. The accuracy of such attacks reflects the information leakage of\n",
      "training algorithms about individual members of the training set. Adversarial\n",
      "defense methods against adversarial examples influence the model's decision\n",
      "boundaries such that model predictions remain unchanged for a small area around\n",
      "each input. However, this objective is optimized on training data. Thus,\n",
      "individual data records in the training set have a significant influence on\n",
      "robust models. This makes the models more vulnerable to inference attacks.\n",
      "To perform the membership inference attacks, we leverage the existing\n",
      "inference methods that exploit model predictions. We also propose two new\n",
      "inference methods that exploit structural properties of robust models on\n",
      "adversarially perturbed data. Our experimental evaluation demonstrates that\n",
      "compared with the natural training (undefended) approach, adversarial defense\n",
      "methods can indeed increase the target model's risk against membership\n",
      "inference attacks.\n",
      "\n",
      "    \n",
      "712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite the improved accuracy of deep neural networks, the discovery of\n",
      "adversarial examples has raised serious safety concerns. In this paper, we\n",
      "study two variants of pointwise robustness, the maximum safe radius problem,\n",
      "which for a given input sample computes the minimum distance to an adversarial\n",
      "example, and the feature robustness problem, which aims to quantify the\n",
      "robustness of individual features to adversarial perturbations. We demonstrate\n",
      "that, under the assumption of Lipschitz continuity, both problems can be\n",
      "approximated using finite optimisation by discretising the input space, and the\n",
      "approximation has provable guarantees, i.e., the error is bounded. We then show\n",
      "that the resulting optimisation problems can be reduced to the solution of\n",
      "two-player turn-based games, where the first player selects features and the\n",
      "second perturbs the image within the feature. While the second player aims to\n",
      "minimise the distance to an adversarial example, depending on the optimisation\n",
      "objective the first player can be cooperative or competitive. We employ an\n",
      "anytime approach to solve the games, in the sense of approximating the value of\n",
      "a game by monotonically improving its upper and lower bounds. The Monte Carlo\n",
      "tree search algorithm is applied to compute upper bounds for both games, and\n",
      "the Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used\n",
      "to compute lower bounds for the maximum safety radius and feature robustness\n",
      "games. When working on the upper bound of the maximum safe radius problem, our\n",
      "tool demonstrates competitive performance against existing adversarial example\n",
      "crafting algorithms. Furthermore, we show how our framework can be deployed to\n",
      "evaluate pointwise robustness of neural networks in safety-critical\n",
      "applications such as traffic sign recognition in self-driving cars.\n",
      "\n",
      "    \n",
      "713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Empirical adversarial risk minimization (EARM) is a widely used mathematical\n",
      "framework to robustly train deep neural nets (DNNs) that are resistant to\n",
      "adversarial attacks. However, both natural and robust accuracies, in\n",
      "classifying clean and adversarial images, respectively, of the trained robust\n",
      "models are far from satisfactory. In this work, we unify the theory of optimal\n",
      "control of transport equations with the practice of training and testing of\n",
      "ResNets. Based on this unified viewpoint, we propose a simple yet effective\n",
      "ResNets ensemble algorithm to boost the accuracy of the robustly trained model\n",
      "on both clean and adversarial images. The proposed algorithm consists of two\n",
      "components: First, we modify the base ResNets by injecting a variance specified\n",
      "Gaussian noise to the output of each residual mapping. Second, we average over\n",
      "the production of multiple jointly trained modified ResNets to get the final\n",
      "prediction. These two steps give an approximation to the Feynman-Kac formula\n",
      "for representing the solution of a transport equation with viscosity, or a\n",
      "convection-diffusion equation. For the CIFAR10 benchmark, this simple algorithm\n",
      "leads to a robust model with a natural accuracy of {\\bf 85.62}\\% on clean\n",
      "images and a robust accuracy of ${\\bf 57.94 \\%}$ under the 20 iterations of the\n",
      "IFGSM attack, which outperforms the current state-of-the-art in defending\n",
      "against IFGSM attack on the CIFAR10. Both natural and robust accuracies of the\n",
      "proposed ResNets ensemble can be improved dynamically as the building block\n",
      "ResNet advances. The code is available at:\n",
      "\\url{this https URL}.\n",
      "\n",
      "    \n",
      "714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks are known to be vulnerable to adversarial attacks. This\n",
      "exposes them to potential exploits in security-sensitive applications and\n",
      "highlights their lack of robustness. This paper uses a variational auto-encoder\n",
      "(VAE) to defend against adversarial attacks for image classification tasks.\n",
      "This VAE defense has a few nice properties: (1) it is quite flexible and its\n",
      "use of randomness makes it harder to attack; (2) it can learn disentangled\n",
      "representations that prevent blurry reconstruction; and (3) a patch-wise VAE\n",
      "defense strategy is used that does not require retraining for different size\n",
      "images. For moderate to severe attacks, this system outperforms or closely\n",
      "matches the performance of JPEG compression, with the best quality parameter.\n",
      "It also has more flexibility and potential for improvement via training.\n",
      "\n",
      "    \n",
      "715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a modern scalable reinforcement learning agent called SEED\n",
      "(Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we\n",
      "show that it is not only possible to train on millions of frames per second but\n",
      "also to lower the cost of experiments compared to current methods. We achieve\n",
      "this with a simple architecture that features centralized inference and an\n",
      "optimized communication layer. SEED adopts two state of the art distributed\n",
      "algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is\n",
      "evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve\n",
      "the state of the art on Football and are able to reach state of the art on\n",
      "Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to\n",
      "80% cost reduction for running experiments is achieved. The implementation\n",
      "along with experiments is open-sourced so that results can be reproduced and\n",
      "novel ideas tried out.\n",
      "\n",
      "    \n",
      "716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a simple yet effective end-to-end trainable deep network with\n",
      "geometry-inspired convolutional operators for detecting vanishing points in\n",
      "images. Traditional convolutional neural networks rely on aggregating edge\n",
      "features and do not have mechanisms to directly exploit the geometric\n",
      "properties of vanishing points as the intersections of parallel lines. In this\n",
      "work, we identify a canonical conic space in which the neural network can\n",
      "effectively compute the global geometric information of vanishing points\n",
      "locally, and we propose a novel operator named conic convolution that can be\n",
      "implemented as regular convolutions in this space. This new operator explicitly\n",
      "enforces feature extractions and aggregations along the structural lines and\n",
      "yet has the same number of parameters as the regular 2D convolution. Our\n",
      "extensive experiments on both synthetic and real-world datasets show that the\n",
      "proposed operator significantly improves the performance of vanishing point\n",
      "detection over traditional methods. The code and dataset have been made\n",
      "publicly available at this https URL.\n",
      "\n",
      "    \n",
      "717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent studies proved that deep learning approaches achieve remarkable\n",
      "results on face detection task. On the other hand, the advances gave rise to a\n",
      "new problem associated with the security of the deep convolutional neural\n",
      "network models unveiling potential risks of DCNNs based applications. Even\n",
      "minor input changes in the digital domain can result in the network being\n",
      "fooled. It was shown then that some deep learning-based face detectors are\n",
      "prone to adversarial attacks not only in a digital domain but also in the real\n",
      "world. In the paper, we investigate the security of the well-known cascade CNN\n",
      "face detection system - MTCNN and introduce an easily reproducible and a robust\n",
      "way to attack it. We propose different face attributes printed on an ordinary\n",
      "white and black printer and attached either to the medical face mask or to the\n",
      "face directly. Our approach is capable of breaking the MTCNN detector in a\n",
      "real-world scenario.\n",
      "\n",
      "    \n",
      "718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Pedestrian detection relying on deep convolution neural networks has made\n",
      "significant progress. Though promising results have been achieved on standard\n",
      "pedestrians, the performance on heavily occluded pedestrians remains far from\n",
      "satisfactory. The main culprits are intra-class occlusions involving other\n",
      "pedestrians and inter-class occlusions caused by other objects, such as cars\n",
      "and bicycles. These result in a multitude of occlusion patterns. We propose an\n",
      "approach for occluded pedestrian detection with the following contributions.\n",
      "First, we introduce a novel mask-guided attention network that fits naturally\n",
      "into popular pedestrian detection pipelines. Our attention network emphasizes\n",
      "on visible pedestrian regions while suppressing the occluded ones by modulating\n",
      "full body features. Second, we empirically demonstrate that coarse-level\n",
      "segmentation annotations provide reasonable approximation to their dense\n",
      "pixel-wise counterparts. Experiments are performed on CityPersons and Caltech\n",
      "datasets. Our approach sets a new state-of-the-art on both datasets. Our\n",
      "approach obtains an absolute gain of 9.5% in log-average miss rate, compared to\n",
      "the best reported results on the heavily occluded (HO) pedestrian set of\n",
      "CityPersons test set. Further, on the HO pedestrian set of Caltech dataset, our\n",
      "method achieves an absolute gain of 5.0% in log-average miss rate, compared to\n",
      "the best reported results. Code and models are available at:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a new, two-stage approach to the vertebrae centroid detection and\n",
      "localization problem. The first stage detects where the vertebrae appear in the\n",
      "scan using 3D samples, the second identifies the specific vertebrae within that\n",
      "region-of-interest using 2D slices. Our solution utilizes new techniques to\n",
      "improve the accuracy of the algorithm such as a revised approach to dense\n",
      "labelling from sparse centroid annotations and usage of large anisotropic\n",
      "kernels in the base level of a U-net architecture to maximize the receptive\n",
      "field. Our method improves the state-of-the-art's mean localization accuracy by\n",
      "0.87mm on a publicly available spine CT benchmark.\n",
      "\n",
      "    \n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We compare the model-free reinforcement learning with the model-based\n",
      "approaches through the lens of the expressive power of neural networks for\n",
      "policies, $Q$-functions, and dynamics. We show, theoretically and empirically,\n",
      "that even for one-dimensional continuous state space, there are many MDPs whose\n",
      "optimal $Q$-functions and policies are much more complex than the dynamics. We\n",
      "hypothesize many real-world MDPs also have a similar property. For these MDPs,\n",
      "model-based planning is a favorable algorithm, because the resulting policies\n",
      "can approximate the optimal policy significantly better than a neural network\n",
      "parameterization can, and model-free or model-based policy optimization rely on\n",
      "policy parameterization. Motivated by the theory, we apply a simple multi-step\n",
      "model-based bootstrapping planner (BOOTS) to bootstrap a weak $Q$-function into\n",
      "a stronger policy. Empirical results show that applying BOOTS on top of\n",
      "model-based or model-free policy optimization algorithms at the test time\n",
      "improves the performance on MuJoCo benchmark tasks.\n",
      "\n",
      "    \n",
      "721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Due to the inherent uncertainty of data, the problem of predicting partial\n",
      "ranking from pairwise comparison data with ties has attracted increasing\n",
      "interest in recent years. However, in real-world scenarios, different\n",
      "individuals often hold distinct preferences. It might be misleading to merely\n",
      "look at a global partial ranking while ignoring personal diversity. In this\n",
      "paper, instead of learning a global ranking which is agreed with the consensus,\n",
      "we pursue the tie-aware partial ranking from an individualized perspective.\n",
      "Particularly, we formulate a unified framework which not only can be used for\n",
      "individualized partial ranking prediction, but also be helpful for abnormal\n",
      "user selection. This is realized by a variable splitting-based algorithm called\n",
      "\\ilbi. Specifically, our algorithm generates a sequence of estimations with a\n",
      "regularization path, where both the hyperparameters and model parameters are\n",
      "updated. At each step of the path, the parameters can be decomposed into three\n",
      "orthogonal parts, namely, abnormal signals, personalized signals and random\n",
      "noise. The abnormal signals can serve the purpose of abnormal user selection,\n",
      "while the abnormal signals and personalized signals together are mainly\n",
      "responsible for individual partial ranking prediction. Extensive experiments on\n",
      "simulated and real-world datasets demonstrate that our new approach\n",
      "significantly outperforms state-of-the-art alternatives. The code is now\n",
      "availiable at this https URL.\n",
      "\n",
      "    \n",
      "722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Transfer learning makes use of data or knowledge in one problem to help solve\n",
      "a different, yet related, problem. It is particularly useful in brain-computer\n",
      "interfaces (BCIs), for coping with variations among different subjects and/or\n",
      "tasks. This paper considers offline unsupervised cross-subject\n",
      "electroencephalogram (EEG) classification, i.e., we have labeled EEG trials\n",
      "from one or more source subjects, but only unlabeled EEG trials from the target\n",
      "subject. We propose a novel manifold embedded knowledge transfer (MEKT)\n",
      "approach, which first aligns the covariance matrices of the EEG trials in the\n",
      "Riemannian manifold, extracts features in the tangent space, and then performs\n",
      "domain adaptation by minimizing the joint probability distribution shift\n",
      "between the source and the target domains, while preserving their geometric\n",
      "structures. MEKT can cope with one or multiple source domains, and can be\n",
      "computed efficiently. We also propose a domain transferability estimation (DTE)\n",
      "approach to identify the most beneficial source domains, in case there are a\n",
      "large number of source domains. Experiments on four EEG datasets from two\n",
      "different BCI paradigms demonstrated that MEKT outperformed several\n",
      "state-of-the-art transfer learning approaches, and DTE can reduce more than\n",
      "half of the computational cost when the number of source subjects is large,\n",
      "with little sacrifice of classification accuracy.\n",
      "\n",
      "    \n",
      "723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Ancient history relies on disciplines such as epigraphy, the study of ancient\n",
      "inscribed texts, for evidence of the recorded past. However, these texts,\n",
      "\"inscriptions\", are often damaged over the centuries, and illegible parts of\n",
      "the text must be restored by specialists, known as epigraphists. This work\n",
      "presents Pythia, the first ancient text restoration model that recovers missing\n",
      "characters from a damaged text input using deep neural networks. Its\n",
      "architecture is carefully designed to handle long-term context information, and\n",
      "deal efficiently with missing or corrupted character and word representations.\n",
      "To train it, we wrote a non-trivial pipeline to convert PHI, the largest\n",
      "digital corpus of ancient Greek inscriptions, to machine actionable text, which\n",
      "we call PHI-ML. On PHI-ML, Pythia's predictions achieve a 30.1% character error\n",
      "rate, compared to the 57.3% of human epigraphists. Moreover, in 73.5% of cases\n",
      "the ground-truth sequence was among the Top-20 hypotheses of Pythia, which\n",
      "effectively demonstrates the impact of this assistive method on the field of\n",
      "digital epigraphy, and sets the state-of-the-art in ancient text restoration.\n",
      "\n",
      "    \n",
      "724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  It is very challenging to work with low-resource languages due to the\n",
      "inadequate availability of data. Using a dictionary to map independently\n",
      "trained word embeddings into a shared vector space has proved to be very useful\n",
      "in learning bilingual embeddings in the past. Here we have tried to map\n",
      "individual embeddings of words in English and their corresponding translated\n",
      "words in low-resource languages like Estonian, Slovenian, Slovakian, and\n",
      "Hungarian. We have used a supervised learning approach. We report accuracy\n",
      "scores through various retrieval strategies which show that it is possible to\n",
      "approach challenging tasks in Natural Language Processing like machine\n",
      "translation for such languages, provided that we have at least some amount of\n",
      "proper bilingual data. We also conclude that we can follow an unsupervised\n",
      "learning path on monolingual text data as that is more suitable for\n",
      "low-resource languages.\n",
      "\n",
      "    \n",
      "725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In low-resource settings, the performance of supervised labeling models can\n",
      "be improved with automatically annotated or distantly supervised data, which is\n",
      "cheap to create but often noisy. Previous works have shown that significant\n",
      "improvements can be reached by injecting information about the confusion\n",
      "between clean and noisy labels in this additional training data into the\n",
      "classifier training. However, for noise estimation, these approaches either do\n",
      "not take the input features (in our case word embeddings) into account, or they\n",
      "need to learn the noise modeling from scratch which can be difficult in a\n",
      "low-resource setting. We propose to cluster the training data using the input\n",
      "features and then compute different confusion matrices for each cluster. To the\n",
      "best of our knowledge, our approach is the first to leverage feature-dependent\n",
      "noise modeling with pre-initialized confusion matrices. We evaluate on\n",
      "low-resource named entity recognition settings in several languages, showing\n",
      "that our methods improve upon other confusion-matrix based methods by up to 9%.\n",
      "\n",
      "    \n",
      "726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Currently, there is a limited understanding of how data privacy concerns vary\n",
      "across the world. The Cambridge Analytica scandal triggered a wide-ranging\n",
      "discussion on social media about user data collection and use practices. We\n",
      "conducted an inter-language study of this online conversation to compare how\n",
      "people speaking different languages react to data privacy breaches. We\n",
      "collected tweets about the scandal written in Spanish and English between April\n",
      "and July 2018. We used the Meaning Extraction Method in both datasets to\n",
      "identify their main topics. They reveal a similar emphasis on Zuckerberg's\n",
      "hearing in the US Congress and the scandal's impact on political issues.\n",
      "However, our analysis also shows that while English speakers tend to attribute\n",
      "responsibilities to companies, Spanish speakers are more likely to connect them\n",
      "to people. These findings show the potential of inter-language comparisons of\n",
      "social media data to deepen the understanding of cultural differences in data\n",
      "privacy perspectives.\n",
      "\n",
      "    \n",
      "727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Large-scale and multidimensional spatiotemporal data sets are becoming\n",
      "ubiquitous in many real-world applications such as monitoring urban traffic and\n",
      "air quality. Making predictions on these time series has become a critical\n",
      "challenge due to not only the large-scale and high-dimensional nature but also\n",
      "the considerable amount of missing data. In this paper, we propose a Bayesian\n",
      "temporal factorization (BTF) framework for modeling multidimensional time\n",
      "series---in particular spatiotemporal data---in the presence of missing values.\n",
      "By integrating low-rank matrix/tensor factorization and vector autoregressive\n",
      "(VAR) process into a single probabilistic graphical model, this framework can\n",
      "characterize both global and local consistencies in large-scale time series\n",
      "data. The graphical model allows us to effectively perform probabilistic\n",
      "predictions and produce uncertainty estimates without imputing those missing\n",
      "values. We develop efficient Gibbs sampling algorithms for model inference and\n",
      "test the proposed BTF framework on several real-world spatiotemporal data sets\n",
      "for both missing data imputation and short-term/long-term rolling prediction\n",
      "tasks. The numerical experiments demonstrate the superiority of the proposed\n",
      "BTF approaches over many state-of-the-art techniques.\n",
      "\n",
      "    \n",
      "728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a recent symplectic integration scheme derived for solving\n",
      "physically motivated systems with non-separable Hamiltonians. We show its\n",
      "relevance to Riemannian manifold Hamiltonian Monte Carlo (RMHMC) and provide an\n",
      "alternative to the currently used generalised leapfrog symplectic integrator,\n",
      "which relies on solving multiple fixed point iterations to convergence. Via\n",
      "this approach, we are able to reduce the number of higher-order derivative\n",
      "calculations per leapfrog step. We explore the implications of this integrator\n",
      "and demonstrate its efficacy in reducing the computational burden of RMHMC. Our\n",
      "code is provided in a new open-source Python package, hamiltorch.\n",
      "\n",
      "    \n",
      "729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We evaluate three simple, normalization-centric changes to improve\n",
      "Transformer training. First, we show that pre-norm residual connections\n",
      "(PreNorm) and smaller initializations enable warmup-free, validation-based\n",
      "training with large learning rates. Second, we propose $\\ell_2$ normalization\n",
      "with a single scale parameter (ScaleNorm) for faster training and better\n",
      "performance. Finally, we reaffirm the effectiveness of normalizing word\n",
      "embeddings to a fixed length (FixNorm). On five low-resource translation pairs\n",
      "from TED Talks-based corpora, these changes always converge, giving an average\n",
      "+1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on\n",
      "IWSLT'15 English-Vietnamese. We observe sharper performance curves, more\n",
      "consistent gradient norms, and a linear relationship between activation scaling\n",
      "and decoder depth. Surprisingly, in the high-resource setting (WMT'14\n",
      "English-German), ScaleNorm and FixNorm remain competitive but PreNorm degrades\n",
      "performance.\n",
      "\n",
      "    \n",
      "730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We study a security threat to batch reinforcement learning and control where\n",
      "the attacker aims to poison the learned policy. The victim is a reinforcement\n",
      "learner / controller which first estimates the dynamics and the rewards from a\n",
      "batch data set, and then solves for the optimal policy with respect to the\n",
      "estimates. The attacker can modify the data set slightly before learning\n",
      "happens, and wants to force the learner into learning a target policy chosen by\n",
      "the attacker. We present a unified framework for solving batch policy poisoning\n",
      "attacks, and instantiate the attack on two standard victims: tabular certainty\n",
      "equivalence learner in reinforcement learning and linear quadratic regulator in\n",
      "control. We show that both instantiation result in a convex optimization\n",
      "problem on which global optimality is guaranteed, and provide analysis on\n",
      "attack feasibility and attack cost. Experiments show the effectiveness of\n",
      "policy poisoning attacks.\n",
      "\n",
      "    \n",
      "731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While we would like agents that can coordinate with humans, current\n",
      "algorithms such as self-play and population-based training create agents that\n",
      "can coordinate with themselves. Agents that assume their partner to be optimal\n",
      "or similar to them can converge to coordination protocols that fail to\n",
      "understand and be understood by humans. To demonstrate this, we introduce a\n",
      "simple environment that requires challenging coordination, based on the popular\n",
      "game Overcooked, and learn a simple model that mimics human play. We evaluate\n",
      "the performance of agents trained via self-play and population-based training.\n",
      "These agents perform very well when paired with themselves, but when paired\n",
      "with our human model, they are significantly worse than agents designed to play\n",
      "with the human model. An experiment with a planning algorithm yields the same\n",
      "conclusion, though only when the human-aware planner is given the exact human\n",
      "model that it is playing with. A user study with real humans shows this pattern\n",
      "as well, though less strongly. Qualitatively, we find that the gains come from\n",
      "having the agent adapt to the human's gameplay. Given this result, we suggest\n",
      "several approaches for designing agents that learn about humans in order to\n",
      "better coordinate with them. Code is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an image translation approach to generate augmented data for\n",
      "mitigating data imbalances in a dataset of histopathology images of colorectal\n",
      "polyps, adenomatous tumors that can lead to colorectal cancer if left\n",
      "untreated. By applying cycle-consistent generative adversarial networks\n",
      "(CycleGANs) to a source domain of normal colonic mucosa images, we generate\n",
      "synthetic colorectal polyp images that belong to diagnostically less common\n",
      "polyp classes. Generated images maintain the general structure of their source\n",
      "image but exhibit adenomatous features that can be enhanced with our proposed\n",
      "filtration module, called Path-Rank-Filter. We evaluate the quality of\n",
      "generated images through Turing tests with four gastrointestinal pathologists,\n",
      "finding that at least two of the four pathologists could not identify generated\n",
      "images at a statistically significant level. Finally, we demonstrate that using\n",
      "CycleGAN-generated images to augment training data improves the AUC of a\n",
      "convolutional neural network for detecting sessile serrated adenomas by over\n",
      "10%, suggesting that our approach might warrant further research for other\n",
      "histopathology image classification tasks.\n",
      "\n",
      "    \n",
      "733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Unsupervised domain adaptation aims to generalize the hypothesis trained in a\n",
      "source domain to an unlabeled target domain. One popular approach to this\n",
      "problem is to learn domain-invariant embeddings for both domains. In this work,\n",
      "we study, theoretically and empirically, the effect of the embedding complexity\n",
      "on generalization to the target domain. In particular, this complexity affects\n",
      "an upper bound on the target risk; this is reflected in experiments, too. Next,\n",
      "we specify our theoretical framework to multilayer neural networks. As a\n",
      "result, we develop a strategy that mitigates sensitivity to the embedding\n",
      "complexity, and empirically achieves performance on par with or better than the\n",
      "best layer-dependent complexity tradeoff.\n",
      "\n",
      "    \n",
      "734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Diagnosing different retinal diseases from Spectral Domain Optical Coherence\n",
      "Tomography (SD-OCT) images is a challenging task. Different automated\n",
      "approaches such as image processing, machine learning and deep learning\n",
      "algorithms have been used for early detection and diagnosis of retinal\n",
      "diseases. Unfortunately, these are prone to error and computational\n",
      "inefficiency, which requires further intervention from human experts. In this\n",
      "paper, we propose a novel convolution neural network architecture to\n",
      "successfully distinguish between different degeneration of retinal layers and\n",
      "their underlying causes. The proposed novel architecture outperforms other\n",
      "classification models while addressing the issue of gradient explosion. Our\n",
      "approach reaches near perfect accuracy of 99.8% and 100% for two separately\n",
      "available Retinal SD-OCT data-set respectively. Additionally, our architecture\n",
      "predicts retinal diseases in real time while outperforming human\n",
      "diagnosticians.\n",
      "\n",
      "    \n",
      "735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent works on domain adaptation exploit adversarial training to obtain\n",
      "domain-invariant feature representations from the joint learning of feature\n",
      "extractor and domain discriminator networks. However, domain adversarial\n",
      "methods render suboptimal performances since they attempt to match the\n",
      "distributions among the domains without considering the task at hand. We\n",
      "propose Drop to Adapt (DTA), which leverages adversarial dropout to learn\n",
      "strongly discriminative features by enforcing the cluster assumption.\n",
      "Accordingly, we design objective functions to support robust domain adaptation.\n",
      "We demonstrate efficacy of the proposed method on various experiments and\n",
      "achieve consistent improvements in both image classification and semantic\n",
      "segmentation tasks. Our source code is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  As evolutionary algorithms (EAs) are general-purpose optimization algorithms,\n",
      "recent theoretical studies have tried to analyze their performance for solving\n",
      "general problem classes, with the goal of providing a general theoretical\n",
      "explanation of the behavior of EAs. Particularly, a simple multi-objective EA,\n",
      "i.e., GSEMO, has been shown to be able to achieve good polynomial-time\n",
      "approximation guarantees for submodular optimization, where the objective\n",
      "function is only required to satisfy some properties but without explicit\n",
      "formulation. Submodular optimization has wide applications in diverse areas,\n",
      "and previous studies have considered the cases where the objective functions\n",
      "are monotone submodular, monotone non-submodular, or non-monotone submodular.\n",
      "To complement this line of research, this paper studies the problem class of\n",
      "maximizing monotone approximately submodular minus modular functions (i.e.,\n",
      "$f=g-c$) with a size constraint, where $g$ is a non-negative monotone\n",
      "approximately submodular function and $c$ is a non-negative modular function,\n",
      "resulting in the objective function $f$ being non-monotone non-submodular. We\n",
      "prove that the GSEMO can achieve the best-known polynomial-time approximation\n",
      "guarantee. Empirical studies on the applications of Bayesian experimental\n",
      "design and directed vertex cover show the excellent performance of the GSEMO.\n",
      "\n",
      "    \n",
      "737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A great deal of historical corpora suffer from errors introduced by the OCR\n",
      "(optical character recognition) methods used in the digitization process.\n",
      "Correcting these errors manually is a time-consuming process and a great part\n",
      "of the automatic approaches have been relying on rules or supervised machine\n",
      "learning. We present a fully automatic unsupervised way of extracting parallel\n",
      "data for training a character-based sequence-to-sequence NMT (neural machine\n",
      "translation) model to conduct OCR error correction.\n",
      "\n",
      "    \n",
      "738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Humans tackle new problems by making inferences that go far beyond the\n",
      "information available, reusing what they have previously learned, and weighing\n",
      "different alternatives in the face of uncertainty. Incorporating these\n",
      "abilities in an artificial system is a major objective in machine learning.\n",
      "Towards this goal, we introduce a Bayesian method based on Gaussian Processes\n",
      "(GPs) that can learn efficiently from a limited amount of data and generalize\n",
      "across new tasks and domains. We frame few-shot learning as a model selection\n",
      "problem by learning a deep kernel across tasks, and then using this kernel as a\n",
      "covariance function in a GP prior for Bayesian inference. This probabilistic\n",
      "treatment allows for cross-domain flexibility, and uncertainty quantification.\n",
      "We provide substantial experimental evidence, showing that the proposed method\n",
      "is better than several state-of-the-art algorithms in few-shot regression and\n",
      "cross-domain classification.\n",
      "\n",
      "    \n",
      "739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of constructing a reduced-rank regression model whose\n",
      "coefficient parameter is represented as a singular value decomposition with\n",
      "sparse singular vectors. The traditional estimation procedure for the\n",
      "coefficient parameter often fails when the true rank of the parameter is high.\n",
      "To overcome this issue, we develop an estimation algorithm with rank and\n",
      "variable selection via sparse regularization and manifold optimization, which\n",
      "enables us to obtain an accurate estimation of the coefficient parameter even\n",
      "if the true rank of the coefficient parameter is high. Using sparse\n",
      "regularization, we can also select an optimal value of the rank. We conduct\n",
      "Monte Carlo experiments and real data analysis to illustrate the effectiveness\n",
      "of our proposed method.\n",
      "\n",
      "    \n",
      "740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present the first dataset targeted at end-to-end NLG in Czech in the\n",
      "restaurant domain, along with several strong baseline models using the\n",
      "sequence-to-sequence approach. While non-English NLG is under-explored in\n",
      "general, Czech, as a morphologically rich language, makes the task even harder:\n",
      "Since Czech requires inflecting named entities, delexicalization or copy\n",
      "mechanisms do not work out-of-the-box and lexicalizing the generated outputs is\n",
      "non-trivial.\n",
      "In our experiments, we present two different approaches to this this problem:\n",
      "(1) using a neural language model to select the correct inflected form while\n",
      "lexicalizing, (2) a two-step generation setup: our sequence-to-sequence model\n",
      "generates an interleaved sequence of lemmas and morphological tags, which are\n",
      "then inflected by a morphological generator.\n",
      "\n",
      "    \n",
      "741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The evolution of social media users' behavior over time complicates\n",
      "user-level comparison tasks such as verification, classification, clustering,\n",
      "and ranking. As a result, naïve approaches may fail to generalize to new\n",
      "users or even to future observations of previously known users. In this paper,\n",
      "we propose a novel procedure to learn a mapping from short episodes of user\n",
      "activity on social media to a vector space in which the distance between points\n",
      "captures the similarity of the corresponding users' invariant features. We fit\n",
      "the model by optimizing a surrogate metric learning objective over a large\n",
      "corpus of unlabeled social media content. Once learned, the mapping may be\n",
      "applied to users not seen at training time and enables efficient comparisons of\n",
      "users in the resulting vector space. We present a comprehensive evaluation to\n",
      "validate the benefits of the proposed approach using data from Reddit, Twitter,\n",
      "and Wikipedia.\n",
      "\n",
      "    \n",
      "742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recurrent neural networks (RNNs) are known to be difficult to train due to\n",
      "the gradient vanishing and exploding problems and thus difficult to learn\n",
      "long-term patterns. Long short-term memory (LSTM) was developed to address\n",
      "these problems, but the use of hyperbolic tangent and the sigmoid activation\n",
      "functions results in gradient decay over layers. Consequently, construction of\n",
      "an efficiently trainable deep RNN is challenging. Moreover, training of LSTM is\n",
      "very compute-intensive as the recurrent connection using matrix product is\n",
      "conducted at every time step. To address these problems, this paper proposes a\n",
      "new type of RNNs with the recurrent connection formulated as Hadamard product,\n",
      "referred to as independently recurrent neural network (IndRNN), where neurons\n",
      "in the same layer are independent of each other and connected across layers.\n",
      "The gradient vanishing and exploding problems are solved in IndRNN by simply\n",
      "regulating the recurrent weights, and thus long-term dependencies can be\n",
      "learned. Moreover, an IndRNN can work with non-saturated activation functions\n",
      "such as ReLU and be still trained robustly. Different deeper IndRNN\n",
      "architectures, including the basic stacked IndRNN, residual IndRNN and densely\n",
      "connected IndRNN, have been investigated, all of which can be much deeper than\n",
      "the existing RNNs. Furthermore, IndRNN reduces the computation at each time\n",
      "step and can be over 10 times faster than the LSTM. The code is made publicly\n",
      "available at this https URL. Experimental\n",
      "results have shown that the proposed IndRNN is able to process very long\n",
      "sequences (over 5000 time steps), can be used to construct very deep networks\n",
      "(the 21 layers residual IndRNN and deep densely connected IndRNN used in the\n",
      "experiment for example). Better performances have been achieved on various\n",
      "tasks with IndRNNs compared with the traditional RNN and LSTM.\n",
      "\n",
      "    \n",
      "743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Ground-based whole sky cameras are extensively used for localized monitoring\n",
      "of clouds nowadays. They capture hemispherical images of the sky at regular\n",
      "intervals using a fisheye lens. In this paper, we propose a framework for\n",
      "estimating solar irradiance from pictures taken by those imagers. Unlike\n",
      "pyranometers, such sky images contain information about cloud coverage and can\n",
      "be used to derive cloud movement. An accurate estimation of solar irradiance\n",
      "using solely those images is thus a first step towards short-term forecasting\n",
      "of solar energy generation based on cloud movement. We derive and validate our\n",
      "model using pyranometers co-located with our whole sky imagers. We achieve a\n",
      "better performance in estimating solar irradiance and in particular its\n",
      "short-term variations as compared to other related methods using ground-based\n",
      "observations.\n",
      "\n",
      "    \n",
      "744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Social media have become a rich source of data, particularly in health\n",
      "research. Yet, the use of such data raises significant ethical questions about\n",
      "the need for the informed consent of those being studied. Consent mechanisms,\n",
      "if even obtained, are typically broad and inflexible, or place a significant\n",
      "burden on the participant. Machine learning algorithms show much promise for\n",
      "facilitating a 'middle ground' approach: using trained models to predict and\n",
      "automate granular consent decisions. Such techniques, however, raise a myriad\n",
      "of follow-on ethical and technical considerations. In this paper, we present an\n",
      "exploratory user study (n = 67) in which we find that we can predict the\n",
      "appropriate flow of health-related social media data with reasonable accuracy,\n",
      "while minimising undesired data leaks. We then attempt to deconstruct the\n",
      "findings of this study, identifying and discussing a number of real-world\n",
      "implications if such a technique were put into practice.\n",
      "\n",
      "    \n",
      "745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  To improve the discriminative and generalization ability of lightweight\n",
      "network for face recognition, we propose an efficient variable group\n",
      "convolutional network called VarGFaceNet. Variable group convolution is\n",
      "introduced by VarGNet to solve the conflict between small computational cost\n",
      "and the unbalance of computational intensity inside a block. We employ variable\n",
      "group convolution to design our network which can support large scale face\n",
      "identification while reduce computational cost and parameters. Specifically, we\n",
      "use a head setting to reserve essential information at the start of the network\n",
      "and propose a particular embedding setting to reduce parameters of\n",
      "fully-connected layer for embedding. To enhance interpretation ability, we\n",
      "employ an equivalence of angular distillation loss to guide our lightweight\n",
      "network and we apply recursive knowledge distillation to relieve the\n",
      "discrepancy between the teacher model and the student model. The champion of\n",
      "deepglint-light track of LFR (2019) challenge demonstrates the effectiveness of\n",
      "our model and approach. Implementation of VarGFaceNet will be released at\n",
      "this https URL soon.\n",
      "\n",
      "    \n",
      "746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Biomedical challenges have become the de facto standard for benchmarking\n",
      "biomedical image analysis algorithms. While the number of challenges is\n",
      "steadily increasing, surprisingly little effort has been invested in ensuring\n",
      "high quality design, execution and reporting for these international\n",
      "competitions. Specifically, results analysis and visualization in the event of\n",
      "uncertainties have been given almost no attention in the literature. Given\n",
      "these shortcomings, the contribution of this paper is two-fold: (1) We present\n",
      "a set of methods to comprehensively analyze and visualize the results of\n",
      "single-task and multi-task challenges and apply them to a number of simulated\n",
      "and real-life challenges to demonstrate their specific strengths and\n",
      "weaknesses; (2) We release the open-source framework challengeR as part of this\n",
      "work to enable fast and wide adoption of the methodology proposed in this\n",
      "paper. Our approach offers an intuitive way to gain important insights into the\n",
      "relative and absolute performance of algorithms, which cannot be revealed by\n",
      "commonly applied visualization techniques. This is demonstrated by the\n",
      "experiments performed within this work. Our framework could thus become an\n",
      "important tool for analyzing and visualizing challenge results in the field of\n",
      "biomedical image analysis and beyond.\n",
      "\n",
      "    \n",
      "747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recognizing emotions in conversations is a challenging task due to the\n",
      "presence of contextual dependencies governed by self- and inter-personal\n",
      "influences. Recent approaches have focused on modeling these dependencies\n",
      "primarily via supervised learning. However, purely supervised strategies demand\n",
      "large amounts of annotated data, which is lacking in most of the available\n",
      "corpora in this task. To tackle this challenge, we look at transfer learning\n",
      "approaches as a viable alternative. Given the large amount of available\n",
      "conversational data, we investigate whether generative conversational models\n",
      "can be leveraged to transfer affective knowledge for the target task of\n",
      "detecting emotions in context. We propose an approach where we first train a\n",
      "neural dialogue model and then perform parameter transfer to initiate our\n",
      "target model. Apart from the traditional pre-trained sentence encoders, we also\n",
      "incorporate parameter transfer from the recurrent components that model\n",
      "inter-sentence context across the whole conversation. Based on this idea, we\n",
      "perform several experiments across multiple datasets and find improvement in\n",
      "performance and robustness against limited training data. Our models also\n",
      "achieve better validation performances in significantly fewer epochs. Overall,\n",
      "we infer that knowledge acquired from dialogue generators can indeed help\n",
      "recognize emotions in conversations.\n",
      "\n",
      "    \n",
      "748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent advances in NLP with language models such as BERT, GPT-2, XLNet or\n",
      "XLM, have allowed surpassing human performance on Reading Comprehension tasks\n",
      "on large-scale datasets (e.g. SQuAD), and this opens up many perspectives for\n",
      "Conversational AI. However, task-specific datasets are mostly in English which\n",
      "makes it difficult to acknowledge progress in foreign languages. Fortunately,\n",
      "state-of-the-art models are now being pre-trained on multiple languages (e.g.\n",
      "BERT was released in a multilingual version managing a hundred languages) and\n",
      "are exhibiting ability for zero-shot transfer from English to others languages\n",
      "on XNLI. In this paper, we run experiments that show that multilingual BERT,\n",
      "trained to solve the complex Question Answering task defined in the English\n",
      "SQuAD dataset, is able to achieve the same task in Japanese and French. It even\n",
      "outperforms the best published results of a baseline which explicitly combines\n",
      "an English model for Reading Comprehension and a Machine Translation Model for\n",
      "transfer. We run further tests on crafted cross-lingual QA datasets (context in\n",
      "one language and question in another) to provide intuition on the mechanisms\n",
      "that allow BERT to transfer the task from one language to another. Finally, we\n",
      "introduce our application Kate. Kate is a conversational agent dedicated to HR\n",
      "support for employees that exploits multilingual models to accurately answer to\n",
      "questions, in several languages, directly from information web pages.\n",
      "\n",
      "    \n",
      "749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Contrastive unsupervised representation learning (CURL) is the\n",
      "state-of-the-art technique to learn representations (as a set of features) from\n",
      "unlabelled data. While CURL has collected several empirical successes recently,\n",
      "theoretical understanding of its performance was still missing. In a recent\n",
      "work, Arora et al. (2019) provide the first generalisation bounds for CURL,\n",
      "relying on a Rademacher complexity. We extend their framework to the flexible\n",
      "PAC-Bayes setting, allowing to deal with the non-iid setting. We present\n",
      "PAC-Bayesian generalisation bounds for CURL, which are then used to derive a\n",
      "new representation learning algorithm. Numerical experiments on real-life\n",
      "datasets illustrate that our algorithm achieves competitive accuracy, and\n",
      "yields generalisation bounds with non-vacuous values.\n",
      "\n",
      "    \n",
      "750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Methods tackling multi-object tracking need to estimate the number of targets\n",
      "in the sensing area as well as to estimate their continuous state. While the\n",
      "majority of existing methods focus on data association, precise state (3D pose)\n",
      "estimation is often only coarsely estimated by approximating targets with\n",
      "centroids or (3D) bounding boxes. However, in automotive scenarios, motion\n",
      "perception of surrounding agents is critical and inaccuracies in the vehicle\n",
      "close-range can have catastrophic consequences. In this work, we focus on\n",
      "precise 3D track state estimation and propose a learning-based approach for\n",
      "object-centric relative motion estimation of partially observed objects.\n",
      "Instead of approximating targets with their centroids, our approach is capable\n",
      "of utilizing noisy 3D point segments of objects to estimate their motion. To\n",
      "that end, we propose a simple, yet effective and efficient network, \\method,\n",
      "that learns to align point clouds. Our evaluation on two different datasets\n",
      "demonstrates that our method outperforms computationally expensive, global 3D\n",
      "registration methods while being significantly more efficient. We make our\n",
      "data, code, and models available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we propose a semi-supervised variational autoencoder for\n",
      "classification of overall survival groups from tumor segmentation masks. The\n",
      "model can use the output of any tumor segmentation algorithm, removing all\n",
      "assumptions on the scanning platform and the specific type of pulse sequences\n",
      "used, thereby increasing its generalization properties. Due to its\n",
      "semi-supervised nature, the method can learn to classify survival time by using\n",
      "a relatively small number of labeled subjects. We validate our model on the\n",
      "publicly available dataset from the Multimodal Brain Tumor Segmentation\n",
      "Challenge (BraTS) 2019.\n",
      "\n",
      "    \n",
      "752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Visual navigation tasks in real world environments often require both\n",
      "self-motion and place recognition feedback. While deep reinforcement learning\n",
      "has shown success in solving these perception and decision-making problems in\n",
      "an end-to-end manner, these algorithms require large amounts of experience to\n",
      "learn navigation policies from high-dimensional inputs, which is generally\n",
      "impractical for real robots due to sample complexity. In this paper, we address\n",
      "these problems with two main contributions. We first leverage place recognition\n",
      "and deep learning techniques combined with goal destination feedback to\n",
      "generate compact, bimodal images representations that can then be used to\n",
      "effectively learn control policies at kilometer scale from a small amount of\n",
      "experience. Second, we present an interactive and realistic framework, called\n",
      "CityLearn, that enables for the first time the training of navigation\n",
      "algorithms across city-sized, real-world environments with extreme\n",
      "environmental changes. CityLearn features over 10 benchmark real-world datasets\n",
      "often used in place recognition research with more than 100 recorded traversals\n",
      "and across 60 cities around the world. We evaluate our approach in two\n",
      "CityLearn environments where our navigation policy is trained using a single\n",
      "traversal. Results show our method can be over 2 orders of magnitude faster\n",
      "than when using raw images and can also generalize across extreme visual\n",
      "changes including day to night and summer to winter transitions.\n",
      "\n",
      "    \n",
      "753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning is attracting significant interest in the neuroimaging\n",
      "community as a means to diagnose psychiatric and neurological disorders from\n",
      "structural magnetic resonance images. However, there is a tendency amongst\n",
      "researchers to adopt architectures optimized for traditional computer vision\n",
      "tasks, rather than design networks customized for neuroimaging data. We address\n",
      "this by introducing NEURO-DRAM, a 3D recurrent visual attention model tailored\n",
      "for neuroimaging classification with the flexibility to incorporate non-imaging\n",
      "information. The model comprises an agent which, trained by reinforcement\n",
      "learning, learns to navigate through volumetric images, selectively attending\n",
      "to the most informative regions for a given task. When applied to Alzheimer's\n",
      "disease prediction, NEURODRAM achieves state-of-the-art classification accuracy\n",
      "on an out-of-sample dataset, significantly outperforming a baseline\n",
      "convolutional neural network. When further applied to the task of predicting\n",
      "which patients with mild cognitive impairment will be diagnosed with\n",
      "Alzheimer's disease within two years, the model achieves state-of-the-art\n",
      "accuracy with no additional training. Encouragingly, the agent learns, without\n",
      "explicit instruction, a search policy in agreement with standardized\n",
      "radiological hallmarks of Alzheimer's disease, suggesting a route to automated\n",
      "biomarker discovery for more poorly understood disorders.\n",
      "\n",
      "    \n",
      "754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose two novel variants of Gromov-Wasserstein (GW) between probability\n",
      "measures in different probability spaces based on projecting these measures\n",
      "into the tree metric spaces. Our first proposed discrepancy, named\n",
      "\\emph{flow-based tree Gromov-Wasserstein}, hinges upon the tree metric from\n",
      "node to root in each tree to define the structure representation of probability\n",
      "measures on trees. The flow-based tree GW shares similar structures with\n",
      "univariate Wasserstein distance while keeping sufficient spatial information of\n",
      "the original projected probability measures. In order to further explore the\n",
      "structure of tree, we proposed another version of flow-based tree GW, which we\n",
      "refer to as \\emph{depth-based tree Gromov-Wasserstein}. That discrepancy\n",
      "considers the alignment of probability measures hierarchically along each depth\n",
      "level of the tree structures. Finally, we demonstrate via extensive simulation\n",
      "studies on large-scale real data sets the relative advantage of the proposed\n",
      "discrepancies.\n",
      "\n",
      "    \n",
      "755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a new task of query auto-completion for estimating instance\n",
      "probabilities. We complete a user query prefix conditioned upon an image. Given\n",
      "the complete query, we fine tune a BERT embedding for estimating probabilities\n",
      "of a broad set of instances. The resulting instance probabilities are used for\n",
      "selection while being agnostic to the segmentation or attention mechanism. Our\n",
      "results demonstrate that auto-completion using both language and vision\n",
      "performs better than using only language, and that fine tuning a BERT embedding\n",
      "allows to efficiently rank instances in the image. In the spirit of\n",
      "reproducible research we make our data, models, and code available.\n",
      "\n",
      "    \n",
      "756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a recurrent neural network based system for automatic quality\n",
      "estimation of natural language generation (NLG) outputs, which jointly learns\n",
      "to assign numerical ratings to individual outputs and to provide pairwise\n",
      "rankings of two different outputs. The latter is trained using pairwise hinge\n",
      "loss over scores from two copies of the rating network.\n",
      "We use learning to rank and synthetic data to improve the quality of ratings\n",
      "assigned by our system: we synthesise training pairs of distorted system\n",
      "outputs and train the system to rank the less distorted one higher. This leads\n",
      "to a 12% increase in correlation with human ratings over the previous\n",
      "benchmark. We also establish the state of the art on the dataset of relative\n",
      "rankings from the E2E NLG Challenge (Dušek et al., 2019), where synthetic\n",
      "data lead to a 4% accuracy increase over the base model.\n",
      "\n",
      "    \n",
      "757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep learning based image Super-Resolution (SR) has shown rapid development\n",
      "due to its ability of big data digestion. Generally, deeper and wider networks\n",
      "can extract richer feature maps and generate SR images with remarkable quality.\n",
      "However, the more complex network we have, the more time consumption is\n",
      "required for practical applications. It is important to have a simplified\n",
      "network for efficient image SR. In this paper, we propose an Attention based\n",
      "Back Projection Network (ABPN) for image super-resolution. Similar to some\n",
      "recent works, we believe that the back projection mechanism can be further\n",
      "developed for SR. Enhanced back projection blocks are suggested to iteratively\n",
      "update low- and high-resolution feature residues. Inspired by recent studies on\n",
      "attention models, we propose a Spatial Attention Block (SAB) to learn the\n",
      "cross-correlation across features at different layers. Based on the assumption\n",
      "that a good SR image should be close to the original LR image after\n",
      "down-sampling. We propose a Refined Back Projection Block (RBPB) for final\n",
      "reconstruction. Extensive experiments on some public and AIM2019 Image\n",
      "Super-Resolution Challenge datasets show that the proposed ABPN can provide\n",
      "state-of-the-art or even better performance in both quantitative and\n",
      "qualitative measurements.\n",
      "\n",
      "    \n",
      "758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Computer vision has undergone a dramatic revolution in performance, driven in\n",
      "large part through deep features trained on large-scale supervised datasets.\n",
      "However, much of these improvements have focused on static image analysis;\n",
      "video understanding has seen rather modest improvements. Even though new\n",
      "datasets and spatiotemporal models have been proposed, simple frame-by-frame\n",
      "classification methods often still remain competitive. We posit that current\n",
      "video datasets are plagued with implicit biases over scene and object structure\n",
      "that can dwarf variations in temporal structure. In this work, we build a video\n",
      "dataset with fully observable and controllable object and scene bias, and which\n",
      "truly requires spatiotemporal understanding in order to be solved. Our dataset,\n",
      "named CATER, is rendered synthetically using a library of standard 3D objects,\n",
      "and tests the ability to recognize compositions of object movements that\n",
      "require long-term reasoning. In addition to being a challenging dataset, CATER\n",
      "also provides a plethora of diagnostic tools to analyze modern spatiotemporal\n",
      "video architectures by being completely observable and controllable. Using\n",
      "CATER, we provide insights into some of the most recent state of the art deep\n",
      "video architectures.\n",
      "\n",
      "    \n",
      "759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Referring expressions are natural language descriptions that identify a\n",
      "particular object within a scene and are widely used in our daily\n",
      "conversations. In this work, we focus on segmenting the object in an image\n",
      "specified by a referring expression. To this end, we propose an end-to-end\n",
      "trainable comprehension network that consists of the language and visual\n",
      "encoders to extract feature representations from both domains. We introduce the\n",
      "spatial-aware dynamic filters to transfer knowledge from text to image, and\n",
      "effectively capture the spatial information of the specified object. To better\n",
      "communicate between the language and visual modules, we employ a caption\n",
      "generation network that takes features shared across both domains as input, and\n",
      "improves both representations via a consistency that enforces the generated\n",
      "sentence to be similar to the given referring expression. We evaluate the\n",
      "proposed framework on two referring expression datasets and show that our\n",
      "method performs favorably against the state-of-the-art algorithms.\n",
      "\n",
      "    \n",
      "760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning multilingual representations of text has proven a successful method\n",
      "for many cross-lingual transfer learning tasks. There are two main paradigms\n",
      "for learning such representations: (1) alignment, which maps different\n",
      "independently trained monolingual representations into a shared space, and (2)\n",
      "joint training, which directly learns unified multilingual representations\n",
      "using monolingual and cross-lingual objectives jointly. In this paper, we first\n",
      "conduct direct comparisons of representations learned using both of these\n",
      "methods across diverse cross-lingual tasks. Our empirical results reveal a set\n",
      "of pros and cons for both methods, and show that the relative performance of\n",
      "alignment versus joint training is task-dependent. Stemming from this analysis,\n",
      "we propose a simple and novel framework that combines these two previously\n",
      "mutually-exclusive approaches. Extensive experiments on various tasks\n",
      "demonstrate that our proposed framework alleviates limitations of both\n",
      "approaches, and outperforms existing methods on the MUSE bilingual lexicon\n",
      "induction (BLI) benchmark. We further show that our proposed framework can\n",
      "generalize to contextualized representations and achieves state-of-the-art\n",
      "results on the CoNLL cross-lingual NER benchmark.\n",
      "\n",
      "    \n",
      "761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a theoretical framework for performing statistical\n",
      "tasks---including, but not limited to, averaging and principal component\n",
      "analysis---on the space of (possibly asymmetric) matrices with arbitrary\n",
      "entries and sizes. This is carried out under the lens of the Gromov-Wasserstein\n",
      "(GW) distance, and our methods translate the Riemannian framework of GW\n",
      "distances developed by Sturm into practical, implementable tools for network\n",
      "data analysis. Our methods are illustrated on datasets of asymmetric stochastic\n",
      "blockmodel networks and planar shapes viewed as metric spaces. On the\n",
      "theoretical front, we supplement the work of Sturm by producing additional\n",
      "results on the tangent structure of this \"space of spaces\", as well as on the\n",
      "gradient flow of the Fréchet functional on this space.\n",
      "\n",
      "    \n",
      "762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Robots can learn the right reward function by querying a human expert.\n",
      "Existing approaches attempt to choose questions where the robot is most\n",
      "uncertain about the human's response; however, they do not consider how easy it\n",
      "will be for the human to answer! In this paper we explore an information gain\n",
      "formulation for optimally selecting questions that naturally account for the\n",
      "human's ability to answer. Our approach identifies questions that optimize the\n",
      "trade-off between robot and human uncertainty, and determines when these\n",
      "questions become redundant or costly. Simulations and a user study show our\n",
      "method not only produces easy questions, but also ultimately results in faster\n",
      "reward learning.\n",
      "\n",
      "    \n",
      "763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  An agent who interacts with a wide population of other agents needs to be\n",
      "aware that there may be variations in their understanding of the world.\n",
      "Furthermore, the machinery which they use to perceive may be inherently\n",
      "different, as is the case between humans and machines. In this work, we present\n",
      "both an image reference game between a speaker and a population of listeners\n",
      "where reasoning about the concepts other agents can comprehend is necessary and\n",
      "a model formulation with this capability. We focus on reasoning about the\n",
      "conceptual understanding of others, as well as adapting to novel gameplay\n",
      "partners and dealing with differences in perceptual machinery. Our experiments\n",
      "on three benchmark image/attribute datasets suggest that our learner indeed\n",
      "encodes information directly pertaining to the understanding of other agents,\n",
      "and that leveraging this information is crucial for maximizing gameplay\n",
      "performance.\n",
      "\n",
      "    \n",
      "764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Autonomous robots have the potential to serve as versatile caregivers that\n",
      "improve quality of life for millions of people worldwide. Yet, conducting\n",
      "research in this area presents numerous challenges, including the risks of\n",
      "physical interaction between people and robots. Physics simulations have been\n",
      "used to optimize and train robots for physical assistance, but have typically\n",
      "focused on a single task. In this paper, we present Assistive Gym, an open\n",
      "source physics simulation framework for assistive robots that models multiple\n",
      "tasks. It includes six simulated environments in which a robotic manipulator\n",
      "can attempt to assist a person with activities of daily living (ADLs): itch\n",
      "scratching, drinking, feeding, body manipulation, dressing, and bathing.\n",
      "Assistive Gym models a person's physical capabilities and preferences for\n",
      "assistance, which are used to provide a reward function. We present baseline\n",
      "policies trained using reinforcement learning for four different commercial\n",
      "robots in the six environments. We demonstrate that modeling human motion\n",
      "results in better assistance and we compare the performance of different\n",
      "robots. Overall, we show that Assistive Gym is a promising tool for assistive\n",
      "robotics research.\n",
      "\n",
      "    \n",
      "765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent approaches for predicting layouts from 360 panoramas produce excellent\n",
      "results. These approaches build on a common framework consisting of three\n",
      "steps: a pre-processing step based on edge-based alignment, prediction of\n",
      "layout elements, and a post-processing step by fitting a 3D layout to the\n",
      "layout elements. Until now, it has been difficult to compare the methods due to\n",
      "multiple different design decisions, such as the encoding network (e.g. SegNet\n",
      "or ResNet), type of elements predicted (e.g. corners, wall/floor boundaries, or\n",
      "semantic segmentation), or method of fitting the 3D layout. To address this\n",
      "challenge, we summarize and describe the common framework, the variants, and\n",
      "the impact of the design decisions. For a complete evaluation, we also propose\n",
      "extended annotations for the Matterport3D dataset, and introduce two\n",
      "depth-based evaluation metrics.\n",
      "\n",
      "    \n",
      "766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Anticipating the intentions of vulnerable road users (VRUs) such as\n",
      "pedestrians and cyclists is critical for performing safe and comfortable\n",
      "driving maneuvers. This is the case for human driving and, thus, should be\n",
      "taken into account by systems providing any level of driving assistance, from\n",
      "advanced driver assistant systems (ADAS) to fully autonomous vehicles (AVs). In\n",
      "this paper, we show how the latest advances on monocular vision-based human\n",
      "pose estimation, i.e. those relying on deep Convolutional Neural Networks\n",
      "(CNNs), enable to recognize the intentions of such VRUs. In the case of\n",
      "cyclists, we assume that they follow traffic rules to indicate future maneuvers\n",
      "with arm signals. In the case of pedestrians, no indications can be assumed.\n",
      "Instead, we hypothesize that the walking pattern of a pedestrian allows to\n",
      "determine if he/she has the intention of crossing the road in the path of the\n",
      "ego-vehicle, so that the ego-vehicle must maneuver accordingly (e.g. slowing\n",
      "down or stopping). In this paper, we show how the same methodology can be used\n",
      "for recognizing pedestrians and cyclists' intentions. For pedestrians, we\n",
      "perform experiments on the JAAD dataset. For cyclists, we did not found an\n",
      "analogous dataset, thus, we created our own one by acquiring and annotating\n",
      "videos which we share with the research community. Overall, the proposed\n",
      "pipeline provides new state-of-the-art results on the intention recognition of\n",
      "VRUs.\n",
      "\n",
      "    \n",
      "767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Effective network congestion control strategies are key to keeping the\n",
      "Internet (or any large computer network) operational. Network congestion\n",
      "control has been dominated by hand-crafted heuristics for decades. Recently,\n",
      "ReinforcementLearning (RL) has emerged as an alternative to automatically\n",
      "optimize such control strategies. Research so far has primarily considered RL\n",
      "interfaces which block the sender while an agent considers its next action.\n",
      "This is largely an artifact of building on top of frameworks designed for RL in\n",
      "games (e.g. OpenAI Gym). However, this does not translate to real-world\n",
      "networking environments, where a network sender waiting on a policy without\n",
      "sending data is costly for throughput. We instead propose to formulate\n",
      "congestion control with an asynchronous RL agent that handles delayed actions.\n",
      "We present MVFST-RL, a scalable framework for congestion control in the QUIC\n",
      "transport protocol that leverages state-of-the-art in asynchronous RL training\n",
      "with off-policy correction. We analyze modeling improvements to mitigate the\n",
      "deviation from Markovian dynamics, and evaluate our method on emulated networks\n",
      "from the Pantheon benchmark platform. The source code is publicly available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present multi-point optimization: an optimization technique that allows to\n",
      "train several models simultaneously without the need to keep the parameters of\n",
      "each one individually. The proposed method is used for a thorough empirical\n",
      "analysis of the loss landscape of neural networks. By extensive experiments on\n",
      "FashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface is\n",
      "surprisingly diverse and intricate in terms of landscape patterns it contains,\n",
      "and 2) adding batch normalization makes it more smooth. Source code to\n",
      "reproduce all the reported results is available on GitHub:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Accurate localization of proteins from fluorescence microscopy images is a\n",
      "challenging task due to the inter-class similarities and intra-class\n",
      "disparities introducing grave concerns in addressing multi-class classification\n",
      "problems. Conventional machine learning-based image prediction relies heavily\n",
      "on pre-processing such as normalization and segmentation followed by\n",
      "hand-crafted feature extraction before classification to identify useful and\n",
      "informative as well as application specific features.We propose an end-to-end\n",
      "Protein Localization Convolutional Neural Network (PLCNN) that classifies\n",
      "protein localization images more accurately and reliably. PLCNN directly\n",
      "processes raw imagery without involving any pre-processing steps and produces\n",
      "outputs without any customization or parameter adjustment for a particular\n",
      "dataset. The output of our approach is computed from probabilities produced by\n",
      "the network. Experimental analysis is performed on five publicly available\n",
      "benchmark datasets. PLCNN consistently outperformed the existing\n",
      "state-of-the-art approaches from machine learning and deep architectures.\n",
      "\n",
      "    \n",
      "770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  By design, discriminatively trained neural network classifiers produce\n",
      "reliable predictions only for in-distribution samples. For their real-world\n",
      "deployments, detecting out-of-distribution (OOD) samples is essential. Assuming\n",
      "OOD to be outside the closed boundary of in-distribution, typical neural\n",
      "classifiers do not contain the knowledge of this boundary for OOD detection\n",
      "during inference. There have been recent approaches to instill this knowledge\n",
      "in classifiers by explicitly training the classifier with OOD samples close to\n",
      "the in-distribution boundary. However, these generated samples fail to cover\n",
      "the entire in-distribution boundary effectively, thereby resulting in a\n",
      "sub-optimal OOD detector. In this paper, we analyze the feasibility of such\n",
      "approaches by investigating the complexity of producing such \"effective\" OOD\n",
      "samples. We also propose a novel algorithm to generate such samples using a\n",
      "manifold learning network (e.g., variational autoencoder) and then train an n+1\n",
      "classifier for OOD detection, where the $n+1^{th}$ class represents the OOD\n",
      "samples. We compare our approach against several recent classifier-based OOD\n",
      "detectors on MNIST and Fashion-MNIST datasets. Overall the proposed approach\n",
      "consistently performs better than the others.\n",
      "\n",
      "    \n",
      "771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The multilingual BERT model is trained on 104 languages and meant to serve as\n",
      "a universal language model and tool for encoding sentences. We explore how well\n",
      "the model performs on several languages across several tasks: a diagnostic\n",
      "classification probing the embeddings for a particular syntactic property, a\n",
      "cloze task testing the language modelling ability to fill in gaps in a\n",
      "sentence, and a natural language generation task testing for the ability to\n",
      "produce coherent text fitting a given context. We find that the currently\n",
      "available multilingual BERT model is clearly inferior to the monolingual\n",
      "counterparts, and cannot in many cases serve as a substitute for a well-trained\n",
      "monolingual model. We find that the English and German models perform well at\n",
      "generation, whereas the multilingual model is lacking, in particular, for\n",
      "Nordic languages.\n",
      "\n",
      "    \n",
      "772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generative adversarial networks (GANs) are a powerful approach to\n",
      "unsupervised learning. They have achieved state-of-the-art performance in the\n",
      "image domain. However, GANs are limited in two ways. They often learn\n",
      "distributions with low support---a phenomenon known as mode collapse---and they\n",
      "do not guarantee the existence of a probability density, which makes evaluating\n",
      "generalization using predictive log-likelihood impossible. In this paper, we\n",
      "develop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs\n",
      "add noise to the output of a density network and optimize an\n",
      "entropy-regularized adversarial loss. The added noise renders tractable\n",
      "approximations of the predictive log-likelihood and stabilizes the training\n",
      "procedure. The entropy regularizer encourages PresGANs to capture all the modes\n",
      "of the data distribution. Fitting PresGANs involves computing the intractable\n",
      "gradients of the entropy regularization term; PresGANs sidestep this\n",
      "intractability using unbiased stochastic estimates. We evaluate PresGANs on\n",
      "several datasets and found they mitigate mode collapse and generate samples\n",
      "with high perceptual quality. We further found that PresGANs reduce the gap in\n",
      "performance in terms of predictive log-likelihood between traditional GANs and\n",
      "variational autoencoders (VAEs).\n",
      "\n",
      "    \n",
      "773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a domain adaptation (DA) system that can be used in multi-source\n",
      "and semi-supervised settings. Using the proposed method we achieved 2nd place\n",
      "on multi-source track and 3rd place on semi-supervised track of the VisDA 2019\n",
      "challenge (this http URL). The source code of the method is\n",
      "available at this https URL.\n",
      "\n",
      "    \n",
      "774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  To accelerate DNNs inference, low-rank approximation has been widely adopted\n",
      "because of its solid theoretical rationale and efficient implementations.\n",
      "Several previous works attempted to directly approximate a pre-trained model by\n",
      "low-rank decomposition; however, small approximation errors in parameters can\n",
      "ripple over a large prediction loss. Apparently, it is not optimal to separate\n",
      "low-rank approximation from training. Unlike previous works, this paper\n",
      "integrates low rank approximation and regularization into the training process.\n",
      "We propose Trained Rank Pruning (TRP), which alternates between low rank\n",
      "approximation and training. TRP maintains the capacity of the original network\n",
      "while imposing low-rank constraints during training. A nuclear regularization\n",
      "optimized by stochastic sub-gradient descent is utilized to further promote low\n",
      "rank in TRP. Networks trained with TRP has a low-rank structure in nature, and\n",
      "is approximated with negligible performance loss, thus eliminating fine-tuning\n",
      "after low rank approximation. The proposed method is comprehensively evaluated\n",
      "on CIFAR-10 and ImageNet, outperforming previous compression counterparts using\n",
      "low rank approximation. Our code is available at:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Interpretability methods often measure the contribution of an input feature\n",
      "to an image classifier's decisions by heuristically removing it via e.g.\n",
      "blurring, adding noise, or graying out, which often produce unrealistic,\n",
      "out-of-samples. Instead, we propose to integrate a generative inpainter into\n",
      "three representative attribution methods to remove an input feature. Compared\n",
      "to the original counterparts, our methods (1) generate more plausible\n",
      "counterfactual samples under the true data generating process; (2) are more\n",
      "robust to hyperparameter settings; and (3) localize objects more accurately.\n",
      "Our findings were consistent across both ImageNet and Places365 datasets and\n",
      "two different pairs of classifiers and inpainters.\n",
      "\n",
      "    \n",
      "776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  With the ubiquity of sensors in the IoT era, statistical observations are\n",
      "becoming increasingly available in the form of massive (multivariate)\n",
      "time-series. Formulated as unsupervised anomaly detection tasks, an abundance\n",
      "of applications like aviation safety management, the health monitoring of\n",
      "complex infrastructures or fraud detection can now rely on such functional\n",
      "data, acquired and stored with an ever finer granularity. The concept of\n",
      "statistical depth, which reflects centrality of an arbitrary observation w.r.t.\n",
      "a statistical population may play a crucial role in this regard, anomalies\n",
      "corresponding to observations with 'small' depth. Supported by sound\n",
      "theoretical and computational developments in the recent decades, it has proven\n",
      "to be extremely useful, in particular in functional spaces. However, most\n",
      "approaches documented in the literature consist in evaluating independently the\n",
      "centrality of each point forming the time series and consequently exhibit a\n",
      "certain insensitivity to possible shape changes. In this paper, we propose a\n",
      "novel notion of functional depth based on the area of the convex hull of\n",
      "sampled curves, capturing gradual departures from centrality, even beyond the\n",
      "envelope of the data, in a natural fashion. We discuss practical relevance of\n",
      "commonly imposed axioms on functional depths and investigate which of them are\n",
      "satisfied by the notion of depth we promote here. Estimation and computational\n",
      "issues are also addressed and various numerical experiments provide empirical\n",
      "evidence of the relevance of the approach proposed.\n",
      "\n",
      "    \n",
      "777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Criminal and victim identification based on crime scene images is an\n",
      "important part of forensic investigation. Criminals usually avoid\n",
      "identification by covering their faces and tattoos in the evidence images,\n",
      "which are taken in uncontrolled environments. Existing identification methods,\n",
      "which make use of biometric traits, such as vein, skin mark, height, skin\n",
      "color, weight, race, etc., are considered for solving this problem. The soft\n",
      "biometric traits, including skin color, gender, height, weight and race,\n",
      "provide useful information but not distinctive enough. Veins and skin marks are\n",
      "limited to high resolution images and some body sites may neither have enough\n",
      "skin marks nor clear veins. Terrorists and rioters tend to expose their wrists\n",
      "in a gesture of triumph, greeting or salute, while paedophiles usually show\n",
      "them when touching victims. However, wrists were neglected by the biometric\n",
      "community for forensic applications. In this paper, a wrist identification\n",
      "algorithm, which includes skin segmentation, key point localization, image to\n",
      "template alignment, large feature set extraction, and classification, is\n",
      "proposed. The proposed algorithm is evaluated on NTU-Wrist-Image-Database-v1,\n",
      "which consists of 3945 images from 731 different wrists, including 205 pairs of\n",
      "wrist images collected from the Internet, taken under uneven illuminations with\n",
      "different poses and resolutions. The experimental results show that wrist is a\n",
      "useful clue for criminal and victim identification. Keywords: biometrics,\n",
      "criminal and victim identification, forensics, wrist.\n",
      "\n",
      "    \n",
      "778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Although there is an unprecedented effort to provide adequate responses in\n",
      "terms of laws and policies to hate content on social media platforms, dealing\n",
      "with hatred online is still a tough problem. Tackling hate speech in the\n",
      "standard way of content deletion or user suspension may be charged with\n",
      "censorship and overblocking. One alternate strategy, that has received little\n",
      "attention so far by the research community, is to actually oppose hate content\n",
      "with counter-narratives (i.e. informed textual responses). In this paper, we\n",
      "describe the creation of the first large-scale, multilingual, expert-based\n",
      "dataset of hate speech/counter-narrative pairs. This dataset has been built\n",
      "with the effort of more than 100 operators from three different NGOs that\n",
      "applied their training and expertise to the task. Together with the collected\n",
      "data we also provide additional annotations about expert demographics, hate and\n",
      "response type, and data augmentation through translation and paraphrasing.\n",
      "Finally, we provide initial experiments to assess the quality of our data.\n",
      "\n",
      "    \n",
      "779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Irrespective of the fact that Machine learning has produced groundbreaking\n",
      "results, it demands an enormous amount of data in order to perform so. Even\n",
      "though data production has been in its all-time high, almost all the data is\n",
      "unlabelled, hence making them unsuitable for training the algorithms. This\n",
      "paper proposes a novel method of extracting the features using Dynamic Mode\n",
      "Decomposition (DMD). The experiment is performed using data samples from\n",
      "Imagenet. The learning is done using SVM-linear, SVM-RBF, Random Kitchen Sink\n",
      "approach (RKS). The results have shown that DMD features with RKS give\n",
      "competing results.\n",
      "\n",
      "    \n",
      "780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Presence of bias and confounding effects is inarguably one of the most\n",
      "critical challenges in machine learning applications that has alluded to\n",
      "pivotal debates in the recent years. Such challenges range from spurious\n",
      "associations of confounding variables in medical studies to the bias of race in\n",
      "gender or face recognition systems. One solution is to enhance datasets and\n",
      "organize them such that they do not reflect biases, which is a cumbersome and\n",
      "intensive task. The alternative is to make use of available data and build\n",
      "models considering these biases. Traditional statistical methods apply\n",
      "straightforward techniques such as residualization or stratification to\n",
      "precomputed features to account for confounding variables. However, these\n",
      "techniques are generally not suitable for end-to-end deep learning methods. In\n",
      "this paper, we propose a method based on the adversarial training strategy to\n",
      "learn discriminative features unbiased and invariant to the confounder(s). This\n",
      "is enabled by incorporating a new adversarial loss function that encourages a\n",
      "vanished correlation between the bias and learned features. We apply our method\n",
      "to synthetic data, medical images, and a gender classification (Gender Shades\n",
      "Pilot Parliaments Benchmark) dataset. Our results show that the learned\n",
      "features by our method not only result in superior prediction performance but\n",
      "also are uncorrelated with the bias or confounder variables. The code is\n",
      "available at this http URL.\n",
      "\n",
      "    \n",
      "781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The major challenge of learning from multi-label data has arisen from the\n",
      "overwhelming size of label space which makes this problem NP-hard. This problem\n",
      "can be alleviated by gradually involving easy to hard tags into the learning\n",
      "process. Besides, the utilization of a diversity maintenance approach avoids\n",
      "overfitting on a subset of easy labels. In this paper, we propose a self-paced\n",
      "multi-label learning with diversity (SPMLD) which aims to cover diverse labels\n",
      "with respect to its learning pace. In addition, the proposed framework is\n",
      "applied to an efficient correlation-based multi-label method. The non-convex\n",
      "objective function is optimized by an extension of the block coordinate descent\n",
      "algorithm. Empirical evaluations on real-world datasets with different\n",
      "dimensions of features and labels imply the effectiveness of the proposed\n",
      "predictive model.\n",
      "\n",
      "    \n",
      "782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce the Mutual Information Machine (MIM), an autoencoder model for\n",
      "learning joint distributions over observations and latent states. The model\n",
      "formulation reflects two key design principles: 1) symmetry, to encourage the\n",
      "encoder and decoder to learn consistent factorizations of the same underlying\n",
      "distribution; and 2) mutual information, to encourage the learning of useful\n",
      "representations for downstream tasks. The objective comprises the\n",
      "Jensen-Shannon divergence between the encoding and decoding joint\n",
      "distributions, plus a mutual information term. We show that this objective can\n",
      "be bounded by a tractable cross-entropy loss between the true model and a\n",
      "parameterized approximation, and relate this to maximum likelihood estimation\n",
      "and variational autoencoders. Experiments show that MIM is capable of learning\n",
      "a latent representation with high mutual information, and good unsupervised\n",
      "clustering, while providing data log likelihood comparable to VAE (with a\n",
      "sufficiently expressive architecture).\n",
      "\n",
      "    \n",
      "783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Sample-efficient exploration is crucial not only for discovering rewarding\n",
      "experiences but also for adapting to environment changes in a task-agnostic\n",
      "fashion. A principled treatment of the problem of optimal input synthesis for\n",
      "system identification is provided within the framework of sequential Bayesian\n",
      "experimental design. In this paper, we present an effective\n",
      "trajectory-optimization-based approximate solution of this otherwise\n",
      "intractable problem that models optimal exploration in an unknown Markov\n",
      "decision process (MDP). By interleaving episodic exploration with Bayesian\n",
      "nonlinear system identification, our algorithm takes advantage of the inductive\n",
      "bias to explore in a directed manner, without assuming prior knowledge of the\n",
      "MDP. Empirical evaluations indicate a clear advantage of the proposed algorithm\n",
      "in terms of the rate of convergence and the final model fidelity when compared\n",
      "to intrinsic-motivation-based algorithms employing exploration bonuses such as\n",
      "prediction error and information gain. Moreover, our method maintains a\n",
      "computational advantage over a recent model-based active exploration (MAX)\n",
      "algorithm, by focusing on the information gain along trajectories instead of\n",
      "seeking a global exploration policy. A reference implementation of our\n",
      "algorithm and the conducted experiments is publicly available.\n",
      "\n",
      "    \n",
      "784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Previous works \\citep{donahue2018adversarial, engel2019gansynth} have found\n",
      "that generating coherent raw audio waveforms with GANs is challenging. In this\n",
      "paper, we show that it is possible to train GANs reliably to generate high\n",
      "quality coherent waveforms by introducing a set of architectural changes and\n",
      "simple training techniques. Subjective evaluation metric (Mean Opinion Score,\n",
      "or MOS) shows the effectiveness of the proposed approach for high quality\n",
      "mel-spectrogram inversion. To establish the generality of the proposed\n",
      "techniques, we show qualitative results of our model in speech synthesis, music\n",
      "domain translation and unconditional music synthesis. We evaluate the various\n",
      "components of the model through ablation studies and suggest a set of\n",
      "guidelines to design general purpose discriminators and generators for\n",
      "conditional sequence synthesis tasks. Our model is non-autoregressive, fully\n",
      "convolutional, with significantly fewer parameters than competing models and\n",
      "generalizes to unseen speakers for mel-spectrogram inversion. Our pytorch\n",
      "implementation runs at more than 100x faster than realtime on GTX 1080Ti GPU\n",
      "and more than 2x faster than real-time on CPU, without any hardware specific\n",
      "optimization tricks. Blog post with samples and accompanying code coming soon.\n",
      "\n",
      "    \n",
      "785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning useful representations is a key ingredient to the success of modern\n",
      "machine learning. Currently, representation learning mostly relies on embedding\n",
      "data into Euclidean space. However, recent work has shown that data in some\n",
      "domains is better modeled by non-euclidean metric spaces, and inappropriate\n",
      "geometry can result in inferior performance. In this paper, we aim to eliminate\n",
      "the inductive bias imposed by the embedding space geometry. Namely, we propose\n",
      "to map data into more general non-vector metric spaces: a weighted graph with a\n",
      "shortest path distance. By design, such graphs can model arbitrary geometry\n",
      "with a proper configuration of edges and weights. Our main contribution is\n",
      "PRODIGE: a method that learns a weighted graph representation of data\n",
      "end-to-end by gradient descent. Greater generality and fewer model assumptions\n",
      "make PRODIGE more powerful than existing embedding-based approaches. We confirm\n",
      "the superiority of our method via extensive experiments on a wide range of\n",
      "tasks, including classification, compression, and collaborative filtering.\n",
      "\n",
      "    \n",
      "786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a visual imitation learning framework that enables learning of\n",
      "robot action policies solely based on expert samples without any robot trials.\n",
      "Robot exploration and on-policy trials in a real-world environment could often\n",
      "be expensive/dangerous. We present a new approach to address this problem by\n",
      "learning a future scene prediction model solely on a collection of expert\n",
      "trajectories consisting of unlabeled example videos and actions, and by\n",
      "enabling generalized action cloning using future image similarity. The robot\n",
      "learns to visually predict the consequences of taking an action, and obtains\n",
      "the policy by evaluating how similar the predicted future image is to an expert\n",
      "image. We develop a stochastic action-conditioned convolutional autoencoder,\n",
      "and present how we take advantage of future images for robot learning. We\n",
      "conduct experiments in simulated and real-life environments using a ground\n",
      "mobility robot with and without obstacles, and compare our models to multiple\n",
      "baseline methods.\n",
      "\n",
      "    \n",
      "787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While it is widely known that neural networks are universal approximators of\n",
      "continuous functions, a less known and perhaps more powerful result is that a\n",
      "neural network with a single hidden layer can approximate accurately any\n",
      "nonlinear continuous operator \\cite{chen1995universal}. This universal\n",
      "approximation theorem is suggestive of the potential application of neural\n",
      "networks in learning nonlinear operators from data. However, the theorem\n",
      "guarantees only a small approximation error for a sufficient large network, and\n",
      "does not consider the important optimization and generalization errors. To\n",
      "realize this theorem in practice, we propose deep operator networks (DeepONets)\n",
      "to learn operators accurately and efficiently from a relatively small dataset.\n",
      "A DeepONet consists of two sub-networks, one for encoding the input function at\n",
      "a fixed number of sensors $x_i, i=1,\\dots,m$ (branch net), and another for\n",
      "encoding the locations for the output functions (trunk net). We perform\n",
      "systematic simulations for identifying two types of operators, i.e., dynamic\n",
      "systems and partial differential equations, and demonstrate that DeepONet\n",
      "significantly reduces the generalization error compared to the fully-connected\n",
      "networks. We also derive theoretically the dependence of the approximation\n",
      "error in terms of the number of sensors (where the input function is defined)\n",
      "as well as the input function type, and we verify the theorem with\n",
      "computational results. More importantly, we observe high-order error\n",
      "convergence in our computational tests, namely polynomial rates (from half\n",
      "order to fourth order) and even exponential convergence with respect to the\n",
      "training dataset size.\n",
      "\n",
      "    \n",
      "788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep neural networks are susceptible to adversarial manipulations in the\n",
      "input domain. The extent of vulnerability has been explored intensively in\n",
      "cases of $\\ell_p$-bounded and $\\ell_p$-minimal adversarial perturbations.\n",
      "However, the vulnerability of DNNs to adversarial perturbations with specific\n",
      "statistical properties or frequency-domain characteristics has not been\n",
      "sufficiently explored. In this paper, we study the smoothness of perturbations\n",
      "and propose SmoothFool, a general and computationally efficient framework for\n",
      "computing smooth adversarial perturbations. Through extensive experiments, we\n",
      "validate the efficacy of the proposed method for both the white-box and\n",
      "black-box attack scenarios. In particular, we demonstrate that: (i) there exist\n",
      "extremely smooth adversarial perturbations for well-established and widely used\n",
      "network architectures, (ii) smoothness significantly enhances the robustness of\n",
      "perturbations against state-of-the-art defense mechanisms, (iii) smoothness\n",
      "improves the transferability of adversarial perturbations across both data\n",
      "points and network architectures, and (iv) class categories exhibit a variable\n",
      "range of susceptibility to smooth perturbations. Our results suggest that\n",
      "smooth APs can play a significant role in exploring the vulnerability extent of\n",
      "DNNs to adversarial examples.\n",
      "\n",
      "    \n",
      "789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Painting captions are often dry and simplistic which motivates us to describe\n",
      "a painting creatively in the style of Shakespearean prose. This is a difficult\n",
      "problem, since there does not exist a large supervised dataset from paintings\n",
      "to Shakespearean prose. Our solution is to use an intermediate English poem\n",
      "description of the painting and then apply language style transfer which\n",
      "results in Shakespearean prose describing the painting. We rate our results by\n",
      "human evaluation on a Likert scale, and evaluate the quality of language style\n",
      "transfer using BLEU score as a function of prose length. We demonstrate the\n",
      "applicability and limitations of our approach by generating Shakespearean prose\n",
      "for famous paintings. We make our models and code publicly available.\n",
      "\n",
      "    \n",
      "790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Understanding human visual attention and saliency is an integral part of\n",
      "vision research. In this context, there is an ever-present need for fresh and\n",
      "diverse benchmark datasets, particularly for insight into special use cases\n",
      "like crowded scenes. We contribute to this end by: (1) reviewing the dynamics\n",
      "behind saliency and crowds. (2) using eye tracking to create a dynamic human\n",
      "eye fixation dataset over a new set of crowd videos gathered from the Internet.\n",
      "The videos are annotated into three distinct density levels. (3) Finally, we\n",
      "evaluate state-of-the-art saliency models on our dataset to identify possible\n",
      "improvements for the design and creation of a more robust saliency model.\n",
      "\n",
      "    \n",
      "791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Failures are challenging for learning to control physical systems since they\n",
      "risk damage, time-consuming resets, and often provide little gradient\n",
      "information. Adding safety constraints to exploration typically requires a lot\n",
      "of prior knowledge and domain expertise. We present a safety measure which\n",
      "implicitly captures how the system dynamics relate to a set of failure states.\n",
      "Not only can this measure be used as a safety function, but also to directly\n",
      "compute the set of safe state-action pairs. Further, we show a model-free\n",
      "approach to learn this measure by active sampling using Gaussian processes.\n",
      "While safety can only be guaranteed after learning the safety measure, we show\n",
      "that failures can already be greatly reduced by using the estimated measure\n",
      "during learning.\n",
      "\n",
      "    \n",
      "792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  PyODDS is an end-to end Python system for outlier detection with database\n",
      "support. PyODDS provides outlier detection algorithms which meet the demands\n",
      "for users in different fields, w/wo data science or machine learning\n",
      "background. PyODDS gives the ability to execute machine learning algorithms\n",
      "in-database without moving data out of the database server or over the network.\n",
      "It also provides access to a wide range of outlier detection algorithms,\n",
      "including statistical analysis and more recent deep learning based approaches.\n",
      "PyODDS is released under the MIT open-source license, and currently available\n",
      "at (this https URL) with official documentations at\n",
      "(this https URL).\n",
      "\n",
      "    \n",
      "793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We cast the problem of image denoising as a domain translation problem\n",
      "between high and low noise domains. By modifying the cycleGAN model, we are\n",
      "able to learn a mapping between these domains on unpaired retinal optical\n",
      "coherence tomography images. In quantitative measurements and a qualitative\n",
      "evaluation by ophthalmologists, we show how this approach outperforms other\n",
      "established methods. The results indicate that the network differentiates\n",
      "subtle changes in the level of noise in the image. Further investigation of the\n",
      "model's feature maps reveals that it has learned to distinguish retinal layers\n",
      "and other distinct regions of the images.\n",
      "\n",
      "    \n",
      "794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generating point clouds, e.g., molecular structures, in arbitrary rotations,\n",
      "translations, and enumerations remains a challenging task. Meanwhile, neural\n",
      "networks utilizing symmetry invariant layers have been shown to be able to\n",
      "optimize their training objective in a data-efficient way. In this spirit, we\n",
      "present an architecture which allows to produce valid Euclidean distance\n",
      "matrices, which by construction are already invariant under rotation and\n",
      "translation of the described object. Motivated by the goal to generate\n",
      "molecular structures in Cartesian space, we use this architecture to construct\n",
      "a Wasserstein GAN utilizing a permutation invariant critic network. This makes\n",
      "it possible to generate molecular structures in a one-shot fashion by producing\n",
      "Euclidean distance matrices which have a three-dimensional embedding.\n",
      "\n",
      "    \n",
      "795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A defining characteristic of intelligent systems is the ability to make\n",
      "action decisions based on the anticipated outcomes. Video prediction systems\n",
      "have been demonstrated as a solution for predicting how the future will unfold\n",
      "visually, and thus, many models have been proposed that are capable of\n",
      "predicting future frames based on a history of observed frames~(and sometimes\n",
      "robot actions). However, a comprehensive method for determining the fitness of\n",
      "different video prediction models at guiding the selection of actions is yet to\n",
      "be developed. Current metrics assess video prediction models based on human\n",
      "perception of frame quality. In contrast, we argue that if these systems are to\n",
      "be used to guide action, necessarily, the actions the robot performs should be\n",
      "encoded in the predicted frames. In this paper, we are proposing a new metric\n",
      "to compare different video prediction models based on this argument. More\n",
      "specifically, we propose an action inference system and quantitatively rank\n",
      "different models based on how well we can infer the robot actions from the\n",
      "predicted frames. Our extensive experiments show that models with high\n",
      "perceptual scores can perform poorly in the proposed action inference tests and\n",
      "thus, may not be suitable options to be used in robot planning systems.\n",
      "\n",
      "    \n",
      "796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The homogeneous transformation between a LiDAR and monocular camera is\n",
      "required for sensor fusion tasks, such as SLAM. While determining such a\n",
      "transformation is not considered glamorous in any sense of the word, it is\n",
      "nonetheless crucial for many modern autonomous systems. Indeed, an error of a\n",
      "few degrees in rotation or a few percent in translation can lead to 20 cm\n",
      "translation errors at a distance of 5 m when overlaying a LiDAR image on a\n",
      "camera image. The biggest impediments to determining the transformation\n",
      "accurately are the relative sparsity of LiDAR point clouds and systematic\n",
      "errors in their distance measurements. This paper proposes (1) the use of\n",
      "targets of known dimension and geometry to ameliorate target pose estimation in\n",
      "face of the quantization and systematic errors inherent in a LiDAR image of a\n",
      "target, and (2) a fitting method for the LiDAR to monocular camera\n",
      "transformation that fundamentally assumes the camera image data is the most\n",
      "accurate information in one's possession.\n",
      "\n",
      "    \n",
      "797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to generate natural language explanations conditioned on the\n",
      "visual perception is a crucial step towards autonomous agents which can explain\n",
      "themselves and communicate with humans. While the research efforts in image and\n",
      "video captioning are giving promising results, this is often done at the\n",
      "expense of the computational requirements of the approaches, limiting their\n",
      "applicability to real contexts. In this paper, we propose a fully-attentive\n",
      "captioning algorithm which can provide state of the art performances on\n",
      "language generation while restricting its computational demands. Our model is\n",
      "inspired by the Transformer model and employs only two Transformer layers in\n",
      "the encoding and decoding stages. Further, it incorporates a novel memory-aware\n",
      "encoding of image regions. Experiments demonstrate that our approach is state\n",
      "of the art in terms of caption quality while featuring reduced computational\n",
      "demands. Further, to evaluate its applicability on autonomous agents, we\n",
      "conduct experiments on simulated scenes taken from the perspective of domestic\n",
      "robots.\n",
      "\n",
      "    \n",
      "798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  From social networks to protein complexes to disease genomes to visual data,\n",
      "hypergraphs are everywhere. However, the scope of research studying deep\n",
      "learning on hypergraphs is still quite sparse and nascent, as there has not yet\n",
      "existed an effective, unified framework for using hyperedge and vertex\n",
      "embeddings jointly in the hypergraph context, despite a large body of prior\n",
      "work that has shown the utility of deep learning over graphs and sets. Building\n",
      "upon these recent advances, we propose \\textit{Deep Hyperedges} (DHE), a\n",
      "modular framework that jointly uses contextual and permutation-invariant vertex\n",
      "membership properties of hyperedges in hypergraphs to perform classification\n",
      "and regression in transductive and inductive learning settings. In our\n",
      "experiments, we use a novel random walk procedure and show that our model\n",
      "achieves and, in most cases, surpasses state-of-the-art performance on\n",
      "benchmark datasets. Additionally, we study our framework's performance on a\n",
      "variety of diverse, non-standard hypergraph datasets and propose several\n",
      "avenues of future work to further enhance DHE.\n",
      "\n",
      "    \n",
      "799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  For many linear and nonlinear systems that arise from the discretization of\n",
      "partial differential equations the construction of an efficient multigrid\n",
      "solver is a challenging task. Here we present a novel approach for the\n",
      "optimization of geometric multigrid methods that is based on evolutionary\n",
      "computation, a generic program optimization technique inspired by the principle\n",
      "of natural evolution. A multigrid solver is represented as a tree of\n",
      "mathematical expressions which we generate based on a tailored grammar. The\n",
      "quality of each solver is evaluated in terms of convergence and compute\n",
      "performance using automated local Fourier analysis (LFA) and roofline\n",
      "performance modeling, respectively. Based on these objectives a multi-objective\n",
      "optimization is performed using strongly typed genetic programming with a\n",
      "non-dominated sorting based selection. To evaluate the model-based prediction\n",
      "and to target concrete applications, scalable implementations of an evolved\n",
      "solver can be automatically generated with the ExaStencils framework. We\n",
      "demonstrate our approach by constructing multigrid solvers for the steady-state\n",
      "heat equation with constant and variable coefficients that consistently perform\n",
      "better than common V- and W-cycles.\n",
      "\n",
      "    \n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The last decades have witnessed the breakthrough of autonomous vehicles\n",
      "(AVs), and the perception capabilities of AVs have been dramatically improved.\n",
      "Various sensors installed on AVs, including, but are not limited to, LiDAR,\n",
      "radar, camera and stereovision, will be collecting massive data and perceiving\n",
      "the surrounding traffic states continuously. In fact, a fleet of AVs can serve\n",
      "as floating (or probe) sensors, which can be utilized to infer traffic\n",
      "information while cruising around the roadway networks. In contrast,\n",
      "conventional traffic sensing methods rely on fixed traffic sensors such as loop\n",
      "detectors, cameras and microwave vehicle detectors. Due to the high cost of\n",
      "conventional traffic sensors, traffic state data are usually obtained in a\n",
      "low-frequency and sparse manner. In view of this, this paper leverages rich\n",
      "data collected through AVs to propose the high-resolution traffic sensing\n",
      "framework. The proposed framework estimates the fundamental traffic state\n",
      "variables, namely, flow, density and speed in high spatio-temporal resolution,\n",
      "and it is developed under different levels of AV perception capabilities and\n",
      "low AV market penetration rate. The Next Generation Simulation (NGSIM) data is\n",
      "adopted to examine the accuracy and robustness of the proposed framework.\n",
      "Experimental results show that the proposed estimation framework achieves high\n",
      "accuracy even with low AV market penetration rate. Sensitivity analysis\n",
      "regarding AV penetration rate, sensor configuration, and perception accuracy\n",
      "will also be studied. This study will help policymakers and private sectors\n",
      "(e.g Uber, Waymo) to understand the values of AVs, especially the values of\n",
      "massive data collected by AVs, in traffic operation and management.\n",
      "\n",
      "    \n",
      "801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent developments in Named Entity Recognition (NER) have resulted in better\n",
      "and better models. However, is there a glass ceiling? Do we know which types of\n",
      "errors are still hard or even impossible to correct? In this paper, we present\n",
      "a detailed analysis of the types of errors in state-of-the-art machine learning\n",
      "(ML) methods. Our study reveals the weak and strong points of the Stanford,\n",
      "CMU, FLAIR, ELMO and BERT models, as well as their shared limitations. We also\n",
      "introduce new techniques for improving annotation, for training processes and\n",
      "for checking a model's quality and stability. Presented results are based on\n",
      "the CoNLL 2003 data set for the English language. A new enriched semantic\n",
      "annotation of errors for this data set and new diagnostic data sets are\n",
      "attached in the supplementary materials.\n",
      "\n",
      "    \n",
      "802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  When humans observe a physical system, they can easily locate objects,\n",
      "understand their interactions, and anticipate future behavior, even in settings\n",
      "with complicated and previously unseen interactions. For computers, however,\n",
      "learning such models from videos in an unsupervised fashion is an unsolved\n",
      "research problem. In this paper, we present STOVE, a novel state-space model\n",
      "for videos, which explicitly reasons about objects and their positions,\n",
      "velocities, and interactions. It is constructed by combining an image model and\n",
      "a dynamics model in compositional manner and improves on previous work by\n",
      "reusing the dynamics model for inference, accelerating and regularizing\n",
      "training. STOVE predicts videos with convincing physical behavior over hundreds\n",
      "of timesteps, outperforms previous unsupervised models, and even approaches the\n",
      "performance of supervised baselines. We further demonstrate the strength of our\n",
      "model as a simulator for sample efficient model-based control in a task with\n",
      "heavily interacting objects.\n",
      "\n",
      "    \n",
      "803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While translating between East Asian languages, many works have discovered\n",
      "clear advantages of using characters as the translation unit. Unfortunately,\n",
      "traditional recurrent neural machine translation systems hinder the practical\n",
      "usage of those character-based systems due to their architectural limitations.\n",
      "They are unfavorable in handling extremely long sequences as well as highly\n",
      "restricted in parallelizing the computations. In this paper, we demonstrate\n",
      "that the new transformer architecture can perform character-based translation\n",
      "better than the recurrent one. We conduct experiments on a low-resource\n",
      "language pair: Japanese-Vietnamese. Our models considerably outperform the\n",
      "state-of-the-art systems which employ word-based recurrent architectures.\n",
      "\n",
      "    \n",
      "804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In fighting against fake news, many fact-checking systems comprised of\n",
      "human-based fact-checking sites (e.g., this http URL and this http URL) and\n",
      "automatic detection systems have been developed in recent years. However,\n",
      "online users still keep sharing fake news even when it has been debunked. It\n",
      "means that early fake news detection may be insufficient and we need another\n",
      "complementary approach to mitigate the spread of misinformation. In this paper,\n",
      "we introduce a novel application of text generation for combating fake news. In\n",
      "particular, we (1) leverage online users named \\emph{fact-checkers}, who cite\n",
      "fact-checking sites as credible evidences to fact-check information in public\n",
      "discourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n",
      "(3) propose and build a deep learning framework to generate responses with\n",
      "fact-checking intention to increase the fact-checkers' engagement in\n",
      "fact-checking activities. Our analysis reveals that the fact-checkers tend to\n",
      "refute misinformation and use formal language (e.g. few swear words and\n",
      "Internet slangs). Our framework successfully generates relevant responses, and\n",
      "outperforms competing models by achieving up to 30\\% improvements. Our\n",
      "qualitative study also confirms that the superiority of our generated responses\n",
      "compared with responses generated from the existing models.\n",
      "\n",
      "    \n",
      "805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Efforts are underway to study ways via which the power of deep neural\n",
      "networks can be extended to non-standard data types such as structured data\n",
      "(e.g., graphs) or manifold-valued data (e.g., unit vectors or special\n",
      "matrices). Often, sizable empirical improvements are possible when the geometry\n",
      "of such data spaces are incorporated into the design of the model,\n",
      "architecture, and the algorithms. Motivated by neuroimaging applications, we\n",
      "study formulations where the data are {\\em sequential manifold-valued\n",
      "measurements}. This case is common in brain imaging, where the samples\n",
      "correspond to symmetric positive definite matrices or orientation distribution\n",
      "functions. Instead of a recurrent model which poses computational/technical\n",
      "issues, and inspired by recent results showing the viability of dilated\n",
      "convolutional models for sequence prediction, we develop a dilated\n",
      "convolutional neural network architecture for this task. On the technical side,\n",
      "we show how the modules needed in our network can be derived while explicitly\n",
      "taking the Riemannian manifold structure into account. We show how the\n",
      "operations needed can leverage known results for calculating the weighted\n",
      "Fréchet Mean (wFM). Finally, we present scientific results for group\n",
      "difference analysis in Alzheimer's disease (AD) where the groups are derived\n",
      "using AD pathology load: here the model finds several brain fiber bundles that\n",
      "are related to AD even when the subjects are all still cognitively healthy.\n",
      "\n",
      "    \n",
      "806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Word embeddings have become a staple of several natural language processing\n",
      "tasks, yet much remains to be understood about their properties. In this work,\n",
      "we analyze word embeddings in terms of their principal components and arrive at\n",
      "a number of novel and counterintuitive observations. In particular, we\n",
      "characterize the utility of variance explained by the principal components as a\n",
      "proxy for downstream performance. Furthermore, through syntactic probing of the\n",
      "principal embedding space, we show that the syntactic information captured by a\n",
      "principal component does not correlate with the amount of variance it explains.\n",
      "Consequently, we investigate the limitations of variance based embedding\n",
      "post-processing and demonstrate that such post-processing is counter-productive\n",
      "in sentence classification and machine translation tasks. Finally, we offer a\n",
      "few precautionary guidelines on applying variance based embedding\n",
      "post-processing and explain why non-isotropic geometry might be integral to\n",
      "word embedding performance.\n",
      "\n",
      "    \n",
      "807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  3D skeleton-based action recognition and motion prediction are two essential\n",
      "problems of human activity understanding. In many previous works: 1) they\n",
      "studied two tasks separately, neglecting internal correlations; 2) they did not\n",
      "capture sufficient relations inside the body. To address these issues, we\n",
      "propose a symbiotic model to handle two tasks jointly; and we propose two\n",
      "scales of graphs to explicitly capture relations among body-joints and\n",
      "body-parts. Together, we propose symbiotic graph neural networks, which contain\n",
      "a backbone, an action-recognition head, and a motion-prediction head. Two heads\n",
      "are trained jointly and enhance each other. For the backbone, we propose\n",
      "multi-branch multi-scale graph convolution networks to extract spatial and\n",
      "temporal features. The multi-scale graph convolution networks are based on\n",
      "joint-scale and part-scale graphs. The joint-scale graphs contain actional\n",
      "graphs, capturing action-based relations, and structural graphs, capturing\n",
      "physical constraints. The part-scale graphs integrate body-joints to form\n",
      "specific parts, representing high-level relations. Moreover, dual bone-based\n",
      "graphs and networks are proposed to learn complementary features. We conduct\n",
      "extensive experiments for skeleton-based action recognition and motion\n",
      "prediction with four datasets, NTU-RGB+D, Kinetics, Human3.6M, and CMU Mocap.\n",
      "Experiments show that our symbiotic graph neural networks achieve better\n",
      "performances on both tasks compared to the state-of-the-art methods.\n",
      "\n",
      "    \n",
      "808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Training deep neural networks on large scientific data is a challenging task\n",
      "that requires enormous compute power, especially if no pre-trained models exist\n",
      "to initialize the process. We present a novel tournament method to train\n",
      "traditional as well as generative adversarial networks built on LBANN, a\n",
      "scalable deep learning framework optimized for HPC systems. LBANN combines\n",
      "multiple levels of parallelism and exploits some of the worlds largest\n",
      "supercomputers. We demonstrate our framework by creating a complex predictive\n",
      "model based on multi-variate data from high-energy-density physics containing\n",
      "hundreds of millions of images and hundreds of millions of scalar values\n",
      "derived from tens of millions of simulations of inertial confinement fusion.\n",
      "Our approach combines an HPC workflow and extends LBANN with optimized data\n",
      "ingestion and the new tournament-style training algorithm to produce a scalable\n",
      "neural network architecture using a CORAL-class supercomputer. Experimental\n",
      "results show that 64 trainers (1024 GPUs) achieve a speedup of 70.2 over a\n",
      "single trainer (16 GPUs) baseline, and an effective 109% parallel efficiency.\n",
      "\n",
      "    \n",
      "809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Dimensionality reduction plays an important role in computer vision problems\n",
      "since it reduces computational cost and is often capable of yielding more\n",
      "discriminative data representation. In this context, Partial Least Squares\n",
      "(PLS) has presented notable results in tasks such as image classification and\n",
      "neural network optimization. However, PLS is infeasible on large datasets\n",
      "(e.g., ImageNet) because it requires all the data to be in memory in advance,\n",
      "which is often impractical due to hardware limitations. Additionally, this\n",
      "requirement prevents us from employing PLS on streaming applications where the\n",
      "data are being continuously generated. Motivated by this, we propose a novel\n",
      "incremental PLS, named Covariance-free Incremental Partial Least Squares\n",
      "(CIPLS), which learns a low-dimensional representation of the data using a\n",
      "single sample at a time. In contrast to other state-of-the-art approaches,\n",
      "instead of adopting a partially-discriminative or SGD-based model, we extend\n",
      "Nonlinear Iterative Partial Least Squares (NIPALS) - the standard algorithm\n",
      "used to compute PLS - for incremental processing. Among the advantages of this\n",
      "approach are the preservation of discriminative information across all\n",
      "components, the possibility of employing its score matrices for feature\n",
      "selection, and its computational efficiency. We validate CIPLS on face\n",
      "verification and image classification tasks, where it outperforms several other\n",
      "incremental dimensionality reduction methods. In the context of feature\n",
      "selection, CIPLS achieves comparable results when compared to state-of-the-art\n",
      "techniques.\n",
      "\n",
      "    \n",
      "810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce MAgent, a platform to support research and development of\n",
      "many-agent reinforcement learning. Unlike previous research platforms on single\n",
      "or multi-agent reinforcement learning, MAgent focuses on supporting the tasks\n",
      "and the applications that require hundreds to millions of agents. Within the\n",
      "interactions among a population of agents, it enables not only the study of\n",
      "learning algorithms for agents' optimal polices, but more importantly, the\n",
      "observation and understanding of individual agent's behaviors and social\n",
      "phenomena emerging from the AI society, including communication languages,\n",
      "leaderships, altruism. MAgent is highly scalable and can host up to one million\n",
      "agents on a single GPU server. MAgent also provides flexible configurations for\n",
      "AI researchers to design their customized environments and agents. In this\n",
      "demo, we present three environments designed on MAgent and show emerged\n",
      "collective intelligence by learning from scratch.\n",
      "\n",
      "    \n",
      "811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore deep reinforcement learning methods for multi-agent domains. We\n",
      "begin by analyzing the difficulty of traditional algorithms in the multi-agent\n",
      "case: Q-learning is challenged by an inherent non-stationarity of the\n",
      "environment, while policy gradient suffers from a variance that increases as\n",
      "the number of agents grows. We then present an adaptation of actor-critic\n",
      "methods that considers action policies of other agents and is able to\n",
      "successfully learn policies that require complex multi-agent coordination.\n",
      "Additionally, we introduce a training regimen utilizing an ensemble of policies\n",
      "for each agent that leads to more robust multi-agent policies. We show the\n",
      "strength of our approach compared to existing methods in cooperative as well as\n",
      "competitive scenarios, where agent populations are able to discover various\n",
      "physical and informational coordination strategies.\n",
      "\n",
      "    \n",
      "812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of multiple agents sensing and acting in environments\n",
      "with the goal of maximising their shared utility. In these environments, agents\n",
      "must learn communication protocols in order to share information that is needed\n",
      "to solve the tasks. By embracing deep neural networks, we are able to\n",
      "demonstrate end-to-end learning of protocols in complex environments inspired\n",
      "by communication riddles and multi-agent computer vision problems with partial\n",
      "observability. We propose two approaches for learning in these domains:\n",
      "Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning\n",
      "(DIAL). The former uses deep Q-learning, while the latter exploits the fact\n",
      "that, during learning, agents can backpropagate error derivatives through\n",
      "(noisy) communication channels. Hence, this approach uses centralised learning\n",
      "but decentralised execution. Our experiments introduce new environments for\n",
      "studying the learning of communication protocols and present a set of\n",
      "engineering innovations that are essential for success in these domains.\n",
      "\n",
      "    \n",
      "813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In the last few years, deep multi-agent reinforcement learning (RL) has\n",
      "become a highly active area of research. A particularly challenging class of\n",
      "problems in this area is partially observable, cooperative, multi-agent\n",
      "learning, in which teams of agents must learn to coordinate their behaviour\n",
      "while conditioning only on their private observations. This is an attractive\n",
      "research area since such problems are relevant to a large number of real-world\n",
      "systems and are also more amenable to evaluation than general-sum problems.\n",
      "Standardised environments such as the ALE and MuJoCo have allowed single-agent\n",
      "RL to move beyond toy domains, such as grid worlds. However, there is no\n",
      "comparable benchmark for cooperative multi-agent RL. As a result, most papers\n",
      "in this field use one-off toy problems, making it difficult to measure real\n",
      "progress. In this paper, we propose the StarCraft Multi-Agent Challenge (SMAC)\n",
      "as a benchmark problem to fill this gap. SMAC is based on the popular real-time\n",
      "strategy game StarCraft II and focuses on micromanagement challenges where each\n",
      "unit is controlled by an independent agent that must act based on local\n",
      "observations. We offer a diverse set of challenge maps and recommendations for\n",
      "best practices in benchmarking and evaluations. We also open-source a deep\n",
      "multi-agent RL learning framework including state-of-the-art algorithms. We\n",
      "believe that SMAC can provide a standard benchmark environment for years to\n",
      "come. Videos of our best agents for several SMAC scenarios are available at:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In many real-world settings, a team of agents must coordinate their behaviour\n",
      "while acting in a decentralised way. At the same time, it is often possible to\n",
      "train the agents in a centralised fashion in a simulated or laboratory setting,\n",
      "where global state information is available and communication constraints are\n",
      "lifted. Learning joint action-values conditioned on extra state information is\n",
      "an attractive way to exploit centralised learning, but the best strategy for\n",
      "then extracting decentralised policies is unclear. Our solution is QMIX, a\n",
      "novel value-based method that can train decentralised policies in a centralised\n",
      "end-to-end fashion. QMIX employs a network that estimates joint action-values\n",
      "as a complex non-linear combination of per-agent values that condition only on\n",
      "local observations. We structurally enforce that the joint-action value is\n",
      "monotonic in the per-agent values, which allows tractable maximisation of the\n",
      "joint action-value in off-policy learning, and guarantees consistency between\n",
      "the centralised and decentralised policies. We evaluate QMIX on a challenging\n",
      "set of StarCraft II micromanagement tasks, and show that QMIX significantly\n",
      "outperforms existing value-based multi-agent reinforcement learning methods.\n",
      "\n",
      "    \n",
      "815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  RLCard is an open-source toolkit for reinforcement learning research in card\n",
      "games. It supports various card environments with easy-to-use interfaces,\n",
      "including Blackjack, Leduc Hold'em, Texas Hold'em, UNO, Dou Dizhu and Mahjong.\n",
      "The goal of RLCard is to bridge reinforcement learning and imperfect\n",
      "information games, and push forward the research of reinforcement learning in\n",
      "domains with multiple agents, large state and action space, and sparse reward.\n",
      "In this paper, we provide an overview of the key components in RLCard, a\n",
      "discussion of the design principles, a brief introduction of the interfaces,\n",
      "and comprehensive evaluations of the environments. The codes and documents are\n",
      "available at this https URL\n",
      "\n",
      "816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning in multi-agent scenarios is a fruitful research direction, but\n",
      "current approaches still show scalability problems in multiple games with\n",
      "general reward settings and different opponent types. The Multi-Agent\n",
      "Reinforcement Learning in MalmÖ (MARLÖ) competition is a new challenge that\n",
      "proposes research in this domain using multiple 3D games. The goal of this\n",
      "contest is to foster research in general agents that can learn across different\n",
      "games and opponent types, proposing a challenge as a milestone in the direction\n",
      "of Artificial General Intelligence.\n",
      "\n",
      "    \n",
      "817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Traffic signal control is an emerging application scenario for reinforcement\n",
      "learning. Besides being as an important problem that affects people's daily\n",
      "life in commuting, traffic signal control poses its unique challenges for\n",
      "reinforcement learning in terms of adapting to dynamic traffic environment and\n",
      "coordinating thousands of agents including vehicles and pedestrians. A key\n",
      "factor in the success of modern reinforcement learning relies on a good\n",
      "simulator to generate a large number of data samples for learning. The most\n",
      "commonly used open-source traffic simulator SUMO is, however, not scalable to\n",
      "large road network and large traffic flow, which hinders the study of\n",
      "reinforcement learning on traffic scenarios. This motivates us to create a new\n",
      "traffic simulator CityFlow with fundamentally optimized data structures and\n",
      "efficient algorithms. CityFlow can support flexible definitions for road\n",
      "network and traffic flow based on synthetic and real-world data. It also\n",
      "provides user-friendly interface for reinforcement learning. Most importantly,\n",
      "CityFlow is more than twenty times faster than SUMO and is capable of\n",
      "supporting city-wide traffic simulation with an interactive render for\n",
      "monitoring. Besides traffic signal control, CityFlow could serve as the base\n",
      "for other transportation studies and can create new possibilities to test\n",
      "machine learning methods in the intelligent transportation domain.\n",
      "\n",
      "    \n",
      "818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Cooperation is critical in multi-agent reinforcement learning (MARL). In the\n",
      "context of traffic signal control, good cooperation among the traffic signal\n",
      "agents enables the vehicles to move through intersections more smoothly.\n",
      "Conventional transportation approaches implement cooperation by pre-calculating\n",
      "the offsets between two intersections. Such pre-calculated offsets are not\n",
      "suitable for dynamic traffic environments. To incorporate cooperation in\n",
      "reinforcement learning (RL), two typical approaches are proposed to take the\n",
      "influence of other agents into consideration: (1) learning the communications\n",
      "(i.e., the representation of influences between agents) and (2) learning joint\n",
      "actions for agents. While joint modeling of actions has shown a preferred trend\n",
      "in recent studies, an in-depth study of improving the learning of\n",
      "communications between agents has not been systematically studied in the\n",
      "context of traffic signal control. To learn the communications between agents,\n",
      "in this paper, we propose to use graph attentional network to facilitate\n",
      "cooperation. Specifically, for a target intersection in a network, our proposed\n",
      "model, CoLight, cannot only incorporate the influences of neighboring\n",
      "intersections but learn to differentiate their impacts to the target\n",
      "intersection. To the best of our knowledge, we are the first to use graph\n",
      "attentional network in the setting of reinforcement learning for traffic signal\n",
      "control. In experiments, we demonstrate that by learning the communication, the\n",
      "proposed model can achieve surprisingly good performance, whereas the existing\n",
      "approaches based on joint action modeling fail to learn well.\n",
      "\n",
      "    \n",
      "819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a unified mechanism for achieving coordination and communication\n",
      "in Multi-Agent Reinforcement Learning (MARL), through rewarding agents for\n",
      "having causal influence over other agents' actions. Causal influence is\n",
      "assessed using counterfactual reasoning. At each timestep, an agent simulates\n",
      "alternate actions that it could have taken, and computes their effect on the\n",
      "behavior of other agents. Actions that lead to bigger changes in other agents'\n",
      "behavior are considered influential and are rewarded. We show that this is\n",
      "equivalent to rewarding agents for having high mutual information between their\n",
      "actions. Empirical results demonstrate that influence leads to enhanced\n",
      "coordination and communication in challenging social dilemma environments,\n",
      "dramatically increasing the learning curves of the deep RL agents, and leading\n",
      "to more meaningful learned communication protocols. The influence rewards for\n",
      "all agents can be computed in a decentralized way by enabling agents to learn a\n",
      "model of other agents using deep neural networks. In contrast, key previous\n",
      "works on emergent communication in the MARL setting were unable to learn\n",
      "diverse policies in a decentralized manner and had to resort to centralized\n",
      "training. Consequently, the influence reward opens up a window of new\n",
      "opportunities for research in this area.\n",
      "\n",
      "    \n",
      "820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Groups of humans are often able to find ways to cooperate with one another in\n",
      "complex, temporally extended social dilemmas. Models based on behavioral\n",
      "economics are only able to explain this phenomenon for unrealistic stateless\n",
      "matrix games. Recently, multi-agent reinforcement learning has been applied to\n",
      "generalize social dilemma problems to temporally and spatially extended Markov\n",
      "games. However, this has not yet generated an agent that learns to cooperate in\n",
      "social dilemmas as humans do. A key insight is that many, but not all, human\n",
      "individuals have inequity averse social preferences. This promotes a particular\n",
      "resolution of the matrix game social dilemma wherein inequity-averse\n",
      "individuals are personally pro-social and punish defectors. Here we extend this\n",
      "idea to Markov games and show that it promotes cooperation in several types of\n",
      "sequential social dilemma, via a profitable interaction with policy\n",
      "learnability. In particular, we find that inequity aversion improves temporal\n",
      "credit assignment for the important class of intertemporal social dilemmas.\n",
      "These results help explain how large-scale cooperation may emerge and persist.\n",
      "\n",
      "    \n",
      "821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Matrix games like Prisoner's Dilemma have guided research on social dilemmas\n",
      "for decades. However, they necessarily treat the choice to cooperate or defect\n",
      "as an atomic action. In real-world social dilemmas these choices are temporally\n",
      "extended. Cooperativeness is a property that applies to policies, not\n",
      "elementary actions. We introduce sequential social dilemmas that share the\n",
      "mixed incentive structure of matrix game social dilemmas but also require\n",
      "agents to learn policies that implement their strategic intentions. We analyze\n",
      "the dynamics of policies learned by multiple self-interested independent\n",
      "learning agents, each using its own deep Q-network, on two Markov games we\n",
      "introduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We\n",
      "characterize how learned behavior in each domain changes as a function of\n",
      "environmental factors including resource abundance. Our experiments show how\n",
      "conflict can emerge from competition over shared resources and shed light on\n",
      "how the sequential nature of real world social dilemmas affects cooperation.\n",
      "\n",
      "    \n",
      "822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Existing multi-agent reinforcement learning methods are limited typically to\n",
      "a small number of agents. When the agent number increases largely, the learning\n",
      "becomes intractable due to the curse of the dimensionality and the exponential\n",
      "growth of agent interactions. In this paper, we present Mean Field\n",
      "Reinforcement Learning where the interactions within the population of agents\n",
      "are approximated by those between a single agent and the average effect from\n",
      "the overall population or neighboring agents; the interplay between the two\n",
      "entities is mutually reinforced: the learning of the individual agent's optimal\n",
      "policy depends on the dynamics of the population, while the dynamics of the\n",
      "population change according to the collective patterns of the individual\n",
      "policies. We develop practical mean field Q-learning and mean field\n",
      "Actor-Critic algorithms and analyze the convergence of the solution to Nash\n",
      "equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\n",
      "justify the learning effectiveness of our mean field approaches. In addition,\n",
      "we report the first result to solve the Ising model via model-free\n",
      "reinforcement learning methods.\n",
      "\n",
      "    \n",
      "823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Reinforcement learning in multi-agent scenarios is important for real-world\n",
      "applications but presents challenges beyond those seen in single-agent\n",
      "settings. We present an actor-critic algorithm that trains decentralized\n",
      "policies in multi-agent settings, using centrally computed critics that share\n",
      "an attention mechanism which selects relevant information for each agent at\n",
      "every timestep. This attention mechanism enables more effective and scalable\n",
      "learning in complex multi-agent environments, when compared to recent\n",
      "approaches. Our approach is applicable not only to cooperative settings with\n",
      "shared rewards, but also individualized reward settings, including adversarial\n",
      "settings, as well as settings that do not provide global states, and it makes\n",
      "no assumptions about the action spaces of the agents. As such, it is flexible\n",
      "enough to be applied to most multi-agent learning problems.\n",
      "\n",
      "    \n",
      "824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multi-agent settings are quickly gathering importance in machine learning.\n",
      "This includes a plethora of recent work on deep multi-agent reinforcement\n",
      "learning, but also can be extended to hierarchical RL, generative adversarial\n",
      "networks and decentralised optimisation. In all these settings the presence of\n",
      "multiple learning agents renders the training problem non-stationary and often\n",
      "leads to unstable training or undesired final results. We present Learning with\n",
      "Opponent-Learning Awareness (LOLA), a method in which each agent shapes the\n",
      "anticipated learning of the other agents in the environment. The LOLA learning\n",
      "rule includes a term that accounts for the impact of one agent's policy on the\n",
      "anticipated parameter update of the other agents. Results show that the\n",
      "encounter of two LOLA agents leads to the emergence of tit-for-tat and\n",
      "therefore cooperation in the iterated prisoners' dilemma, while independent\n",
      "learning does not. In this domain, LOLA also receives higher payouts compared\n",
      "to a naive learner, and is robust against exploitation by higher order\n",
      "gradient-based methods. Applied to repeated matching pennies, LOLA agents\n",
      "converge to the Nash equilibrium. In a round robin tournament we show that LOLA\n",
      "agents successfully shape the learning of a range of multi-agent learning\n",
      "algorithms from literature, resulting in the highest average returns on the\n",
      "IPD. We also show that the LOLA update rule can be efficiently calculated using\n",
      "an extension of the policy gradient estimator, making the method suitable for\n",
      "model-free RL. The method thus scales to large parameter and input spaces and\n",
      "nonlinear function approximators. We apply LOLA to a grid world task with an\n",
      "embedded social dilemma using recurrent policies and opponent modelling. By\n",
      "explicitly considering the learning of the other agent, LOLA agents learn to\n",
      "cooperate out of self-interest. The code is at this http URL.\n",
      "\n",
      "    \n",
      "825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Large-scale online ride-sharing platforms have substantially transformed our\n",
      "lives by reallocating transportation resources to alleviate traffic congestion\n",
      "and promote transportation efficiency. An efficient fleet management strategy\n",
      "not only can significantly improve the utilization of transportation resources\n",
      "but also increase the revenue and customer satisfaction. It is a challenging\n",
      "task to design an effective fleet management strategy that can adapt to an\n",
      "environment involving complex dynamics between demand and supply. Existing\n",
      "studies usually work on a simplified problem setting that can hardly capture\n",
      "the complicated stochastic demand-supply variations in high-dimensional space.\n",
      "In this paper we propose to tackle the large-scale fleet management problem\n",
      "using reinforcement learning, and propose a contextual multi-agent\n",
      "reinforcement learning framework including two concrete algorithms, namely\n",
      "contextual deep Q-learning and contextual multi-agent actor-critic, to achieve\n",
      "explicit coordination among a large number of agents adaptive to different\n",
      "contexts. We show significant improvements of the proposed framework over\n",
      "state-of-the-art approaches through extensive empirical studies.\n",
      "\n",
      "    \n",
      "826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  While multi-agent interactions can be naturally modeled as a graph, the\n",
      "environment has traditionally been considered as a black box. We propose to\n",
      "create a shared agent-entity graph, where agents and environmental entities\n",
      "form vertices, and edges exist between the vertices which can communicate with\n",
      "each other. Agents learn to cooperate by exchanging messages along the edges of\n",
      "this graph. Our proposed multi-agent reinforcement learning framework is\n",
      "invariant to the number of agents or entities present in the system as well as\n",
      "permutation invariance, both of which are desirable properties for any\n",
      "multi-agent system representation. We present state-of-the-art results on\n",
      "coverage, formation and line control tasks for multi-agent teams in a fully\n",
      "decentralized framework and further show that the learned policies quickly\n",
      "transfer to scenarios with different team sizes along with strong zero-shot\n",
      "generalization performance. This is an important step towards developing\n",
      "multi-agent teams which can be realistically deployed in the real world without\n",
      "assuming complete prior knowledge or instantaneous communication at unbounded\n",
      "distances.\n",
      "\n",
      "    \n",
      "827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most of the prior work on multi-agent reinforcement learning (MARL) achieves\n",
      "optimal collaboration by directly controlling the agents to maximize a common\n",
      "reward. In this paper, we aim to address this from a different angle. In\n",
      "particular, we consider scenarios where there are self-interested agents (i.e.,\n",
      "worker agents) which have their own minds (preferences, intentions, skills,\n",
      "etc.) and can not be dictated to perform tasks they do not wish to do. For\n",
      "achieving optimal coordination among these agents, we train a super agent\n",
      "(i.e., the manager) to manage them by first inferring their minds based on both\n",
      "current and past observations and then initiating contracts to assign suitable\n",
      "tasks to workers and promise to reward them with corresponding bonuses so that\n",
      "they will agree to work together. The objective of the manager is maximizing\n",
      "the overall productivity as well as minimizing payments made to the workers for\n",
      "ad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\n",
      "Management Reinforcement Learning (M^3RL), which consists of agent modeling and\n",
      "policy learning. We have evaluated our approach in two environments, Resource\n",
      "Collection and Crafting, to simulate multi-agent management problems with\n",
      "various task settings and multiple designs for the worker agents. The\n",
      "experimental results have validated the effectiveness of our approach in\n",
      "modeling worker agents' minds online, and in achieving optimal ad-hoc teaming\n",
      "with good generalization and fast adaptation.\n",
      "\n",
      "    \n",
      "828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a novel hierarchical agent architecture for multi-agent\n",
      "reinforcement learning with concealed information. The hierarchy is grounded in\n",
      "the concealed information about other players, which resolves \"the chicken or\n",
      "the egg\" nature of option discovery. We factorise the value function over a\n",
      "latent representation of the concealed information and then re-use this latent\n",
      "space to factorise the policy into options. Low-level policies (options) are\n",
      "trained to respond to particular states of other agents grouped by the latent\n",
      "representation, while the top level (meta-policy) learns to infer the latent\n",
      "representation from its own observation thereby to select the right option.\n",
      "This grounding facilitates credit assignment across the levels of hierarchy. We\n",
      "show that this helps generalisation---performance against a held-out set of\n",
      "pre-trained competitors, while training in self- or population-play---and\n",
      "resolution of social dilemmas in self-play.\n",
      "\n",
      "    \n",
      "829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the multi-agent reinforcement learning setting with imperfect\n",
      "information in which each agent is trying to maximize its own utility. The\n",
      "reward function depends on the hidden state (or goal) of both agents, so the\n",
      "agents must infer the other players' hidden goals from their observed behavior\n",
      "in order to solve the tasks. We propose a new approach for learning in these\n",
      "domains: Self Other-Modeling (SOM), in which an agent uses its own policy to\n",
      "predict the other agent's actions and update its belief of their hidden state\n",
      "in an online manner. We evaluate this approach on three different tasks and\n",
      "show that the agents are able to learn better policies using their estimate of\n",
      "the other players' hidden states, in both cooperative and adversarial settings.\n",
      "\n",
      "    \n",
      "830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of \\emph{fully decentralized} multi-agent\n",
      "reinforcement learning (MARL), where the agents are located at the nodes of a\n",
      "time-varying communication network. Specifically, we assume that the reward\n",
      "functions of the agents might correspond to different tasks, and are only known\n",
      "to the corresponding agent. Moreover, each agent makes individual decisions\n",
      "based on both the information observed locally and the messages received from\n",
      "its neighbors over the network. Within this setting, the collective goal of the\n",
      "agents is to maximize the globally averaged return over the network through\n",
      "exchanging information with their neighbors. To this end, we propose two\n",
      "decentralized actor-critic algorithms with function approximation, which are\n",
      "applicable to large-scale MARL problems where both the number of states and the\n",
      "number of agents are massively large. Under the decentralized structure, the\n",
      "actor step is performed individually by each agent with no need to infer the\n",
      "policies of others. For the critic step, we propose a consensus update via\n",
      "communication over the network. Our algorithms are fully incremental and can be\n",
      "implemented in an online fashion. Convergence analyses of the algorithms are\n",
      "provided when the value functions are approximated within the class of linear\n",
      "functions. Extensive simulation results with both linear and nonlinear function\n",
      "approximations are presented to validate the proposed algorithms. Our work\n",
      "appears to be the first study of fully decentralized MARL algorithms for\n",
      "networked agents with function approximation, with provable convergence\n",
      "guarantees.\n",
      "\n",
      "    \n",
      "831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many real-world problems, such as network packet routing and urban traffic\n",
      "control, are naturally modeled as multi-agent reinforcement learning (RL)\n",
      "problems. However, existing multi-agent RL methods typically scale poorly in\n",
      "the problem size. Therefore, a key challenge is to translate the success of\n",
      "deep learning on single-agent RL to the multi-agent setting. A major stumbling\n",
      "block is that independent Q-learning, the most popular multi-agent RL method,\n",
      "introduces nonstationarity that makes it incompatible with the experience\n",
      "replay memory on which deep Q-learning relies. This paper proposes two methods\n",
      "that address this problem: 1) using a multi-agent variant of importance\n",
      "sampling to naturally decay obsolete data and 2) conditioning each agent's\n",
      "value function on a fingerprint that disambiguates the age of the data sampled\n",
      "from the replay memory. Results on a challenging decentralised variant of\n",
      "StarCraft unit micromanagement confirm that these methods enable the successful\n",
      "combination of experience replay with multi-agent RL.\n",
      "\n",
      "    \n",
      "832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many real-world reinforcement learning tasks require multiple agents to make\n",
      "sequential decisions under the agents' interaction, where well-coordinated\n",
      "actions among the agents are crucial to achieve the target goal better at these\n",
      "tasks. One way to accelerate the coordination effect is to enable multiple\n",
      "agents to communicate with each other in a distributed manner and behave as a\n",
      "group. In this paper, we study a practical scenario when (i) the communication\n",
      "bandwidth is limited and (ii) the agents share the communication medium so that\n",
      "only a restricted number of agents are able to simultaneously use the medium,\n",
      "as in the state-of-the-art wireless networking standards. This calls for a\n",
      "certain form of communication scheduling. In that regard, we propose a\n",
      "multi-agent deep reinforcement learning framework, called SchedNet, in which\n",
      "agents learn how to schedule themselves, how to encode the messages, and how to\n",
      "select actions based on received messages. SchedNet is capable of deciding\n",
      "which agents should be entitled to broadcasting their (encoded) messages, by\n",
      "learning the importance of each agent's partially observed information. We\n",
      "evaluate SchedNet against multiple baselines under two different applications,\n",
      "namely, cooperative communication and navigation, and predator-prey. Our\n",
      "experiments show a non-negligible performance gap between SchedNet and other\n",
      "mechanisms such as the ones without communication and with vanilla scheduling\n",
      "methods, e.g., round robin, ranging from 32% to 43%.\n",
      "\n",
      "    \n",
      "833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\n",
      "an inference problem by introducing a binary random variable o, which stands\n",
      "for the \"optimality\". In this paper, we redefine the binary random variable o\n",
      "in multi-agent setting and formalize multi-agent reinforcement learning (MARL)\n",
      "as probabilistic inference. We derive a variational lower bound of the\n",
      "likelihood of achieving the optimality and name it as Regularized Opponent\n",
      "Model with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\n",
      "perspective on opponent modeling and show how it can improve the performance of\n",
      "training agents theoretically and empirically in cooperative games. To optimize\n",
      "ROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\n",
      "convergence. We extend the exact algorithm to complex environments by proposing\n",
      "an approximate version, ROMMEO-AC. We evaluate these two algorithms on the\n",
      "challenging iterated matrix game and differential game respectively and show\n",
      "that they can outperform strong MARL baselines.\n",
      "\n",
      "    \n",
      "834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore value-based solutions for multi-agent reinforcement learning\n",
      "(MARL) tasks in the centralized training with decentralized execution (CTDE)\n",
      "regime popularized recently. However, VDN and QMIX are representative examples\n",
      "that use the idea of factorization of the joint action-value function into\n",
      "individual ones for decentralized execution. VDN and QMIX address only a\n",
      "fraction of factorizable MARL tasks due to their structural constraint in\n",
      "factorization such as additivity and monotonicity. In this paper, we propose a\n",
      "new factorization method for MARL, QTRAN, which is free from such structural\n",
      "constraints and takes on a new approach to transforming the original joint\n",
      "action-value function into an easily factorizable one, with the same optimal\n",
      "actions. QTRAN guarantees more general factorization than VDN or QMIX, thus\n",
      "covering a much wider class of MARL tasks than does previous methods. Our\n",
      "experiments for the tasks of multi-domain Gaussian-squeeze and modified\n",
      "predator-prey demonstrate QTRAN's superior performance with especially larger\n",
      "margins in games whose payoffs penalize non-cooperative behavior more\n",
      "aggressively.\n",
      "\n",
      "    \n",
      "835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\n",
      "learners must overcome a number of pathologies to learn optimal joint policies.\n",
      "Addressing one pathology often leaves approaches vulnerable towards others. For\n",
      "instance, hysteretic Q-learning addresses miscoordination while leaving agents\n",
      "vulnerable towards misleading stochastic rewards. Other methods, such as\n",
      "leniency, have proven more robust when dealing with multiple pathologies\n",
      "simultaneously. However, leniency has predominately been studied within the\n",
      "context of strategic form games (bimatrix games) and fully observable Markov\n",
      "games consisting of a small number of probabilistic state transitions. This\n",
      "raises the question of whether these findings scale to more complex domains.\n",
      "For this purpose we implement a temporally extend version of the Climb Game,\n",
      "within which agents must overcome multiple pathologies simultaneously,\n",
      "including relative overgeneralisation, stochasticity, the alter-exploration and\n",
      "moving target problems, while learning from a large observation space. We find\n",
      "that existing lenient and hysteretic approaches fail to consistently learn near\n",
      "optimal joint-policies in this environment. To address these pathologies we\n",
      "introduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\n",
      "which discards episodes yielding cumulative rewards outside the range of\n",
      "expanding intervals. NUI-DDQN consistently gravitates towards optimal\n",
      "joint-policies in our environment, overcoming the outlined pathologies.\n",
      "\n",
      "    \n",
      "836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Much of the success of single agent deep reinforcement learning (DRL) in\n",
      "recent years can be attributed to the use of experience replay memories (ERM),\n",
      "which allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\n",
      "stored state transitions. However, care is required when using ERMs for\n",
      "multi-agent deep reinforcement learning (MA-DRL), as stored transitions can\n",
      "become outdated because agents update their policies in parallel [11]. In this\n",
      "work we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\n",
      "decaying temperature values that control the amount of leniency applied towards\n",
      "negative policy updates that are sampled from the ERM. This introduces optimism\n",
      "in the value-function update, and has been shown to facilitate cooperation in\n",
      "tabular fully-cooperative multi-agent reinforcement learning problems. We\n",
      "evaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\n",
      "(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\n",
      "that uses average reward learning near terminal states. Evaluations take place\n",
      "in extended variations of the Coordinated Multi-Agent Object Transportation\n",
      "Problem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\n",
      "rewards. We find that LDQN agents are more likely to converge to the optimal\n",
      "policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\n",
      "agents.\n",
      "\n",
      "    \n",
      "837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Cooperative game is a critical research area in multi-agent reinforcement\n",
      "learning (MARL). Global reward game is a subclass of cooperative games, where\n",
      "all agents aim to maximize cumulative global rewards. Credit assignment is an\n",
      "important problem studied in the global reward game. Most of works stand by the\n",
      "view of non-cooperative-game theoretical framework with the shared reward\n",
      "approach, i.e., each agent being assigned a shared global reward directly.\n",
      "This, however, may give each agent an inaccurate feedback on its contribution\n",
      "to the group. In this paper, we introduce a cooperative-game theoretical\n",
      "framework and extend it to the infinite-horizon case. We show that our proposed\n",
      "framework is a superset of the global reward game. Based on this framework, we\n",
      "propose a local reward approach called Shapley Q-value that can distribute the\n",
      "cumulative global rewards fairly, reflecting each agent's own contribution in\n",
      "contrast to the shared reward approach. Moreover, we derive an MARL algorithm\n",
      "called Shapley Q-value policy gradient (SQPG), using Shapley Q-value as\n",
      "critics. We evaluate SQPG on Cooperative Navigation, Prey-and-Predator and\n",
      "Traffic Junction, compared with MADDPG, COMA, Independent A2C and Independent\n",
      "DDPG. In the experiments, SQPG shows the better performance than the baselines.\n",
      "In addition, we also plot the Shapley Q-value and validate the property of\n",
      "fairly distributing the global rewards.\n",
      "\n",
      "    \n",
      "838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The detection of anatomical landmarks is a vital step for medical image\n",
      "analysis and applications for diagnosis, interpretation and guidance. Manual\n",
      "annotation of landmarks is a tedious process that requires domain-specific\n",
      "expertise and introduces inter-observer variability. This paper proposes a new\n",
      "detection approach for multiple landmarks based on multi-agent reinforcement\n",
      "learning. Our hypothesis is that the position of all anatomical landmarks is\n",
      "interdependent and non-random within the human anatomy, thus finding one\n",
      "landmark can help to deduce the location of others. Using a Deep Q-Network\n",
      "(DQN) architecture we construct an environment and agent with implicit\n",
      "inter-communication such that we can accommodate K agents acting and learning\n",
      "simultaneously, while they attempt to detect K different landmarks. During\n",
      "training the agents collaborate by sharing their accumulated knowledge for a\n",
      "collective gain. We compare our approach with state-of-the-art architectures\n",
      "and achieve significantly better accuracy by reducing the detection error by\n",
      "50%, while requiring fewer computational resources and time to train compared\n",
      "to the naive approach of training K agents separately.\n",
      "\n",
      "    \n",
      "839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art meta reinforcement learning algorithms typically assume the\n",
      "setting of a single agent interacting with its environment in a sequential\n",
      "manner. A negative side-effect of this sequential execution paradigm is that,\n",
      "as the environment becomes more and more challenging, and thus requiring more\n",
      "interaction episodes for the meta-learner, it needs the agent to reason over\n",
      "longer and longer time-scales. To combat the difficulty of long time-scale\n",
      "credit assignment, we propose an alternative parallel framework, which we name\n",
      "\"Concurrent Meta-Reinforcement Learning\" (CMRL), that transforms the temporal\n",
      "credit assignment problem into a multi-agent reinforcement learning one. In\n",
      "this multi-agent setting, a set of parallel agents are executed in the same\n",
      "environment and each of these \"rollout\" agents are given the means to\n",
      "communicate with each other. The goal of the communication is to coordinate, in\n",
      "a collaborative manner, the most efficient exploration of the shared task the\n",
      "agents are currently assigned. This coordination therefore represents the\n",
      "meta-learning aspect of the framework, as each agent can be assigned or assign\n",
      "itself a particular section of the current task's state space. This framework\n",
      "is in contrast to standard RL methods that assume that each parallel rollout\n",
      "occurs independently, which can potentially waste computation if many of the\n",
      "rollouts end up sampling the same part of the state space. Furthermore, the\n",
      "parallel setting enables us to define several reward sharing functions and\n",
      "auxiliary losses that are non-trivial to apply in the sequential setting. We\n",
      "demonstrate the effectiveness of our proposed CMRL at improving over sequential\n",
      "methods in a variety of challenging tasks.\n",
      "\n",
      "    \n",
      "840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A standard belief on emerging collective behavior is that it emerges from\n",
      "simple individual rules. Most of the mathematical research on such collective\n",
      "behavior starts from imperative individual rules, like always go to the center.\n",
      "But how could an (optimal) individual rule emerge during a short period within\n",
      "the group lifetime, especially if communication is not available. We argue that\n",
      "such rules can actually emerge in a group in a short span of time via\n",
      "collective (multi-agent) reinforcement learning, i.e learning via rewards and\n",
      "punishments. We consider the gathering problem: several agents (social animals,\n",
      "swarming robots...) must gather around a same position, which is not determined\n",
      "in advance. They must do so without communication on their planned decision,\n",
      "just by looking at the position of other agents. We present the first\n",
      "experimental evidence that a gathering behavior can be learned without\n",
      "communication in a partially observable environment. The learned behavior has\n",
      "the same properties as a self-stabilizing distributed algorithm, as processes\n",
      "can gather from any initial state (and thus tolerate any transient failure).\n",
      "Besides, we show that it is possible to tolerate the brutal loss of up to 90\\%\n",
      "of agents without significant impact on the behavior.\n",
      "\n",
      "    \n",
      "841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Reinforcement Learning (RL) is a learning paradigm concerned with learning to\n",
      "control a system so as to maximize an objective over the long term. This\n",
      "approach to learning has received immense interest in recent times and success\n",
      "manifests itself in the form of human-level performance on games like\n",
      "\\textit{Go}. While RL is emerging as a practical component in real-life\n",
      "systems, most successes have been in Single Agent domains. This report will\n",
      "instead specifically focus on challenges that are unique to Multi-Agent Systems\n",
      "interacting in mixed cooperative and competitive environments. The report\n",
      "concludes with advances in the paradigm of training Multi-Agent Systems called\n",
      "\\textit{Decentralized Actor, Centralized Critic}, based on an extension of MDPs\n",
      "called \\textit{Decentralized Partially Observable MDP}s, which has seen a\n",
      "renewed interest lately.\n",
      "\n",
      "    \n",
      "842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Here we explore a new algorithmic framework for multi-agent reinforcement\n",
      "learning, called Malthusian reinforcement learning, which extends self-play to\n",
      "include fitness-linked population size dynamics that drive ongoing innovation.\n",
      "In Malthusian RL, increases in a subpopulation's average return drive\n",
      "subsequent increases in its size, just as Thomas Malthus argued in 1798 was the\n",
      "relationship between preindustrial income levels and population growth.\n",
      "Malthusian reinforcement learning harnesses the competitive pressures arising\n",
      "from growing and shrinking population size to drive agents to explore regions\n",
      "of state and policy spaces that they could not otherwise reach. Furthermore, in\n",
      "environments where there are potential gains from specialization and division\n",
      "of labor, we show that Malthusian reinforcement learning is better positioned\n",
      "to take advantage of such synergies than algorithms based on self-play.\n",
      "\n",
      "    \n",
      "843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents an upgraded, real world application oriented version of\n",
      "gym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement\n",
      "Learning (RL) toolkit, which complies with OpenAI Gym. The content discusses\n",
      "the new ROS 2 based software architecture and summarizes the results obtained\n",
      "using Proximal Policy Optimization (PPO). Ultimately, the output of this work\n",
      "presents a benchmarking system for robotics that allows different techniques\n",
      "and algorithms to be compared using the same virtual conditions. We have\n",
      "evaluated environments with different levels of complexity of the Modular\n",
      "Articulated Robotic Arm (MARA), reaching accuracies in the millimeter scale.\n",
      "The converged results show the feasibility and usefulness of the gym-gazebo 2\n",
      "toolkit, its potential and applicability in industrial use cases, using modular\n",
      "robots.\n",
      "\n",
      "    \n",
      "844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to act in multiple environments and transfer previous knowledge\n",
      "to new situations can be considered a critical aspect of any intelligent agent.\n",
      "Towards this goal, we define a novel method of multitask and transfer learning\n",
      "that enables an autonomous agent to learn how to behave in multiple tasks\n",
      "simultaneously, and then generalize its knowledge to new domains. This method,\n",
      "termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model\n",
      "compression techniques to train a single policy network that learns how to act\n",
      "in a set of distinct tasks by using the guidance of several expert teachers. We\n",
      "then show that the representations learnt by the deep policy network are\n",
      "capable of generalizing to new tasks with no prior expert guidance, speeding up\n",
      "learning in novel environments. Although our method can in general be applied\n",
      "to a wide range of problems, we use Atari games as a testing environment to\n",
      "demonstrate these methods.\n",
      "\n",
      "    \n",
      "845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The purpose of this technical report is two-fold. First of all, it introduces\n",
      "a suite of challenging continuous control tasks (integrated with OpenAI Gym)\n",
      "based on currently existing robotics hardware. The tasks include pushing,\n",
      "sliding and pick & place with a Fetch robotic arm as well as in-hand object\n",
      "manipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards\n",
      "and follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent\n",
      "is told what to do using an additional input.\n",
      "The second part of the paper presents a set of concrete research ideas for\n",
      "improving RL algorithms, most of which are related to Multi-Goal RL and\n",
      "Hindsight Experience Replay.\n",
      "\n",
      "    \n",
      "846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Intrinsically motivated spontaneous exploration is a key enabler of\n",
      "autonomous lifelong learning in human children. It allows them to discover and\n",
      "acquire large repertoires of skills through self-generation, self-selection,\n",
      "self-ordering and self-experimentation of learning goals. We present the\n",
      "unsupervised multi-goal reinforcement learning formal framework as well as an\n",
      "algorithmic approach called intrinsically motivated goal exploration processes\n",
      "(IMGEP) to enable similar properties of autonomous learning in machines. The\n",
      "IMGEP algorithmic architecture relies on several principles: 1) self-generation\n",
      "of goals as parameterized reinforcement learning problems; 2) selection of\n",
      "goals based on intrinsic rewards; 3) exploration with parameterized\n",
      "time-bounded policies and fast incremental goal-parameterized policy search; 4)\n",
      "systematic reuse of information acquired when targeting a goal for improving\n",
      "other goals. We present a particularly efficient form of IMGEP that uses a\n",
      "modular representation of goal spaces as well as intrinsic rewards based on\n",
      "learning progress. We show how IMGEPs automatically generate a learning\n",
      "curriculum within an experimental setup where a real humanoid robot can explore\n",
      "multiple spaces of goals with several hundred continuous dimensions. While no\n",
      "particular target goal is provided to the system beforehand, this curriculum\n",
      "allows the discovery of skills of increasing complexity, that act as stepping\n",
      "stone for learning more complex skills (like nested tool use). We show that\n",
      "learning several spaces of diverse problems can be more efficient for learning\n",
      "complex skills than only trying to directly learn these complex skills. We\n",
      "illustrate the computational efficiency of IMGEPs as these robotic experiments\n",
      "use a simple memory-based low-level policy representations and search\n",
      "algorithm, enabling the whole system to learn online and incrementally on a\n",
      "Raspberry Pi 3.\n",
      "\n",
      "    \n",
      "847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In Multi-Goal Reinforcement Learning, an agent learns to achieve multiple\n",
      "goals with a goal-conditioned policy. During learning, the agent first collects\n",
      "the trajectories into a replay buffer, and later these trajectories are\n",
      "selected randomly for replay. However, the achieved goals in the replay buffer\n",
      "are often biased towards the behavior policies. From a Bayesian perspective,\n",
      "when there is no prior knowledge about the target goal distribution, the agent\n",
      "should learn uniformly from diverse achieved goals. Therefore, we first propose\n",
      "a novel multi-goal RL objective based on weighted entropy. This objective\n",
      "encourages the agent to maximize the expected return, as well as to achieve\n",
      "more diverse goals. Secondly, we developed a maximum entropy-based\n",
      "prioritization framework to optimize the proposed objective. For evaluation of\n",
      "this framework, we combine it with Deep Deterministic Policy Gradient, both\n",
      "with or without Hindsight Experience Replay. On a set of multi-goal robotic\n",
      "tasks of OpenAI Gym, we compare our method with other baselines and show\n",
      "promising improvements in both performance and sample-efficiency.\n",
      "\n",
      "    \n",
      "848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces SC2LE (StarCraft II Learning Environment), a\n",
      "reinforcement learning environment based on the StarCraft II game. This domain\n",
      "poses a new grand challenge for reinforcement learning, representing a more\n",
      "difficult class of problems than considered in most prior work. It is a\n",
      "multi-agent problem with multiple players interacting; there is imperfect\n",
      "information due to a partially observed map; it has a large action space\n",
      "involving the selection and control of hundreds of units; it has a large state\n",
      "space that must be observed solely from raw input feature planes; and it has\n",
      "delayed credit assignment requiring long-term strategies over thousands of\n",
      "steps. We describe the observation, action, and reward specification for the\n",
      "StarCraft II domain and provide an open source Python-based interface for\n",
      "communicating with the game engine. In addition to the main game maps, we\n",
      "provide a suite of mini-games focusing on different elements of StarCraft II\n",
      "gameplay. For the main game maps, we also provide an accompanying dataset of\n",
      "game replay data from human expert players. We give initial baseline results\n",
      "for neural networks trained from this data to predict game outcomes and player\n",
      "actions. Finally, we present initial baseline results for canonical deep\n",
      "reinforcement learning agents applied to the StarCraft II domain. On the\n",
      "mini-games, these agents learn to achieve a level of play that is comparable to\n",
      "a novice player. However, when trained on the main game, these agents are\n",
      "unable to make significant progress. Thus, SC2LE offers a new and challenging\n",
      "environment for exploring deep reinforcement learning algorithms and\n",
      "architectures.\n",
      "\n",
      "    \n",
      "849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose ELF, an Extensive, Lightweight and Flexible\n",
      "platform for fundamental reinforcement learning research. Using ELF, we\n",
      "implement a highly customizable real-time strategy (RTS) engine with three game\n",
      "environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a\n",
      "miniature version of StarCraft, captures key game dynamics and runs at 40K\n",
      "frame-per-second (FPS) per core on a Macbook Pro notebook. When coupled with\n",
      "modern reinforcement learning methods, the system can train a full-game bot\n",
      "against built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition,\n",
      "our platform is flexible in terms of environment-agent communication\n",
      "topologies, choices of RL methods, changes in game parameters, and can host\n",
      "existing C/C++-based game environments like Arcade Learning Environment. Using\n",
      "ELF, we thoroughly explore training parameters and show that a network with\n",
      "Leaky ReLU and Batch Normalization coupled with long-horizon training and\n",
      "progressive curriculum beats the rule-based built-in AI more than $70\\%$ of the\n",
      "time in the full game of Mini-RTS. Strong performance is also achieved on the\n",
      "other two games. In game replays, we show our agents learn interesting\n",
      "strategies. ELF, along with its RL platform, is open-sourced at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present TorchCraft, a library that enables deep learning research on\n",
      "Real-Time Strategy (RTS) games such as StarCraft: Brood War, by making it\n",
      "easier to control these games from a machine learning framework, here Torch.\n",
      "This white paper argues for using RTS games as a benchmark for AI research, and\n",
      "describes the design and components of TorchCraft.\n",
      "\n",
      "    \n",
      "851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We release a dataset of 65646 StarCraft replays that contains 1535 million\n",
      "frames and 496 million player actions. We provide full game state data along\n",
      "with the original replays that can be viewed in StarCraft. The game state data\n",
      "was recorded every 3 frames which ensures suitability for a wide variety of\n",
      "machine learning tasks such as strategy classification, inverse reinforcement\n",
      "learning, imitation learning, forward modeling, partial information extraction,\n",
      "and others. We use TorchCraft to extract and store the data, which standardizes\n",
      "the data format for both reading from replays and reading directly from the\n",
      "game. Furthermore, the data can be used on different operating systems and\n",
      "platforms. The dataset contains valid, non-corrupted replays only and its\n",
      "quality and diversity was ensured by a number of heuristics. We illustrate the\n",
      "diversity of the data with various statistics and provide examples of tasks\n",
      "that benefit from the dataset. We make the dataset available at\n",
      "this https URL . En Taro Adun!\n",
      "\n",
      "    \n",
      "852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper advocates the exploration of the full state of recorded real-time\n",
      "strategy (RTS) games, by human or robotic players, to discover how to reason\n",
      "about tactics and strategy. We present a dataset of StarCraft games\n",
      "encompassing the most of the games' state (not only player's orders). We\n",
      "explain one of the possible usages of this dataset by clustering armies on\n",
      "their compositions. This reduction of armies compositions to mixtures of\n",
      "Gaussian allow for strategic reasoning at the level of the components. We\n",
      "evaluated this clustering method by predicting the outcomes of battles based on\n",
      "armies compositions' mixtures components\n",
      "\n",
      "    \n",
      "853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a dockerized version of a real-time strategy game StarCraft: Brood\n",
      "War, commonly used as a domain for AI research, with a pre-installed collection\n",
      "of AI developement tools supporting all the major types of StarCraft bots. This\n",
      "provides a convenient way to deploy StarCraft AIs on numerous hosts at once and\n",
      "across multiple platforms despite limited OS support of StarCraft. In this\n",
      "technical report, we describe the design of our Docker images and present a few\n",
      "use cases.\n",
      "\n",
      "    \n",
      "854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Macro-management is an important problem in StarCraft, which has been studied\n",
      "for a long time. Various datasets together with assorted methods have been\n",
      "proposed in the last few years. But these datasets have some defects for\n",
      "boosting the academic and industrial research: 1) There're neither standard\n",
      "preprocessing, parsing and feature extraction procedures nor predefined\n",
      "training, validation and test set in some datasets. 2) Some datasets are only\n",
      "specified for certain tasks in macro-management. 3) Some datasets are either\n",
      "too small or don't have enough labeled data for modern machine learning\n",
      "algorithms such as deep neural networks. So most previous methods are trained\n",
      "with various features, evaluated on different test sets from the same or\n",
      "different datasets, making it difficult to be compared directly. To boost the\n",
      "research of macro-management in StarCraft, we release a new dataset MSC based\n",
      "on the platform SC2LE. MSC consists of well-designed feature vectors,\n",
      "pre-defined high-level actions and final result of each match. We also split\n",
      "MSC into training, validation and test set for the convenience of evaluation\n",
      "and comparison. Besides the dataset, we propose a baseline model and present\n",
      "initial baseline results for global state evaluation and build order\n",
      "prediction, which are two of the key tasks in macro-management. Various\n",
      "downstream tasks and analyses of the dataset are also described for the sake of\n",
      "research on macro-management in StarCraft II. Homepage:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning when to communicate and doing that effectively is essential in\n",
      "multi-agent tasks. Recent works show that continuous communication allows\n",
      "efficient training with back-propagation in multi-agent scenarios, but have\n",
      "been restricted to fully-cooperative tasks. In this paper, we present\n",
      "Individualized Controlled Continuous Communication Model (IC3Net) which has\n",
      "better training efficiency than simple continuous communication model, and can\n",
      "be applied to semi-cooperative and competitive settings along with the\n",
      "cooperative settings. IC3Net controls continuous communication with a gating\n",
      "mechanism and uses individualized rewards foreach agent to gain better\n",
      "performance and scalability while fixing credit assignment issues. Using\n",
      "variety of tasks including StarCraft BroodWars explore and combat scenarios, we\n",
      "show that our network yields improved performance and convergence rates than\n",
      "the baselines as the scale increases. Our results convey that IC3Net agents\n",
      "learn when to communicate based on the scenario and profitability.\n",
      "\n",
      "    \n",
      "856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Starcraft II (SC2) is widely considered as the most challenging Real Time\n",
      "Strategy (RTS) game. The underlying challenges include a large observation\n",
      "space, a huge (continuous and infinite) action space, partial observations,\n",
      "simultaneous move for all players, and long horizon delayed rewards for local\n",
      "decisions. To push the frontier of AI research, Deepmind and Blizzard jointly\n",
      "developed the StarCraft II Learning Environment (SC2LE) as a testbench of\n",
      "complex decision making systems. SC2LE provides a few mini games such as\n",
      "MoveToBeacon, CollectMineralShards, and DefeatRoaches, where some AI agents\n",
      "have achieved the performance level of human professional players. However, for\n",
      "full games, the current AI agents are still far from achieving human\n",
      "professional level performance. To bridge this gap, we present two full game AI\n",
      "agents in this paper - the AI agent TStarBot1 is based on deep reinforcement\n",
      "learning over a flat action structure, and the AI agent TStarBot2 is based on\n",
      "hard-coded rules over a hierarchical action structure. Both TStarBot1 and\n",
      "TStarBot2 are able to defeat the built-in AI agents from level 1 to level 10 in\n",
      "a full game (1v1 Zerg-vs-Zerg game on the AbyssalReef map), noting that level\n",
      "8, level 9, and level 10 are cheating agents with unfair advantages such as\n",
      "full vision on the whole map and resource harvest boosting. To the best of our\n",
      "knowledge, this is the first public work to investigate AI agents that can\n",
      "defeat the built-in AI in the StarCraft II full game.\n",
      "\n",
      "    \n",
      "857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  StarCraft (SC) is one of the most popular and successful Real Time Strategy\n",
      "(RTS) games. In recent years, SC is also widely accepted as a challenging\n",
      "testbed for AI research because of its enormous state space, partially observed\n",
      "information, multi-agent collaboration, and so on. With the help of annual\n",
      "AIIDE and CIG competitions, a growing number of SC bots are proposed and\n",
      "continuously improved. However, a large gap remains between the top-level bot\n",
      "and the professional human player. One vital reason is that current SC bots\n",
      "mainly rely on predefined rules to select macro actions during their games.\n",
      "These rules are not scalable and efficient enough to cope with the enormous yet\n",
      "partially observed state space in the game. In this paper, we propose a deep\n",
      "reinforcement learning (DRL) framework to improve the selection of macro\n",
      "actions. Our framework is based on the combination of the Ape-X DQN and the\n",
      "Long-Short-Term-Memory (LSTM). We use this framework to build our bot, named as\n",
      "LastOrder. Our evaluation, based on training against all bots from the AIIDE\n",
      "2017 StarCraft AI competition set, shows that LastOrder achieves an 83% winning\n",
      "rate, outperforming 26 bots in total 28 entrants.\n",
      "\n",
      "    \n",
      "858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  StarCraft provides an extremely challenging platform for reinforcement\n",
      "learning due to its huge state-space and game length. The previous fastest\n",
      "method requires days to train a full-length game policy in a single commercial\n",
      "machine. Introduction of background knowledge can accelerate the training of\n",
      "reinforcement learning. But how to effectively introduce background knowledge\n",
      "is still an open question. In this paper, we incorporate the background\n",
      "knowledge to reinforcement learning in the form of a thought-game. With the\n",
      "thought-game, the policy is firstly trained in the thought-game fastly and is\n",
      "then transferred to the real game using mapping functions for the second phase\n",
      "training. In our experiments, the trained agent can achieve a 100\\% win-rate on\n",
      "the map \\textit{Simple64} against the most difficult non-cheating built-in bot\n",
      "(level-7), and the training is 100 times faster than the previous ones under\n",
      "the same computational resource. To test the generalization performance of the\n",
      "agent, a Golden level of StarCraft~II Ladder human player has competed with the\n",
      "agent. With restricted strategy, the agent wins the human player by 4 out of 5\n",
      "games. We also apply thought-game idea to another game which is \"StarCraft:\n",
      "Brood War\", the predecessor of StarCraft II. The thought-game approach might\n",
      "shed some light for further studies of efficient reinforcement learning.\n",
      "\n",
      "    \n",
      "859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We formulate the problem of defogging as state estimation and future state\n",
      "prediction from previous, partial observations in the context of real-time\n",
      "strategy games. We propose to employ encoder-decoder neural networks for this\n",
      "task, and introduce proxy tasks and baselines for evaluation to assess their\n",
      "ability of capturing basic game rules and high-level dynamics. By combining\n",
      "convolutional neural networks and recurrent networks, we exploit spatial and\n",
      "sequential correlations and train well-performing models on a large dataset of\n",
      "human games of StarCraft: Brood War. Finally, we demonstrate the relevance of\n",
      "our models to downstream tasks by applying them for enemy unit prediction in a\n",
      "state-of-the-art, rule-based StarCraft bot. We observe improvements in win\n",
      "rates against several strong community bots.\n",
      "\n",
      "    \n",
      "860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Real-Time Strategy (RTS) games have recently become a popular testbed for\n",
      "artificial intelligence research. They represent a complex adversarial domain\n",
      "providing a number of interesting AI challenges. There exists a wide variety of\n",
      "research-supporting software tools, libraries and frameworks for one RTS game\n",
      "in particular -- StarCraft: Brood War. These tools are designed to address\n",
      "various specific sub-problems, such as resource allocation or opponent\n",
      "modelling so that researchers can focus exclusively on the tasks relevant to\n",
      "them. We present one such tool -- a library called StarAlgo that produces plans\n",
      "for the coordinated movement of squads (groups of combat units) within the game\n",
      "world. StarAlgo library can solve the squad movement planning problem using one\n",
      "of two algorithms: Monte Carlo Tree Search Considering Durations (MCTSCD) and a\n",
      "slightly modified version of Negamax. We evaluate both the algorithms, compare\n",
      "them, and demonstrate their usage. The library is implemented as a static C++\n",
      "library that can be easily plugged into most StarCraft AI bots.\n",
      "\n",
      "    \n",
      "861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In January 2019, DeepMind revealed AlphaStar to the world-the first\n",
      "artificial intelligence (AI) system to beat a professional player at the game\n",
      "of StarCraft II-representing a milestone in the progress of AI. AlphaStar draws\n",
      "on many areas of AI research, including deep learning, reinforcement learning,\n",
      "game theory, and evolutionary computation (EC). In this paper we analyze\n",
      "AlphaStar primarily through the lens of EC, presenting a new look at the system\n",
      "and relating it to many concepts in the field. We highlight some of its most\n",
      "interesting aspects-the use of Lamarckian evolution, competitive co-evolution,\n",
      "and quality diversity. In doing so, we hope to provide a bridge between the\n",
      "wider EC community and one of the most significant AI systems developed in\n",
      "recent times.\n",
      "\n",
      "    \n",
      "862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce Act2Vec, a general framework for learning context-based action\n",
      "representation for Reinforcement Learning. Representing actions in a vector\n",
      "space help reinforcement learning algorithms achieve better performance by\n",
      "grouping similar actions and utilizing relations between different actions. We\n",
      "show how prior knowledge of an environment can be extracted from demonstrations\n",
      "and injected into action vector representations that encode natural compatible\n",
      "behavior. We then use these for augmenting state representations as well as\n",
      "improving function approximation of Q-values. We visualize and test action\n",
      "embeddings in three domains including a drawing task, a high dimensional\n",
      "navigation task, and the large action space domain of StarCraft II.\n",
      "\n",
      "    \n",
      "863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce an approach for deep reinforcement learning (RL) that improves\n",
      "upon the efficiency, generalization capacity, and interpretability of\n",
      "conventional approaches through structured perception and relational reasoning.\n",
      "It uses self-attention to iteratively reason about the relations between\n",
      "entities in a scene and to guide a model-free policy. Our results show that in\n",
      "a novel navigation and planning task called Box-World, our agent finds\n",
      "interpretable solutions that improve upon baselines in terms of sample\n",
      "complexity, ability to generalize to more complex scenes than experienced\n",
      "during training, and overall performance. In the StarCraft II Learning\n",
      "Environment, our agent achieves state-of-the-art performance on six mini-games\n",
      "-- surpassing human grandmaster performance on four. By considering\n",
      "architectural inductive biases, our work opens new directions for overcoming\n",
      "important, but stubborn, challenges in deep RL.\n",
      "\n",
      "    \n",
      "864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Cooperative multi-agent systems can be naturally used to model many real\n",
      "world problems, such as network packet routing and the coordination of\n",
      "autonomous vehicles. There is a great need for new reinforcement learning\n",
      "methods that can efficiently learn decentralised policies for such systems. To\n",
      "this end, we propose a new multi-agent actor-critic method called\n",
      "counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised\n",
      "critic to estimate the Q-function and decentralised actors to optimise the\n",
      "agents' policies. In addition, to address the challenges of multi-agent credit\n",
      "assignment, it uses a counterfactual baseline that marginalises out a single\n",
      "agent's action, while keeping the other agents' actions fixed. COMA also uses a\n",
      "critic representation that allows the counterfactual baseline to be computed\n",
      "efficiently in a single forward pass. We evaluate COMA in the testbed of\n",
      "StarCraft unit micromanagement, using a decentralised variant with significant\n",
      "partial observability. COMA significantly improves average performance over\n",
      "other multi-agent actor-critic methods in this setting, and the best performing\n",
      "agents are competitive with state-of-the-art centralised controllers that get\n",
      "access to the full state.\n",
      "\n",
      "    \n",
      "865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces MazeBase: an environment for simple 2D games, designed\n",
      "as a sandbox for machine learning approaches to reasoning and planning. Within\n",
      "it, we create 10 simple games embodying a range of algorithmic tasks (e.g.\n",
      "if-then statements or set negation). A variety of neural models (fully\n",
      "connected, convolutional network, memory network) are deployed via\n",
      "reinforcement learning on these games, with and without a procedurally\n",
      "generated curriculum. Despite the tasks' simplicity, the performance of the\n",
      "models is far from optimal, suggesting directions for future development. We\n",
      "also demonstrate the versatility of MazeBase by using it to emulate small\n",
      "combat scenarios from StarCraft. Models trained on the MazeBase version can be\n",
      "directly applied to StarCraft, where they consistently beat the in-game AI.\n",
      "\n",
      "    \n",
      "866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Computing expected predictions has many interesting applications in areas\n",
      "such as fairness, handling missing values, and data analysis. Unfortunately,\n",
      "computing expectations of a discriminative model with respect to a probability\n",
      "distribution defined by an arbitrary generative model has been proven to be\n",
      "hard in general. In fact, the task is intractable even for simple models such\n",
      "as logistic regression and a naive Bayes distribution. In this paper, we\n",
      "identify a pair of generative and discriminative models that enables tractable\n",
      "computation of expectations of the latter with respect to the former, as well\n",
      "as moments of any order, in case of regression. Specifically, we consider\n",
      "expressive probabilistic circuits with certain structural constraints that\n",
      "support tractable probabilistic inference. Moreover, we exploit the tractable\n",
      "computation of high-order moments to derive an algorithm to approximate the\n",
      "expectations, for classification scenarios in which exact computations are\n",
      "intractable. We evaluate the effectiveness of our exact and approximate\n",
      "algorithms in handling missing data during prediction time where they prove to\n",
      "be competitive to standard imputation techniques on a variety of datasets.\n",
      "Finally, we illustrate how expected prediction framework can be used to reason\n",
      "about the behaviour of discriminative models.\n",
      "\n",
      "    \n",
      "867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Sentiment classification is an important process in understanding people's\n",
      "perception towards a product, service, or topic. Many natural language\n",
      "processing models have been proposed to solve the sentiment classification\n",
      "problem. However, most of them have focused on binary sentiment classification.\n",
      "In this paper, we use a promising deep learning model called BERT to solve the\n",
      "fine-grained sentiment classification task. Experiments show that our model\n",
      "outperforms other popular models for this task without sophisticated\n",
      "architecture. We also demonstrate the effectiveness of transfer learning in\n",
      "natural language processing in the process.\n",
      "\n",
      "    \n",
      "868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We propose a new variational model for nonlinear image fusion. Our approach\n",
      "incorporates the osmosis model proposed in Vogel et al. (2013) and Weickert et\n",
      "al. (2013) as an energy term in a variational model. The osmosis energy is\n",
      "known to realize visually plausible image data fusion. As a consequence, our\n",
      "method is invariant to multiplicative brightness changes. On the practical\n",
      "side, it requires minimal supervision and parameter tuning and can encode prior\n",
      "information on the structure of the images to be fused. We develop a\n",
      "primal-dual algorithm for solving this new image fusion model and we apply the\n",
      "resulting minimisation scheme to multi-modal image fusion for face fusion,\n",
      "colour transfer and some cultural heritage conservation challenges. Visual\n",
      "comparison to state-of-the-art proves the quality and flexibility of our\n",
      "method.\n",
      "\n",
      "    \n",
      "869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The Neural Arithmetic Logic Unit (NALU) is a neural network layer that can\n",
      "learn exact arithmetic operations between the elements of a hidden state. The\n",
      "goal of NALU is to learn perfect extrapolation, which requires learning the\n",
      "exact underlying logic of an unknown arithmetic problem. Evaluating the\n",
      "performance of the NALU is non-trivial as one arithmetic problem might have\n",
      "many solutions. As a consequence, single-instance MSE has been used to evaluate\n",
      "and compare performance between models. However, it can be hard to interpret\n",
      "what magnitude of MSE represents a correct solution and models sensitivity to\n",
      "initialization. We propose using a success-criterion to measure if and when a\n",
      "model converges. Using a success-criterion we can summarize success-rate over\n",
      "many initialization seeds and calculate confidence intervals. We contribute a\n",
      "generalized version of the previous arithmetic benchmark to measure models\n",
      "sensitivity under different conditions. This is, to our knowledge, the first\n",
      "extensive evaluation with respect to convergence of the NALU and its sub-units.\n",
      "Using a success-criterion to summarize 4800 experiments we find that\n",
      "consistently learning arithmetic extrapolation is challenging, in particular\n",
      "for multiplication.\n",
      "\n",
      "    \n",
      "870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Several computational models have been developed to detect and analyze\n",
      "dialect variation in recent years. Most of these models assume a predefined set\n",
      "of geographical regions over which they detect and analyze dialectal variation.\n",
      "However, dialect variation occurs at multiple levels of geographic resolution\n",
      "ranging from cities within a state, states within a country, and between\n",
      "countries across continents. In this work, we propose a model that enables\n",
      "detection of dialectal variation at multiple levels of geographic resolution\n",
      "obviating the need for a-priori definition of the resolution level. Our method\n",
      "DialectGram, learns dialect-sensitive word embeddings while being agnostic of\n",
      "the geographic resolution. Specifically it only requires one-time training and\n",
      "enables analysis of dialectal variation at a chosen resolution post-hoc -- a\n",
      "significant departure from prior models which need to be re-trained whenever\n",
      "the pre-defined set of regions changes. Furthermore, DialectGram explicitly\n",
      "models senses thus enabling one to estimate the proportion of each sense usage\n",
      "in any given region. Finally, we quantitatively evaluate our model against\n",
      "other baselines on a new evaluation dataset DialectSim (in English) and show\n",
      "that DialectGram can effectively model linguistic variation.\n",
      "\n",
      "    \n",
      "871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  News articles such as sports game reports are often thought to closely follow\n",
      "the underlying game statistics, but in practice they contain a notable amount\n",
      "of background knowledge, interpretation, insight into the game, and quotes that\n",
      "are not present in the official statistics. This poses a challenge for\n",
      "automated data-to-text news generation with real-world news corpora as training\n",
      "data. We report on the development of a corpus of Finnish ice hockey news,\n",
      "edited to be suitable for training of end-to-end news generation methods, as\n",
      "well as demonstrate generation of text, which was judged by journalists to be\n",
      "relatively close to a viable product. The new dataset and system source code\n",
      "are available for research purposes at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Face is one of the most important things for communication with the world\n",
      "around us. It also forms our identity and expressions. Estimating the face\n",
      "structure is a fundamental task in computer vision with applications in\n",
      "different areas such as face recognition and medical surgeries. Recently, deep\n",
      "learning techniques achieved significant results for 3D face reconstruction\n",
      "from flat images. The main challenge of such techniques is a vital need for\n",
      "large 3D face datasets. Usually, this challenge is handled by synthetic face\n",
      "generation. However, synthetic datasets suffer from the existence of\n",
      "non-possible faces. Here, we propose a face manifold learning method for\n",
      "synthetic diverse face dataset generation. First, the face structure is divided\n",
      "into the shape and expression groups. Then, a fully convolutional autoencoder\n",
      "network is exploited to deal with the non-possible faces, and, simultaneously,\n",
      "preserving the dataset diversity. Simulation results show that the proposed\n",
      "method is capable of denoising highly corrupted faces. The diversity of the\n",
      "generated dataset is evaluated qualitatively and quantitatively and compared to\n",
      "the existing methods. Experiments show that our manifold learning method\n",
      "outperforms the state of the art methods significantly.\n",
      "\n",
      "    \n",
      "873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generating visualizations and interpretations from high-dimensional data is a\n",
      "common problem in many fields. Two key approaches for tackling this problem are\n",
      "clustering and representation learning. There are very performant deep\n",
      "clustering models on the one hand and interpretable representation learning\n",
      "techniques, often relying on latent topological structures such as\n",
      "self-organizing maps, on the other hand. However, current methods do not yet\n",
      "successfully combine these two approaches. We present a new deep architecture\n",
      "for probabilistic clustering, VarPSOM, and its extension to time series data,\n",
      "VarTPSOM. We show that they achieve superior clustering performance compared to\n",
      "current deep clustering methods on static MNIST/Fashion-MNIST data as well as\n",
      "medical time series, while inducing an interpretable representation. Moreover,\n",
      "on the medical time series, VarTPSOM successfully predicts future trajectories\n",
      "in the original data space.\n",
      "\n",
      "    \n",
      "874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Empirical scoring functions based on either molecular force fields or\n",
      "cheminformatics descriptors are widely used, in conjunction with molecular\n",
      "docking, during the early stages of drug discovery to predict potency and\n",
      "binding affinity of a drug-like molecule to a given target. These models\n",
      "require expert-level knowledge of physical chemistry and biology to be encoded\n",
      "as hand-tuned parameters or features rather than allowing the underlying model\n",
      "to select features in a data-driven procedure. Here, we develop a general\n",
      "3-dimensional spatial convolution operation for learning atomic-level chemical\n",
      "interactions directly from atomic coordinates and demonstrate its application\n",
      "to structure-based bioactivity prediction. The atomic convolutional neural\n",
      "network is trained to predict the experimentally determined binding affinity of\n",
      "a protein-ligand complex by direct calculation of the energy associated with\n",
      "the complex, protein, and ligand given the crystal structure of the binding\n",
      "pose. Non-covalent interactions present in the complex that are absent in the\n",
      "protein-ligand sub-structures are identified and the model learns the\n",
      "interaction strength associated with these features. We test our model by\n",
      "predicting the binding free energy of a subset of protein-ligand complexes\n",
      "found in the PDBBind dataset and compare with state-of-the-art cheminformatics\n",
      "and machine learning-based approaches. We find that all methods achieve\n",
      "experimental accuracy and that atomic convolutional networks either outperform\n",
      "or perform competitively with the cheminformatics based methods. Unlike all\n",
      "previous protein-ligand prediction systems, atomic convolutional networks are\n",
      "end-to-end and fully-differentiable. They represent a new data-driven,\n",
      "physics-based deep learning model paradigm that offers a strong foundation for\n",
      "future improvements in structure-based bioactivity prediction.\n",
      "\n",
      "    \n",
      "875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep Learning has revolutionized vision via convolutional neural networks\n",
      "(CNNs) and natural language processing via recurrent neural networks (RNNs).\n",
      "However, success stories of Deep Learning with standard feed-forward neural\n",
      "networks (FNNs) are rare. FNNs that perform well are typically shallow and,\n",
      "therefore cannot exploit many levels of abstract representations. We introduce\n",
      "self-normalizing neural networks (SNNs) to enable high-level abstract\n",
      "representations. While batch normalization requires explicit normalization,\n",
      "neuron activations of SNNs automatically converge towards zero mean and unit\n",
      "variance. The activation function of SNNs are \"scaled exponential linear units\"\n",
      "(SELUs), which induce self-normalizing properties. Using the Banach fixed-point\n",
      "theorem, we prove that activations close to zero mean and unit variance that\n",
      "are propagated through many network layers will converge towards zero mean and\n",
      "unit variance -- even under the presence of noise and perturbations. This\n",
      "convergence property of SNNs allows to (1) train deep networks with many\n",
      "layers, (2) employ strong regularization, and (3) to make learning highly\n",
      "robust. Furthermore, for activations not close to unit variance, we prove an\n",
      "upper and lower bound on the variance, thus, vanishing and exploding gradients\n",
      "are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning\n",
      "repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with\n",
      "standard FNNs and other machine learning methods such as random forests and\n",
      "support vector machines. SNNs significantly outperformed all competing FNN\n",
      "methods at 121 UCI tasks, outperformed all competing methods at the Tox21\n",
      "dataset, and set a new record at an astronomy data set. The winning SNN\n",
      "architectures are often very deep. Implementations are available at:\n",
      "this http URL.\n",
      "\n",
      "    \n",
      "876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Supervised learning on molecules has incredible potential to be useful in\n",
      "chemistry, drug discovery, and materials science. Luckily, several promising\n",
      "and closely related neural network models invariant to molecular symmetries\n",
      "have already been described in the literature. These models learn a message\n",
      "passing algorithm and aggregation procedure to compute a function of their\n",
      "entire input graph. At this point, the next step is to find a particularly\n",
      "effective variant of this general approach and apply it to chemical prediction\n",
      "benchmarks until we either solve them or reach the limits of the approach. In\n",
      "this paper, we reformulate existing models into a single common framework we\n",
      "call Message Passing Neural Networks (MPNNs) and explore additional novel\n",
      "variations within this framework. Using MPNNs we demonstrate state of the art\n",
      "results on an important molecular property prediction benchmark; these results\n",
      "are strong enough that we believe future work should focus on datasets with\n",
      "larger molecules or more accurate ground truth labels.\n",
      "\n",
      "    \n",
      "877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Graph-structured data appears frequently in domains including chemistry,\n",
      "natural language semantics, social networks, and knowledge bases. In this work,\n",
      "we study feature learning techniques for graph-structured inputs. Our starting\n",
      "point is previous work on Graph Neural Networks (Scarselli et al., 2009), which\n",
      "we modify to use gated recurrent units and modern optimization techniques and\n",
      "then extend to output sequences. The result is a flexible and broadly useful\n",
      "class of neural network models that has favorable inductive biases relative to\n",
      "purely sequence-based models (e.g., LSTMs) when the problem is\n",
      "graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and\n",
      "graph algorithm learning tasks. We then show it achieves state-of-the-art\n",
      "performance on a problem from program verification, in which subgraphs need to\n",
      "be matched to abstract data structures.\n",
      "\n",
      "    \n",
      "878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Multi-task learning (MTL) has led to successes in many applications of\n",
      "machine learning, from natural language processing and speech recognition to\n",
      "computer vision and drug discovery. This article aims to give a general\n",
      "overview of MTL, particularly in deep neural networks. It introduces the two\n",
      "most common methods for MTL in Deep Learning, gives an overview of the\n",
      "literature, and discusses recent advances. In particular, it seeks to help ML\n",
      "practitioners apply MTL by shedding light on how MTL works and providing\n",
      "guidelines for choosing appropriate auxiliary tasks.\n",
      "\n",
      "    \n",
      "879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a convolutional neural network that operates directly on graphs.\n",
      "These networks allow end-to-end learning of prediction pipelines whose inputs\n",
      "are graphs of arbitrary size and shape. The architecture we present generalizes\n",
      "standard molecular feature extraction methods based on circular fingerprints.\n",
      "We show that these data-driven features are more interpretable, and have better\n",
      "predictive performance on a variety of tasks.\n",
      "\n",
      "    \n",
      "880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Deep generative models such as generative adversarial networks, variational\n",
      "autoencoders, and autoregressive models are rapidly growing in popularity for\n",
      "the discovery of new molecules and materials. In this work, we introduce\n",
      "MOlecular SEtS (MOSES), a benchmarking platform to support research on machine\n",
      "learning for drug discovery. MOSES implements several popular molecular\n",
      "generation models and includes a set of metrics that evaluate the diversity and\n",
      "quality of generated molecules. MOSES is meant to standardize the research on\n",
      "molecular generation and facilitate the sharing and comparison of new models.\n",
      "Additionally, we provide a large-scale comparison of existing state of the art\n",
      "models and elaborate on current challenges for generative models that might\n",
      "prove fertile ground for new research. Our platform and source code are freely\n",
      "available at this https URL.\n",
      "\n",
      "    \n",
      "881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We seek to automate the design of molecules based on specific chemical\n",
      "properties. In computational terms, this task involves continuous embedding and\n",
      "generation of molecular graphs. Our primary contribution is the direct\n",
      "realization of molecular graphs, a task previously approached by generating\n",
      "linear SMILES strings instead of graphs. Our junction tree variational\n",
      "autoencoder generates molecular graphs in two phases, by first generating a\n",
      "tree-structured scaffold over chemical substructures, and then combining them\n",
      "into a molecule with a graph message passing network. This approach allows us\n",
      "to incrementally expand molecules while maintaining chemical validity at every\n",
      "step. We evaluate our model on multiple tasks ranging from molecular generation\n",
      "to optimization. Across these tasks, our model outperforms previous\n",
      "state-of-the-art baselines by a significant margin.\n",
      "\n",
      "    \n",
      "882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generating molecules with desired chemical properties is important for drug\n",
      "discovery. The use of generative neural networks is promising for this task.\n",
      "However, from visual inspection, it often appears that generated samples lack\n",
      "diversity. In this paper, we quantify this internal chemical diversity, and we\n",
      "raise the following challenge: can a nontrivial AI model reproduce natural\n",
      "chemical diversity for desired molecules? To illustrate this question, we\n",
      "consider two generative models: a Reinforcement Learning model and the recently\n",
      "introduced ORGAN. Both fail at this challenge. We hope this challenge will\n",
      "stimulate research in this direction.\n",
      "\n",
      "    \n",
      "883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Docking is an important tool in computational drug discovery that aims to\n",
      "predict the binding pose of a ligand to a target protein through a combination\n",
      "of pose scoring and optimization. A scoring function that is differentiable\n",
      "with respect to atom positions can be used for both scoring and gradient-based\n",
      "optimization of poses for docking. Using a differentiable grid-based atomic\n",
      "representation as input, we demonstrate that a scoring function learned by\n",
      "training a convolutional neural network (CNN) to identify binding poses can\n",
      "also be applied to pose optimization. We also show that an iteratively-trained\n",
      "CNN that includes poses optimized by the first CNN in its training set performs\n",
      "even better at optimizing randomly initialized poses than either the first CNN\n",
      "scoring function or AutoDock Vina.\n",
      "\n",
      "    \n",
      "884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Computational approaches to drug discovery can reduce the time and cost\n",
      "associated with experimental assays and enable the screening of novel\n",
      "chemotypes. Structure-based drug design methods rely on scoring functions to\n",
      "rank and predict binding affinities and poses. The ever-expanding amount of\n",
      "protein-ligand binding and structural data enables the use of deep machine\n",
      "learning techniques for protein-ligand scoring.\n",
      "We describe convolutional neural network (CNN) scoring functions that take as\n",
      "input a comprehensive 3D representation of a protein-ligand interaction. A CNN\n",
      "scoring function automatically learns the key features of protein-ligand\n",
      "interactions that correlate with binding. We train and optimize our CNN scoring\n",
      "functions to discriminate between correct and incorrect binding poses and known\n",
      "binders and non-binders. We find that our CNN scoring function outperforms the\n",
      "AutoDock Vina scoring function when ranking poses both for pose prediction and\n",
      "virtual screening.\n",
      "\n",
      "    \n",
      "885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We develop a Bayesian \"sum-of-trees\" model where each tree is constrained by\n",
      "a regularization prior to be a weak learner, and fitting and inference are\n",
      "accomplished via an iterative Bayesian backfitting MCMC algorithm that\n",
      "generates samples from a posterior. Effectively, BART is a nonparametric\n",
      "Bayesian regression approach which uses dimensionally adaptive random basis\n",
      "elements. Motivated by ensemble methods in general, and boosting algorithms in\n",
      "particular, BART is defined by a statistical model: a prior and a likelihood.\n",
      "This approach enables full posterior inference including point and interval\n",
      "estimates of the unknown regression function as well as the marginal effects of\n",
      "potential predictors. By keeping track of predictor inclusion frequencies, BART\n",
      "can also be used for model-free variable selection. BART's many features are\n",
      "illustrated with a bake-off against competing methods on 42 different data\n",
      "sets, with a simulation experiment and on a drug discovery classification\n",
      "problem.\n",
      "\n",
      "    \n",
      "886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The identification of novel drug-target (DT) interactions is a substantial\n",
      "part of the drug discovery process. Most of the computational methods that have\n",
      "been proposed to predict DT interactions have focused on binary classification,\n",
      "where the goal is to determine whether a DT pair interacts or not. However,\n",
      "protein-ligand interactions assume a continuum of binding strength values, also\n",
      "called binding affinity and predicting this value still remains a challenge.\n",
      "The increase in the affinity data available in DT knowledge-bases allows the\n",
      "use of advanced learning techniques such as deep learning architectures in the\n",
      "prediction of binding affinities. In this study, we propose a deep-learning\n",
      "based model that uses only sequence information of both targets and drugs to\n",
      "predict DT interaction binding affinities. The few studies that focus on DT\n",
      "binding affinity prediction use either 3D structures of protein-ligand\n",
      "complexes or 2D features of compounds. One novel approach used in this work is\n",
      "the modeling of protein sequences and compound 1D representations with\n",
      "convolutional neural networks (CNNs). The results show that the proposed deep\n",
      "learning based model that uses the 1D representations of targets and drugs is\n",
      "an effective approach for drug target binding affinity prediction. The model in\n",
      "which high-level representations of a drug and a target are constructed via\n",
      "CNNs achieved the best Concordance Index (CI) performance in one of our larger\n",
      "benchmark data sets, outperforming the KronRLS algorithm and SimBoost, a\n",
      "state-of-the-art method for DT binding affinity prediction.\n",
      "\n",
      "    \n",
      "887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Predicating macroscopic influences of drugs on human body, like efficacy and\n",
      "toxicity, is a central problem of small-molecule based drug discovery.\n",
      "Molecules can be represented as an undirected graph, and we can utilize graph\n",
      "convolution networks to predication molecular properties. However, graph\n",
      "convolutional networks and other graph neural networks all focus on learning\n",
      "node-level representation rather than graph-level representation. Previous\n",
      "works simply sum all feature vectors for all nodes in the graph to obtain the\n",
      "graph feature vector for drug predication. In this paper, we introduce a dummy\n",
      "super node that is connected with all nodes in the graph by a directed edge as\n",
      "the representation of the graph and modify the graph operation to help the\n",
      "dummy super node learn graph-level feature. Thus, we can handle graph-level\n",
      "classification and regression in the same way as node-level classification and\n",
      "regression. In addition, we apply focal loss to address class imbalance in drug\n",
      "datasets. The experiments on MoleculeNet show that our method can effectively\n",
      "improve the performance of molecular properties predication.\n",
      "\n",
      "    \n",
      "888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In de novo drug design, computational strategies are used to generate novel\n",
      "molecules with good affinity to the desired biological target. In this work, we\n",
      "show that recurrent neural networks can be trained as generative models for\n",
      "molecular structures, similar to statistical language models in natural\n",
      "language processing. We demonstrate that the properties of the generated\n",
      "molecules correlate very well with the properties of the molecules used to\n",
      "train the model. In order to enrich libraries with molecules active towards a\n",
      "given biological target, we propose to fine-tune the model with small sets of\n",
      "molecules, which are known to be active against that target.\n",
      "Against Staphylococcus aureus, the model reproduced 14% of 6051 hold-out test\n",
      "molecules that medicinal chemists designed, whereas against Plasmodium\n",
      "falciparum (Malaria) it reproduced 28% of 1240 test molecules. When coupled\n",
      "with a scoring function, our model can perform the complete de novo drug design\n",
      "cycle to generate large sets of novel molecules for drug discovery.\n",
      "\n",
      "    \n",
      "889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Adversarial training provides a means of regularizing supervised learning\n",
      "algorithms while virtual adversarial training is able to extend supervised\n",
      "learning algorithms to the semi-supervised setting. However, both methods\n",
      "require making small perturbations to numerous entries of the input vector,\n",
      "which is inappropriate for sparse high-dimensional inputs such as one-hot word\n",
      "representations. We extend adversarial and virtual adversarial training to the\n",
      "text domain by applying perturbations to the word embeddings in a recurrent\n",
      "neural network rather than to the original input itself. The proposed method\n",
      "achieves state of the art results on multiple benchmark semi-supervised and\n",
      "purely supervised tasks. We provide visualizations and analysis showing that\n",
      "the learned word embeddings have improved in quality and that while training,\n",
      "the model is less prone to overfitting.\n",
      "\n",
      "    \n",
      "890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Named entity recognition is a challenging task that has traditionally\n",
      "required large amounts of knowledge in the form of feature engineering and\n",
      "lexicons to achieve high performance. In this paper, we present a novel neural\n",
      "network architecture that automatically detects word- and character-level\n",
      "features using a hybrid bidirectional LSTM and CNN architecture, eliminating\n",
      "the need for most feature engineering. We also propose a novel method of\n",
      "encoding partial lexicon matches in neural networks and compare it to existing\n",
      "approaches. Extensive evaluation shows that, given only tokenized text and\n",
      "publicly available word embeddings, our system is competitive on the CoNLL-2003\n",
      "dataset and surpasses the previously reported state of the art performance on\n",
      "the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed\n",
      "from publicly-available sources, we establish new state of the art performance\n",
      "with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing\n",
      "systems that employ heavy feature engineering, proprietary lexicons, and rich\n",
      "entity linking information.\n",
      "\n",
      "    \n",
      "891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present StarSpace, a general-purpose neural embedding model that can solve\n",
      "a wide variety of problems: labeling tasks such as text classification, ranking\n",
      "tasks such as information retrieval/web search, collaborative filtering-based\n",
      "or content-based recommendation, embedding of multi-relational graphs, and\n",
      "learning word, sentence or document level embeddings. In each case the model\n",
      "works by embedding those entities comprised of discrete features and comparing\n",
      "them against each other -- learning similarities dependent on the task.\n",
      "Empirical results on a number of tasks show that StarSpace is highly\n",
      "competitive with existing methods, whilst also being generally applicable to\n",
      "new cases where those methods are not.\n",
      "\n",
      "    \n",
      "892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Word embeddings are a popular approach to unsupervised learning of word\n",
      "relationships that are widely used in natural language processing. In this\n",
      "article, we present a new set of embeddings for medical concepts learned using\n",
      "an extremely large collection of multimodal medical data. Leaning on recent\n",
      "theoretical insights, we demonstrate how an insurance claims database of 60\n",
      "million members, a collection of 20 million clinical notes, and 1.7 million\n",
      "full text biomedical journal articles can be combined to embed concepts into a\n",
      "common space, resulting in the largest ever set of embeddings for 108,477\n",
      "medical concepts. To evaluate our approach, we present a new benchmark\n",
      "methodology based on statistical power specifically designed to test embeddings\n",
      "of medical concepts. Our approach, called cui2vec, attains state-of-the-art\n",
      "performance relative to previous methods in most instances. Finally, we provide\n",
      "a downloadable set of pre-trained embeddings for other researchers to use, as\n",
      "well as an online tool for interactive exploration of the cui2vec embeddings\n",
      "\n",
      "    \n",
      "893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Named Entity Recognition (NER) is one of the most common tasks of the natural\n",
      "language processing. The purpose of NER is to find and classify tokens in text\n",
      "documents into predefined categories called tags, such as person names,\n",
      "quantity expressions, percentage expressions, names of locations,\n",
      "organizations, as well as expression of time, currency and others. Although\n",
      "there is a number of approaches have been proposed for this task in Russian\n",
      "language, it still has a substantial potential for the better solutions. In\n",
      "this work, we studied several deep neural network models starting from vanilla\n",
      "Bi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with\n",
      "Conditional Random Fields (CRF) as well as highway networks and finally adding\n",
      "external word embeddings. All models were evaluated across three datasets:\n",
      "Gareev's dataset, Person-1000, FactRuEval-2016. We found that extension of\n",
      "Bi-LSTM model with CRF significantly increased the quality of predictions.\n",
      "Encoding input tokens with external word embeddings reduced training time and\n",
      "allowed to achieve state of the art for the Russian NER task.\n",
      "\n",
      "    \n",
      "894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Distributed dense word vectors have been shown to be effective at capturing\n",
      "token-level semantic and syntactic regularities in language, while topic models\n",
      "can form interpretable representations over documents. In this work, we\n",
      "describe lda2vec, a model that learns dense word vectors jointly with\n",
      "Dirichlet-distributed latent document-level mixtures of topic vectors. In\n",
      "contrast to continuous dense document representations, this formulation\n",
      "produces sparse, interpretable document mixtures through a non-negative simplex\n",
      "constraint. Our method is simple to incorporate into existing automatic\n",
      "differentiation frameworks and allows for unsupervised document representations\n",
      "geared for use by scientists while simultaneously learning word vectors and the\n",
      "linear relationships between them.\n",
      "\n",
      "    \n",
      "895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the task of aligning two sets of points in high dimension, which\n",
      "has many applications in natural language processing and computer vision. As an\n",
      "example, it was recently shown that it is possible to infer a bilingual\n",
      "lexicon, without supervised data, by aligning word embeddings trained on\n",
      "monolingual data. These recent advances are based on adversarial training to\n",
      "learn the mapping between the two embeddings. In this paper, we propose to use\n",
      "an alternative formulation, based on the joint estimation of an orthogonal\n",
      "matrix and a permutation matrix. While this problem is not convex, we propose\n",
      "to initialize our optimization algorithm by using a convex relaxation,\n",
      "traditionally considered for the graph isomorphism problem. We propose a\n",
      "stochastic algorithm to minimize our cost function on large scale problems.\n",
      "Finally, we evaluate our method on the problem of unsupervised word\n",
      "translation, by aligning word embeddings trained on monolingual data. On this\n",
      "task, our method obtains state of the art results, while requiring less\n",
      "computational resources than competing approaches.\n",
      "\n",
      "    \n",
      "896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  State-of-the-art methods for learning cross-lingual word embeddings have\n",
      "relied on bilingual dictionaries or parallel corpora. Recent studies showed\n",
      "that the need for parallel data supervision can be alleviated with\n",
      "character-level information. While these methods showed encouraging results,\n",
      "they are not on par with their supervised counterparts and are limited to pairs\n",
      "of languages sharing a common alphabet. In this work, we show that we can build\n",
      "a bilingual dictionary between two languages without using any parallel\n",
      "corpora, by aligning monolingual word embedding spaces in an unsupervised way.\n",
      "Without using any character information, our model even outperforms existing\n",
      "supervised methods on cross-lingual tasks for some language pairs. Our\n",
      "experiments demonstrate that our method works very well also for distant\n",
      "language pairs, like English-Russian or English-Chinese. We finally describe\n",
      "experiments on the English-Esperanto low-resource language pair, on which there\n",
      "only exists a limited amount of parallel data, to show the potential impact of\n",
      "our method in fully unsupervised machine translation. Our code, embeddings and\n",
      "dictionaries are publicly available.\n",
      "\n",
      "    \n",
      "897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many modern NLP systems rely on word embeddings, previously trained in an\n",
      "unsupervised manner on large corpora, as base features. Efforts to obtain\n",
      "embeddings for larger chunks of text, such as sentences, have however not been\n",
      "so successful. Several attempts at learning unsupervised representations of\n",
      "sentences have not reached satisfactory enough performance to be widely\n",
      "adopted. In this paper, we show how universal sentence representations trained\n",
      "using the supervised data of the Stanford Natural Language Inference datasets\n",
      "can consistently outperform unsupervised methods like SkipThought vectors on a\n",
      "wide range of transfer tasks. Much like how computer vision uses ImageNet to\n",
      "obtain features, which can then be transferred to other tasks, our work tends\n",
      "to indicate the suitability of natural language inference for transfer learning\n",
      "to other NLP tasks. Our encoder is publicly available.\n",
      "\n",
      "    \n",
      "898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Despite the fast developmental pace of new sentence embedding methods, it is\n",
      "still challenging to find comprehensive evaluations of these different\n",
      "techniques. In the past years, we saw significant improvements in the field of\n",
      "sentence embeddings and especially towards the development of universal\n",
      "sentence encoders that could provide inductive transfer to a wide variety of\n",
      "downstream tasks. In this work, we perform a comprehensive evaluation of recent\n",
      "methods using a wide variety of downstream and linguistic feature probing\n",
      "tasks. We show that a simple approach using bag-of-words with a recently\n",
      "introduced language model for deep context-dependent word embeddings proved to\n",
      "yield better results in many tasks when compared to sentence encoders trained\n",
      "on entailment datasets. We also show, however, that we are still far away from\n",
      "a universal encoder that can perform consistently across several downstream\n",
      "tasks.\n",
      "\n",
      "    \n",
      "899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Probabilistic atlas priors have been commonly used to derive adaptive and\n",
      "robust brain MRI segmentation algorithms. Widely-used neuroimage analysis\n",
      "pipelines rely heavily on these techniques, which are often computationally\n",
      "expensive. In contrast, there has been a recent surge of approaches that\n",
      "leverage deep learning to implement segmentation tools that are computationally\n",
      "efficient at test time. However, most of these strategies rely on learning from\n",
      "manually annotated images. These supervised deep learning methods are therefore\n",
      "sensitive to the intensity profiles in the training dataset. To develop a deep\n",
      "learning-based segmentation model for a new image dataset (e.g., of different\n",
      "contrast), one usually needs to create a new labeled training dataset, which\n",
      "can be prohibitively expensive, or rely on suboptimal ad hoc adaptation or\n",
      "augmentation approaches. In this paper, we propose an alternative strategy that\n",
      "combines a conventional probabilistic atlas-based segmentation with deep\n",
      "learning, enabling one to train a segmentation model for new MRI scans without\n",
      "the need for any manually segmented images. Our experiments include thousands\n",
      "of brain MRI scans and demonstrate that the proposed method achieves good\n",
      "accuracy for a brain MRI segmentation task for different MRI contrasts,\n",
      "requiring only approximately 15 seconds at test time on a GPU. The code is\n",
      "freely available at this http URL.\n",
      "\n",
      "    \n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We address the problem of segmenting 3D multi-modal medical images in\n",
      "scenarios where very few labeled examples are available for training.\n",
      "Leveraging the recent success of adversarial learning for semi-supervised\n",
      "segmentation, we propose a novel method based on Generative Adversarial\n",
      "Networks (GANs) to train a segmentation model with both labeled and unlabeled\n",
      "images. The proposed method prevents over-fitting by learning to discriminate\n",
      "between true and fake patches obtained by a generator network. Our work extends\n",
      "current adversarial learning approaches, which focus on 2D single-modality\n",
      "images, to the more challenging context of 3D volumes of multiple modalities.\n",
      "The proposed method is evaluated on the problem of segmenting brain MRI from\n",
      "the iSEG-2017 and MRBrainS 2013 datasets. Significant performance improvement\n",
      "is reported, compared to state-of-art segmentation networks trained in a\n",
      "fully-supervised manner. In addition, our work presents a comprehensive\n",
      "analysis of different GAN architectures for semi-supervised segmentation,\n",
      "showing recent techniques like feature matching to yield a higher performance\n",
      "than conventional adversarial training approaches. Our code is publicly\n",
      "available at this https URL\n",
      "\n",
      "901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent analysis identified distinct genomic subtypes of lower-grade glioma\n",
      "tumors which are associated with shape features. In this study, we propose a\n",
      "fully automatic way to quantify tumor imaging characteristics using deep\n",
      "learning-based segmentation and test whether these characteristics are\n",
      "predictive of tumor genomic subtypes. We used preoperative imaging and genomic\n",
      "data of 110 patients from 5 institutions with lower-grade gliomas from The\n",
      "Cancer Genome Atlas. Based on automatic deep learning segmentations, we\n",
      "extracted three features which quantify two-dimensional and three-dimensional\n",
      "characteristics of the tumors. Genomic data for the analyzed cohort of patients\n",
      "consisted of previously identified genomic clusters based on IDH mutation and\n",
      "1p/19q co-deletion, DNA methylation, gene expression, DNA copy number, and\n",
      "microRNA expression. To analyze the relationship between the imaging features\n",
      "and genomic clusters, we conducted the Fisher exact test for 10 hypotheses for\n",
      "each pair of imaging feature and genomic subtype. To account for multiple\n",
      "hypothesis testing, we applied a Bonferroni correction. P-values lower than\n",
      "0.005 were considered statistically significant. We found the strongest\n",
      "association between RNASeq clusters and the bounding ellipsoid volume ratio\n",
      "($p<0.0002$) and between RNASeq clusters and margin fluctuation ($p<0.005$). In\n",
      "addition, we identified associations between bounding ellipsoid volume ratio\n",
      "and all tested molecular subtypes ($p<0.02$) as well as between angular\n",
      "standard deviation and RNASeq cluster ($p<0.02$). In terms of automatic tumor\n",
      "segmentation that was used to generate the quantitative image characteristics,\n",
      "our deep learning algorithm achieved a mean Dice coefficient of 82% which is\n",
      "comparable to human performance.\n",
      "\n",
      "    \n",
      "902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This study investigates a 3D and fully convolutional neural network (CNN) for\n",
      "subcortical brain structure segmentation in MRI. 3D CNN architectures have been\n",
      "generally avoided due to their computational and memory requirements during\n",
      "inference. We address the problem via small kernels, allowing deeper\n",
      "architectures. We further model both local and global context by embedding\n",
      "intermediate-layer outputs in the final prediction, which encourages\n",
      "consistency between features extracted at different scales and embeds\n",
      "fine-grained information directly in the segmentation process. Our model is\n",
      "efficiently trained end-to-end on a graphics processing unit (GPU), in a single\n",
      "stage, exploiting the dense inference capabilities of fully CNNs.\n",
      "We performed comprehensive experiments over two publicly available datasets.\n",
      "First, we demonstrate a state-of-the-art performance on the ISBR dataset. Then,\n",
      "we report a {\\em large-scale} multi-site evaluation over 1112 unregistered\n",
      "subject datasets acquired from 17 different sites (ABIDE dataset), with ages\n",
      "ranging from 7 to 64 years, showing that our method is robust to various\n",
      "acquisition protocols, demographics and clinical factors. Our method yielded\n",
      "segmentations that are highly consistent with a standard atlas-based approach,\n",
      "while running in a fraction of the time needed by atlas-based methods and\n",
      "avoiding registration/normalization steps. This makes it convenient for massive\n",
      "multi-site neuroanatomical imaging studies. To the best of our knowledge, our\n",
      "work is the first to study subcortical structure segmentation on such\n",
      "large-scale and heterogeneous data.\n",
      "\n",
      "    \n",
      "903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recently, dense connections have attracted substantial attention in computer\n",
      "vision because they facilitate gradient flow and implicit deep supervision\n",
      "during training. Particularly, DenseNet, which connects each layer to every\n",
      "other layer in a feed-forward fashion, has shown impressive performances in\n",
      "natural image classification tasks. We propose HyperDenseNet, a 3D fully\n",
      "convolutional neural network that extends the definition of dense connectivity\n",
      "to multi-modal segmentation problems. Each imaging modality has a path, and\n",
      "dense connections occur not only between the pairs of layers within the same\n",
      "path, but also between those across different paths. This contrasts with the\n",
      "existing multi-modal CNN approaches, in which modeling several modalities\n",
      "relies entirely on a single joint layer (or level of abstraction) for fusion,\n",
      "typically either at the input or at the output of the network. Therefore, the\n",
      "proposed network has total freedom to learn more complex combinations between\n",
      "the modalities, within and in-between all the levels of abstraction, which\n",
      "increases significantly the learning representation. We report extensive\n",
      "evaluations over two different and highly competitive multi-modal brain tissue\n",
      "segmentation challenges, iSEG 2017 and MRBrainS 2013, with the former focusing\n",
      "on 6-month infant data and the latter on adult images. HyperDenseNet yielded\n",
      "significant improvements over many state-of-the-art segmentation networks,\n",
      "ranking at the top on both benchmarks. We further provide a comprehensive\n",
      "experimental analysis of features re-use, which confirms the importance of\n",
      "hyper-dense connections in multi-modal representation learning. Our code is\n",
      "publicly available at this https URL.\n",
      "\n",
      "    \n",
      "904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Inspired by recent successes of deep learning in computer vision, we propose\n",
      "a novel framework for encoding time series as different types of images,\n",
      "namely, Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov\n",
      "Transition Fields (MTF). This enables the use of techniques from computer\n",
      "vision for time series classification and imputation. We used Tiled\n",
      "Convolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn\n",
      "high-level features from the individual and compound GASF-GADF-MTF images. Our\n",
      "approaches achieve highly competitive results when compared to nine of the\n",
      "current best time series classification approaches. Inspired by the bijection\n",
      "property of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on\n",
      "the GASF images of four standard and one synthesized compound dataset. The\n",
      "imputation MSE on test data is reduced by 12.18%-48.02% when compared to using\n",
      "the raw data. An analysis of the features and weights learned via tiled CNNs\n",
      "and DAs explains why the approaches work.\n",
      "\n",
      "    \n",
      "905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Spatial studies of transcriptome provide biologists with gene expression maps\n",
      "of heterogeneous and complex tissues. However, most experimental protocols for\n",
      "spatial transcriptomics suffer from the need to select beforehand a small\n",
      "fraction of genes to be quantified over the entire transcriptome. Standard\n",
      "single-cell RNA sequencing (scRNA-seq) is more prevalent, easier to implement\n",
      "and can in principle capture any gene but cannot recover the spatial location\n",
      "of the cells. In this manuscript, we focus on the problem of imputation of\n",
      "missing genes in spatial transcriptomic data based on (unpaired) standard\n",
      "scRNA-seq data from the same biological tissue. Building upon domain adaptation\n",
      "work, we propose gimVI, a deep generative model for the integration of spatial\n",
      "transcriptomic data and scRNA-seq data that can be used to impute missing\n",
      "genes. After describing our generative model and an inference procedure for it,\n",
      "we compare gimVI to alternative methods from computational biology or domain\n",
      "adaptation on real datasets and outperform Seurat Anchors, Liger and CORAL to\n",
      "impute held-out genes.\n",
      "\n",
      "    \n",
      "906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents the input convex neural network architecture. These are\n",
      "scalar-valued (potentially deep) neural networks with constraints on the\n",
      "network parameters such that the output of the network is a convex function of\n",
      "(some of) the inputs. The networks allow for efficient inference via\n",
      "optimization over some inputs to the network given others, and can be applied\n",
      "to settings including structured prediction, data imputation, reinforcement\n",
      "learning, and others. In this paper we lay the basic groundwork for these\n",
      "models, proposing methods for inference, optimization and learning, and analyze\n",
      "their representational power. We show that many existing neural network\n",
      "architectures can be made input-convex with a minor modification, and develop\n",
      "specialized optimization algorithms tailored to this setting. Finally, we\n",
      "highlight the performance of the methods on multi-label prediction, image\n",
      "completion, and reinforcement learning problems, where we show improvement over\n",
      "the existing state of the art in many cases.\n",
      "\n",
      "    \n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  As sound event classification moves towards larger datasets, issues of label\n",
      "noise become inevitable. Web sites can supply large volumes of user-contributed\n",
      "audio and metadata, but inferring labels from this metadata introduces errors\n",
      "due to unreliable inputs, and limitations in the mapping. There is, however,\n",
      "little research into the impact of these errors. To foster the investigation of\n",
      "label noise in sound event classification we present FSDnoisy18k, a dataset\n",
      "containing 42.5 hours of audio across 20 sound classes, including a small\n",
      "amount of manually-labeled data and a larger quantity of real-world noisy data.\n",
      "We characterize the label noise empirically, and provide a CNN baseline system.\n",
      "Experiments suggest that training with large amounts of noisy data can\n",
      "outperform training with smaller amounts of carefully-labeled data. We also\n",
      "show that noise-robust loss functions can be effective in improving performance\n",
      "in presence of corrupted labels.\n",
      "\n",
      "    \n",
      "908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Sound event detection (SED) methods are tasked with labeling segments of\n",
      "audio recordings by the presence of active sound sources. SED is typically\n",
      "posed as a supervised machine learning problem, requiring strong annotations\n",
      "for the presence or absence of each sound source at every time instant within\n",
      "the recording. However, strong annotations of this type are both labor- and\n",
      "cost-intensive for human annotators to produce, which limits the practical\n",
      "scalability of SED methods.\n",
      "In this work, we treat SED as a multiple instance learning (MIL) problem,\n",
      "where training labels are static over a short excerpt, indicating the presence\n",
      "or absence of sound sources but not their temporal locality. The models,\n",
      "however, must still produce temporally dynamic predictions, which must be\n",
      "aggregated (pooled) when comparing against static labels during training. To\n",
      "facilitate this aggregation, we develop a family of adaptive pooling\n",
      "operators---referred to as auto-pool---which smoothly interpolate between\n",
      "common pooling operators, such as min-, max-, or average-pooling, and\n",
      "automatically adapt to the characteristics of the sound sources in question. We\n",
      "evaluate the proposed pooling operators on three datasets, and demonstrate that\n",
      "in each case, the proposed methods outperform non-adaptive pooling operators\n",
      "for static prediction, and nearly match the performance of models trained with\n",
      "strong, dynamic annotations. The proposed method is evaluated in conjunction\n",
      "with convolutional neural networks, but can be readily applied to any\n",
      "differentiable model for time-series label prediction.\n",
      "\n",
      "    \n",
      "909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Spatiotemporal forecasting has various applications in neuroscience, climate\n",
      "and transportation domain. Traffic forecasting is one canonical example of such\n",
      "learning task. The task is challenging due to (1) complex spatial dependency on\n",
      "road networks, (2) non-linear temporal dynamics with changing road conditions\n",
      "and (3) inherent difficulty of long-term forecasting. To address these\n",
      "challenges, we propose to model the traffic flow as a diffusion process on a\n",
      "directed graph and introduce Diffusion Convolutional Recurrent Neural Network\n",
      "(DCRNN), a deep learning framework for traffic forecasting that incorporates\n",
      "both spatial and temporal dependency in the traffic flow. Specifically, DCRNN\n",
      "captures the spatial dependency using bidirectional random walks on the graph,\n",
      "and the temporal dependency using the encoder-decoder architecture with\n",
      "scheduled sampling. We evaluate the framework on two real-world large scale\n",
      "road network traffic datasets and observe consistent improvement of 12% - 15%\n",
      "over state-of-the-art baselines.\n",
      "\n",
      "    \n",
      "910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Accurate and real-time traffic forecasting plays an important role in the\n",
      "Intelligent Traffic System and is of great significance for urban traffic\n",
      "planning, traffic management, and traffic control. However, traffic forecasting\n",
      "has always been considered an open scientific issue, owing to the constraints\n",
      "of urban road network topological structure and the law of dynamic change with\n",
      "time, namely, spatial dependence and temporal dependence. To capture the\n",
      "spatial and temporal dependence simultaneously, we propose a novel neural\n",
      "network-based traffic forecasting method, the temporal graph convolutional\n",
      "network (T-GCN) model, which is in combination with the graph convolutional\n",
      "network (GCN) and gated recurrent unit (GRU). Specifically, the GCN is used to\n",
      "learn complex topological structures to capture spatial dependence and the\n",
      "gated recurrent unit is used to learn dynamic changes of traffic data to\n",
      "capture temporal dependence. Then, the T-GCN model is employed to traffic\n",
      "forecasting based on the urban road network. Experiments demonstrate that our\n",
      "T-GCN model can obtain the spatio-temporal correlation from traffic data and\n",
      "the predictions outperform state-of-art baselines on real-world traffic\n",
      "datasets. Our tensorflow implementation of the T-GCN is available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Predicting traffic conditions from online route queries is a challenging task\n",
      "as there are many complicated interactions over the roads and crowds involved.\n",
      "In this paper, we intend to improve traffic prediction by appropriate\n",
      "integration of three kinds of implicit but essential factors encoded in\n",
      "auxiliary information. We do this within an encoder-decoder sequence learning\n",
      "framework that integrates the following data: 1) offline geographical and\n",
      "social attributes. For example, the geographical structure of roads or public\n",
      "social events such as national celebrations; 2) road intersection information.\n",
      "In general, traffic congestion occurs at major junctions; 3) online crowd\n",
      "queries. For example, when many online queries issued for the same destination\n",
      "due to a public performance, the traffic around the destination will\n",
      "potentially become heavier at this location after a while. Qualitative and\n",
      "quantitative experiments on a real-world dataset from Baidu have demonstrated\n",
      "the effectiveness of our framework.\n",
      "\n",
      "    \n",
      "912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Interpretability of deep neural networks is a recently emerging area of\n",
      "machine learning research targeting a better understanding of how models\n",
      "perform feature selection and derive their classification decisions. In this\n",
      "paper, two neural network architectures are trained on spectrogram and raw\n",
      "waveform data for audio classification tasks on a newly created audio dataset\n",
      "and layer-wise relevance propagation (LRP), a previously proposed\n",
      "interpretability method, is applied to investigate the models' feature\n",
      "selection and decision making. It is demonstrated that the networks are highly\n",
      "reliant on feature marked as relevant by LRP through systematic manipulation of\n",
      "the input data. Our results show that by making deep audio classifiers\n",
      "interpretable, one can analyze and compare the properties and strategies of\n",
      "different models beyond classification accuracy, which potentially opens up new\n",
      "ways for model improvements.\n",
      "\n",
      "    \n",
      "913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNNs) have proven very effective in image\n",
      "classification and show promise for audio. We use various CNN architectures to\n",
      "classify the soundtracks of a dataset of 70M training videos (5.24 million\n",
      "hours) with 30,871 video-level labels. We examine fully connected Deep Neural\n",
      "Networks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We\n",
      "investigate varying the size of both training set and label vocabulary, finding\n",
      "that analogs of the CNNs used in image classification do well on our audio\n",
      "classification task, and larger training and label sets help up to a point. A\n",
      "model using embeddings from these classifiers does much better than raw\n",
      "features on the Audio Set [5] Acoustic Event Detection (AED) classification\n",
      "task.\n",
      "\n",
      "    \n",
      "914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Efficient audio synthesis is an inherently difficult machine learning task,\n",
      "as human perception is sensitive to both global structure and fine-scale\n",
      "waveform coherence. Autoregressive models, such as WaveNet, model local\n",
      "structure at the expense of global latent structure and slow iterative\n",
      "sampling, while Generative Adversarial Networks (GANs), have global latent\n",
      "conditioning and efficient parallel sampling, but struggle to generate\n",
      "locally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact\n",
      "generate high-fidelity and locally-coherent audio by modeling log magnitudes\n",
      "and instantaneous frequencies with sufficient frequency resolution in the\n",
      "spectral domain. Through extensive empirical investigations on the NSynth\n",
      "dataset, we demonstrate that GANs are able to outperform strong WaveNet\n",
      "baselines on automated and human evaluation metrics, and efficiently generate\n",
      "audio several orders of magnitude faster than their autoregressive\n",
      "counterparts.\n",
      "\n",
      "    \n",
      "915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Audio signals are sampled at high temporal resolutions, and learning to\n",
      "synthesize audio requires capturing structure across a range of timescales.\n",
      "Generative adversarial networks (GANs) have seen wide success at generating\n",
      "images that are both locally and globally coherent, but they have seen little\n",
      "application to audio generation. In this paper we introduce WaveGAN, a first\n",
      "attempt at applying GANs to unsupervised synthesis of raw-waveform audio.\n",
      "WaveGAN is capable of synthesizing one second slices of audio waveforms with\n",
      "global coherence, suitable for sound effect generation. Our experiments\n",
      "demonstrate that, without labels, WaveGAN learns to produce intelligible words\n",
      "when trained on a small-vocabulary speech dataset, and can also synthesize\n",
      "audio from other domains such as drums, bird vocalizations, and piano. We\n",
      "compare WaveGAN to a method which applies GANs designed for image generation on\n",
      "image-like audio feature representations, finding both approaches to be\n",
      "promising.\n",
      "\n",
      "    \n",
      "916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we propose a novel model for unconditional audio generation\n",
      "based on generating one audio sample at a time. We show that our model, which\n",
      "profits from combining memory-less modules, namely autoregressive multilayer\n",
      "perceptrons, and stateful recurrent neural networks in a hierarchical structure\n",
      "is able to capture underlying sources of variations in the temporal sequences\n",
      "over very long time spans, on three datasets of different nature. Human\n",
      "evaluation on the generated samples indicate that our model is preferred over\n",
      "competing models. We also show how each component of the model contributes to\n",
      "the exhibited performance.\n",
      "\n",
      "    \n",
      "917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce a new audio processing technique that increases the sampling\n",
      "rate of signals such as speech or music using deep convolutional neural\n",
      "networks. Our model is trained on pairs of low and high-quality audio examples;\n",
      "at test-time, it predicts missing samples within a low-resolution signal in an\n",
      "interpolation process similar to image super-resolution. Our method is simple\n",
      "and does not involve specialized audio processing techniques; in our\n",
      "experiments, it outperforms baselines on standard speech and music benchmarks\n",
      "at upscaling ratios of 2x, 4x, and 6x. The method has practical applications in\n",
      "telephony, compression, and text-to-speech generation; it demonstrates the\n",
      "effectiveness of feed-forward convolutional architectures on an audio\n",
      "generation task.\n",
      "\n",
      "    \n",
      "918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Capturing high-level structure in audio waveforms is challenging because a\n",
      "single second of audio spans tens of thousands of timesteps. While long-range\n",
      "dependencies are difficult to model directly in the time domain, we show that\n",
      "they can be more tractably modelled in two-dimensional time-frequency\n",
      "representations such as spectrograms. By leveraging this representational\n",
      "advantage, in conjunction with a highly expressive probabilistic model and a\n",
      "multiscale generation procedure, we design a model capable of generating\n",
      "high-fidelity audio samples which capture structure at timescales that\n",
      "time-domain models have yet to achieve. We apply our model to a variety of\n",
      "audio generation tasks, including unconditional speech generation, music\n",
      "generation, and text-to-speech synthesis---showing improvements over previous\n",
      "approaches in both density estimates and human judgments.\n",
      "\n",
      "    \n",
      "919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  End-to-end models for raw audio generation are a challenge, specially if they\n",
      "have to work with non-parallel data, which is a desirable setup in many\n",
      "situations. Voice conversion, in which a model has to impersonate a speaker in\n",
      "a recording, is one of those situations. In this paper, we propose Blow, a\n",
      "single-scale normalizing flow using hypernetwork conditioning to perform\n",
      "many-to-many voice conversion between raw audio. Blow is trained end-to-end,\n",
      "with non-parallel data, on a frame-by-frame basis using a single speaker\n",
      "identifier. We show that Blow compares favorably to existing flow-based\n",
      "architectures and other competitive baselines, obtaining equal or better\n",
      "performance in both objective and subjective evaluations. We further assess the\n",
      "impact of its main components with an ablation study, and quantify a number of\n",
      "properties such as the necessary amount of training data or the preference for\n",
      "source or target speakers.\n",
      "\n",
      "    \n",
      "920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generative models are successfully used for image synthesis in the recent\n",
      "years. But when it comes to other modalities like audio, text etc little\n",
      "progress has been made. Recent works focus on generating audio from a\n",
      "generative model in an unsupervised setting. We explore the possibility of\n",
      "using generative models conditioned on class labels. Concatenation based\n",
      "conditioning and conditional scaling were explored in this work with various\n",
      "hyper-parameter tuning methods. In this paper we introduce Conditional WaveGANs\n",
      "(cWaveGAN). Find our implementation at this https URL\n",
      "\n",
      "921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Dilated convolutions, also known as atrous convolutions, have been widely\n",
      "explored in deep convolutional neural networks (DCNNs) for various dense\n",
      "prediction tasks. However, dilated convolutions suffer from the gridding\n",
      "artifacts, which hampers the performance. In this work, we propose two simple\n",
      "yet effective degridding methods by studying a decomposition of dilated\n",
      "convolutions. Unlike existing models, which explore solutions by focusing on a\n",
      "block of cascaded dilated convolutional layers, our methods address the\n",
      "gridding artifacts by smoothing the dilated convolution itself. In addition, we\n",
      "point out that the two degridding approaches are intrinsically related and\n",
      "define separable and shared (SS) operations, which generalize the proposed\n",
      "methods. We further explore SS operations in view of operations on graphs and\n",
      "propose the SS output layer, which is able to smooth the entire DCNNs by only\n",
      "replacing the output layer. We evaluate our degridding methods and the SS\n",
      "output layer thoroughly, and visualize the smoothing effect through effective\n",
      "receptive field analysis. Results show that our methods degridding yield\n",
      "consistent improvements on the performance of dense prediction tasks, while\n",
      "adding negligible amounts of extra training parameters. And the SS output layer\n",
      "improves the performance significantly and is very efficient in terms of number\n",
      "of training parameters.\n",
      "\n",
      "    \n",
      "922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  It has been shown recently that deep convolutional generative adversarial\n",
      "networks (GANs) can learn to generate music in the form of piano-rolls, which\n",
      "represent music by binary-valued time-pitch matrices. However, existing models\n",
      "can only generate real-valued piano-rolls and require further post-processing,\n",
      "such as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final\n",
      "binary-valued results. In this paper, we study whether we can have a\n",
      "convolutional GAN model that directly creates binary-valued piano-rolls by\n",
      "using binary neurons. Specifically, we propose to append to the generator an\n",
      "additional refiner network, which uses binary neurons at the output layer. The\n",
      "whole network is trained in two stages. Firstly, the generator and the\n",
      "discriminator are pretrained. Then, the refiner network is trained along with\n",
      "the discriminator to learn to binarize the real-valued piano-rolls the\n",
      "pretrained generator creates. Experimental results show that using binary\n",
      "neurons instead of HT or BS indeed leads to better results in a number of\n",
      "objective measures. Moreover, deterministic binary neurons perform better than\n",
      "stochastic ones in both objective measures and a subjective test. The source\n",
      "code, training data and audio examples of the generated results can be found at\n",
      "this https URL .\n",
      "\n",
      "    \n",
      "923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Generating music has a few notable differences from generating images and\n",
      "videos. First, music is an art of time, necessitating a temporal model. Second,\n",
      "music is usually composed of multiple instruments/tracks with their own\n",
      "temporal dynamics, but collectively they unfold over time interdependently.\n",
      "Lastly, musical notes are often grouped into chords, arpeggios or melodies in\n",
      "polyphonic music, and thereby introducing a chronological ordering of notes is\n",
      "not naturally suitable. In this paper, we propose three models for symbolic\n",
      "multi-track music generation under the framework of generative adversarial\n",
      "networks (GANs). The three models, which differ in the underlying assumptions\n",
      "and accordingly the network architectures, are referred to as the jamming\n",
      "model, the composer model and the hybrid model. We trained the proposed models\n",
      "on a dataset of over one hundred thousand bars of rock music and applied them\n",
      "to generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.\n",
      "A few intra-track and inter-track objective metrics are also proposed to\n",
      "evaluate the generative results, in addition to a subjective user study. We\n",
      "show that our models can generate coherent music of four bars right from\n",
      "scratch (i.e. without human inputs). We also extend our models to human-AI\n",
      "cooperative music generation: given a specific track composed by human, we can\n",
      "generate four additional tracks to accompany it. All code, the dataset and the\n",
      "rendered audio samples are available at this https URL .\n",
      "\n",
      "    \n",
      "924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Existing research on music generation focuses on composition, but often\n",
      "ignores the expressive performance characteristics required for plausible\n",
      "renditions of resultant pieces. In this paper, we introduce the Nintendo\n",
      "Entertainment System Music Database (NES-MDB), a large corpus allowing for\n",
      "separate examination of the tasks of composition and performance. NES-MDB\n",
      "contains thousands of multi-instrumental songs composed for playback by the\n",
      "compositionally-constrained NES audio synthesizer. For each song, the dataset\n",
      "contains a musical score for four instrument voices as well as expressive\n",
      "attributes for the dynamics and timbre of each voice. Unlike datasets comprised\n",
      "of General MIDI files, NES-MDB includes all of the information needed to render\n",
      "exact acoustic performances of the original compositions. Alongside the\n",
      "dataset, we provide a tool that renders generated compositions as NES-style\n",
      "audio by emulating the device's audio processor. Additionally, we establish\n",
      "baselines for the tasks of composition, which consists of learning the\n",
      "semantics of composing for the NES synthesizer, and performance, which involves\n",
      "finding a mapping between a composition and realistic expressive attributes.\n",
      "\n",
      "    \n",
      "925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent progress in deep learning for audio synthesis opens the way to models\n",
      "that directly produce the waveform, shifting away from the traditional paradigm\n",
      "of relying on vocoders or MIDI synthesizers for speech or music generation.\n",
      "Despite their successes, current state-of-the-art neural audio synthesizers\n",
      "such as WaveNet and SampleRNN suffer from prohibitive training and inference\n",
      "times because they are based on autoregressive models that generate audio\n",
      "samples one at a time at a rate of 16kHz. In this work, we study the more\n",
      "computationally efficient alternative of generating the waveform frame-by-frame\n",
      "with large strides. We present SING, a lightweight neural audio synthesizer for\n",
      "the original task of generating musical notes given desired instrument, pitch\n",
      "and velocity. Our model is trained end-to-end to generate notes from nearly\n",
      "1000 instruments with a single decoder, thanks to a new loss function that\n",
      "minimizes the distances between the log spectrograms of the generated and\n",
      "target waveforms. On the generalization task of synthesizing notes for pairs of\n",
      "pitch and instrument not seen during training, SING produces audio with\n",
      "significantly improved perceptual quality compared to a state-of-the-art\n",
      "autoencoder based on WaveNet as measured by a Mean Opinion Score (MOS), and is\n",
      "about 32 times faster for training and 2, 500 times faster for inference.\n",
      "\n",
      "    \n",
      "926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Lidar based 3D object detection is inevitable for autonomous driving, because\n",
      "it directly links to environmental understanding and therefore builds the base\n",
      "for prediction and motion planning. The capacity of inferencing highly sparse\n",
      "3D data in real-time is an ill-posed problem for lots of other application\n",
      "areas besides automated vehicles, e.g. augmented reality, personal robotics or\n",
      "industrial automation. We introduce Complex-YOLO, a state of the art real-time\n",
      "3D object detection network on point clouds only. In this work, we describe a\n",
      "network that expands YOLOv2, a fast 2D standard object detector for RGB images,\n",
      "by a specific complex regression strategy to estimate multi-class 3D boxes in\n",
      "Cartesian space. Thus, we propose a specific Euler-Region-Proposal Network\n",
      "(E-RPN) to estimate the pose of the object by adding an imaginary and a real\n",
      "fraction to the regression network. This ends up in a closed complex space and\n",
      "avoids singularities, which occur by single angle estimations. The E-RPN\n",
      "supports to generalize well during training. Our experiments on the KITTI\n",
      "benchmark suite show that we outperform current leading methods for 3D object\n",
      "detection specifically in terms of efficiency. We achieve state of the art\n",
      "results for cars, pedestrians and cyclists by being more than five times faster\n",
      "than the fastest competitor. Further, our model is capable of estimating all\n",
      "eight KITTI-classes, including Vans, Trucks or sitting pedestrians\n",
      "simultaneously with high accuracy.\n",
      "\n",
      "    \n",
      "927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Robots that navigate among pedestrians use collision avoidance algorithms to\n",
      "enable safe and efficient operation. Recent works present deep reinforcement\n",
      "learning as a framework to model the complex interactions and cooperation.\n",
      "However, they are implemented using key assumptions about other agents'\n",
      "behavior that deviate from reality as the number of agents in the environment\n",
      "increases. This work extends our previous approach to develop an algorithm that\n",
      "learns collision avoidance among a variety of types of dynamic agents without\n",
      "assuming they follow any particular behavior rules. This work also introduces a\n",
      "strategy using LSTM that enables the algorithm to use observations of an\n",
      "arbitrary number of other agents, instead of previous methods that have a fixed\n",
      "observation size. The proposed algorithm outperforms our previous approach in\n",
      "simulation as the number of agents increases, and the algorithm is demonstrated\n",
      "on a fully autonomous robotic vehicle traveling at human walking speed, without\n",
      "the use of a 3D Lidar.\n",
      "\n",
      "    \n",
      "928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many problems in computer vision and robotics can be phrased as non-linear\n",
      "least squares optimization problems represented by factor graphs, for example,\n",
      "simultaneous localization and mapping (SLAM), structure from motion (SfM),\n",
      "motion planning, and control. We have developed an open-source C++/Python\n",
      "framework miniSAM, for solving such factor graph based least squares problems.\n",
      "Compared to most existing frameworks for least squares solvers, miniSAM has (1)\n",
      "full Python/NumPy API, which enables more agile development and easy binding\n",
      "with existing Python projects, and (2) a wide list of sparse linear solvers,\n",
      "including CUDA enabled sparse linear solvers. Our benchmarking results shows\n",
      "miniSAM offers comparable performances on various types of problems, with more\n",
      "flexible and smoother development experience.\n",
      "\n",
      "    \n",
      "929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Sampling-based Motion Planners (SMPs) have become increasingly popular as\n",
      "they provide collision-free path solutions regardless of obstacle geometry in a\n",
      "given environment. However, their computational complexity increases\n",
      "significantly with the dimensionality of the motion planning problem. Adaptive\n",
      "sampling is one of the ways to speed up SMPs by sampling a particular region of\n",
      "a configuration space that is more likely to contain an optimal path solution.\n",
      "Although there are a wide variety of algorithms for adaptive sampling, they\n",
      "rely on hand-crafted heuristics; furthermore, their performance decreases\n",
      "significantly in high-dimensional spaces. In this paper, we present a neural\n",
      "network-based adaptive sampler for motion planning called Deep Sampling-based\n",
      "Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their\n",
      "overall speed significantly while exhibiting efficient scalability to\n",
      "higher-dimensional problems. DeepSMP's neural architecture comprises of a\n",
      "Contractive AutoEncoder which encodes given workspaces directly from a raw\n",
      "point cloud data, and a Dropout-based stochastic deep feedforward neural\n",
      "network which takes the workspace encoding, start and goal configuration, and\n",
      "iteratively generates feasible samples for SMPs to compute end-to-end\n",
      "collision-free optimal paths. DeepSMP is not only consistently computationally\n",
      "efficient in all tested environments but has also shown remarkable\n",
      "generalization to completely unseen environments. We evaluate DeepSMP on\n",
      "multiple planning problems including planning of a point-mass robot,\n",
      "rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The\n",
      "results show that on average our method is at least 7 times faster in\n",
      "point-mass and rigid-body case and about 28 times faster in 6-link robot case\n",
      "than the existing state-of-the-art.\n",
      "\n",
      "    \n",
      "930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In the past, Acoustic Scene Classification systems have been based on hand\n",
      "crafting audio features that are input to a classifier. Nowadays, the common\n",
      "trend is to adopt data driven techniques, e.g., deep learning, where audio\n",
      "representations are learned from data. In this paper, we propose a system that\n",
      "consists of a simple fusion of two methods of the aforementioned types: a deep\n",
      "learning approach where log-scaled mel-spectrograms are input to a\n",
      "convolutional neural network, and a feature engineering approach, where a\n",
      "collection of hand-crafted features is input to a gradient boosting machine. We\n",
      "first show that both methods provide complementary information to some extent.\n",
      "Then, we use a simple late fusion strategy to combine both methods. We report\n",
      "classification accuracy of each method individually and the combined system on\n",
      "the TUT Acoustic Scenes 2017 dataset. The proposed fused system outperforms\n",
      "each of the individual methods and attains a classification accuracy of 72.8%\n",
      "on the evaluation set, improving the baseline system by 11.8%.\n",
      "\n",
      "    \n",
      "931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  What is a good visual representation for autonomous agents? We address this\n",
      "question in the context of semantic visual navigation, which is the problem of\n",
      "a robot finding its way through a complex environment to a target object, e.g.\n",
      "go to the refrigerator. Instead of acquiring a metric semantic map of an\n",
      "environment and using planning for navigation, our approach learns navigation\n",
      "policies on top of representations that capture spatial layout and semantic\n",
      "contextual cues. We propose to using high level semantic and contextual\n",
      "features including segmentation and detection masks obtained by off-the-shelf\n",
      "state-of-the-art vision as observations and use deep network to learn the\n",
      "navigation policy. This choice allows using additional data, from orthogonal\n",
      "sources, to better train different parts of the model the representation\n",
      "extraction is trained on large standard vision datasets while the navigation\n",
      "component leverages large synthetic environments for training. This combination\n",
      "of real and synthetic is possible because equitable feature representations are\n",
      "available in both (e.g., segmentation and detection masks), which alleviates\n",
      "the need for domain adaptation. Both the representation and the navigation\n",
      "policy can be readily applied to real non-synthetic environments as\n",
      "demonstrated on the Active Vision Dataset [1]. Our approach gets successfully\n",
      "to the target in 54% of the cases in unexplored environments, compared to 46%\n",
      "for non-learning based approach, and 28% for the learning-based baseline.\n",
      "\n",
      "    \n",
      "932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The cost of large scale data collection and annotation often makes the\n",
      "application of machine learning algorithms to new tasks or datasets\n",
      "prohibitively expensive. One approach circumventing this cost is training\n",
      "models on synthetic data where annotations are provided automatically. Despite\n",
      "their appeal, such models often fail to generalize from synthetic to real\n",
      "images, necessitating domain adaptation algorithms to manipulate these models\n",
      "before they can be successfully applied. Existing approaches focus either on\n",
      "mapping representations from one domain to the other, or on learning to extract\n",
      "features that are invariant to the domain from which they were extracted.\n",
      "However, by focusing only on creating a mapping or shared representation\n",
      "between the two domains, they ignore the individual characteristics of each\n",
      "domain. We suggest that explicitly modeling what is unique to each domain can\n",
      "improve a model's ability to extract domain-invariant features. Inspired by\n",
      "work on private-shared component analysis, we explicitly learn to extract image\n",
      "representations that are partitioned into two subspaces: one component which is\n",
      "private to each domain and one which is shared across domains. Our model is\n",
      "trained not only to perform the task we care about in the source domain, but\n",
      "also to use the partitioned representation to reconstruct the images from both\n",
      "domains. Our novel architecture results in a model that outperforms the\n",
      "state-of-the-art on a range of unsupervised domain adaptation scenarios and\n",
      "additionally produces visualizations of the private and shared representations\n",
      "enabling interpretation of the domain adaptation process.\n",
      "\n",
      "    \n",
      "933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose a new loss function called generalized end-to-end\n",
      "(GE2E) loss, which makes the training of speaker verification models more\n",
      "efficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\n",
      "TE2E, the GE2E loss function updates the network in a way that emphasizes\n",
      "examples that are difficult to verify at each step of the training process.\n",
      "Additionally, the GE2E loss does not require an initial stage of example\n",
      "selection. With these properties, our model with the new loss function\n",
      "decreases speaker verification EER by more than 10%, while reducing the\n",
      "training time by 60% at the same time. We also introduce the MultiReader\n",
      "technique, which allows us to do domain adaptation - training a more accurate\n",
      "model that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\n",
      "well as multiple dialects.\n",
      "\n",
      "    \n",
      "934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Pronounced as \"musician\", the musicnn library contains a set of pre-trained\n",
      "musically motivated convolutional neural networks for music audio tagging:\n",
      "this https URL. This repository also includes some\n",
      "pre-trained vgg-like baselines. These models can be used as out-of-the-box\n",
      "music audio taggers, as music feature extractors, or as pre-trained models for\n",
      "transfer learning.\n",
      "We also provide the code to train the aforementioned models:\n",
      "this https URL. This framework also allows\n",
      "implementing novel models. For example, a musically motivated convolutional\n",
      "neural network with an attention-based output layer (instead of the temporal\n",
      "pooling layer) can achieve state-of-the-art results for music audio tagging:\n",
      "90.77 ROC-AUC / 38.61 PR-AUC on the MagnaTagATune dataset --- and 88.81 ROC-AUC\n",
      "/ 31.51 PR-AUC on the Million Song Dataset.\n",
      "\n",
      "    \n",
      "935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper introduces Task 2 of the DCASE2019 Challenge, titled \"Audio\n",
      "tagging with noisy labels and minimal supervision\". This task was hosted on the\n",
      "Kaggle platform as \"Freesound Audio Tagging 2019\". The task evaluates systems\n",
      "for multi-label audio tagging using a large set of noisy-labeled data, and a\n",
      "much smaller set of manually-labeled data, under a large vocabulary setting of\n",
      "80 everyday sound classes. In addition, the proposed dataset poses an acoustic\n",
      "mismatch problem between the noisy train set and the test set due to the fact\n",
      "that they come from different web audio sources. This can correspond to a\n",
      "realistic scenario given by the difficulty in gathering large amounts of\n",
      "manually labeled data. We present the task setup, the FSDKaggle2019 dataset\n",
      "prepared for this scientific evaluation, and a baseline system consisting of a\n",
      "convolutional neural network. All these resources are freely available.\n",
      "\n",
      "    \n",
      "936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Audio tagging aims to infer descriptive labels from audio clips. Audio\n",
      "tagging is challenging due to the limited size of data and noisy labels. In\n",
      "this paper, we describe our solution for the DCASE 2018 Task 2 general audio\n",
      "tagging challenge. The contributions of our solution include: We investigated a\n",
      "variety of convolutional neural network architectures to solve the audio\n",
      "tagging task. Statistical features are applied to capture statistical patterns\n",
      "of audio features to improve the classification performance. Ensemble learning\n",
      "is applied to ensemble the outputs from the deep classifiers to utilize\n",
      "complementary information. a sample re-weight strategy is employed for ensemble\n",
      "training to address the noisy label problem. Our system achieves a mean average\n",
      "precision (mAP@3) of 0.958, outperforming the baseline system of 0.704. Our\n",
      "system ranked the 1st and 4th out of 558 submissions in the public and private\n",
      "leaderboard of DCASE 2018 Task 2 challenge. Our codes are available at\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes Task 2 of the DCASE 2018 Challenge, titled\n",
      "\"General-purpose audio tagging of Freesound content with AudioSet labels\". This\n",
      "task was hosted on the Kaggle platform as \"Freesound General-Purpose Audio\n",
      "Tagging Challenge\". The goal of the task is to build an audio tagging system\n",
      "that can recognize the category of an audio clip from a subset of 41 diverse\n",
      "categories drawn from the AudioSet Ontology. We present the task, the dataset\n",
      "prepared for the competition, and a baseline system.\n",
      "\n",
      "    \n",
      "938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Audio tagging aims to predict one or several labels in an audio clip. Many\n",
      "previous works use weakly labelled data (WLD) for audio tagging, where only\n",
      "presence or absence of sound events is known, but the order of sound events is\n",
      "unknown. To use the order information of sound events, we propose sequential\n",
      "labelled data (SLD), where both the presence or absence and the order\n",
      "information of sound events are known. To utilize SLD in audio tagging, we\n",
      "propose a Convolutional Recurrent Neural Network followed by a Connectionist\n",
      "Temporal Classification (CRNN-CTC) objective function to map from an audio clip\n",
      "spectrogram to SLD. Experiments show that CRNN-CTC obtains an Area Under Curve\n",
      "(AUC) score of 0.986 in audio tagging, outperforming the baseline CRNN of 0.908\n",
      "and 0.815 with Max Pooling and Average Pooling, respectively. In addition, we\n",
      "show CRNN-CTC has the ability to predict the order of sound events in an audio\n",
      "clip.\n",
      "\n",
      "    \n",
      "939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Environmental audio tagging aims to predict only the presence or absence of\n",
      "certain acoustic events in the interested acoustic scene. In this paper we make\n",
      "contributions to audio tagging in two parts, respectively, acoustic modeling\n",
      "and feature learning. We propose to use a shrinking deep neural network (DNN)\n",
      "framework incorporating unsupervised feature learning to handle the multi-label\n",
      "classification task. For the acoustic modeling, a large set of contextual\n",
      "frames of the chunk are fed into the DNN to perform a multi-label\n",
      "classification for the expected tags, considering that only chunk (or\n",
      "utterance) level rather than frame-level labels are available. Dropout and\n",
      "background noise aware training are also adopted to improve the generalization\n",
      "capability of the DNNs. For the unsupervised feature learning, we propose to\n",
      "use a symmetric or asymmetric deep de-noising auto-encoder (sDAE or aDAE) to\n",
      "generate new data-driven features from the Mel-Filter Banks (MFBs) features.\n",
      "The new features, which are smoothed against background noise and more compact\n",
      "with contextual information, can further improve the performance of the DNN\n",
      "baseline. Compared with the standard Gaussian Mixture Model (GMM) baseline of\n",
      "the DCASE 2016 audio tagging challenge, our proposed method obtains a\n",
      "significant equal error rate (EER) reduction from 0.21 to 0.13 on the\n",
      "development set. The proposed aDAE system can get a relative 6.7% EER reduction\n",
      "compared with the strong DNN baseline on the development set. Finally, the\n",
      "results also show that our approach obtains the state-of-the-art performance\n",
      "with 0.15 EER on the evaluation set of the DCASE 2016 audio tagging task while\n",
      "EER of the first prize of this challenge is 0.17.\n",
      "\n",
      "    \n",
      "940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability of deep convolutional neural networks (CNN) to learn\n",
      "discriminative spectro-temporal patterns makes them well suited to\n",
      "environmental sound classification. However, the relative scarcity of labeled\n",
      "data has impeded the exploitation of this family of high-capacity models. This\n",
      "study has two primary contributions: first, we propose a deep convolutional\n",
      "neural network architecture for environmental sound classification. Second, we\n",
      "propose the use of audio data augmentation for overcoming the problem of data\n",
      "scarcity and explore the influence of different augmentations on the\n",
      "performance of the proposed CNN architecture. Combined with data augmentation,\n",
      "the proposed model produces state-of-the-art results for environmental sound\n",
      "classification. We show that the improved performance stems from the\n",
      "combination of a deep, high-capacity model and an augmented training set: this\n",
      "combination outperforms both the proposed CNN without augmentation and a\n",
      "\"shallow\" dictionary learning model with augmentation. Finally, we examine the\n",
      "influence of each augmentation on the model's classification accuracy for each\n",
      "class, and observe that the accuracy for each class is influenced differently\n",
      "by each augmentation, suggesting that the performance of the model could be\n",
      "improved further by applying class-conditional data augmentation.\n",
      "\n",
      "    \n",
      "941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  End-to-end neural network based approaches to audio modelling are generally\n",
      "outperformed by models trained on high-level data representations. In this\n",
      "paper we present preliminary work that shows the feasibility of training the\n",
      "first layers of a deep convolutional neural network (CNN) model to learn the\n",
      "commonly-used log-scaled mel-spectrogram transformation. Secondly, we\n",
      "demonstrate that upon initializing the first layers of an end-to-end CNN\n",
      "classifier with the learned transformation, convergence and performance on the\n",
      "ESC-50 environmental sound classification dataset are similar to a CNN-based\n",
      "model trained on the highly pre-processed log-scaled mel-spectrogram features.\n",
      "\n",
      "    \n",
      "942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ConditionaL Neural Network (CLNN) exploits the nature of the temporal\n",
      "sequencing of the sound signal represented in a spectrogram, and its variant\n",
      "the Masked ConditionaL Neural Network (MCLNN) induces the network to learn in\n",
      "frequency bands by embedding a filterbank-like sparseness over the network's\n",
      "links using a binary mask. Additionally, the masking automates the exploration\n",
      "of different feature combinations concurrently analogous to handcrafting the\n",
      "optimum combination of features for a recognition task. We have evaluated the\n",
      "MCLNN performance using the Urbansound8k dataset of environmental sounds.\n",
      "Additionally, we present a collection of manually recorded sounds for rail and\n",
      "road traffic, YorNoise, to investigate the confusion rates among machine\n",
      "generated sounds possessing low-frequency components. MCLNN has achieved\n",
      "competitive results without augmentation and using 12% of the trainable\n",
      "parameters utilized by an equivalent model based on state-of-the-art\n",
      "Convolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k\n",
      "dataset with YorNoise, where experiments have shown that common tonal\n",
      "properties affect the classification performance.\n",
      "\n",
      "    \n",
      "943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose a framework for environmental sound classification\n",
      "in a low-data context (less than 100 labeled examples per class). We show that\n",
      "using pre-trained image classification models along with the usage of data\n",
      "augmentation techniques results in higher performance over alternative\n",
      "approaches. We applied this system to the task of Urban Sound Tagging, part of\n",
      "the DCASE 2019. The objective was to label different sources of noise from raw\n",
      "audio data. A modified form of MobileNetV2, a convolutional neural network\n",
      "(CNN) model was trained to classify both coarse and fine tags jointly. The\n",
      "proposed model uses log-scaled Mel-spectrogram as the representation format for\n",
      "the audio data. Mixup, Random erasing, scaling, and shifting are used as data\n",
      "augmentation techniques. A second model that uses scaled labels was built to\n",
      "account for human errors in the annotations. The proposed model achieved the\n",
      "first rank on the leaderboard with Micro-AUPRC values of 0.751 and 0.860 on\n",
      "fine and coarse tags, respectively.\n",
      "\n",
      "    \n",
      "944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Stereo image pairs can be used to improve the performance of super-resolution\n",
      "(SR) since additional information is provided from a second viewpoint. However,\n",
      "it is challenging to incorporate this information for SR since disparities\n",
      "between stereo images vary significantly. In this paper, we propose a\n",
      "parallax-attention stereo superresolution network (PASSRnet) to integrate the\n",
      "information from a stereo image pair for SR. Specifically, we introduce a\n",
      "parallax-attention mechanism with a global receptive field along the epipolar\n",
      "line to handle different stereo images with large disparity variations. We also\n",
      "propose a new and the largest dataset for stereo image SR (namely, Flickr1024).\n",
      "Extensive experiments demonstrate that the parallax-attention mechanism can\n",
      "capture correspondence between stereo images to improve SR performance with a\n",
      "small computational and memory cost. Comparative results show that our PASSRnet\n",
      "achieves the state-of-the-art performance on the Middlebury, KITTI 2012 and\n",
      "KITTI 2015 datasets.\n",
      "\n",
      "    \n",
      "945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  With the popularity of dual cameras in recently released smart phones, a\n",
      "growing number of super-resolution (SR) methods have been proposed to enhance\n",
      "the resolution of stereo image pairs. However, the lack of high-quality stereo\n",
      "datasets has limited the research in this area. To facilitate the training and\n",
      "evaluation of novel stereo SR algorithms, in this paper, we present a\n",
      "large-scale stereo dataset named Flickr1024, which contains 1024 pairs of\n",
      "high-quality images and covers diverse scenarios. We first introduce the data\n",
      "acquisition and processing pipeline, and then compare several popular stereo\n",
      "datasets. Finally, we conduct crossdataset experiments to investigate the\n",
      "potential benefits introduced by our dataset. Experimental results show that,\n",
      "as compared to the KITTI and Middlebury datasets, our Flickr1024 dataset can\n",
      "help to handle the over-fitting problem and significantly improves the\n",
      "performance of stereo SR methods. The Flickr1024 dataset is available online\n",
      "at: this https URL.\n",
      "\n",
      "    \n",
      "946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a method for audio denoising that combines processing done in both\n",
      "the time domain and the time-frequency domain. Given a noisy audio clip, the\n",
      "method trains a deep neural network to fit this signal. Since the fitting is\n",
      "only partly successful and is able to better capture the underlying clean\n",
      "signal than the noise, the output of the network helps to disentangle the clean\n",
      "audio from the rest of the signal. The method is completely unsupervised and\n",
      "only trains on the specific audio clip that is being denoised. Our experiments\n",
      "demonstrate favorable performance in comparison to the literature methods, and\n",
      "our code and audio samples are available at https: //github.com/mosheman5/DNP.\n",
      "Index Terms: Audio denoising; Unsupervised learning\n",
      "\n",
      "    \n",
      "947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Perceiving a scene most fully requires all the senses. Yet modeling how\n",
      "objects look and sound is challenging: most natural scenes and events contain\n",
      "multiple objects, and the audio track mixes all the sound sources together. We\n",
      "propose to learn audio-visual object models from unlabeled video, then exploit\n",
      "the visual context to perform audio source separation in novel videos. Our\n",
      "approach relies on a deep multi-instance multi-label learning framework to\n",
      "disentangle the audio frequency bases that map to individual visual objects,\n",
      "even without observing/hearing those objects in isolation. We show how the\n",
      "recovered disentangled bases can be used to guide audio source separation to\n",
      "obtain better-separated, object-level sounds. Our work is the first to learn\n",
      "audio source separation from large-scale \"in the wild\" videos containing\n",
      "multiple audio sources per video. We obtain state-of-the-art results on\n",
      "visually-aided audio source separation and audio denoising. Our video results:\n",
      "this http URL\n",
      "\n",
      "948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Learning how objects sound from video is challenging, since they often\n",
      "heavily overlap in a single audio channel. Current methods for visually-guided\n",
      "audio source separation sidestep the issue by training with artificially mixed\n",
      "video clips, but this puts unwieldy restrictions on training data collection\n",
      "and may even prevent learning the properties of \"true\" mixed sounds. We\n",
      "introduce a co-separation training paradigm that permits learning object-level\n",
      "sounds from unlabeled multi-source videos. Our novel training objective\n",
      "requires that the deep neural network's separated audio for similar-looking\n",
      "objects be consistently identifiable, while simultaneously reproducing accurate\n",
      "video-level audio tracks for each source training pair. Our approach\n",
      "disentangles sounds in realistic test videos, even in cases where an object was\n",
      "not observed individually during training. We obtain state-of-the-art results\n",
      "on visually-guided audio source separation and audio denoising for the MUSIC,\n",
      "AudioSet, and AV-Bench datasets.\n",
      "\n",
      "    \n",
      "949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We explore frame-level audio feature learning for chord recognition using\n",
      "artificial neural networks. We present the argument that chroma vectors\n",
      "potentially hold enough information to model harmonic content of audio for\n",
      "chord recognition, but that standard chroma extractors compute too noisy\n",
      "features. This leads us to propose a learned chroma feature extractor based on\n",
      "artificial neural networks. It is trained to compute chroma features that\n",
      "encode harmonic information important for chord recognition, while being robust\n",
      "to irrelevant interferences. We achieve this by feeding the network an audio\n",
      "spectrum with context instead of a single frame as input. This way, the network\n",
      "can learn to selectively compensate noise and resolve harmonic ambiguities.\n",
      "We compare the resulting features to hand-crafted ones by using a simple\n",
      "linear frame-wise classifier for chord recognition on various data sets. The\n",
      "results show that the learned feature extractor produces superior chroma\n",
      "vectors for chord recognition.\n",
      "\n",
      "    \n",
      "950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Chord recognition is an important task since chords are highly abstract and\n",
      "descriptive features of music. For effective chord recognition, it is essential\n",
      "to utilize relevant context in audio sequence. While various machine learning\n",
      "models such as convolutional neural networks (CNNs) and recurrent neural\n",
      "networks (RNNs) have been employed for the task, most of them have limitations\n",
      "in capturing long-term dependency or require training of an additional model.\n",
      "In this work, we utilize a self-attention mechanism for chord recognition to\n",
      "focus on certain regions of chords. Training of the proposed bi-directional\n",
      "Transformer for chord recognition (BTC) consists of a single phase while\n",
      "showing competitive performance. Through an attention map analysis, we have\n",
      "visualized how attention was performed. It turns out that the model was able to\n",
      "divide segments of chords by utilizing adaptive receptive field of the\n",
      "attention mechanism. Furthermore, it was observed that the model was able to\n",
      "effectively capture long-term dependencies, making use of essential information\n",
      "regardless of distance.\n",
      "\n",
      "    \n",
      "951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Every minute, hundreds of hours of video are uploaded to social media sites\n",
      "and the Internet from around the world. This material creates a visual record\n",
      "of the experiences of a significant percentage of humanity and can help\n",
      "illuminate how we live in the present moment. When properly analyzed, this\n",
      "video can also help analysts to reconstruct events of interest, including war\n",
      "crimes, human rights violations, and terrorist acts. Machine learning and\n",
      "computer vision can play a crucial role in this process. In this technical\n",
      "report, we describe the Video Event Reconstruction and Analysis (VERA) system.\n",
      "This new tool brings together a variety of capabilities we have developed over\n",
      "the past few years (including video synchronization and geolocation to order\n",
      "unstructured videos lacking metadata over time and space, and sound recognition\n",
      "algorithms) to enable the reconstruction and analysis of events captured on\n",
      "video. Among other uses, VERA enables the localization of a shooter from just a\n",
      "few videos that include the sound of gunshots. To demonstrate the efficacy of\n",
      "this suite of tools, we present the results of estimating the shooter's\n",
      "location of the Las Vegas Shooting in 2017 and show that VERA accurately\n",
      "predicts the shooter's location using only the first few gunshots. We then\n",
      "point out future directions that can help improve the system and further reduce\n",
      "unnecessary human labor in the process. All of the components of VERA run\n",
      "through a web interface that enables human-in-the-loop verification to ensure\n",
      "accurate estimations. All relevant source code, including the web interface and\n",
      "machine learning models, is freely available on Github. We hope that\n",
      "researchers and software developers will be inspired to improve and expand this\n",
      "system moving forward to better meet the needs of human rights and public\n",
      "safety.\n",
      "\n",
      "    \n",
      "952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a novel learning-based approach to estimate the\n",
      "direction-of-arrival (DOA) of a sound source using a convolutional recurrent\n",
      "neural network (CRNN) trained via regression on synthetic data and Cartesian\n",
      "labels. We also describe an improved method to generate synthetic data to train\n",
      "the neural network using state-of-the-art sound propagation algorithms that\n",
      "model specular as well as diffuse reflections of sound. We compare our model\n",
      "against three other CRNNs trained using different formulations of the same\n",
      "problem: classification on categorical labels, and regression on spherical\n",
      "coordinate labels. In practice, our model achieves up to 43% decrease in\n",
      "angular error over prior methods. The use of diffuse reflection results in 34%\n",
      "and 41% reduction in angular prediction errors on LOCATA and SOFA datasets,\n",
      "respectively, over prior methods based on image-source methods. Our method\n",
      "results in an additional 3% error reduction over prior schemes that use\n",
      "classification based networks, and we use 36% fewer network parameters.\n",
      "\n",
      "    \n",
      "953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We investigate supervised learning strategies that improve the training of\n",
      "neural network audio classifiers on small annotated collections. In particular,\n",
      "we study whether (i) a naive regularization of the solution space, (ii)\n",
      "prototypical networks, (iii) transfer learning, or (iv) their combination, can\n",
      "foster deep learning models to better leverage a small amount of training\n",
      "examples. To this end, we evaluate (i-iv) for the tasks of acoustic event\n",
      "recognition and acoustic scene classification, considering from 1 to 100\n",
      "labeled examples per class. Results indicate that transfer learning is a\n",
      "powerful strategy in such scenarios, but prototypical networks show promising\n",
      "results when one does not count with external or validation data.\n",
      "\n",
      "    \n",
      "954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A general problem in acoustic scene classification task is the mismatched\n",
      "conditions between training and testing data, which significantly reduces the\n",
      "performance of the developed methods on classification accuracy. As a\n",
      "countermeasure, we present the first method of unsupervised adversarial domain\n",
      "adaptation for acoustic scene classification. We employ a model pre-trained on\n",
      "data from one set of conditions and by using data from other set of conditions,\n",
      "we adapt the model in order that its output cannot be used for classifying the\n",
      "set of conditions that input data belong to. We use a freely available dataset\n",
      "from the DCASE 2018 challenge Task 1, subtask B, that contains data from\n",
      "mismatched recording devices. We consider the scenario where the annotations\n",
      "are available for the data recorded from one device, but not for the rest. Our\n",
      "results show that with our model agnostic method we can achieve $\\sim 10\\%$\n",
      "increase at the accuracy on an unseen and unlabeled dataset, while keeping\n",
      "almost the same performance on the labeled dataset.\n",
      "\n",
      "    \n",
      "955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A challenging problem in deep learning-based machine listening field is the\n",
      "degradation of the performance when using data from unseen conditions. In this\n",
      "paper we focus on the acoustic scene classification (ASC) task and propose an\n",
      "adversarial deep learning method to allow adapting an acoustic scene\n",
      "classification system to deal with a new acoustic channel resulting from data\n",
      "captured with a different recording device. We build upon the theoretical model\n",
      "of H{\\Delta}H-distance and previous adversarial discriminative deep learning\n",
      "method for ASC unsupervised domain adaptation, and we present an adversarial\n",
      "training based method using the Wasserstein distance. We improve the\n",
      "state-of-the-art mean accuracy on the data from the unseen conditions from 32%\n",
      "to 45%, using the TUT Acoustic Scenes dataset.\n",
      "\n",
      "    \n",
      "956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper, we propose a new strategy for acoustic scene classification\n",
      "(ASC) , namely recognizing acoustic scenes through identifying distinct sound\n",
      "events. This differs from existing strategies, which focus on characterizing\n",
      "global acoustical distributions of audio or the temporal evolution of\n",
      "short-term audio features, without analysis down to the level of sound events.\n",
      "To identify distinct sound events for each scene, we formulate ASC in a\n",
      "multi-instance learning (MIL) framework, where each audio recording is mapped\n",
      "into a bag-of-instances representation. Here, instances can be seen as\n",
      "high-level representations for sound events inside a scene. We also propose a\n",
      "MIL neural networks model, which implicitly identifies distinct instances\n",
      "(i.e., sound events). Furthermore, we propose two specially designed modules\n",
      "that model the multi-temporal scale and multi-modal natures of the sound events\n",
      "respectively. The experiments were conducted on the official development set of\n",
      "the DCASE2018 Task1 Subtask B, and our best-performing model improves over the\n",
      "official baseline by 9.4% (68.3% vs 58.9%) in terms of classification accuracy.\n",
      "This study indicates that recognizing acoustic scenes by identifying distinct\n",
      "sound events is effective and paves the way for future studies that combine\n",
      "this strategy with previous ones.\n",
      "\n",
      "    \n",
      "957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Convolutional Neural Networks (CNNs) can learn effective features, though\n",
      "have been shown to suffer from a performance drop when the distribution of the\n",
      "data changes from training to test data. In this paper we analyze the internal\n",
      "representations of CNNs and observe that the representations of unseen data in\n",
      "each class, spread more (with higher variance) in the embedding space of the\n",
      "CNN compared to representations of the training data. More importantly, this\n",
      "difference is more extreme if the unseen data comes from a shifted\n",
      "distribution. Based on this observation, we objectively evaluate the degree of\n",
      "representation's variance in each class via eigenvalue decomposition on the\n",
      "within-class covariance of the internal representations of CNNs and observe the\n",
      "same behaviour. This can be problematic as larger variances might lead to\n",
      "mis-classification if the sample crosses the decision boundary of its class. We\n",
      "apply nearest neighbor classification on the representations and empirically\n",
      "show that the embeddings with the high variance actually have significantly\n",
      "worse KNN classification performances, although this could not be foreseen from\n",
      "their end-to-end classification results. To tackle this problem, we propose\n",
      "Deep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that\n",
      "significantly reduces the within-class covariance of a DNN's representation,\n",
      "improving performance on unseen test data from a shifted distribution. We\n",
      "empirically evaluate DWCCA on two datasets for Acoustic Scene Classification\n",
      "(DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA\n",
      "significantly improve the network's internal representation, it also increases\n",
      "the end-to-end classification accuracy, especially when the test set exhibits a\n",
      "distribution shift. By adding DWCCA to a VGG network, we achieve around 6\n",
      "percentage points improvement in the case of a distribution mismatch.\n",
      "\n",
      "    \n",
      "958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has shown that depth estimation from a stereo pair of images can\n",
      "be formulated as a supervised learning task to be resolved with convolutional\n",
      "neural networks (CNNs). However, current architectures rely on patch-based\n",
      "Siamese networks, lacking the means to exploit context information for finding\n",
      "correspondence in illposed regions. To tackle this problem, we propose PSMNet,\n",
      "a pyramid stereo matching network consisting of two main modules: spatial\n",
      "pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage\n",
      "of the capacity of global context information by aggregating context in\n",
      "different scales and locations to form a cost volume. The 3D CNN learns to\n",
      "regularize cost volume using stacked multiple hourglass networks in conjunction\n",
      "with intermediate supervision. The proposed approach was evaluated on several\n",
      "benchmark datasets. Our method ranked first in the KITTI 2012 and 2015\n",
      "leaderboards before March 18, 2018. The codes of PSMNet are available at:\n",
      "this https URL.\n",
      "\n",
      "    \n",
      "959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Stereo matching algorithms usually consist of four steps, including matching\n",
      "cost calculation, matching cost aggregation, disparity calculation, and\n",
      "disparity refinement. Existing CNN-based methods only adopt CNN to solve parts\n",
      "of the four steps, or use different networks to deal with different steps,\n",
      "making them difficult to obtain the overall optimal solution. In this paper, we\n",
      "propose a network architecture to incorporate all steps of stereo matching. The\n",
      "network consists of three parts. The first part calculates the multi-scale\n",
      "shared features. The second part performs matching cost calculation, matching\n",
      "cost aggregation and disparity calculation to estimate the initial disparity\n",
      "using shared features. The initial disparity and the shared features are used\n",
      "to calculate the feature constancy that measures correctness of the\n",
      "correspondence between two input images. The initial disparity and the feature\n",
      "constancy are then fed to a sub-network to refine the initial disparity. The\n",
      "proposed method has been evaluated on the Scene Flow and KITTI datasets. It\n",
      "achieves the state-of-the-art performance on the KITTI 2012 and KITTI 2015\n",
      "benchmarks while maintaining a very fast running time.\n",
      "\n",
      "    \n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present a method for extracting depth information from a rectified image\n",
      "pair. Our approach focuses on the first stage of many stereo algorithms: the\n",
      "matching cost computation. We approach the problem by learning a similarity\n",
      "measure on small image patches using a convolutional neural network. Training\n",
      "is carried out in a supervised manner by constructing a binary classification\n",
      "data set with examples of similar and dissimilar pairs of patches. We examine\n",
      "two network architectures for this task: one tuned for speed, the other for\n",
      "accuracy. The output of the convolutional neural network is used to initialize\n",
      "the stereo matching cost. A series of post-processing steps follow: cross-based\n",
      "cost aggregation, semiglobal matching, a left-right consistency check, subpixel\n",
      "enhancement, a median filter, and a bilateral filter. We evaluate our method on\n",
      "the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it\n",
      "outperforms other approaches on all three data sets.\n",
      "\n",
      "    \n",
      "961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Depth prediction is one of the fundamental problems in computer vision. In\n",
      "this paper, we propose a simple yet effective convolutional spatial propagation\n",
      "network (CSPN) to learn the affinity matrix for various depth estimation tasks.\n",
      "Specifically, it is an efficient linear propagation model, in which the\n",
      "propagation is performed with a manner of recurrent convolutional operation,\n",
      "and the affinity among neighboring pixels is learned through a deep\n",
      "convolutional neural network (CNN). We can append this module to any output\n",
      "from a state-of-the-art (SOTA) depth estimation networks to improve their\n",
      "performances. In practice, we further extend CSPN in two aspects: 1) take\n",
      "sparse depth map as additional input, which is useful for the task of depth\n",
      "completion; 2) similar to commonly used 3D convolution operation in CNNs, we\n",
      "propose 3D CSPN to handle features with one additional dimension, which is\n",
      "effective in the task of stereo matching using 3D cost volume. For the tasks of\n",
      "sparse to dense, a.k.a depth completion. We experimented the proposed CPSN\n",
      "conjunct algorithms over the popular NYU v2 and KITTI datasets, where we show\n",
      "that our proposed algorithms not only produce high quality (e.g., 30% more\n",
      "reduction in depth error), but also run faster (e.g., 2 to 5x faster) than\n",
      "previous SOTA spatial propagation network. We also evaluated our stereo\n",
      "matching algorithm on the Scene Flow and KITTI Stereo datasets, and rank 1st on\n",
      "both the KITTI Stereo 2012 and 2015 benchmarks, which demonstrates the\n",
      "effectiveness of the proposed module. The code of CSPN proposed in this work\n",
      "will be released at this https URL.\n",
      "\n",
      "    \n",
      "962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present an accurate stereo matching method using local expansion moves\n",
      "based on graph cuts. This new move-making scheme is used to efficiently infer\n",
      "per-pixel 3D plane labels on a pairwise Markov random field (MRF) that\n",
      "effectively combines recently proposed slanted patch matching and curvature\n",
      "regularization terms. The local expansion moves are presented as many\n",
      "alpha-expansions defined for small grid regions. The local expansion moves\n",
      "extend traditional expansion moves by two ways: localization and spatial\n",
      "propagation. By localization, we use different candidate alpha-labels according\n",
      "to the locations of local alpha-expansions. By spatial propagation, we design\n",
      "our local alpha-expansions to propagate currently assigned labels for nearby\n",
      "regions. With this localization and spatial propagation, our method can\n",
      "efficiently infer MRF models with a continuous label space using randomized\n",
      "search. Our method has several advantages over previous approaches that are\n",
      "based on fusion moves or belief propagation; it produces submodular moves\n",
      "deriving a subproblem optimality; it helps find good, smooth, piecewise linear\n",
      "disparity maps; it is suitable for parallelization; it can use cost-volume\n",
      "filtering techniques for accelerating the matching cost computations. Even\n",
      "using a simple pairwise MRF, our method is shown to have best performance in\n",
      "the Middlebury stereo benchmark V2 and V3.\n",
      "\n",
      "    \n",
      "963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper presents StereoNet, the first end-to-end deep architecture for\n",
      "real-time stereo matching that runs at 60 fps on an NVidia Titan X, producing\n",
      "high-quality, edge-preserved, quantization-free disparity maps. A key insight\n",
      "of this paper is that the network achieves a sub-pixel matching precision than\n",
      "is a magnitude higher than those of traditional stereo matching approaches.\n",
      "This allows us to achieve real-time performance by using a very low resolution\n",
      "cost volume that encodes all the information needed to achieve high disparity\n",
      "precision. Spatial precision is achieved by employing a learned edge-aware\n",
      "upsampling function. Our model uses a Siamese network to extract features from\n",
      "the left and right image. A first estimate of the disparity is computed in a\n",
      "very low resolution cost volume, then hierarchically the model re-introduces\n",
      "high-frequency details through a learned upsampling function that uses compact\n",
      "pixel-to-pixel refinement networks. Leveraging color input as a guide, this\n",
      "function is capable of producing high-quality edge-aware output. We achieve\n",
      "compelling results on multiple benchmarks, showing how the proposed method\n",
      "offers extreme flexibility at an acceptable computational budget.\n",
      "\n",
      "    \n",
      "964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Human beings process stereoscopic correspondence across multiple scales.\n",
      "However, this bio-inspiration is ignored by state-of-the-art cost aggregation\n",
      "methods for dense stereo correspondence. In this paper, a generic cross-scale\n",
      "cost aggregation framework is proposed to allow multi-scale interaction in cost\n",
      "aggregation. We firstly reformulate cost aggregation from a unified\n",
      "optimization perspective and show that different cost aggregation methods\n",
      "essentially differ in the choices of similarity kernels. Then, an inter-scale\n",
      "regularizer is introduced into optimization and solving this new optimization\n",
      "problem leads to the proposed framework. Since the regularization term is\n",
      "independent of the similarity kernel, various cost aggregation methods can be\n",
      "integrated into the proposed general framework. We show that the cross-scale\n",
      "framework is important as it effectively and efficiently expands\n",
      "state-of-the-art cost aggregation methods and leads to significant\n",
      "improvements, when evaluated on Middlebury, KITTI and New Tsukuba datasets.\n",
      "\n",
      "    \n",
      "965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Stereo matching estimates the disparity between a rectified image pair, which\n",
      "is of great importance to depth sensing, autonomous driving, and other related\n",
      "tasks. Previous works built cost volumes with cross-correlation or\n",
      "concatenation of left and right features across all disparity levels, and then\n",
      "a 2D or 3D convolutional neural network is utilized to regress the disparity\n",
      "maps. In this paper, we propose to construct the cost volume by group-wise\n",
      "correlation. The left features and the right features are divided into groups\n",
      "along the channel dimension, and correlation maps are computed among each group\n",
      "to obtain multiple matching cost proposals, which are then packed into a cost\n",
      "volume. Group-wise correlation provides efficient representations for measuring\n",
      "feature similarities and will not lose too much information like full\n",
      "correlation. It also preserves better performance when reducing parameters\n",
      "compared with previous methods. The 3D stacked hourglass network proposed in\n",
      "previous works is improved to boost the performance and decrease the inference\n",
      "computational cost. Experiment results show that our method outperforms\n",
      "previous methods on Scene Flow, KITTI 2012, and KITTI 2015 datasets. The code\n",
      "is available at this https URL\n",
      "\n",
      "966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this paper we address issues with image retrieval benchmarking on standard\n",
      "and popular Oxford 5k and Paris 6k datasets. In particular, annotation errors,\n",
      "the size of the dataset, and the level of challenge are addressed: new\n",
      "annotation for both datasets is created with an extra attention to the\n",
      "reliability of the ground truth. Three new protocols of varying difficulty are\n",
      "introduced. The protocols allow fair comparison between different methods,\n",
      "including those using a dataset pre-processing stage. For each dataset, 15 new\n",
      "challenging queries are introduced. Finally, a new set of 1M hard,\n",
      "semi-automatically cleaned distractors is selected.\n",
      "An extensive comparison of the state-of-the-art methods is performed on the\n",
      "new benchmark. Different types of methods are evaluated, ranging from\n",
      "local-feature-based to modern CNN based methods. The best results are achieved\n",
      "by taking the best of the two worlds. Most importantly, image retrieval appears\n",
      "far from being solved.\n",
      "\n",
      "    \n",
      "967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present MMDetection, an object detection toolbox that contains a rich set\n",
      "of object detection and instance segmentation methods as well as related\n",
      "components and modules. The toolbox started from a codebase of MMDet team who\n",
      "won the detection track of COCO Challenge 2018. It gradually evolves into a\n",
      "unified platform that covers many popular detection methods and contemporary\n",
      "modules. It not only includes training and inference codes, but also provides\n",
      "weights for more than 200 network models. We believe this toolbox is by far the\n",
      "most complete detection toolbox. In this paper, we introduce the various\n",
      "features of this toolbox. In addition, we also conduct a benchmarking study on\n",
      "different methods, components, and their hyper-parameters. We wish that the\n",
      "toolbox and benchmark could serve the growing research community by providing a\n",
      "flexible toolkit to reimplement existing methods and develop their own new\n",
      "detectors. Code and models are available at\n",
      "this https URL. The project is under active\n",
      "development and we will keep this document updated.\n",
      "\n",
      "    \n",
      "968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We have recently seen the emergence of several publicly available Natural\n",
      "Language Understanding (NLU) toolkits, which map user utterances to structured,\n",
      "but more abstract, Dialogue Act (DA) or Intent specifications, while making\n",
      "this process accessible to the lay developer. In this paper, we present the\n",
      "first wide coverage evaluation and comparison of some of the most popular NLU\n",
      "services, on a large, multi-domain (21 domains) dataset of 25K user utterances\n",
      "that we have collected and annotated with Intent and Entity Type specifications\n",
      "and which will be released as part of this submission. The results show that on\n",
      "Intent classification Watson significantly outperforms the other platforms,\n",
      "namely, Dialogflow, LUIS and Rasa; though these also perform well.\n",
      "Interestingly, on Entity Type recognition, Watson performs significantly worse\n",
      "due to its low Precision. Again, Dialogflow, LUIS and Rasa perform well on this\n",
      "task.\n",
      "\n",
      "    \n",
      "969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  AutoML serves as the bridge between varying levels of expertise when\n",
      "designing machine learning systems and expedites the data science process. A\n",
      "wide range of techniques is taken to address this, however there does not exist\n",
      "an objective comparison of these techniques. We present a benchmark of current\n",
      "open source AutoML solutions using open source datasets. We test auto-sklearn,\n",
      "TPOT, auto_ml, and H2O's AutoML solution against a compiled set of regression\n",
      "and classification datasets sourced from OpenML and find that auto-sklearn\n",
      "performs the best across classification datasets and TPOT performs the best\n",
      "across regression datasets.\n",
      "\n",
      "    \n",
      "970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In this article we introduce the Arcade Learning Environment (ALE): both a\n",
      "challenge problem and a platform and methodology for evaluating the development\n",
      "of general, domain-independent AI technology. ALE provides an interface to\n",
      "hundreds of Atari 2600 game environments, each one different, interesting, and\n",
      "designed to be a challenge for human players. ALE presents significant research\n",
      "challenges for reinforcement learning, model learning, model-based planning,\n",
      "imitation learning, transfer learning, and intrinsic motivation. Most\n",
      "importantly, it provides a rigorous testbed for evaluating and comparing\n",
      "approaches to these problems. We illustrate the promise of ALE by developing\n",
      "and benchmarking domain-independent agents designed using well-established AI\n",
      "techniques for both reinforcement learning and planning. In doing so, we also\n",
      "propose an evaluation methodology made possible by ALE, reporting empirical\n",
      "results on over 55 different games. All of the software, including the\n",
      "benchmark agents, is publicly available.\n",
      "\n",
      "    \n",
      "971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper describes ANN-Benchmarks, a tool for evaluating the performance of\n",
      "in-memory approximate nearest neighbor algorithms. It provides a standard\n",
      "interface for measuring the performance and quality achieved by nearest\n",
      "neighbor algorithms on different standard data sets. It supports several\n",
      "different ways of integrating $k$-NN algorithms, and its configuration system\n",
      "automatically tests a range of parameter settings for each algorithm.\n",
      "Algorithms are compared with respect to many different (approximate) quality\n",
      "measures, and adding more is easy and fast; the included plotting front-ends\n",
      "can visualise these as images, $\\LaTeX$ plots, and websites with interactive\n",
      "plots. ANN-Benchmarks aims to provide a constantly updated overview of the\n",
      "current state of the art of $k$-NN algorithms. In the short term, this overview\n",
      "allows users to choose the correct $k$-NN algorithm and parameters for their\n",
      "similarity search task; in the longer term, algorithm designers will be able to\n",
      "use this overview to test and refine automatic parameter tuning. The paper\n",
      "gives an overview of the system, evaluates the results of the benchmark, and\n",
      "points out directions for future work. Interestingly, very different approaches\n",
      "to $k$-NN search yield comparable quality-performance trade-offs. The system is\n",
      "available at this http URL .\n",
      "\n",
      "    \n",
      "972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present PartNet: a consistent, large-scale dataset of 3D objects annotated\n",
      "with fine-grained, instance-level, and hierarchical 3D part information. Our\n",
      "dataset consists of 573,585 part instances over 26,671 3D models covering 24\n",
      "object categories. This dataset enables and serves as a catalyst for many tasks\n",
      "such as shape analysis, dynamic 3D scene modeling and simulation, affordance\n",
      "analysis, and others. Using our dataset, we establish three benchmarking tasks\n",
      "for evaluating 3D part recognition: fine-grained semantic segmentation,\n",
      "hierarchical semantic segmentation, and instance segmentation. We benchmark\n",
      "four state-of-the-art 3D deep learning algorithms for fine-grained semantic\n",
      "segmentation and three baseline methods for hierarchical semantic segmentation.\n",
      "We also propose a novel method for part instance segmentation and demonstrate\n",
      "its superior performance over existing methods.\n",
      "\n",
      "    \n",
      "973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce EvalAI, an open source platform for evaluating and comparing\n",
      "machine learning (ML) and artificial intelligence algorithms (AI) at scale.\n",
      "EvalAI is built to provide a scalable solution to the research community to\n",
      "fulfill the critical need of evaluating machine learning models and agents\n",
      "acting in an environment against annotations or with a human-in-the-loop. This\n",
      "will help researchers, students, and data scientists to create, collaborate,\n",
      "and participate in AI challenges organized around the globe. By simplifying and\n",
      "standardizing the process of benchmarking these models, EvalAI seeks to lower\n",
      "the barrier to entry for participating in the global scientific effort to push\n",
      "the frontiers of machine learning and artificial intelligence, thereby\n",
      "increasing the rate of measurable progress in this domain.\n",
      "\n",
      "    \n",
      "974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Fairness is an increasingly important concern as machine learning models are\n",
      "used to support decision making in high-stakes applications such as mortgage\n",
      "lending, hiring, and prison sentencing. This paper introduces a new open source\n",
      "Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released\n",
      "under an Apache v2.0 license {this https URL). The main\n",
      "objectives of this toolkit are to help facilitate the transition of fairness\n",
      "research algorithms to use in an industrial setting and to provide a common\n",
      "framework for fairness researchers to share and evaluate algorithms.\n",
      "The package includes a comprehensive set of fairness metrics for datasets and\n",
      "models, explanations for these metrics, and algorithms to mitigate bias in\n",
      "datasets and models. It also includes an interactive Web experience\n",
      "(this https URL) that provides a gentle introduction to the\n",
      "concepts and capabilities for line-of-business users, as well as extensive\n",
      "documentation, usage guidance, and industry-specific tutorials to enable data\n",
      "scientists and practitioners to incorporate the most appropriate tool for their\n",
      "problem into their work products. The architecture of the package has been\n",
      "engineered to conform to a standard paradigm used in data science, thereby\n",
      "further improving usability for practitioners. Such architectural design and\n",
      "abstractions enable researchers and developers to extend the toolkit with their\n",
      "new algorithms and improvements, and to use it for performance benchmarking. A\n",
      "built-in testing infrastructure maintains code quality.\n",
      "\n",
      "    \n",
      "975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We introduce Texygen, a benchmarking platform to support research on\n",
      "open-domain text generation models. Texygen has not only implemented a majority\n",
      "of text generation models, but also covered a set of metrics that evaluate the\n",
      "diversity, the quality and the consistency of the generated texts. The Texygen\n",
      "platform could help standardize the research on text generation and facilitate\n",
      "the sharing of fine-tuned open-source implementations among researchers for\n",
      "their work. As a consequence, this would help in improving the reproductivity\n",
      "and reliability of future research work in text generation.\n",
      "\n",
      "    \n",
      "976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automatically describing an image with a sentence is a long-standing\n",
      "challenge in computer vision and natural language processing. Due to recent\n",
      "progress in object detection, attribute classification, action recognition,\n",
      "etc., there is renewed interest in this area. However, evaluating the quality\n",
      "of descriptions has proven to be challenging. We propose a novel paradigm for\n",
      "evaluating image descriptions that uses human consensus. This paradigm consists\n",
      "of three main parts: a new triplet-based method of collecting human annotations\n",
      "to measure consensus, a new automated metric (CIDEr) that captures consensus,\n",
      "and two new datasets: PASCAL-50S and ABSTRACT-50S that contain 50 sentences\n",
      "describing each image. Our simple metric captures human judgment of consensus\n",
      "better than existing metrics across sentences generated by various sources. We\n",
      "also evaluate five state-of-the-art image description approaches using this new\n",
      "protocol and provide a benchmark for future comparisons. A version of CIDEr\n",
      "named CIDEr-D is available as a part of MS COCO evaluation server to enable\n",
      "systematic evaluation and benchmarking.\n",
      "\n",
      "    \n",
      "977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Habitat, a new platform for research in embodied artificial\n",
      "intelligence (AI). Habitat enables training embodied agents (virtual robots) in\n",
      "highly efficient photorealistic 3D simulation, before transferring the learned\n",
      "skills to reality.\n",
      "Specifically, Habitat consists of the following: 1. Habitat-Sim: a flexible,\n",
      "high-performance 3D simulator with configurable agents, multiple sensors, and\n",
      "generic 3D dataset handling (with built-in support for SUNCG, Matterport3D,\n",
      "Gibson datasets). Habitat-Sim is fast -- when rendering a scene from the\n",
      "Matterport3D dataset, Habitat-Sim achieves several thousand frames per second\n",
      "(fps) running single-threaded, and can reach over 10,000 fps multi-process on a\n",
      "single GPU, which is orders of magnitude faster than the closest simulator. 2.\n",
      "Habitat-API: a modular high-level library for end-to-end development of\n",
      "embodied AI algorithms -- defining embodied AI tasks (e.g. navigation,\n",
      "instruction following, question answering), configuring and training embodied\n",
      "agents (via imitation or reinforcement learning, or via classic SLAM), and\n",
      "benchmarking using standard metrics.\n",
      "These large-scale engineering contributions enable us to answer scientific\n",
      "questions requiring experiments that were till now impracticable or `merely'\n",
      "impractical. Specifically, in the context of point-goal navigation (1) we\n",
      "revisit the comparison between learning and SLAM approaches from two recent\n",
      "works and find evidence for the opposite conclusion -- that learning\n",
      "outperforms SLAM, if scaled to total experience far surpassing that of previous\n",
      "investigations, and (2) we conduct the first cross-dataset generalization\n",
      "experiments {train, test} x {Matterport3D, Gibson} for multiple sensors {blind,\n",
      "RGB, RGBD, D} and find that only agents with depth (D) sensors generalize\n",
      "across datasets. We hope that our open-source platform and these findings will\n",
      "advance research in embodied AI.\n",
      "\n",
      "    \n",
      "978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Semantic segmentation benefits robotics related applications especially\n",
      "autonomous driving. Most of the research on semantic segmentation is only on\n",
      "increasing the accuracy of segmentation models with little attention to\n",
      "computationally efficient solutions. The few work conducted in this direction\n",
      "does not provide principled methods to evaluate the different design choices\n",
      "for segmentation. In this paper, we address this gap by presenting a real-time\n",
      "semantic segmentation benchmarking framework with a decoupled design for\n",
      "feature extraction and decoding methods. The framework is comprised of\n",
      "different network architectures for feature extraction such as VGG16, Resnet18,\n",
      "MobileNet, and ShuffleNet. It is also comprised of multiple meta-architectures\n",
      "for segmentation that define the decoding methodology. These include SkipNet,\n",
      "UNet, and Dilation Frontend. Experimental results are presented on the\n",
      "Cityscapes dataset for urban scenes. The modular design allows novel\n",
      "architectures to emerge, that lead to 143x GFLOPs reduction in comparison to\n",
      "SegNet. This benchmarking framework is publicly available at\n",
      "\"this https URL\".\n",
      "\n",
      "    \n",
      "979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The selection, development, or comparison of machine learning methods in data\n",
      "mining can be a difficult task based on the target problem and goals of a\n",
      "particular study. Numerous publicly available real-world and simulated\n",
      "benchmark datasets have emerged from different sources, but their organization\n",
      "and adoption as standards have been inconsistent. As such, selecting and\n",
      "curating specific benchmarks remains an unnecessary burden on machine learning\n",
      "practitioners and data scientists. The present study introduces an accessible,\n",
      "curated, and developing public benchmark resource to facilitate identification\n",
      "of the strengths and weaknesses of different machine learning methodologies. We\n",
      "compare meta-features among the current set of benchmark datasets in this\n",
      "resource to characterize the diversity of available data. Finally, we apply a\n",
      "number of established machine learning methods to the entire benchmark suite\n",
      "and analyze how datasets and algorithms cluster in terms of performance. This\n",
      "work is an important first step towards understanding the limitations of\n",
      "popular benchmarking suites and developing a resource that connects existing\n",
      "benchmarking standards to more diverse and efficient standards in the future.\n",
      "\n",
      "    \n",
      "980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  In mainstream computer vision and machine learning, public datasets such as\n",
      "ImageNet, COCO and KITTI have helped drive enormous improvements by enabling\n",
      "researchers to understand the strengths and limitations of different algorithms\n",
      "via performance comparison. However, this type of approach has had limited\n",
      "translation to problems in robotic assisted surgery as this field has never\n",
      "established the same level of common datasets and benchmarking methods. In 2015\n",
      "a sub-challenge was introduced at the EndoVis workshop where a set of robotic\n",
      "images were provided with automatically generated annotations from robot\n",
      "forward kinematics. However, there were issues with this dataset due to the\n",
      "limited background variation, lack of complex motion and inaccuracies in the\n",
      "annotation. In this work we present the results of the 2017 challenge on\n",
      "robotic instrument segmentation which involved 10 teams participating in\n",
      "binary, parts and type based segmentation of articulated da Vinci robotic\n",
      "instruments.\n",
      "\n",
      "    \n",
      "981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  This paper proposes an end-to-end deep hashing framework with category mask\n",
      "for fast video retrieval. We train our network in a supervised way by fully\n",
      "exploiting inter-class diversity and intra-class identity. Classification loss\n",
      "is optimized to maximize inter-class diversity, while intra-pair is introduced\n",
      "to learn representative intra-class identity. We investigate the binary bits\n",
      "distribution related to categories and find out that the effectiveness of\n",
      "binary bits is highly correlated with data categories, and some bits may\n",
      "degrade classification performance of some categories. We then design hash code\n",
      "generation scheme with category mask to filter out bits with negative\n",
      "contribution. Experimental results demonstrate the proposed method outperforms\n",
      "several state-of-the-arts under various evaluation metrics on public datasets.\n",
      "\n",
      "    \n",
      "982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present TRANX, a transition-based neural semantic parser that maps natural\n",
      "language (NL) utterances into formal meaning representations (MRs). TRANX uses\n",
      "a transition system based on the abstract syntax description language for the\n",
      "target MR, which gives it two major advantages: (1) it is highly accurate,\n",
      "using information from the syntax of the target MR to constrain the output\n",
      "space and model the information flow, and (2) it is highly generalizable, and\n",
      "can easily be applied to new types of MR by just writing a new abstract syntax\n",
      "description corresponding to the allowable structures in the MR. Experiments on\n",
      "four different semantic parsing and code generation tasks show that our system\n",
      "is generalizable, extensible, and effective, registering strong results\n",
      "compared to existing neural semantic parsers.\n",
      "\n",
      "    \n",
      "983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Semantic parsing is the task of transducing natural language (NL) utterances\n",
      "into formal meaning representations (MRs), commonly represented as tree\n",
      "structures. Annotating NL utterances with their corresponding MRs is expensive\n",
      "and time-consuming, and thus the limited availability of labeled data often\n",
      "becomes the bottleneck of data-driven, supervised models. We introduce\n",
      "StructVAE, a variational auto-encoding model for semisupervised semantic\n",
      "parsing, which learns both from limited amounts of parallel data, and\n",
      "readily-available unlabeled NL utterances. StructVAE models latent MRs not\n",
      "observed in the unlabeled data as tree-structured latent variables. Experiments\n",
      "on semantic parsing on the ATIS domain and Python code generation show that\n",
      "with extra unlabeled data, StructVAE outperforms strong supervised models.\n",
      "\n",
      "    \n",
      "984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many language generation tasks require the production of text conditioned on\n",
      "both structured and unstructured inputs. We present a novel neural network\n",
      "architecture which generates an output sequence conditioned on an arbitrary\n",
      "number of input functions. Crucially, our approach allows both the choice of\n",
      "conditioning context and the granularity of generation, for example characters\n",
      "or tokens, to be marginalised, thus permitting scalable and effective training.\n",
      "Using this framework, we address the problem of generating programming code\n",
      "from a mixed natural language and structured specification. We create two new\n",
      "data sets for this paradigm derived from the collectible trading card games\n",
      "Magic the Gathering and Hearthstone. On these, and a third preexisting corpus,\n",
      "we demonstrate that marginalising multiple predictors allows our model to\n",
      "outperform strong benchmarks.\n",
      "\n",
      "    \n",
      "985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Automated documentation of programming source code and automated code\n",
      "generation from natural language are challenging tasks of both practical and\n",
      "scientific interest. Progress in these areas has been limited by the low\n",
      "availability of parallel corpora of code and natural language descriptions,\n",
      "which tend to be small and constrained to specific domains.\n",
      "In this work we introduce a large and diverse parallel corpus of a hundred\n",
      "thousands Python functions with their documentation strings (\"docstrings\")\n",
      "generated by scraping open source repositories on GitHub. We describe baseline\n",
      "results for the code documentation and code generation tasks obtained by neural\n",
      "machine translation. We also experiment with data augmentation techniques to\n",
      "further increase the amount of training data.\n",
      "We release our datasets and processing scripts in order to stimulate research\n",
      "in these areas.\n",
      "\n",
      "    \n",
      "986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Research on question answering with knowledge base has recently seen an\n",
      "increasing use of deep architectures. In this extended abstract, we study the\n",
      "application of the neural machine translation paradigm for question parsing. We\n",
      "employ a sequence-to-sequence model to learn graph patterns in the SPARQL graph\n",
      "query language and their compositions. Instead of inducing the programs through\n",
      "question-answer pairs, we expect a semi-supervised approach, where alignments\n",
      "between questions and queries are built through templates. We argue that the\n",
      "coverage of language utterances can be expanded using late notable works in\n",
      "natural language generation.\n",
      "\n",
      "    \n",
      "987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Code generation maps a program description to executable source code in a\n",
      "programming language. Existing approaches mainly rely on a recurrent neural\n",
      "network (RNN) as the decoder. However, we find that a program contains\n",
      "significantly more tokens than a natural language sentence, and thus it may be\n",
      "inappropriate for RNN to capture such a long sequence. In this paper, we\n",
      "propose a grammar-based structural convolutional neural network (CNN) for code\n",
      "generation. Our model generates a program by predicting the grammar rules of\n",
      "the programming language; we design several CNN modules, including the\n",
      "tree-based convolution and pre-order convolution, whose information is further\n",
      "aggregated by dedicated attentive pooling layers. Experimental results on the\n",
      "HearthStone benchmark dataset show that our CNN code generator significantly\n",
      "outperforms the previous state-of-the-art method by 5 percentage points;\n",
      "additional experiments on several semantic parsing tasks demonstrate the\n",
      "robustness of our model. We also conduct in-depth ablation test to better\n",
      "understand each component of our model.\n",
      "\n",
      "    \n",
      "988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Synthesizing SQL queries from natural language is a long-standing open\n",
      "problem and has been attracting considerable interest recently. Toward solving\n",
      "the problem, the de facto approach is to employ a sequence-to-sequence-style\n",
      "model. Such an approach will necessarily require the SQL queries to be\n",
      "serialized. Since the same SQL query may have multiple equivalent\n",
      "serializations, training a sequence-to-sequence-style model is sensitive to the\n",
      "choice from one of them. This phenomenon is documented as the \"order-matters\"\n",
      "problem. Existing state-of-the-art approaches rely on reinforcement learning to\n",
      "reward the decoder when it generates any of the equivalent serializations.\n",
      "However, we observe that the improvement from reinforcement learning is\n",
      "limited.\n",
      "In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally\n",
      "solve this problem by avoiding the sequence-to-sequence structure when the\n",
      "order does not matter. In particular, we employ a sketch-based approach where\n",
      "the sketch contains a dependency graph so that one prediction can be done by\n",
      "taking into consideration only the previous predictions that it depends on. In\n",
      "addition, we propose a sequence-to-set model as well as the column attention\n",
      "mechanism to synthesize the query based on the sketch. By combining all these\n",
      "novel techniques, we show that SQLNet can outperform the prior art by 9% to 13%\n",
      "on the WikiSQL task.\n",
      "\n",
      "    \n",
      "989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  A significant amount of the world's knowledge is stored in relational\n",
      "databases. However, the ability for users to retrieve facts from a database is\n",
      "limited due to a lack of understanding of query languages such as SQL. We\n",
      "propose Seq2SQL, a deep neural network for translating natural language\n",
      "questions to corresponding SQL queries. Our model leverages the structure of\n",
      "SQL queries to significantly reduce the output space of generated queries.\n",
      "Moreover, we use rewards from in-the-loop query execution over the database to\n",
      "learn a policy to generate unordered parts of the query, which we show are less\n",
      "suitable for optimization via cross entropy loss. In addition, we will publish\n",
      "WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL\n",
      "queries distributed across 24241 tables from Wikipedia. This dataset is\n",
      "required to train our model and is an order of magnitude larger than comparable\n",
      "datasets. By applying policy-based reinforcement learning with a query\n",
      "execution environment to WikiSQL, our model Seq2SQL outperforms attentional\n",
      "sequence to sequence models, improving execution accuracy from 35.9% to 59.4%\n",
      "and logical form accuracy from 23.4% to 48.3%.\n",
      "\n",
      "    \n",
      "990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Spider, a large-scale, complex and cross-domain semantic parsing\n",
      "and text-to-SQL dataset annotated by 11 college students. It consists of 10,181\n",
      "questions and 5,693 unique complex SQL queries on 200 databases with multiple\n",
      "tables, covering 138 different domains. We define a new complex and\n",
      "cross-domain semantic parsing and text-to-SQL task where different complex SQL\n",
      "queries and databases appear in train and test sets. In this way, the task\n",
      "requires the model to generalize well to both new SQL queries and new database\n",
      "schemas. Spider is distinct from most of the previous semantic parsing tasks\n",
      "because they all use a single database and the exact same programs in the train\n",
      "set and the test set. We experiment with various state-of-the-art models and\n",
      "the best model achieves only 12.4% exact matching accuracy on a database split\n",
      "setting. This shows that Spider presents a strong challenge for future\n",
      "research. Our dataset and task are publicly available at\n",
      "this https URL\n",
      "\n",
      "991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  To be informative, an evaluation must measure how well systems generalize to\n",
      "realistic unseen data. We identify limitations of and propose improvements to\n",
      "current evaluations of text-to-SQL systems. First, we compare human-generated\n",
      "and automatically generated questions, characterizing properties of queries\n",
      "necessary for real-world applications. To facilitate evaluation on multiple\n",
      "datasets, we release standardized and improved versions of seven existing\n",
      "datasets and one new text-to-SQL dataset. Second, we show that the current\n",
      "division of data into training and test sets measures robustness to variations\n",
      "in the way questions are asked, but only partially tests how well systems\n",
      "generalize to new queries; therefore, we propose a complementary dataset split\n",
      "for evaluation of future work. Finally, we demonstrate how the common practice\n",
      "of anonymizing variables during evaluation removes an important challenge of\n",
      "the task. Our observations highlight key difficulties, and our methodology\n",
      "enables effective measurement of future development.\n",
      "\n",
      "    \n",
      "992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Most existing studies in text-to-SQL tasks do not require generating complex\n",
      "SQL queries with multiple clauses or sub-queries, and generalizing to new,\n",
      "unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network\n",
      "to address the complex and cross-domain text-to-SQL generation task.\n",
      "SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL\n",
      "generation path history and table-aware column attention encoders. We evaluate\n",
      "SyntaxSQLNet on the Spider text-to-SQL task, which contains databases with\n",
      "multiple tables and complex SQL queries with multiple SQL clauses and nested\n",
      "queries. We use a database split setting where databases in the test set are\n",
      "unseen during training. Experimental results show that SyntaxSQLNet can handle\n",
      "a significantly greater number of complex SQL examples than prior work,\n",
      "outperforming the previous state-of-the-art model by 7.3% in exact matching\n",
      "accuracy. We also show that SyntaxSQLNet can further improve the performance by\n",
      "an additional 7.5% using a cross-domain augmentation method, resulting in a\n",
      "14.8% improvement in total. To our knowledge, we are the first to study this\n",
      "complex and cross-domain text-to-SQL task.\n",
      "\n",
      "    \n",
      "993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Interacting with relational databases through natural language helps users of\n",
      "any background easily query and analyze a vast amount of data. This requires a\n",
      "system that understands users' questions and converts them to SQL queries\n",
      "automatically. In this paper we present a novel approach, TypeSQL, which views\n",
      "this problem as a slot filling task. Additionally, TypeSQL utilizes type\n",
      "information to better understand rare entities and numbers in natural language\n",
      "questions. We test this idea on the WikiSQL dataset and outperform the prior\n",
      "state-of-the-art by 5.5% in much less time. We also show that accessing the\n",
      "content of databases can significantly improve the performance when users'\n",
      "queries are not well-formed. TypeSQL gets 82.6% accuracy, a 17.5% absolute\n",
      "improvement compared to the previous content-sensitive model.\n",
      "\n",
      "    \n",
      "994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of neural semantic parsing, which translates natural\n",
      "language questions into executable SQL queries. We introduce a new mechanism,\n",
      "execution guidance, to leverage the semantics of SQL. It detects and excludes\n",
      "faulty programs during the decoding procedure by conditioning on the execution\n",
      "of partially generated program. The mechanism can be used with any\n",
      "autoregressive generative model, which we demonstrate on four state-of-the-art\n",
      "recurrent or template-based semantic parsing models. We demonstrate that\n",
      "execution guidance universally improves model performance on various\n",
      "text-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\n",
      "and GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\n",
      "of 83.8% on WikiSQL.\n",
      "\n",
      "    \n",
      "995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  The ability to generate natural language sequences from source code snippets\n",
      "has a variety of applications such as code summarization, documentation, and\n",
      "retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine\n",
      "translation (NMT), have achieved state-of-the-art performance on these tasks by\n",
      "treating source code as a sequence of tokens. We present ${\\rm {\\scriptsize\n",
      "CODE2SEQ}}$: an alternative approach that leverages the syntactic structure of\n",
      "programming languages to better encode source code. Our model represents a code\n",
      "snippet as the set of compositional paths in its abstract syntax tree (AST) and\n",
      "uses attention to select the relevant paths while decoding. We demonstrate the\n",
      "effectiveness of our approach for two tasks, two programming languages, and\n",
      "four datasets of up to $16$M examples. Our model significantly outperforms\n",
      "previous models that were specifically designed for programming languages, as\n",
      "well as state-of-the-art NMT models. An interactive online demo of our model is\n",
      "available at this http URL. Our code, data and trained models are\n",
      "available at this http URL.\n",
      "\n",
      "    \n",
      "996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are\n",
      "widely used because they are expressive and are easy to train. Our interest\n",
      "lies in empirically evaluating the expressiveness and the learnability of LSTMs\n",
      "in the sequence-to-sequence regime by training them to evaluate short computer\n",
      "programs, a domain that has traditionally been seen as too complex for neural\n",
      "networks. We consider a simple class of programs that can be evaluated with a\n",
      "single left-to-right pass using constant memory. Our main result is that LSTMs\n",
      "can learn to map the character-level representations of such programs to their\n",
      "correct outputs. Notably, it was necessary to use curriculum learning, and\n",
      "while conventional curriculum learning proved ineffective, we developed a new\n",
      "variant of curriculum learning that improved our networks' performance in all\n",
      "experimental conditions. The improved curriculum had a dramatic impact on an\n",
      "addition problem, making it possible to train an LSTM to add two 9-digit\n",
      "numbers with 99% accuracy.\n",
      "\n",
      "    \n",
      "997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Neural machine translation models are used to automatically generate a\n",
      "document from given source code since this can be regarded as a machine\n",
      "translation task. Source code summarization is one of the components for\n",
      "automatic document generation, which generates a summary in natural language\n",
      "from given source code. This suggests that techniques used in neural machine\n",
      "translation, such as Long Short-Term Memory (LSTM), can be used for source code\n",
      "summarization. However, there is a considerable difference between source code\n",
      "and natural language: Source code is essentially {\\em structured}, having loops\n",
      "and conditional branching, etc. Therefore, there is some obstacle to apply\n",
      "known machine translation models to source code.\n",
      "Abstract syntax trees (ASTs) capture these structural properties and play an\n",
      "important role in recent machine learning studies on source code. Tree-LSTM is\n",
      "proposed as a generalization of LSTMs for tree-structured data. However, there\n",
      "is a critical issue when applying it to ASTs: It cannot handle a tree that\n",
      "contains nodes having an arbitrary number of children and their order\n",
      "simultaneously, which ASTs generally have such nodes. To address this issue, we\n",
      "propose an extension of Tree-LSTM, which we call \\emph{Multi-way Tree-LSTM} and\n",
      "apply it for source code summarization. As a result of computational\n",
      "experiments, our proposal achieved better results when compared with several\n",
      "state-of-the-art techniques.\n",
      "\n",
      "    \n",
      "998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Semantic code search is the task of retrieving relevant code given a natural\n",
      "language query. While related to other information retrieval tasks, it requires\n",
      "bridging the gap between the language used in code (often abbreviated and\n",
      "highly technical) and natural language more suitable to describe vague concepts\n",
      "and ideas.\n",
      "To enable evaluation of progress on code search, we are releasing the\n",
      "CodeSearchNet Corpus and are presenting the CodeSearchNet Challenge, which\n",
      "consists of 99 natural language queries with about 4k expert relevance\n",
      "annotations of likely results from CodeSearchNet Corpus. The corpus contains\n",
      "about 6 million functions from open-source code spanning six programming\n",
      "languages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet\n",
      "Corpus also contains automatically generated query-like natural language for 2\n",
      "million functions, obtained from mechanically scraping and preprocessing\n",
      "associated function documentation. In this article, we describe the methodology\n",
      "used to obtain the corpus and expert labels, as well as a number of simple\n",
      "baseline solutions for the task.\n",
      "We hope that CodeSearchNet Challenge encourages researchers and practitioners\n",
      "to study this interesting task further and will host a competition and\n",
      "leaderboard to track the progress on the challenge. We are also keen on\n",
      "extending CodeSearchNet Challenge to more queries and programming languages in\n",
      "the future.\n",
      "\n",
      "    \n",
      "999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the task of program synthesis in the presence of a reward\n",
      "function over the output of programs, where the goal is to find programs with\n",
      "maximal rewards. We employ an iterative optimization scheme, where we train an\n",
      "RNN on a dataset of K best programs from a priority queue of the generated\n",
      "programs so far. Then, we synthesize new programs and add them to the priority\n",
      "queue by sampling from the RNN. We benchmark our algorithm, called priority\n",
      "queue training (or PQT), against genetic algorithm and reinforcement learning\n",
      "baselines on a simple but expressive Turing complete programming language\n",
      "called BF. Our experimental results show that our simple PQT algorithm\n",
      "significantly outperforms the baselines. By adding a program length penalty to\n",
      "the reward function, we are able to synthesize short, human readable programs.\n",
      "\n",
      "    \n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\n",
      "way to leverage a memory buffer of promising trajectories to reduce the\n",
      "variance of policy gradient estimate. MAPO is applicable to deterministic\n",
      "environments with discrete actions, such as structured prediction and\n",
      "combinatorial optimization tasks. We express the expected return objective as a\n",
      "weighted sum of two terms: an expectation over the high-reward trajectories\n",
      "inside the memory buffer, and a separate expectation over trajectories outside\n",
      "the buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\n",
      "weight clipping to accelerate and stabilize training; (2) systematic\n",
      "exploration to discover high-reward trajectories; (3) distributed sampling from\n",
      "inside and outside of the memory buffer to scale up training. MAPO improves the\n",
      "sample efficiency and robustness of policy gradient, especially on tasks with\n",
      "sparse rewards. We evaluate MAPO on weakly supervised program synthesis from\n",
      "natural language (semantic parsing). On the WikiTableQuestions benchmark, we\n",
      "improve the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\n",
      "WikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\n",
      "supervision, outperforming several strong baselines with full supervision. Our\n",
      "source code is available at\n",
      "this https URL\n",
      "\n",
      "1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We develop a first line of attack for solving programming competition-style\n",
      "problems from input-output examples using deep learning. The approach is to\n",
      "train a neural network to predict properties of the program that generated the\n",
      "outputs from the inputs. We use the neural network's predictions to augment\n",
      "search techniques from the programming languages community, including\n",
      "enumerative search and an SMT-based solver. Empirically, we show that our\n",
      "approach leads to an order of magnitude speedup over the strong non-augmented\n",
      "baselines and a Recurrent Neural Network approach, and that we are able to\n",
      "solve problems of difficulty comparable to the simplest problems on programming\n",
      "competition websites.\n",
      "\n",
      "    \n",
      "1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Human activity recognition is typically addressed by detecting key concepts\n",
      "like global and local motion, features related to object classes present in the\n",
      "scene, as well as features related to the global context. The next open\n",
      "challenges in activity recognition require a level of understanding that pushes\n",
      "beyond this and call for models with capabilities for fine distinction and\n",
      "detailed comprehension of interactions between actors and objects in a scene.\n",
      "We propose a model capable of learning to reason about semantically meaningful\n",
      "spatiotemporal interactions in videos. The key to our approach is a choice of\n",
      "performing this reasoning at the object level through the integration of state\n",
      "of the art object detection networks. This allows the model to learn detailed\n",
      "spatial interactions that exist at a semantic, object-interaction relevant\n",
      "level. We evaluate our method on three standard datasets (Twenty-BN\n",
      "Something-Something, VLOG and EPIC Kitchens) and achieve state of the art\n",
      "results on all of them. Finally, we show visualizations of the interactions\n",
      "learned by the model, which illustrate object classes and their interactions\n",
      "corresponding to different activity classes.\n",
      "\n",
      "    \n",
      "1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Synthesizing programs using example input/outputs is a classic problem in\n",
      "artificial intelligence. We present a method for solving Programming By Example\n",
      "(PBE) problems by using a neural model to guide the search of a constraint\n",
      "logic programming system called miniKanren. Crucially, the neural model uses\n",
      "miniKanren's internal representation as input; miniKanren represents a PBE\n",
      "problem as recursive constraints imposed by the provided examples. We explore\n",
      "Recurrent Neural Network and Graph Neural Network models. We contribute a\n",
      "modified miniKanren, drivable by an external agent, available at\n",
      "this https URL. We show that our neural-guided approach\n",
      "using constraints can synthesize programs faster in many cases, and\n",
      "importantly, can generalize to larger problems.\n",
      "\n",
      "    \n",
      "1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  We consider the problem of generating automatic code given sample\n",
      "input-output pairs. We train a neural network to map from the current state and\n",
      "the outputs to the program's next statement. The neural network optimizes\n",
      "multiple tasks concurrently: the next operation out of a set of high level\n",
      "commands, the operands of the next statement, and which variables can be\n",
      "dropped from memory. Using our method we are able to create programs that are\n",
      "more than twice as long as existing state-of-the-art solutions, while improving\n",
      "the success rate for comparable lengths, and cutting the run-time by two orders\n",
      "of magnitude. Our code, including an implementation of various literature\n",
      "baselines, is publicly available at this https URL\n",
      "\n",
      "1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent two-stream deep Convolutional Neural Networks (ConvNets) have made\n",
      "significant progress in recognizing human actions in videos. Despite their\n",
      "success, methods extending the basic two-stream ConvNet have not systematically\n",
      "explored possible network architectures to further exploit spatiotemporal\n",
      "dynamics within video sequences. Further, such networks often use different\n",
      "baseline two-stream networks. Therefore, the differences and the distinguishing\n",
      "factors between various methods using Recurrent Neural Networks (RNN) or\n",
      "convolutional networks on temporally-constructed feature vectors\n",
      "(Temporal-ConvNet) are unclear. In this work, we first demonstrate a strong\n",
      "baseline two-stream ConvNet using ResNet-101. We use this baseline to\n",
      "thoroughly examine the use of both RNNs and Temporal-ConvNets for extracting\n",
      "spatiotemporal information. Building upon our experimental results, we then\n",
      "propose and investigate two different networks to further integrate\n",
      "spatiotemporal information: 1) temporal segment RNN and 2) Inception-style\n",
      "Temporal-ConvNet. We demonstrate that using both RNNs (using LSTMs) and\n",
      "Temporal-ConvNets on spatiotemporal feature matrices are able to exploit\n",
      "spatiotemporal dynamics to improve the overall performance. However, each of\n",
      "these methods require proper care to achieve state-of-the-art performance; for\n",
      "example, LSTMs require pre-segmented data or else they cannot fully exploit\n",
      "temporal information. Our analysis identifies specific limitations for each\n",
      "method that could form the basis of future work. Our experimental results on\n",
      "UCF101 and HMDB51 datasets achieve state-of-the-art performances, 94.1% and\n",
      "69.0%, respectively, without requiring extensive temporal augmentation.\n",
      "\n",
      "    \n",
      "1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Over the past decade, multivariate time series classification has received\n",
      "great attention. We propose transforming the existing univariate time series\n",
      "classification models, the Long Short Term Memory Fully Convolutional Network\n",
      "(LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series\n",
      "classification model by augmenting the fully convolutional block with a\n",
      "squeeze-and-excitation block to further improve accuracy. Our proposed models\n",
      "outperform most state-of-the-art models while requiring minimum preprocessing.\n",
      "The proposed models work efficiently on various complex multivariate time\n",
      "series classification tasks such as activity recognition or action recognition.\n",
      "Furthermore, the proposed models are highly efficient at test time and small\n",
      "enough to deploy on memory constrained systems.\n",
      "\n",
      "    \n",
      "1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Research on depth-based human activity analysis achieved outstanding\n",
      "performance and demonstrated the effectiveness of 3D representation for action\n",
      "recognition. The existing depth-based and RGB+D-based action recognition\n",
      "benchmarks have a number of limitations, including the lack of large-scale\n",
      "training samples, realistic number of distinct class categories, diversity in\n",
      "camera views, varied environmental conditions, and variety of human subjects.\n",
      "In this work, we introduce a large-scale dataset for RGB+D human action\n",
      "recognition, which is collected from 106 distinct subjects and contains more\n",
      "than 114 thousand video samples and 8 million frames. This dataset contains 120\n",
      "different action classes including daily, mutual, and health-related\n",
      "activities. We evaluate the performance of a series of existing 3D activity\n",
      "analysis methods on this dataset, and show the advantage of applying deep\n",
      "learning methods for 3D-based human action recognition. Furthermore, we\n",
      "investigate a novel one-shot 3D activity recognition problem on our dataset,\n",
      "and a simple yet effective Action-Part Semantic Relevance-aware (APSR)\n",
      "framework is proposed for this task, which yields promising results for\n",
      "recognition of the novel action classes. We believe the introduction of this\n",
      "large-scale dataset will enable the community to apply, adapt, and develop\n",
      "various data-hungry learning techniques for depth-based and RGB+D-based human\n",
      "activity understanding. [The dataset is available at:\n",
      "this http URL]\n",
      "\n",
      "    \n",
      "1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Cross-correlator plays a significant role in many visual perception tasks,\n",
      "such as object detection and tracking. Beyond the linear cross-correlator, this\n",
      "paper proposes a kernel cross-correlator (KCC) that breaks traditional\n",
      "limitations. First, by introducing the kernel trick, the KCC extends the linear\n",
      "cross-correlation to non-linear space, which is more robust to signal noises\n",
      "and distortions. Second, the connection to the existing works shows that KCC\n",
      "provides a unified solution for correlation filters. Third, KCC is applicable\n",
      "to any kernel function and is not limited to circulant structure on training\n",
      "data, thus it is able to predict affine transformations with customized\n",
      "properties. Last, by leveraging the fast Fourier transform (FFT), KCC\n",
      "eliminates direct calculation of kernel vectors, thus achieves better\n",
      "performance yet still with a reasonable computational cost. Comprehensive\n",
      "experiments on visual tracking and human activity recognition using wearable\n",
      "devices demonstrate its robustness, flexibility, and efficiency. The source\n",
      "codes of both experiments are released at this https URL\n",
      "\n",
      "1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeoKyung\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:986: InsecureRequestWarning: Unverified HTTPS request is being made to host 'arxiv.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Many recent advancements in Computer Vision are attributed to large datasets.\n",
      "Open-source software packages for Machine Learning and inexpensive commodity\n",
      "hardware have reduced the barrier of entry for exploring novel approaches at\n",
      "scale. It is possible to train models over millions of examples within a few\n",
      "days. Although large-scale datasets exist for image understanding, such as\n",
      "ImageNet, there are no comparable size video classification datasets.\n",
      "In this paper, we introduce YouTube-8M, the largest multi-label video\n",
      "classification dataset, composed of ~8 million videos (500K hours of video),\n",
      "annotated with a vocabulary of 4800 visual entities. To get the videos and\n",
      "their labels, we used a YouTube video annotation system, which labels videos\n",
      "with their main topics. While the labels are machine-generated, they have\n",
      "high-precision and are derived from a variety of human-based signals including\n",
      "metadata and query click signals. We filtered the video labels (Knowledge Graph\n",
      "entities) using both automated and manual curation strategies, including asking\n",
      "human raters if the labels are visually recognizable. Then, we decoded each\n",
      "video at one-frame-per-second, and used a Deep CNN pre-trained on ImageNet to\n",
      "extract the hidden representation immediately prior to the classification\n",
      "layer. Finally, we compressed the frame features and make both the features and\n",
      "video-level labels available for download.\n",
      "We trained various (modest) classification models on the dataset, evaluated\n",
      "them using popular evaluation metrics, and report them as baselines. Despite\n",
      "the size of the dataset, some of our models train to convergence in less than a\n",
      "day on a single machine using TensorFlow. We plan to release code for training\n",
      "a TensorFlow model and for computing metrics.\n",
      "\n",
      "    \n",
      "1010\n",
      "['AbstractRecurrent neural network grammars (RNNGs) are generative models of (tree , string ) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.', 'It is pdf', 'AbstractWe introduce the novel task of predicting adverbial presupposition triggers, which is useful for natural language generation tasks such as summarization and dialogue systems. We introduce two new corpora, derived from the Penn Treebank and the Annotated English Gigaword dataset and investigate the use of a novel attention mechanism tailored to this task. Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters, minimizing the added computational cost of our mechanism. We demonstrate that this model statistically outperforms our baselines.', 'AbstractExtractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.', 'AbstractWe propose a novel paradigm of grounding comparative adjectives within the realm of color descriptions. Given a reference RGB color and a comparative term (e.g., lighter, darker), our model learns to ground the comparative as a direction in the RGB space such that the colors along the vector, rooted at the reference color, satisfy the comparison. Our model generates grounded representations of comparative adjectives with an average accuracy of 0.65 cosine similarity to the desired direction of change. These vectors approach colors with Delta-E scores of under 7 compared to the target colors, indicating the differences are very small with respect to human perception. Our approach makes use of a newly created dataset for this task derived from existing labeled color data.', 'AbstractMany recent papers address reading comprehension, where examples consist of (question, passage, answer) tuples. Presumably, a model must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50% accuracy, sometimes matching the full model. Interestingly, while CBT provides 20-sentence passages, only the last is needed for accurate prediction. By comparison, SQuAD and CNN appear better-constructed.', 'AbstractEven though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available.To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.The contribution of this work apart from the open-sourced dataset is two-fold:firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.', 'AbstractCurrent state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features. However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax. In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL. Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates. Syntax is incorporated by training one attention head to attend to syntactic parents for each token. Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model. In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10% reduction in error. On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1. LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.', 'AbstractMachine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT’14 English-French and WMT’16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points. On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semi-supervised and supervised approaches leveraging the paucity of available bitexts. Our code for NMT and PBSMT is publicly available.', 'AbstractWe introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'AbstractFollowing the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones.', 'It is pdf', 'It is pdf', 'AbstractMulti-label classification is an important yet challenging task in natural language processing. It is more complex than single-label classification in that the labels tend to be correlated. Existing methods tend to ignore the correlations between labels. Besides, different parts of the text can contribute differently for predicting different labels, which is not considered by existing models. In this paper, we propose to view the multi-label classification task as a sequence generation problem, and apply a sequence generation model with a novel decoder structure to solve it. Extensive experimental results show that our proposed methods outperform previous work by a substantial margin. Further analysis of experimental results demonstrates that the proposed methods not only capture the correlations between labels, but also select the most informative words automatically when predicting different labels.', 'AbstractWe study German affixoids, a type of morpheme in between affixes and free stems. Several properties have been associated with them – increased productivity; a bleached semantics, which is often evaluative and/or intensifying and thus of relevance to sentiment analysis; and the existence of a free morpheme counterpart – but not been validated empirically. In experiments on a new data set that we make available, we put these key assumptions from the morphological literature to the test and show that despite the fact that affixoids generate many low-frequency formations, we can classify these as affixoid or non-affixoid instances with a best F1-score of 74%.', 'AbstractMost previous work in unsupervised semantic modeling in the presence of metadata has assumed that our goal is to make latent dimensions more correlated with metadata, but in practice the exact opposite is often true. Some users want topic models that highlight differences between, for example, authors, but others seek more subtle connections across authors. We introduce three metrics for identifying topics that are highly correlated with metadata, and demonstrate that this problem affects between 30 and 50% of the topics in models trained on two real-world collections, regardless of the size of the model. We find that we can predict which words cause this phenomenon and that by selectively subsampling these words we dramatically reduce topic-metadata correlation, improve topic stability, and maintain or even improve model quality.', 'AbstractThe aim of this paper is to argue for a coherent Universal Dependencies approach to the core vs. non-core distinction. We demonstrate inconsistencies in the current version 2 of UD in this respect – mostly resulting from the preservation of the argument–adjunct dichotomy despite the declared avoidance of this distinction – and propose a relatively conservative modification of UD that is free from these problems.', 'AbstractIn this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available. We release our implementations as an open-source toolkit.', 'AbstractIn this paper, we present AnlamVer, which is a semantic model evaluation dataset for Turkish designed to evaluate word similarity and word relatedness tasks while discriminating those two relations from each other. Our dataset consists of 500 word-pairs annotated by 12 human subjects, and each pair has two distinct scores for similarity and relatedness. Word-pairs are selected to enable the evaluation of distributional semantic models by multiple attributes of words and word-pair relations such as frequency, morphology, concreteness and relation types (e.g., synonymy, antonymy). Our aim is to provide insights to semantic model researchers by evaluating models in multiple attributes. We balance dataset word-pairs by their frequencies to evaluate the robustness of semantic models concerning out-of-vocabulary and rare words problems, which are caused by the rich derivational and inflectional morphology of the Turkish language.', 'AbstractWe provide a detailed overview of the various approaches that were proposed to date to solve the task of Open Information Extraction. We present the major challenges that such systems face, show the evolution of the suggested approaches over time and depict the specific issues they address. In addition, we provide a critique of the commonly applied evaluation procedures for assessing the performance of Open IE systems and highlight some directions for future work.', 'AbstractWe investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks (i.e. NER, Chunking, and POS tagging). Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners.', '\\nAbstract:  Neural networks models for NLP are typically implemented without the explicit\\nencoding of language rules and yet they are able to break one performance\\nrecord after another. This has generated a lot of research interest in\\ninterpreting the representations learned by these networks. We propose here a\\nnovel interpretation approach that relies on the only processing system we have\\nthat does understand language: the human brain. We use brain imaging recordings\\nof subjects reading complex natural text to interpret word and sequence\\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\\nstudy how their representations differ across layer depth, context length, and\\nattention type. Our results reveal differences in the context-related\\nrepresentations across these models. Further, in the transformer models, we\\nfind an interaction between layer depth and context length, and between layer\\ndepth and attention type. We finally hypothesize that altering BERT to better\\nalign with brain recordings would enable it to also better understand language.\\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\\nincreased brain-alignment outperforms the original model. Cognitive\\nneuroscientists have already begun using NLP networks to study the brain, and\\nthis work closes the loop to allow the interaction between NLP and cognitive\\nneuroscience to be a true cross-pollination.\\n\\n    ', 'It is pdf', '\\nAbstract:  In this work, we demonstrate that 3D poses in video can be effectively\\nestimated with a fully convolutional model based on dilated temporal\\nconvolutions over 2D keypoints. We also introduce back-projection, a simple and\\neffective semi-supervised training method that leverages unlabeled video data.\\nWe start with predicted 2D keypoints for unlabeled video, then estimate 3D\\nposes and finally back-project to the input 2D keypoints. In the supervised\\nsetting, our fully-convolutional model outperforms the previous best result\\nfrom the literature by 6 mm mean per-joint position error on Human3.6M,\\ncorresponding to an error reduction of 11%, and the model also shows\\nsignificant improvements on HumanEva-I. Moreover, experiments with\\nback-projection show that it comfortably outperforms previous state-of-the-art\\nresults in semi-supervised settings where labeled data is scarce. Code and\\nmodels are available at this https URL\\n', '\\nAbstract:  We propose a unified formulation for the problem of 3D human pose estimation\\nfrom a single raw RGB image that reasons jointly about 2D joint estimation and\\n3D pose reconstruction to improve both tasks. We take an integrated approach\\nthat fuses probabilistic knowledge of 3D human pose with a multi-stage CNN\\narchitecture and uses the knowledge of plausible 3D landmark locations to\\nrefine the search for better 2D locations. The entire process is trained\\nend-to-end, is extremely efficient and obtains state- of-the-art results on\\nHuman3.6M outperforming previous approaches both on 2D and 3D errors.\\n\\n    ', \"\\nAbstract:  We present some updates to YOLO! We made a bunch of little design changes to\\nmake it better. We also trained this new network that's pretty swell. It's a\\nlittle bigger than last time but more accurate. It's still fast though, don't\\nworry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but\\nthree times faster. When we look at the old .5 IOU mAP detection metric YOLOv3\\nis quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5\\nmAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always,\\nall the code is online at this https URL\\n\", '\\nAbstract:  We present YOLO, a new approach to object detection. Prior work on object\\ndetection repurposes classifiers to perform detection. Instead, we frame object\\ndetection as a regression problem to spatially separated bounding boxes and\\nassociated class probabilities. A single neural network predicts bounding boxes\\nand class probabilities directly from full images in one evaluation. Since the\\nwhole detection pipeline is a single network, it can be optimized end-to-end\\ndirectly on detection performance.\\nOur unified architecture is extremely fast. Our base YOLO model processes\\nimages in real-time at 45 frames per second. A smaller version of the network,\\nFast YOLO, processes an astounding 155 frames per second while still achieving\\ndouble the mAP of other real-time detectors. Compared to state-of-the-art\\ndetection systems, YOLO makes more localization errors but is far less likely\\nto predict false detections where nothing exists. Finally, YOLO learns very\\ngeneral representations of objects. It outperforms all other detection methods,\\nincluding DPM and R-CNN, by a wide margin when generalizing from natural images\\nto artwork on both the Picasso Dataset and the People-Art Dataset.\\n\\n    ', '\\nAbstract:  This paper proposes a distributed Multi-Agent Reinforcement Learning (MARL)\\nalgorithm for a team of Unmanned Aerial Vehicles (UAVs). The proposed MARL\\nalgorithm allows UAVs to learn cooperatively to provide a full coverage of an\\nunknown field of interest while minimizing the overlapping sections among their\\nfield of views. Two challenges in MARL for such a system are discussed in the\\npaper: firstly, the complex dynamic of the joint-actions of the UAV team, that\\nwill be solved using game-theoretic correlated equilibrium, and secondly, the\\nchallenge in huge dimensional state space representation will be tackled with\\nefficient function approximation techniques. We also provide our experimental\\nresults in detail with both simulation and physical implementation to show that\\nthe UAV team can successfully learn to accomplish the task.\\n\\n    ', '\\nAbstract:  Flocking control has been studied extensively along with the wide application\\nof multi-vehicle systems. In this paper the Multi-vehicles System (MVS)\\nflocking control with collision avoidance and communication preserving is\\nconsidered based on the deep reinforcement learning framework. Specifically the\\ndeep deterministic policy gradient (DDPG) with centralized training and\\ndistributed execution process is implemented to obtain the flocking control\\npolicy. First, to avoid the dynamically changed observation of state, a three\\nlayers tensor based representation of the observation is used so that the state\\nremains constant although the observation dimension is changing. A reward\\nfunction is designed to guide the way-points tracking, collision avoidance and\\ncommunication preserving. The reward function is augmented by introducing the\\nlocal reward function of neighbors. Finally, a centralized training process\\nwhich trains the shared policy based on common training set among all agents.\\nThe proposed method is tested under simulated scenarios with different setup.\\n\\n    ', '\\nAbstract:  In this paper we study the problem of steering a team of Unmanned Aerial\\nVehicles (UAVs) toward a static configuration which maximizes the visibility of\\na 3D environment. The UAVs are assumed to be equipped with visual sensors\\nconstrained by a maximum sensing range and the prior knowledge on the\\nenvironment is considered to be very sparse. To solve this problem on-line,\\nderivative-free measurement-based optimization algorithms can be adopted, even\\nthough they are strongly limited by local optimality. To overcome this\\nlimitation, we propose to exploit the partial initial knowledge on the\\nenvironment to find suitable initial configurations from which the agents start\\nthe local optimization. In particular, a constrained centroidal Voronoi\\ntessellation on a coarse approximation of the surface to cover is proposed. The\\nbehavior of the agent is so based on a two-step optimization approach, where a\\nstochastic optimization algorithm based on the on-line acquired information\\nfollows the geometrical-based initialization. The algorithm performance is\\nevaluated in simulation and in particular the improvement on the solution\\nbrought by the Voronoi tessellation with respect to different initializations\\nis analyzed.\\n\\n    ', '\\nAbstract:  The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.\\n\\n    ', '\\nAbstract:  We introduce a new language representation model called BERT, which stands\\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to pre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right context in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output layer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language inference, without substantial task-specific architecture\\nmodifications.\\nBERT is conceptually simple and empirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, including\\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\\n(5.1 point absolute improvement).\\n\\n    ', \"\\nAbstract:  In this work, we establish dense correspondences between RGB image and a\\nsurface-based representation of the human body, a task we refer to as dense\\nhuman pose estimation. We first gather dense correspondences for 50K persons\\nappearing in the COCO dataset by introducing an efficient annotation pipeline.\\nWe then use our dataset to train CNN-based systems that deliver dense\\ncorrespondence 'in the wild', namely in the presence of background, occlusions\\nand scale variations. We improve our training set's effectiveness by training\\nan 'inpainting' network that can fill in missing groundtruth values and report\\nclear improvements with respect to the best results that would be achievable in\\nthe past. We experiment with fully-convolutional networks and region-based\\nmodels and observe a superiority of the latter; we further improve accuracy\\nthrough cascading, obtaining a system that delivers highly0accurate results in\\nreal time. Supplementary materials and videos are provided on the project page\\nthis http URL\\n\", '\\nAbstract:  We describe Human Mesh Recovery (HMR), an end-to-end framework for\\nreconstructing a full 3D mesh of a human body from a single RGB image. In\\ncontrast to most current methods that compute 2D or 3D joint locations, we\\nproduce a richer and more useful mesh representation that is parameterized by\\nshape and 3D joint angles. The main objective is to minimize the reprojection\\nloss of keypoints, which allow our model to be trained using images in-the-wild\\nthat only have ground truth 2D annotations. However, the reprojection loss\\nalone leaves the model highly under constrained. In this work we address this\\nproblem by introducing an adversary trained to tell whether a human body\\nparameter is real or not using a large database of 3D human meshes. We show\\nthat HMR can be trained with and without using any paired 2D-to-3D supervision.\\nWe do not rely on intermediate 2D keypoint detections and infer 3D pose and\\nshape parameters directly from image pixels. Our model runs in real-time given\\na bounding box containing the person. We demonstrate our approach on various\\nimages in-the-wild and out-perform previous optimization based methods that\\noutput 3D meshes and show competitive results on tasks such as 3D joint\\nlocation estimation and part segmentation.\\n\\n    ', '\\nAbstract:  This paper presents a simple method for \"do as I do\" motion transfer: given a\\nsource video of a person dancing, we can transfer that performance to a novel\\n(amateur) target after only a few minutes of the target subject performing\\nstandard moves. We approach this problem as video-to-video translation using\\npose as an intermediate representation. To transfer the motion, we extract\\nposes from the source subject and apply the learned pose-to-appearance mapping\\nto generate the target subject. We predict two consecutive frames for\\ntemporally coherent video results and introduce a separate pipeline for\\nrealistic face synthesis. Although our method is quite simple, it produces\\nsurprisingly compelling results (see video). This motivates us to also provide\\na forensics tool for reliable synthetic content detection, which is able to\\ndistinguish videos synthesized by our system from real data. In addition, we\\nrelease a first-of-its-kind open-source dataset of videos that can be legally\\nused for training and motion transfer.\\n\\n    ', '\\nAbstract:  Vector representations of sentences, trained on massive text corpora, are\\nwidely used as generic sentence embeddings across a variety of NLP problems.\\nThe learned representations are generally assumed to be continuous and\\nreal-valued, giving rise to a large memory footprint and slow retrieval speed,\\nwhich hinders their applicability to low-resource (memory and computation)\\nplatforms, such as mobile devices. In this paper, we propose four different\\nstrategies to transform continuous and generic sentence embeddings into a\\nbinarized form, while preserving their rich semantic information. The\\nintroduced methods are evaluated across a wide range of downstream tasks, where\\nthe binarized sentence embeddings are demonstrated to degrade performance by\\nonly about 2% relative to their continuous counterparts, while reducing the\\nstorage requirement by over 98%. Moreover, with the learned binary\\nrepresentations, the semantic relatedness of two sentences can be evaluated by\\nsimply calculating their Hamming distance, which is more computational\\nefficient compared with the inner product operation between continuous\\nembeddings. Detailed analysis and case study further validate the effectiveness\\nof proposed methods.\\n\\n    ', '\\nAbstract:  Bidirectional Encoder Representations from Transformers (BERT) has shown\\nmarvelous improvements across various NLP tasks. Recently, an upgraded version\\nof BERT has been released with Whole Word Masking (WWM), which mitigate the\\ndrawbacks of masking partial WordPiece tokens in pre-training BERT. In this\\ntechnical report, we adapt whole word masking in Chinese text, that masking the\\nwhole word instead of masking Chinese characters, which could bring another\\nchallenge in Masked Language Model (MLM) pre-training task. The proposed models\\nare verified on various NLP tasks, across sentence-level to document-level,\\nincluding machine reading comprehension (CMRC 2018, DRCD, CJRC), natural\\nlanguage inference (XNLI), sentiment classification (ChnSentiCorp), sentence\\npair matching (LCQMC, BQ Corpus), and document classification (THUCNews).\\nExperimental results on these datasets show that the whole word masking could\\nbring another significant gain. Moreover, we also examine the effectiveness of\\nthe Chinese pre-trained models: BERT, ERNIE, BERT-wwm, BERT-wwm-ext,\\nRoBERTa-wwm-ext, and RoBERTa-wwm-ext-large. We release all the pre-trained\\nmodels: \\\\url{this https URL\\n', '\\nAbstract:  While deep learning techniques have shown promising results in many natural\\nlanguage processing (NLP) tasks, it has not been widely applied to the clinical\\ndomain. The lack of large datasets and the pervasive use of domain-specific\\nlanguage (i.e. abbreviations and acronyms) in the clinical domain causes slower\\nprogress in NLP tasks than that of the general NLP tasks. To fill this gap, we\\nemploy word/subword-level based models that adopt large-scale data-driven\\nmethods such as pre-trained language models and transfer learning in analyzing\\ntext for the clinical domain. Empirical results demonstrate the superiority of\\nthe proposed methods by achieving 90.6% accuracy in medical domain natural\\nlanguage inference task. Furthermore, we inspect the independent strengths of\\nthe proposed approaches in quantitative and qualitative manners. This analysis\\nwill help researchers to select necessary components in building models for the\\nmedical domain.\\n\\n    ', '\\nAbstract:  We present an end-to-end approach to extract semantic concepts directly from\\nthe speech audio signal. To overcome the lack of data available for this spoken\\nlanguage understanding approach, we investigate the use of a transfer learning\\nstrategy based on the principles of curriculum learning. This approach allows\\nus to exploit out-of-domain data that can help to prepare a fully neural\\narchitecture. Experiments are carried out on the French MEDIA and PORTMEDIA\\ncorpora and show that this end-to-end SLU approach reaches the best results\\never published on this task. We compare our approach to a classical pipeline\\napproach that uses ASR, POS tagging, lemmatizer, chunker... and other NLP tools\\nthat aim to enrich ASR outputs that feed an SLU text to concepts system. Last,\\nwe explore the promising capacity of our end-to-end SLU approach to address the\\nproblem of domain portability.\\n\\n    ', '\\nAbstract:  Recent advances in language modeling using deep neural networks have shown\\nthat these models learn representations, that vary with the network depth from\\nmorphology to semantic relationships like co-reference. We apply pre-trained\\nlanguage models to low-resource named entity recognition for Historic German.\\nWe show on a series of experiments that character-based pre-trained language\\nmodels do not run into trouble when faced with low-resource datasets. Our\\npre-trained character-based language models improve upon classical CRF-based\\nmethods and previous work on Bi-LSTMs by boosting F1 score performance by up to\\n6%. Our pre-trained language and NER models are publicly available under\\nthis https URL .\\n\\n    ', '\\nAbstract:  This paper describes a new method to extract relevant keywords from patent\\nclaims, as part of the task of retrieving other patents with similar claims\\n(search for prior art). The method combines a qualitative analysis of the\\nwriting style of the claims with NLP methods to parse text, in order to\\nrepresent a legal text as a specialization arborescence of terms. In this\\nsetting, the set of extracted keywords are yielding better search results than\\nkeywords extracted with traditional methods such as tf-idf. The performance is\\nmeasured on the search results of a query consisting of the extracted keywords.\\n\\n    ', '\\nAbstract:  This paper addresses the task of readability assessment for the texts aimed\\nat second language (L2) learners. One of the major challenges in this task is\\nthe lack of significantly sized level-annotated data. For the present work, we\\ncollected a dataset of CEFR-graded texts tailored for learners of English as an\\nL2 and investigated text readability assessment for both native and L2\\nlearners. We applied a generalization method to adapt models trained on larger\\nnative corpora to estimate text readability for learners, and explored domain\\nadaptation and self-learning techniques to make use of the native data to\\nimprove system performance on the limited L2 data. In our experiments, the best\\nperforming model for readability on learner texts achieves an accuracy of 0.797\\nand PCC of $0.938$.\\n\\n    ', \"\\nAbstract:  We present a novel method for constructing Variational Autoencoder (VAE).\\nInstead of using pixel-by-pixel loss, we enforce deep feature consistency\\nbetween the input and the output of a VAE, which ensures the VAE's output to\\npreserve the spatial correlation characteristics of the input, thus leading the\\noutput to have a more natural visual appearance and better perceptual quality.\\nBased on recent deep learning works such as style transfer, we employ a\\npre-trained deep convolutional neural network (CNN) and use its hidden features\\nto define a feature perceptual loss for VAE training. Evaluated on the CelebA\\nface dataset, we show that our model produces better results than other methods\\nin the literature. We also show that our method can produce latent vectors that\\ncan capture the semantic information of face expressions and can be used to\\nachieve state-of-the-art performance in facial attribute prediction.\\n\\n    \", '\\nAbstract:  We study the problem of video-to-video synthesis, whose goal is to learn a\\nmapping function from an input source video (e.g., a sequence of semantic\\nsegmentation masks) to an output photorealistic video that precisely depicts\\nthe content of the source video. While its image counterpart, the\\nimage-to-image synthesis problem, is a popular topic, the video-to-video\\nsynthesis problem is less explored in the literature. Without understanding\\ntemporal dynamics, directly applying existing image synthesis approaches to an\\ninput video often results in temporally incoherent videos of low visual\\nquality. In this paper, we propose a novel video-to-video synthesis approach\\nunder the generative adversarial learning framework. Through carefully-designed\\ngenerator and discriminator architectures, coupled with a spatio-temporal\\nadversarial objective, we achieve high-resolution, photorealistic, temporally\\ncoherent video results on a diverse set of input formats including segmentation\\nmasks, sketches, and poses. Experiments on multiple benchmarks show the\\nadvantage of our method compared to strong baselines. In particular, our model\\nis capable of synthesizing 2K resolution videos of street scenes up to 30\\nseconds long, which significantly advances the state-of-the-art of video\\nsynthesis. Finally, we apply our approach to future video prediction,\\noutperforming several state-of-the-art competing systems.\\n\\n    ', '\\nAbstract:  Designing convolutional neural networks (CNN) for mobile devices is\\nchallenging because mobile models need to be small and fast, yet still\\naccurate. Although significant efforts have been dedicated to design and\\nimprove mobile CNNs on all dimensions, it is very difficult to manually balance\\nthese trade-offs when there are so many architectural possibilities to\\nconsider. In this paper, we propose an automated mobile neural architecture\\nsearch (MNAS) approach, which explicitly incorporate model latency into the\\nmain objective so that the search can identify a model that achieves a good\\ntrade-off between accuracy and latency. Unlike previous work, where latency is\\nconsidered via another, often inaccurate proxy (e.g., FLOPS), our approach\\ndirectly measures real-world inference latency by executing the model on mobile\\nphones. To further strike the right balance between flexibility and search\\nspace size, we propose a novel factorized hierarchical search space that\\nencourages layer diversity throughout the network. Experimental results show\\nthat our approach consistently outperforms state-of-the-art mobile CNN models\\nacross multiple vision tasks. On the ImageNet classification task, our MnasNet\\nachieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x\\nfaster than MobileNetV2 [29] with 0.5% higher accuracy and 2.3x faster than\\nNASNet [36] with 1.2% higher accuracy. Our MnasNet also achieves better mAP\\nquality than MobileNets for COCO object detection. Code is at\\nthis https URL\\n', '\\nAbstract:  We introduce instancewise feature selection as a methodology for model\\ninterpretation. Our method is based on learning a function to extract a subset\\nof features that are most informative for each given example. This feature\\nselector is trained to maximize the mutual information between selected\\nfeatures and the response variable, where the conditional distribution of the\\nresponse variable given the input is the model to be explained. We develop an\\nefficient variational approximation to the mutual information, and show the\\neffectiveness of our method on a variety of synthetic and real data sets using\\nboth quantitative metrics and human evaluation.\\n\\n    ', '\\nAbstract:  Existing deep learning based image inpainting methods use a standard\\nconvolutional network over the corrupted image, using convolutional filter\\nresponses conditioned on both valid pixels as well as the substitute values in\\nthe masked holes (typically the mean value). This often leads to artifacts such\\nas color discrepancy and blurriness. Post-processing is usually used to reduce\\nsuch artifacts, but are expensive and may fail. We propose the use of partial\\nconvolutions, where the convolution is masked and renormalized to be\\nconditioned on only valid pixels. We further include a mechanism to\\nautomatically generate an updated mask for the next layer as part of the\\nforward pass. Our model outperforms other methods for irregular masks. We show\\nqualitative and quantitative comparisons with other methods to validate our\\napproach.\\n\\n    ', '\\nAbstract:  In this paper we describe a new mobile architecture, MobileNetV2, that\\nimproves the state of the art performance of mobile models on multiple tasks\\nand benchmarks as well as across a spectrum of different model sizes. We also\\ndescribe efficient ways of applying these mobile models to object detection in\\na novel framework we call SSDLite. Additionally, we demonstrate how to build\\nmobile semantic segmentation models through a reduced form of DeepLabv3 which\\nwe call Mobile DeepLabv3.\\nThe MobileNetV2 architecture is based on an inverted residual structure where\\nthe input and output of the residual block are thin bottleneck layers opposite\\nto traditional residual models which use expanded representations in the input\\nan MobileNetV2 uses lightweight depthwise convolutions to filter features in\\nthe intermediate expansion layer. Additionally, we find that it is important to\\nremove non-linearities in the narrow layers in order to maintain\\nrepresentational power. We demonstrate that this improves performance and\\nprovide an intuition that led to this design. Finally, our approach allows\\ndecoupling of the input/output domains from the expressiveness of the\\ntransformation, which provides a convenient framework for further analysis. We\\nmeasure our performance on Imagenet classification, COCO object detection, VOC\\nimage segmentation. We evaluate the trade-offs between accuracy, and number of\\noperations measured by multiply-adds (MAdd), as well as the number of\\nparameters\\n\\n    ', '\\nAbstract:  Despite recent progress in generative image modeling, successfully generating\\nhigh-resolution, diverse samples from complex datasets such as ImageNet remains\\nan elusive goal. To this end, we train Generative Adversarial Networks at the\\nlargest scale yet attempted, and study the instabilities specific to such\\nscale. We find that applying orthogonal regularization to the generator renders\\nit amenable to a simple \"truncation trick,\" allowing fine control over the\\ntrade-off between sample fidelity and variety by reducing the variance of the\\nGenerator\\'s input. Our modifications lead to models which set the new state of\\nthe art in class-conditional image synthesis. When trained on ImageNet at\\n128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of\\n166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous\\nbest IS of 52.52 and FID of 18.6.\\n\\n    ', '\\nAbstract:  An analysis of different techniques for recognizing and detecting objects\\nunder extreme scale variation is presented. Scale specific and scale invariant\\ndesign of detectors are compared by training them with different configurations\\nof input data. By evaluating the performance of different network architectures\\nfor classifying small objects on ImageNet, we show that CNNs are not robust to\\nchanges in scale. Based on this analysis, we propose to train and test\\ndetectors on the same scales of an image-pyramid. Since small and large objects\\nare difficult to recognize at smaller and larger scales respectively, we\\npresent a novel training scheme called Scale Normalization for Image Pyramids\\n(SNIP) which selectively back-propagates the gradients of object instances of\\ndifferent sizes as a function of the image scale. On the COCO dataset, our\\nsingle model performance is 45.7% and an ensemble of 3 networks obtains an mAP\\nof 48.3%. We use off-the-shelf ImageNet-1000 pre-trained models and only train\\nwith bounding box supervision. Our submission won the Best Student Entry in the\\nCOCO 2017 challenge. Code will be made available at\\n\\\\url{this http URL}.\\n\\n    ', '\\nAbstract:  Hardware support for deep convolutional neural networks (CNNs) is critical to\\nadvanced computer vision in mobile and embedded devices. Current designs,\\nhowever, accelerate generic CNNs; they do not exploit the unique\\ncharacteristics of real-time vision. We propose to use the temporal redundancy\\nin natural video to avoid unnecessary computation on most frames. A new\\nalgorithm, activation motion compensation, detects changes in the visual input\\nand incrementally updates a previously-computed output. The technique takes\\ninspiration from video compression and applies well-known motion estimation\\ntechniques to adapt to visual changes. We use an adaptive key frame rate to\\ncontrol the trade-off between efficiency and vision quality as the input\\nchanges. We implement the technique in hardware as an extension to existing\\nstate-of-the-art CNN accelerator designs. The new unit reduces the average\\nenergy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%\\nloss in vision accuracy.\\n\\n    ', '\\nAbstract:  Image restoration algorithms are typically evaluated by some distortion\\nmeasure (e.g. PSNR, SSIM, IFC, VIF) or by human opinion scores that quantify\\nperceived perceptual quality. In this paper, we prove mathematically that\\ndistortion and perceptual quality are at odds with each other. Specifically, we\\nstudy the optimal probability for correctly discriminating the outputs of an\\nimage restoration algorithm from real images. We show that as the mean\\ndistortion decreases, this probability must increase (indicating worse\\nperceptual quality). As opposed to the common belief, this result holds true\\nfor any distortion measure, and is not only a problem of the PSNR or SSIM\\ncriteria. We also show that generative-adversarial-nets (GANs) provide a\\nprincipled way to approach the perception-distortion bound. This constitutes\\ntheoretical support to their observed success in low-level vision tasks. Based\\non our analysis, we propose a new methodology for evaluating image restoration\\nmethods, and use it to perform an extensive comparison between recent\\nsuper-resolution algorithms.\\n\\n    ', \"\\nAbstract:  We introduce a data-driven approach for unsupervised video retargeting that\\ntranslates content from one domain to another while preserving the style native\\nto a domain, i.e., if contents of John Oliver's speech were to be transferred\\nto Stephen Colbert, then the generated content/speech should be in Stephen\\nColbert's style. Our approach combines both spatial and temporal information\\nalong with adversarial losses for content translation and style preservation.\\nIn this work, we first study the advantages of using spatiotemporal constraints\\nover spatial constraints for effective retargeting. We then demonstrate the\\nproposed approach for the problems where information in both space and time\\nmatters such as face-to-face translation, flower-to-flower, wind and cloud\\nsynthesis, sunrise and sunset.\\n\\n    \", '\\nAbstract:  Obtaining models that capture imaging markers relevant for disease\\nprogression and treatment monitoring is challenging. Models are typically based\\non large amounts of data with annotated examples of known markers aiming at\\nautomating detection. High annotation effort and the limitation to a vocabulary\\nof known markers limit the power of such approaches. Here, we perform\\nunsupervised learning to identify anomalies in imaging data as candidates for\\nmarkers. We propose AnoGAN, a deep convolutional generative adversarial network\\nto learn a manifold of normal anatomical variability, accompanying a novel\\nanomaly scoring scheme based on the mapping from image space to a latent space.\\nApplied to new data, the model labels anomalies, and scores image patches\\nindicating their fit into the learned distribution. Results on optical\\ncoherence tomography images of the retina demonstrate that the approach\\ncorrectly identifies anomalous images, such as images containing retinal fluid\\nor hyperreflective foci.\\n\\n    ', '\\nAbstract:  Flow-based generative models (Dinh et al., 2014) are conceptually attractive\\ndue to tractability of the exact log-likelihood, tractability of exact\\nlatent-variable inference, and parallelizability of both training and\\nsynthesis. In this paper we propose Glow, a simple type of generative flow\\nusing an invertible 1x1 convolution. Using our method we demonstrate a\\nsignificant improvement in log-likelihood on standard benchmarks. Perhaps most\\nstrikingly, we demonstrate that a generative model optimized towards the plain\\nlog-likelihood objective is capable of efficient realistic-looking synthesis\\nand manipulation of large images. The code for our model is available at\\nthis https URL\\n', '\\nAbstract:  Deep learning systems have become ubiquitous in many aspects of our lives.\\nUnfortunately, it has been shown that such systems are vulnerable to\\nadversarial attacks, making them prone to potential unlawful uses. Designing\\ndeep neural networks that are robust to adversarial attacks is a fundamental\\nstep in making such systems safer and deployable in a broader variety of\\napplications (e.g. autonomous driving), but more importantly is a necessary\\nstep to design novel and more advanced architectures built on new computational\\nparadigms rather than marginally building on the existing ones. In this paper\\nwe introduce PeerNets, a novel family of convolutional networks alternating\\nclassical Euclidean convolutions with graph convolutions to harness information\\nfrom a graph of peer samples. This results in a form of non-local forward\\npropagation in the model, where latent features are conditioned on the global\\nstructure induced by the graph, that is up to 3 times more robust to a variety\\nof white- and black-box adversarial attacks compared to conventional\\narchitectures with almost no drop in accuracy.\\n\\n    ', '\\nAbstract:  Current neural network-based classifiers are susceptible to adversarial\\nexamples even in the black-box setting, where the attacker only has query\\naccess to the model. In practice, the threat model for real-world systems is\\noften more restrictive than the typical black-box model where the adversary can\\nobserve the full output of the network on arbitrarily many chosen inputs. We\\ndefine three realistic threat models that more accurately characterize many\\nreal-world classifiers: the query-limited setting, the partial-information\\nsetting, and the label-only setting. We develop new attacks that fool\\nclassifiers under these more restrictive threat models, where previous methods\\nwould be impractical or ineffective. We demonstrate that our methods are\\neffective against an ImageNet classifier under our proposed threat models. We\\nalso demonstrate a targeted black-box attack against a commercial classifier,\\novercoming the challenges of limited query access, partial information, and\\nother practical issues to break the Google Cloud Vision API.\\n\\n    ', '\\nAbstract:  Convolutional neural networks (CNNs) have been successfully applied to many\\nrecognition and learning tasks using a universal recipe; training a deep model\\non a very large dataset of supervised examples. However, this approach is\\nrather restrictive in practice since collecting a large set of labeled images\\nis very expensive. One way to ease this problem is coming up with smart ways\\nfor choosing images to be labelled from a very large collection (ie. active\\nlearning).\\nOur empirical study suggests that many of the active learning heuristics in\\nthe literature are not effective when applied to CNNs in batch setting.\\nInspired by these limitations, we define the problem of active learning as\\ncore-set selection, ie. choosing set of points such that a model learned over\\nthe selected subset is competitive for the remaining data points. We further\\npresent a theoretical result characterizing the performance of any selected\\nsubset using the geometry of the datapoints. As an active learning algorithm,\\nwe choose the subset which is expected to yield best result according to our\\ncharacterization. Our experiments show that the proposed method significantly\\noutperforms existing approaches in image classification experiments by a large\\nmargin.\\n\\n    ', '\\nAbstract:  Currently, the neural network architecture design is mostly guided by the\\n\\\\emph{indirect} metric of computation complexity, i.e., FLOPs. However, the\\n\\\\emph{direct} metric, e.g., speed, also depends on the other factors such as\\nmemory access cost and platform characterics. Thus, this work proposes to\\nevaluate the direct metric on the target platform, beyond only considering\\nFLOPs. Based on a series of controlled experiments, this work derives several\\npractical \\\\emph{guidelines} for efficient network design. Accordingly, a new\\narchitecture is presented, called \\\\emph{ShuffleNet V2}. Comprehensive ablation\\nexperiments verify that our model is the state-of-the-art in terms of speed and\\naccuracy tradeoff.\\n\\n    ', '\\nAbstract:  We propose a new system for generating art. The system generates art by\\nlooking at art and learning about style; and becomes creative by increasing the\\narousal potential of the generated art by deviating from the learned styles. We\\nbuild over Generative Adversarial Networks (GAN), which have shown the ability\\nto learn to generate novel images simulating a given distribution. We argue\\nthat such networks are limited in their ability to generate creative products\\nin their original design. We propose modifications to its objective to make it\\ncapable of generating creative art by maximizing deviation from established\\nstyles and minimizing deviation from art distribution. We conducted experiments\\nto compare the response of human subjects to the generated art with their\\nresponse to art created by artists. The results show that human subjects could\\nnot distinguish art generated by the proposed system from art generated by\\ncontemporary artists and shown in top art fairs. Human subjects even rated the\\ngenerated images higher on various scales.\\n\\n    ', '\\nAbstract:  In this paper, we present a simple yet effective padding scheme that can be\\nused as a drop-in module for existing convolutional neural networks. We call it\\npartial convolution based padding, with the intuition that the padded region\\ncan be treated as holes and the original input as non-holes. Specifically,\\nduring the convolution operation, the convolution results are re-weighted near\\nimage borders based on the ratios between the padded area and the convolution\\nsliding window area. Extensive experiments with various deep network models on\\nImageNet classification and semantic segmentation demonstrate that the proposed\\npadding scheme consistently outperforms standard zero padding with better\\naccuracy.\\n\\n    ', '\\nAbstract:  We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)\\nwhich views the discriminator as an energy function that attributes low\\nenergies to the regions near the data manifold and higher energies to other\\nregions. Similar to the probabilistic GANs, a generator is seen as being\\ntrained to produce contrastive samples with minimal energies, while the\\ndiscriminator is trained to assign high energies to these generated samples.\\nViewing the discriminator as an energy function allows to use a wide variety of\\narchitectures and loss functionals in addition to the usual binary classifier\\nwith logistic output. Among them, we show one instantiation of EBGAN framework\\nas using an auto-encoder architecture, with the energy being the reconstruction\\nerror, in place of the discriminator. We show that this form of EBGAN exhibits\\nmore stable behavior than regular GANs during training. We also show that a\\nsingle-scale architecture can be trained to generate high-resolution images.\\n\\n    ', '\\nAbstract:  Despite significant recent advances in the field of face recognition,\\nimplementing face verification and recognition efficiently at scale presents\\nserious challenges to current approaches. In this paper we present a system,\\ncalled FaceNet, that directly learns a mapping from face images to a compact\\nEuclidean space where distances directly correspond to a measure of face\\nsimilarity. Once this space has been produced, tasks such as face recognition,\\nverification and clustering can be easily implemented using standard techniques\\nwith FaceNet embeddings as feature vectors.\\nOur method uses a deep convolutional network trained to directly optimize the\\nembedding itself, rather than an intermediate bottleneck layer as in previous\\ndeep learning approaches. To train, we use triplets of roughly aligned matching\\n/ non-matching face patches generated using a novel online triplet mining\\nmethod. The benefit of our approach is much greater representational\\nefficiency: we achieve state-of-the-art face recognition performance using only\\n128-bytes per face.\\nOn the widely used Labeled Faces in the Wild (LFW) dataset, our system\\nachieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves\\n95.12%. Our system cuts the error rate in comparison to the best published\\nresult by 30% on both datasets.\\nWe also introduce the concept of harmonic embeddings, and a harmonic triplet\\nloss, which describe different versions of face embeddings (produced by\\ndifferent networks) that are compatible to each other and allow for direct\\ncomparison between each other.\\n\\n    ', '\\nAbstract:  In this work, we address the problem of musical timbre transfer, where the\\ngoal is to manipulate the timbre of a sound sample from one instrument to match\\nanother instrument while preserving other musical content, such as pitch,\\nrhythm, and loudness. In principle, one could apply image-based style transfer\\ntechniques to a time-frequency representation of an audio signal, but this\\ndepends on having a representation that allows independent manipulation of\\ntimbre as well as high-quality waveform generation. We introduce TimbreTron, a\\nmethod for musical timbre transfer which applies \"image\" domain style transfer\\nto a time-frequency representation of the audio signal, and then produces a\\nhigh-quality waveform using a conditional WaveNet synthesizer. We show that the\\nConstant Q Transform (CQT) representation is particularly well-suited to\\nconvolutional architectures due to its approximate pitch equivariance. Based on\\nhuman perceptual evaluations, we confirmed that TimbreTron recognizably\\ntransferred the timbre while otherwise preserving the musical content, for both\\nmonophonic and polyphonic samples.\\n\\n    ', \"\\nAbstract:  Training modern deep learning models requires large amounts of computation,\\noften provided by GPUs. Scaling computation from one GPU to many can enable\\nmuch faster training and research progress but entails two complications.\\nFirst, the training library must support inter-GPU communication. Depending on\\nthe particular methods employed, this communication may entail anywhere from\\nnegligible to significant overhead. Second, the user must modify his or her\\ntraining code to take advantage of inter-GPU communication. Depending on the\\ntraining library's API, the modification required may be either significant or\\nminimal.\\nExisting methods for enabling multi-GPU training under the TensorFlow library\\nentail non-negligible communication overhead and require users to heavily\\nmodify their model-building code, leading many researchers to avoid the whole\\nmess and stick with slower single-GPU training. In this paper we introduce\\nHorovod, an open source library that improves on both obstructions to scaling:\\nit employs efficient inter-GPU communication via ring reduction and requires\\nonly a few lines of modification to user code, enabling faster, easier\\ndistributed training in TensorFlow. Horovod is available under the Apache 2.0\\nlicense at this https URL\\n\", \"\\nAbstract:  Consider learning a policy from example expert behavior, without interaction\\nwith the expert or access to reinforcement signal. One approach is to recover\\nthe expert's cost function with inverse reinforcement learning, then extract a\\npolicy from that cost function with reinforcement learning. This approach is\\nindirect and can be slow. We propose a new general framework for directly\\nextracting a policy from data, as if it were obtained by reinforcement learning\\nfollowing inverse reinforcement learning. We show that a certain instantiation\\nof our framework draws an analogy between imitation learning and generative\\nadversarial networks, from which we derive a model-free imitation learning\\nalgorithm that obtains significant performance gains over existing model-free\\nmethods in imitating complex behaviors in large, high-dimensional environments.\\n\\n    \", '\\nAbstract:  We propose an alternative generator architecture for generative adversarial\\nnetworks, borrowing from style transfer literature. The new architecture leads\\nto an automatically learned, unsupervised separation of high-level attributes\\n(e.g., pose and identity when trained on human faces) and stochastic variation\\nin the generated images (e.g., freckles, hair), and it enables intuitive,\\nscale-specific control of the synthesis. The new generator improves the\\nstate-of-the-art in terms of traditional distribution quality metrics, leads to\\ndemonstrably better interpolation properties, and also better disentangles the\\nlatent factors of variation. To quantify interpolation quality and\\ndisentanglement, we propose two new, automated methods that are applicable to\\nany generator architecture. Finally, we introduce a new, highly varied and\\nhigh-quality dataset of human faces.\\n\\n    ', '\\nAbstract:  We present a method for detecting objects in images using a single deep\\nneural network. Our approach, named SSD, discretizes the output space of\\nbounding boxes into a set of default boxes over different aspect ratios and\\nscales per feature map location. At prediction time, the network generates\\nscores for the presence of each object category in each default box and\\nproduces adjustments to the box to better match the object shape. Additionally,\\nthe network combines predictions from multiple feature maps with different\\nresolutions to naturally handle objects of various sizes. Our SSD model is\\nsimple relative to methods that require object proposals because it completely\\neliminates proposal generation and subsequent pixel or feature resampling stage\\nand encapsulates all computation in a single network. This makes SSD easy to\\ntrain and straightforward to integrate into systems that require a detection\\ncomponent. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets\\nconfirm that SSD has comparable accuracy to methods that utilize an additional\\nobject proposal step and is much faster, while providing a unified framework\\nfor both training and inference. Compared to other single stage methods, SSD\\nhas much better accuracy, even with a smaller input image size. For $300\\\\times\\n300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan\\nX and for $500\\\\times 500$ input, SSD achieves 75.1% mAP, outperforming a\\ncomparable state of the art Faster R-CNN model. Code is available at\\nthis https URL .\\n\\n    ', '\\nAbstract:  Deep learning thrives with large neural networks and large datasets. However,\\nlarger networks and larger datasets result in longer training times that impede\\nresearch and development progress. Distributed synchronous SGD offers a\\npotential solution to this problem by dividing SGD minibatches over a pool of\\nparallel workers. Yet to make this scheme efficient, the per-worker workload\\nmust be large, which implies nontrivial growth in the SGD minibatch size. In\\nthis paper, we empirically show that on the ImageNet dataset large minibatches\\ncause optimization difficulties, but when these are addressed the trained\\nnetworks exhibit good generalization. Specifically, we show no loss of accuracy\\nwhen training with large minibatch sizes up to 8192 images. To achieve this\\nresult, we adopt a hyper-parameter-free linear scaling rule for adjusting\\nlearning rates as a function of minibatch size and develop a new warmup scheme\\nthat overcomes optimization challenges early in training. With these simple\\ntechniques, our Caffe2-based system trains ResNet-50 with a minibatch size of\\n8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using\\ncommodity hardware, our implementation achieves ~90% scaling efficiency when\\nmoving from 8 to 256 GPUs. Our findings enable training visual recognition\\nmodels on internet-scale data with high efficiency.\\n\\n    ', '\\nAbstract:  Batch Normalization (BatchNorm) is a widely adopted technique that enables\\nfaster and more stable training of deep neural networks (DNNs). Despite its\\npervasiveness, the exact reasons for BatchNorm\\'s effectiveness are still poorly\\nunderstood. The popular belief is that this effectiveness stems from\\ncontrolling the change of the layers\\' input distributions during training to\\nreduce the so-called \"internal covariate shift\". In this work, we demonstrate\\nthat such distributional stability of layer inputs has little to do with the\\nsuccess of BatchNorm. Instead, we uncover a more fundamental impact of\\nBatchNorm on the training process: it makes the optimization landscape\\nsignificantly smoother. This smoothness induces a more predictive and stable\\nbehavior of the gradients, allowing for faster training.\\n\\n    ', '\\nAbstract:  Conditional GANs are at the forefront of natural image synthesis. The main\\ndrawback of such models is the necessity for labeled data. In this work we\\nexploit two popular unsupervised learning techniques, adversarial training and\\nself-supervision, and take a step towards bridging the gap between conditional\\nand unconditional GANs. In particular, we allow the networks to collaborate on\\nthe task of representation learning, while being adversarial with respect to\\nthe classic GAN game. The role of self-supervision is to encourage the\\ndiscriminator to learn meaningful feature representations which are not\\nforgotten during training. We test empirically both the quality of the learned\\nimage representations, and the quality of the synthesized images. Under the\\nsame conditions, the self-supervised GAN attains a similar performance to\\nstate-of-the-art conditional counterparts. Finally, we show that this approach\\nto fully unsupervised learning can be scaled to attain an FID of 23.4 on\\nunconditional ImageNet generation.\\n\\n    ', \"\\nAbstract:  The problem of arbitrary object tracking has traditionally been tackled by\\nlearning a model of the object's appearance exclusively online, using as sole\\ntraining data the video itself. Despite the success of these methods, their\\nonline-only approach inherently limits the richness of the model they can\\nlearn. Recently, several attempts have been made to exploit the expressive\\npower of deep convolutional networks. However, when the object to track is not\\nknown beforehand, it is necessary to perform Stochastic Gradient Descent online\\nto adapt the weights of the network, severely compromising the speed of the\\nsystem. In this paper we equip a basic tracking algorithm with a novel\\nfully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset\\nfor object detection in video. Our tracker operates at frame-rates beyond\\nreal-time and, despite its extreme simplicity, achieves state-of-the-art\\nperformance in multiple benchmarks.\\n\\n    \", '\\nAbstract:  Training set bugs are flaws in the data that adversely affect machine\\nlearning. The training set is usually too large for man- ual inspection, but\\none may have the resources to verify a few trusted items. The set of trusted\\nitems may not by itself be adequate for learning, so we propose an algorithm\\nthat uses these items to identify bugs in the training set and thus im- proves\\nlearning. Specifically, our approach seeks the smallest set of changes to the\\ntraining set labels such that the model learned from this corrected training\\nset predicts labels of the trusted items correctly. We flag the items whose\\nlabels are changed as potential bugs, whose labels can be checked for veracity\\nby human experts. To find the bugs in this way is a challenging combinatorial\\nbilevel optimization problem, but it can be relaxed into a continuous\\noptimization problem. Ex- periments on toy and real data demonstrate that our\\napproach can identify training set bugs effectively and suggest appro- priate\\nchanges to the labels. Our algorithm is a step toward trustworthy machine\\nlearning.\\n\\n    ', '\\nAbstract:  Recently, Neural Architecture Search (NAS) has successfully identified neural\\nnetwork architectures that exceed human designed ones on large-scale image\\nclassification. In this paper, we study NAS for semantic image segmentation.\\nExisting works often focus on searching the repeatable cell structure, while\\nhand-designing the outer network structure that controls the spatial resolution\\nchanges. This choice simplifies the search space, but becomes increasingly\\nproblematic for dense image prediction which exhibits a lot more network level\\narchitectural variations. Therefore, we propose to search the network level\\nstructure in addition to the cell level structure, which forms a hierarchical\\narchitecture search space. We present a network level search space that\\nincludes many popular designs, and develop a formulation that allows efficient\\ngradient-based architecture search (3 P100 GPU days on Cityscapes images). We\\ndemonstrate the effectiveness of the proposed method on the challenging\\nCityscapes, PASCAL VOC 2012, and ADE20K datasets. Auto-DeepLab, our\\narchitecture searched specifically for semantic image segmentation, attains\\nstate-of-the-art performance without any ImageNet pretraining.\\n\\n    ', '\\nAbstract:  We introduce a new algorithm named WGAN, an alternative to traditional GAN\\ntraining. In this new model, we show that we can improve the stability of\\nlearning, get rid of problems like mode collapse, and provide meaningful\\nlearning curves useful for debugging and hyperparameter searches. Furthermore,\\nwe show that the corresponding optimization problem is sound, and provide\\nextensive theoretical work highlighting the deep connections to other distances\\nbetween distributions.\\n\\n    ', \"\\nAbstract:  Convolutions are a fundamental building block of modern computer vision\\nsystems. Recent approaches have argued for going beyond convolutions in order\\nto capture long-range dependencies. These efforts focus on augmenting\\nconvolutional models with content-based interactions, such as self-attention\\nand non-local means, to achieve gains on a number of vision tasks. The natural\\nquestion that arises is whether attention can be a stand-alone primitive for\\nvision models instead of serving as just an augmentation on top of\\nconvolutions. In developing and testing a pure self-attention vision model, we\\nverify that self-attention can indeed be an effective stand-alone layer. A\\nsimple procedure of replacing all instances of spatial convolutions with a form\\nof self-attention applied to ResNet model produces a fully self-attentional\\nmodel that outperforms the baseline on ImageNet classification with 12% fewer\\nFLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention\\nmodel matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and\\n34% fewer parameters. Detailed ablation studies demonstrate that self-attention\\nis especially impactful when used in later layers. These results establish that\\nstand-alone self-attention is an important addition to the vision\\npractitioner's toolbox.\\n\\n    \", \"\\nAbstract:  A generative recurrent neural network is quickly trained in an unsupervised\\nmanner to model popular reinforcement learning environments through compressed\\nspatio-temporal representations. The world model's extracted features are fed\\ninto compact and simple policies trained by evolution, achieving state of the\\nart results in various environments. We also train our agent entirely inside of\\nan environment generated by its own internal world model, and transfer this\\npolicy back into the actual environment. Interactive version of paper at\\nthis https URL\\n\", \"\\nAbstract:  One of the main barriers for deploying neural networks on embedded systems\\nhas been large memory and power consumption of existing neural networks. In\\nthis work, we introduce SqueezeNext, a new family of neural network\\narchitectures whose design was guided by considering previous architectures\\nsuch as SqueezeNet, as well as by simulation results on a neural network\\naccelerator. This new network is able to match AlexNet's accuracy on the\\nImageNet benchmark with $112\\\\times$ fewer parameters, and one of its deeper\\nvariants is able to achieve VGG-19 accuracy with only 4.4 Million parameters,\\n($31\\\\times$ smaller than VGG-19). SqueezeNext also achieves better top-5\\nclassification accuracy with $1.3\\\\times$ fewer parameters as compared to\\nMobileNet, but avoids using depthwise-separable convolutions that are\\ninefficient on some mobile processor platforms. This wide range of accuracy\\ngives the user the ability to make speed-accuracy tradeoffs, depending on the\\navailable resources on the target hardware. Using hardware simulation results\\nfor power and inference speed on an embedded system has guided us to design\\nvariations of the baseline model that are $2.59\\\\times$/$8.26\\\\times$ faster and\\n$2.25\\\\times$/$7.5\\\\times$ more energy efficient as compared to\\nSqueezeNet/AlexNet without any accuracy degradation.\\n\\n    \", '\\nAbstract:  This paper proposes a method for learning joint embeddings of images and text\\nusing a two-branch neural network with multiple layers of linear projections\\nfollowed by nonlinearities. The network is trained using a large margin\\nobjective that combines cross-view ranking constraints with within-view\\nneighborhood structure preservation constraints inspired by metric learning\\nliterature. Extensive experiments show that our approach gains significant\\nimprovements in accuracy for image-to-text and text-to-image retrieval. Our\\nmethod achieves new state-of-the-art results on the Flickr30K and MSCOCO\\nimage-sentence datasets and shows promise on the new task of phrase\\nlocalization on the Flickr30K Entities dataset.\\n\\n    ', '\\nAbstract:  We consider the problem of anomaly detection in images, and present a new\\ndetection technique. Given a sample of images, all known to belong to a\\n\"normal\" class (e.g., dogs), we show how to train a deep neural model that can\\ndetect out-of-distribution images (i.e., non-dog objects). The main idea behind\\nour scheme is to train a multi-class model to discriminate between dozens of\\ngeometric transformations applied on all the given images. The auxiliary\\nexpertise learned by the model generates feature detectors that effectively\\nidentify, at test time, anomalous images based on the softmax activation\\nstatistics of the model when applied on transformed images. We present\\nextensive experiments using the proposed detector, which indicate that our\\nalgorithm improves state-of-the-art methods by a wide margin.\\n\\n    ', '\\nAbstract:  We consider image transformation problems, where an input image is\\ntransformed into an output image. Recent methods for such problems typically\\ntrain feed-forward convolutional neural networks using a \\\\emph{per-pixel} loss\\nbetween the output and ground-truth images. Parallel work has shown that\\nhigh-quality images can be generated by defining and optimizing\\n\\\\emph{perceptual} loss functions based on high-level features extracted from\\npretrained networks. We combine the benefits of both approaches, and propose\\nthe use of perceptual loss functions for training feed-forward networks for\\nimage transformation tasks. We show results on image style transfer, where a\\nfeed-forward network is trained to solve the optimization problem proposed by\\nGatys et al in real-time. Compared to the optimization-based method, our\\nnetwork gives similar qualitative results but is three orders of magnitude\\nfaster. We also experiment with single-image super-resolution, where replacing\\na per-pixel loss with a perceptual loss gives visually pleasing results.\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks (CNNs) are commonly thought to recognise\\nobjects by learning increasingly complex representations of object shapes. Some\\nrecent studies suggest a more important role of image textures. We here put\\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\\nhuman observers on images with a texture-shape cue conflict. We show that\\nImageNet-trained CNNs are strongly biased towards recognising textures rather\\nthan shapes, which is in stark contrast to human behavioural evidence and\\nreveals fundamentally different classification strategies. We then demonstrate\\nthat the same standard architecture (ResNet-50) that learns a texture-based\\nrepresentation on ImageNet is able to learn a shape-based representation\\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\\nThis provides a much better fit for human behavioural performance in our\\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\\npsychophysical trials across 97 observers) and comes with a number of\\nunexpected emergent benefits such as improved object detection performance and\\npreviously unseen robustness towards a wide range of image distortions,\\nhighlighting advantages of a shape-based representation.\\n\\n    ', '\\nAbstract:  While it is nearly effortless for humans to quickly assess the perceptual\\nsimilarity between two images, the underlying processes are thought to be quite\\ncomplex. Despite this, the most widely used perceptual metrics today, such as\\nPSNR and SSIM, are simple, shallow functions, and fail to account for many\\nnuances of human perception. Recently, the deep learning community has found\\nthat features of the VGG network trained on ImageNet classification has been\\nremarkably useful as a training loss for image synthesis. But how perceptual\\nare these so-called \"perceptual losses\"? What elements are critical for their\\nsuccess? To answer these questions, we introduce a new dataset of human\\nperceptual similarity judgments. We systematically evaluate deep features\\nacross different architectures and tasks and compare them with classic metrics.\\nWe find that deep features outperform all previous metrics by large margins on\\nour dataset. More surprisingly, this result is not restricted to\\nImageNet-trained VGG features, but holds across different deep architectures\\nand levels of supervision (supervised, self-supervised, or even unsupervised).\\nOur results suggest that perceptual similarity is an emergent property shared\\nacross deep visual representations.\\n\\n    ', \"\\nAbstract:  Recent studies have shown remarkable success in image-to-image translation\\nfor two domains. However, existing approaches have limited scalability and\\nrobustness in handling more than two domains, since different models should be\\nbuilt independently for every pair of image domains. To address this\\nlimitation, we propose StarGAN, a novel and scalable approach that can perform\\nimage-to-image translations for multiple domains using only a single model.\\nSuch a unified model architecture of StarGAN allows simultaneous training of\\nmultiple datasets with different domains within a single network. This leads to\\nStarGAN's superior quality of translated images compared to existing models as\\nwell as the novel capability of flexibly translating an input image to any\\ndesired target domain. We empirically demonstrate the effectiveness of our\\napproach on a facial attribute transfer and a facial expression synthesis\\ntasks.\\n\\n    \", '\\nAbstract:  Deep neural networks excel in regimes with large amounts of data, but tend to\\nstruggle when data is scarce or when they need to adapt quickly to changes in\\nthe task. In response, recent work in meta-learning proposes training a\\nmeta-learner on a distribution of similar tasks, in the hopes of generalization\\nto novel but related tasks by learning a high-level strategy that captures the\\nessence of the problem it is asked to solve. However, many recent meta-learning\\napproaches are extensively hand-designed, either using architectures\\nspecialized to a particular application, or hard-coding algorithmic components\\nthat constrain how the meta-learner solves the task. We propose a class of\\nsimple and generic meta-learner architectures that use a novel combination of\\ntemporal convolutions and soft attention; the former to aggregate information\\nfrom past experience and the latter to pinpoint specific pieces of information.\\nIn the most extensive set of meta-learning experiments to date, we evaluate the\\nresulting Simple Neural AttentIve Learner (or SNAIL) on several\\nheavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\\nlearning, SNAIL attains state-of-the-art performance by significant margins.\\n\\n    ', \"\\nAbstract:  We propose spatially-adaptive normalization, a simple but effective layer for\\nsynthesizing photorealistic images given an input semantic layout. Previous\\nmethods directly feed the semantic layout as input to the deep network, which\\nis then processed through stacks of convolution, normalization, and\\nnonlinearity layers. We show that this is suboptimal as the normalization\\nlayers tend to ``wash away'' semantic information. To address the issue, we\\npropose using the input layout for modulating the activations in normalization\\nlayers through a spatially-adaptive, learned transformation. Experiments on\\nseveral challenging datasets demonstrate the advantage of the proposed method\\nover existing approaches, regarding both visual fidelity and alignment with\\ninput layouts. Finally, our model allows user control over both semantic and\\nstyle. Code is available at this https URL .\\n\\n    \", '\\nAbstract:  Neural networks for image recognition have evolved through extensive manual\\ndesign from simple chain-like models to structures with multiple wiring paths.\\nThe success of ResNets and DenseNets is due in large part to their innovative\\nwiring plans. Now, neural architecture search (NAS) studies are exploring the\\njoint optimization of wiring and operation types, however, the space of\\npossible wirings is constrained and still driven by manual design despite being\\nsearched. In this paper, we explore a more diverse set of connectivity patterns\\nthrough the lens of randomly wired neural networks. To do this, we first define\\nthe concept of a stochastic network generator that encapsulates the entire\\nnetwork generation process. Encapsulation provides a unified view of NAS and\\nrandomly wired networks. Then, we use three classical random graph models to\\ngenerate randomly wired graphs for networks. The results are surprising:\\nseveral variants of these random generators yield network instances that have\\ncompetitive accuracy on the ImageNet benchmark. These results suggest that new\\nefforts focusing on designing better network generators may lead to new\\nbreakthroughs by exploring less constrained search spaces with more room for\\nnovel design.\\n\\n    ', 'It is pdf', '\\nAbstract:  Incidental scene text spotting is considered one of the most difficult and\\nvaluable challenges in the document analysis community. Most existing methods\\ntreat text detection and recognition as separate tasks. In this work, we\\npropose a unified end-to-end trainable Fast Oriented Text Spotting (FOTS)\\nnetwork for simultaneous detection and recognition, sharing computation and\\nvisual information among the two complementary tasks. Specially, RoIRotate is\\nintroduced to share convolutional features between detection and recognition.\\nBenefiting from convolution sharing strategy, our FOTS has little computation\\noverhead compared to baseline text detection network, and the joint training\\nmethod learns more generic features to make our method perform better than\\nthese two-stage methods. Experiments on ICDAR 2015, ICDAR 2017 MLT, and ICDAR\\n2013 datasets demonstrate that the proposed method outperforms state-of-the-art\\nmethods significantly, which further allows us to develop the first real-time\\noriented text spotting system which surpasses all previous state-of-the-art\\nresults by more than 5% on ICDAR 2015 text spotting task while keeping 22.6\\nfps.\\n\\n    ', '\\nAbstract:  This paper presents a novel unsupervised domain adaptation framework, called\\nSynergistic Image and Feature Adaptation (SIFA), to effectively tackle the\\nproblem of domain shift. Domain adaptation has become an important and hot\\ntopic in recent studies on deep learning, aiming to recover performance\\ndegradation when applying the neural networks to new testing domains. Our\\nproposed SIFA is an elegant learning diagram which presents synergistic fusion\\nof adaptations from both image and feature perspectives. In particular, we\\nsimultaneously transform the appearance of images across domains and enhance\\ndomain-invariance of the extracted features towards the segmentation task. The\\nfeature encoder layers are shared by both perspectives to grasp their mutual\\nbenefits during the end-to-end learning procedure. Without using any annotation\\nfrom the target domain, the learning of our unified model is guided by\\nadversarial losses, with multiple discriminators employed from various aspects.\\nWe have extensively validated our method with a challenging application of\\ncross-modality medical image segmentation of cardiac structures. Experimental\\nresults demonstrate that our SIFA model recovers the degraded performance from\\n17.2% to 73.0%, and outperforms the state-of-the-art methods by a significant\\nmargin.\\n\\n    ', '\\nAbstract:  Modern deep transfer learning approaches have mainly focused on learning\\ngeneric feature vectors from one task that are transferable to other tasks,\\nsuch as word embeddings in language and pretrained convolutional features in\\nvision. However, these approaches usually transfer unary features and largely\\nignore more structured graphical representations. This work explores the\\npossibility of learning generic latent relational graphs that capture\\ndependencies between pairs of data units (e.g., words or pixels) from\\nlarge-scale unlabeled data and transferring the graphs to downstream tasks. Our\\nproposed transfer learning framework improves performance on various tasks\\nincluding question answering, natural language inference, sentiment analysis,\\nand image classification. We also show that the learned graphs are generic\\nenough to be transferred to different embeddings on which the graphs have not\\nbeen trained (including GloVe embeddings, ELMo embeddings, and task-specific\\nRNN hidden unit), or embedding-free units such as image pixels.\\n\\n    ', '\\nAbstract:  Transformers have a potential of learning longer-term dependency, but are\\nlimited by a fixed-length context in the setting of language modeling. We\\npropose a novel neural architecture Transformer-XL that enables learning\\ndependency beyond a fixed length without disrupting temporal coherence. It\\nconsists of a segment-level recurrence mechanism and a novel positional\\nencoding scheme. Our method not only enables capturing longer-term dependency,\\nbut also resolves the context fragmentation problem. As a result,\\nTransformer-XL learns dependency that is 80% longer than RNNs and 450% longer\\nthan vanilla Transformers, achieves better performance on both short and long\\nsequences, and is up to 1,800+ times faster than vanilla Transformers during\\nevaluation. Notably, we improve the state-of-the-art results of bpc/perplexity\\nto 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion\\nWord, and 54.5 on Penn Treebank (without finetuning). When trained only on\\nWikiText-103, Transformer-XL manages to generate reasonably coherent, novel\\ntext articles with thousands of tokens. Our code, pretrained models, and\\nhyperparameters are available in both Tensorflow and PyTorch.\\n\\n    ', '\\nAbstract:  We present a principled approach to uncover the structure of visual data by\\nsolving a novel deep learning task coined visual permutation learning. The goal\\nof this task is to find the permutation that recovers the structure of data\\nfrom shuffled versions of it. In the case of natural images, this task boils\\ndown to recovering the original image from patches shuffled by an unknown\\npermutation matrix. Unfortunately, permutation matrices are discrete, thereby\\nposing difficulties for gradient-based methods. To this end, we resort to a\\ncontinuous approximation of these matrices using doubly-stochastic matrices\\nwhich we generate from standard CNN predictions using Sinkhorn iterations.\\nUnrolling these iterations in a Sinkhorn network layer, we propose DeepPermNet,\\nan end-to-end CNN model for this task. The utility of DeepPermNet is\\ndemonstrated on two challenging computer vision problems, namely, (i) relative\\nattributes learning and (ii) self-supervised representation learning. Our\\nresults show state-of-the-art performance on the Public Figures and OSR\\nbenchmarks for (i) and on the classification and segmentation tasks on the\\nPASCAL VOC dataset for (ii).\\n\\n    ', '\\nAbstract:  A key advance in learning generative models is the use of amortized inference\\ndistributions that are jointly trained with the models. We find that existing\\ntraining objectives for variational autoencoders can lead to inaccurate\\namortized inference distributions and, in some cases, improving the objective\\nprovably degrades the inference quality. In addition, it has been observed that\\nvariational autoencoders tend to ignore the latent variables when combined with\\na decoding distribution that is too flexible. We again identify the cause in\\nexisting training criteria and propose a new class of objectives (InfoVAE) that\\nmitigate these problems. We show that our model can significantly improve the\\nquality of the variational posterior and can make effective use of the latent\\nfeatures regardless of the flexibility of the decoding distribution. Through\\nextensive qualitative and quantitative analyses, we demonstrate that our models\\noutperform competing approaches on multiple performance metrics.\\n\\n    ', '\\nAbstract:  Several recent works have shown how highly realistic human head images can be\\nobtained by training convolutional neural networks to generate them. In order\\nto create a personalized talking head model, these works require training on a\\nlarge dataset of images of a single person. However, in many practical\\nscenarios, such personalized talking head models need to be learned from a few\\nimage views of a person, potentially even a single image. Here, we present a\\nsystem with such few-shot capability. It performs lengthy meta-learning on a\\nlarge dataset of videos, and after that is able to frame few- and one-shot\\nlearning of neural talking head models of previously unseen people as\\nadversarial training problems with high capacity generators and discriminators.\\nCrucially, the system is able to initialize the parameters of both the\\ngenerator and the discriminator in a person-specific way, so that training can\\nbe based on just a few images and done quickly, despite the need to tune tens\\nof millions of parameters. We show that such an approach is able to learn\\nhighly realistic and personalized talking head models of new people and even\\nportrait paintings.\\n\\n    ', '\\nAbstract:  The interpretation of deep learning models is a challenge due to their size,\\ncomplexity, and often opaque internal state. In addition, many systems, such as\\nimage classifiers, operate on low-level features rather than high-level\\nconcepts. To address these challenges, we introduce Concept Activation Vectors\\n(CAVs), which provide an interpretation of a neural net\\'s internal state in\\nterms of human-friendly concepts. The key idea is to view the high-dimensional\\ninternal state of a neural net as an aid, not an obstacle. We show how to use\\nCAVs as part of a technique, Testing with CAVs (TCAV), that uses directional\\nderivatives to quantify the degree to which a user-defined concept is important\\nto a classification result--for example, how sensitive a prediction of \"zebra\"\\nis to the presence of stripes. Using the domain of image classification as a\\ntesting ground, we describe how CAVs may be used to explore hypotheses and\\ngenerate insights for a standard image classification network as well as a\\nmedical application.\\n\\n    ', '\\nAbstract:  Unsupervised image-to-image translation methods learn to map images in a\\ngiven class to an analogous image in a different class, drawing on unstructured\\n(non-registered) datasets of images. While remarkably successful, current\\nmethods require access to many images in both source and destination classes at\\ntraining time. We argue this greatly limits their use. Drawing inspiration from\\nthe human capability of picking up the essence of a novel object from a small\\nnumber of examples and generalizing from there, we seek a few-shot,\\nunsupervised image-to-image translation algorithm that works on previously\\nunseen target classes that are specified, at test time, only by a few example\\nimages. Our model achieves this few-shot generation capability by coupling an\\nadversarial training scheme with a novel network design. Through extensive\\nexperimental validation and comparisons to several baseline methods on\\nbenchmark datasets, we verify the effectiveness of the proposed framework. Our\\nimplementation and datasets are available at this https URL .\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks (ConvNets) are commonly developed at a fixed\\nresource budget, and then scaled up for better accuracy if more resources are\\navailable. In this paper, we systematically study model scaling and identify\\nthat carefully balancing network depth, width, and resolution can lead to\\nbetter performance. Based on this observation, we propose a new scaling method\\nthat uniformly scales all dimensions of depth/width/resolution using a simple\\nyet highly effective compound coefficient. We demonstrate the effectiveness of\\nthis method on scaling up MobileNets and ResNet.\\nTo go even further, we use neural architecture search to design a new\\nbaseline network and scale it up to obtain a family of models, called\\nEfficientNets, which achieve much better accuracy and efficiency than previous\\nConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4%\\ntop-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x\\nfaster on inference than the best existing ConvNet. Our EfficientNets also\\ntransfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%),\\nFlowers (98.8%), and 3 other transfer learning datasets, with an order of\\nmagnitude fewer parameters. Source code is at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Cross-entropy loss together with softmax is arguably one of the most common\\nused supervision components in convolutional neural networks (CNNs). Despite\\nits simplicity, popularity and excellent performance, the component does not\\nexplicitly encourage discriminative learning of features. In this paper, we\\npropose a generalized large-margin softmax (L-Softmax) loss which explicitly\\nencourages intra-class compactness and inter-class separability between learned\\nfeatures. Moreover, L-Softmax not only can adjust the desired margin but also\\ncan avoid overfitting. We also show that the L-Softmax loss can be optimized by\\ntypical stochastic gradient descent. Extensive experiments on four benchmark\\ndatasets demonstrate that the deeply-learned features with L-softmax loss\\nbecome more discriminative, hence significantly boosting the performance on a\\nvariety of visual classification and verification tasks.\\n\\n    ', '\\nAbstract:  Intersection over Union (IoU) is the most popular evaluation metric used in\\nthe object detection benchmarks. However, there is a gap between optimizing the\\ncommonly used distance losses for regressing the parameters of a bounding box\\nand maximizing this metric value. The optimal objective for a metric is the\\nmetric itself. In the case of axis-aligned 2D bounding boxes, it can be shown\\nthat $IoU$ can be directly used as a regression loss. However, $IoU$ has a\\nplateau making it infeasible to optimize in the case of non-overlapping\\nbounding boxes. In this paper, we address the weaknesses of $IoU$ by\\nintroducing a generalized version as both a new loss and a new metric. By\\nincorporating this generalized $IoU$ ($GIoU$) as a loss into the state-of-the\\nart object detection frameworks, we show a consistent improvement on their\\nperformance using both the standard, $IoU$ based, and new, $GIoU$ based,\\nperformance measures on popular object detection benchmarks such as PASCAL VOC\\nand MS COCO.\\n\\n    ', '\\nAbstract:  We report a method to convert discrete representations of molecules to and\\nfrom a multidimensional continuous representation. This model allows us to\\ngenerate new molecules for efficient exploration and optimization through\\nopen-ended spaces of chemical compounds. A deep neural network was trained on\\nhundreds of thousands of existing chemical structures to construct three\\ncoupled functions: an encoder, a decoder and a predictor. The encoder converts\\nthe discrete representation of a molecule into a real-valued continuous vector,\\nand the decoder converts these continuous vectors back to discrete molecular\\nrepresentations. The predictor estimates chemical properties from the latent\\ncontinuous vector representation of the molecule. Continuous representations\\nallow us to automatically generate novel chemical structures by performing\\nsimple operations in the latent space, such as decoding random vectors,\\nperturbing known chemical structures, or interpolating between molecules.\\nContinuous representations also allow the use of powerful gradient-based\\noptimization to efficiently guide the search for optimized functional\\ncompounds. We demonstrate our method in the domain of drug-like molecules and\\nalso in the set of molecules with fewer that nine heavy atoms.\\n\\n    ', '\\nAbstract:  With the capability of modeling bidirectional contexts, denoising\\nautoencoding based pretraining like BERT achieves better performance than\\npretraining approaches based on autoregressive language modeling. However,\\nrelying on corrupting the input with masks, BERT neglects dependency between\\nthe masked positions and suffers from a pretrain-finetune discrepancy. In light\\nof these pros and cons, we propose XLNet, a generalized autoregressive\\npretraining method that (1) enables learning bidirectional contexts by\\nmaximizing the expected likelihood over all permutations of the factorization\\norder and (2) overcomes the limitations of BERT thanks to its autoregressive\\nformulation. Furthermore, XLNet integrates ideas from Transformer-XL, the\\nstate-of-the-art autoregressive model, into pretraining. Empirically, under\\ncomparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a\\nlarge margin, including question answering, natural language inference,\\nsentiment analysis, and document ranking.\\n\\n    ', '\\nAbstract:  This paper proposes a CS scheme that exploits the representational power of\\nrestricted Boltzmann machines and deep learning architectures to model the\\nprior distribution of the sparsity pattern of signals belonging to the same\\nclass. The determined probability distribution is then used in a maximum a\\nposteriori (MAP) approach for the reconstruction. The parameters of the prior\\ndistribution are learned from training data. The motivation behind this\\napproach is to model the higher-order statistical dependencies between the\\ncoefficients of the sparse representation, with the final goal of improving the\\nreconstruction. The performance of the proposed method is validated on the\\nBerkeley Segmentation Dataset and the MNIST Database of handwritten digits.\\n\\n    ', '\\nAbstract:  Feature pyramids are widely exploited by both the state-of-the-art one-stage\\nobject detectors (e.g., DSSD, RetinaNet, RefineDet) and the two-stage object\\ndetectors (e.g., Mask R-CNN, DetNet) to alleviate the problem arising from\\nscale variation across object instances. Although these object detectors with\\nfeature pyramids achieve encouraging results, they have some limitations due to\\nthat they only simply construct the feature pyramid according to the inherent\\nmulti-scale, pyramidal architecture of the backbones which are actually\\ndesigned for object classification task. Newly, in this work, we present a\\nmethod called Multi-Level Feature Pyramid Network (MLFPN) to construct more\\neffective feature pyramids for detecting objects of different scales. First, we\\nfuse multi-level features (i.e. multiple layers) extracted by backbone as the\\nbase feature. Second, we feed the base feature into a block of alternating\\njoint Thinned U-shape Modules and Feature Fusion Modules and exploit the\\ndecoder layers of each u-shape module as the features for detecting objects.\\nFinally, we gather up the decoder layers with equivalent scales (sizes) to\\ndevelop a feature pyramid for object detection, in which every feature map\\nconsists of the layers (features) from multiple levels. To evaluate the\\neffectiveness of the proposed MLFPN, we design and train a powerful end-to-end\\none-stage object detector we call M2Det by integrating it into the architecture\\nof SSD, which gets better detection performance than state-of-the-art one-stage\\ndetectors. Specifically, on MS-COCO benchmark, M2Det achieves AP of 41.0 at\\nspeed of 11.8 FPS with single-scale inference strategy and AP of 44.2 with\\nmulti-scale inference strategy, which is the new state-of-the-art results among\\none-stage detectors. The code will be made available on\\n\\\\url{this https URL.\\n\\n    ', '\\nAbstract:  Region-based object detection infers object regions for one or more\\ncategories in an image. Due to the recent advances in deep learning and region\\nproposal methods, object detectors based on convolutional neural networks\\n(CNNs) have been flourishing and provided the promising detection results.\\nHowever, the detection accuracy is degraded often because of the low\\ndiscriminability of object CNN features caused by occlusions and inaccurate\\nregion proposals. In this paper, we therefore propose a region decomposition\\nand assembly detector (R-DAD) for more accurate object detection.\\nIn the proposed R-DAD, we first decompose an object region into multiple\\nsmall regions. To capture an entire appearance and part details of the object\\njointly, we extract CNN features within the whole object region and decomposed\\nregions. We then learn the semantic relations between the object and its parts\\nby combining the multi-region features stage by stage with region assembly\\nblocks, and use the combined and high-level semantic features for the object\\nclassification and localization. In addition, for more accurate region\\nproposals, we propose a multi-scale proposal layer that can generate object\\nproposals of various scales. We integrate the R-DAD into several feature\\nextractors, and prove the distinct performance improvement on PASCAL07/12 and\\nMSCOCO18 compared to the recent convolutional detectors.\\n\\n    ', 'It is pdf', '\\nAbstract:  A well-trained model should classify objects with a unanimous score for every\\ncategory. This requires the high-level semantic features should be as much\\nalike as possible among samples. To achive this, previous works focus on\\nre-designing the loss or proposing new regularization constraints. In this\\npaper, we provide a new perspective. For each category, it is assumed that\\nthere are two feature sets: one with reliable information and the other with\\nless reliable source. We argue that the reliable set could guide the feature\\nlearning of the less reliable set during training - in spirit of student\\nmimicking teacher behavior and thus pushing towards a more compact class\\ncentroid in the feature space. Such a scheme also benefits the reliable set\\nsince samples become closer within the same category - implying that it is\\neasier for the classifier to identify. We refer to this mutual learning process\\nas feature intertwiner and embed it into object detection. It is well-known\\nthat objects of low resolution are more difficult to detect due to the loss of\\ndetailed information during network forward pass (e.g., RoI operation). We thus\\nregard objects of high resolution as the reliable set and objects of low\\nresolution as the less reliable set. Specifically, an intertwiner is designed\\nto minimize the distribution divergence between two sets. The choice of\\ngenerating an effective feature representation for the reliable set is further\\ninvestigated, where we introduce the optimal transport (OT) theory into the\\nframework. Samples in the less reliable set are better aligned with aid of OT\\nmetric. Incorporated with such a plug-and-play intertwiner, we achieve an\\nevident improvement over previous state-of-the-arts.\\n\\n    ', '\\nAbstract:  This work addresses the unsupervised adaptation of an existing object\\ndetector to a new target domain. We assume that a large number of unlabeled\\nvideos from this domain are readily available. We automatically obtain labels\\non the target data by using high-confidence detections from the existing\\ndetector, augmented with hard (misclassified) examples acquired by exploiting\\ntemporal cues using a tracker. These automatically-obtained labels are then\\nused for re-training the original model. A modified knowledge distillation loss\\nis proposed, and we investigate several ways of assigning soft-labels to the\\ntraining examples from the target domain. Our approach is empirically evaluated\\non challenging face and pedestrian detection tasks: a face detector trained on\\nWIDER-Face, which consists of high-quality images crawled from the web, is\\nadapted to a large-scale surveillance data set; a pedestrian detector trained\\non clear, daytime images from the BDD-100K driving data set is adapted to all\\nother scenarios such as rainy, foggy, night-time. Our results demonstrate the\\nusefulness of incorporating hard examples obtained from tracking, the advantage\\nof using soft-labels via distillation loss versus hard-labels, and show\\npromising performance as a simple method for unsupervised domain adaptation of\\nobject detectors, with minimal dependence on hyper-parameters.\\n\\n    ', '\\nAbstract:  Compared with model architectures, the training process, which is also\\ncrucial to the success of detectors, has received relatively less attention in\\nobject detection. In this work, we carefully revisit the standard training\\npractice of detectors, and find that the detection performance is often limited\\nby the imbalance during the training process, which generally consists in three\\nlevels - sample level, feature level, and objective level. To mitigate the\\nadverse effects caused thereby, we propose Libra R-CNN, a simple but effective\\nframework towards balanced learning for object detection. It integrates three\\nnovel components: IoU-balanced sampling, balanced feature pyramid, and balanced\\nL1 loss, respectively for reducing the imbalance at sample, feature, and\\nobjective level. Benefitted from the overall balanced design, Libra R-CNN\\nsignificantly improves the detection performance. Without bells and whistles,\\nit achieves 2.5 points and 2.0 points higher Average Precision (AP) than FPN\\nFaster R-CNN and RetinaNet respectively on MSCOCO.\\n\\n    ', '\\nAbstract:  We motivate and present feature selective anchor-free (FSAF) module, a simple\\nand effective building block for single-shot object detectors. It can be\\nplugged into single-shot detectors with feature pyramid structure. The FSAF\\nmodule addresses two limitations brought up by the conventional anchor-based\\ndetection: 1) heuristic-guided feature selection; 2) overlap-based anchor\\nsampling. The general concept of the FSAF module is online feature selection\\napplied to the training of multi-level anchor-free branches. Specifically, an\\nanchor-free branch is attached to each level of the feature pyramid, allowing\\nbox encoding and decoding in the anchor-free manner at an arbitrary level.\\nDuring training, we dynamically assign each instance to the most suitable\\nfeature level. At the time of inference, the FSAF module can work jointly with\\nanchor-based branches by outputting predictions in parallel. We instantiate\\nthis concept with simple implementations of anchor-free branches and online\\nfeature selection strategy. Experimental results on the COCO detection track\\nshow that our FSAF module performs better than anchor-based counterparts while\\nbeing faster. When working jointly with anchor-based branches, the FSAF module\\nrobustly improves the baseline RetinaNet by a large margin under various\\nsettings, while introducing nearly free inference overhead. And the resulting\\nbest model can achieve a state-of-the-art 44.6% mAP, outperforming all existing\\nsingle-shot detectors on COCO.\\n\\n    ', '\\nAbstract:  With the advent of deep learning, object detection drifted from a bottom-up\\nto a top-down recognition problem. State of the art algorithms enumerate a\\nnear-exhaustive list of object locations and classify each into: object or not.\\nIn this paper, we show that bottom-up approaches still perform competitively.\\nWe detect four extreme points (top-most, left-most, bottom-most, right-most)\\nand one center point of objects using a standard keypoint estimation network.\\nWe group the five keypoints into a bounding box if they are geometrically\\naligned. Object detection is then a purely appearance-based keypoint estimation\\nproblem, without region classification or implicit feature learning. The\\nproposed method performs on-par with the state-of-the-art region based\\ndetection methods, with a bounding box AP of 43.2% on COCO test-dev. In\\naddition, our estimated extreme points directly span a coarse octagonal mask,\\nwith a COCO Mask AP of 18.9%, much better than the Mask AP of vanilla bounding\\nboxes. Extreme point guided segmentation further improves this to 34.6% Mask\\nAP.\\n\\n    ', '\\nAbstract:  Weakly supervised object detection (WSOD) is a challenging task when provided\\nwith image category supervision but required to simultaneously learn object\\nlocations and object detectors. Many WSOD approaches adopt multiple instance\\nlearning (MIL) and have non-convex loss functions which are prone to get stuck\\ninto local minima (falsely localize object parts) while missing full object\\nextent during training. In this paper, we introduce a continuation optimization\\nmethod into MIL and thereby creating continuation multiple instance learning\\n(C-MIL), with the intention of alleviating the non-convexity problem in a\\nsystematic way. We partition instances into spatially related and class related\\nsubsets, and approximate the original loss function with a series of smoothed\\nloss functions defined within the subsets. Optimizing smoothed loss functions\\nprevents the training procedure falling prematurely into local minima and\\nfacilitates the discovery of Stable Semantic Extremal Regions (SSERs) which\\nindicate full object extent. On the PASCAL VOC 2007 and 2012 datasets, C-MIL\\nimproves the state-of-the-art of weakly supervised object detection and weakly\\nsupervised object localization with large margins.\\n\\n    ', '\\nAbstract:  Current state-of-the-art object objectors are fine-tuned from the\\noff-the-shelf networks pretrained on large-scale classification dataset\\nImageNet, which incurs some additional problems: 1) The classification and\\ndetection have different degrees of sensitivity to translation, resulting in\\nthe learning objective bias; 2) The architecture is limited by the\\nclassification network, leading to the inconvenience of modification. To cope\\nwith these problems, training detectors from scratch is a feasible solution.\\nHowever, the detectors trained from scratch generally perform worse than the\\npretrained ones, even suffer from the convergence issue in training. In this\\npaper, we explore to train object detectors from scratch robustly. By analysing\\nthe previous work on optimization landscape, we find that one of the overlooked\\npoints in current trained-from-scratch detector is the BatchNorm. Resorting to\\nthe stable and predictable gradient brought by BatchNorm, detectors can be\\ntrained from scratch stably while keeping the favourable performance\\nindependent to the network architecture. Taking this advantage, we are able to\\nexplore various types of networks for object detection, without suffering from\\nthe poor convergence. By extensive experiments and analyses on downsampling\\nfactor, we propose the Root-ResNet backbone network, which makes full use of\\nthe information from original images. Our ScratchDet achieves the\\nstate-of-the-art accuracy on PASCAL VOC 2007, 2012 and MS COCO among all the\\ntrain-from-scratch detectors and even performs better than several one-stage\\npretrained methods. Codes will be made publicly available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Large-scale object detection datasets (e.g., MS-COCO) try to define the\\nground truth bounding boxes as clear as possible. However, we observe that\\nambiguities are still introduced when labeling the bounding boxes. In this\\npaper, we propose a novel bounding box regression loss for learning bounding\\nbox transformation and localization variance together. Our loss greatly\\nimproves the localization accuracies of various architectures with nearly no\\nadditional computation. The learned localization variance allows us to merge\\nneighboring bounding boxes during non-maximum suppression (NMS), which further\\nimproves the localization performance. On MS-COCO, we boost the Average\\nPrecision (AP) of VGG-16 Faster R-CNN from 23.6% to 29.1%. More importantly,\\nfor ResNet-50-FPN Mask R-CNN, our method improves the AP and AP90 by 1.8% and\\n6.2% respectively, which significantly outperforms previous state-of-the-art\\nbounding box refinement methods. Our code and models are available at:\\nthis http URL\\n', '\\nAbstract:  Weakly supervised object detection aims at reducing the amount of supervision\\nrequired to train detection models. Such models are traditionally learned from\\nimages/videos labelled only with the object class and not the object bounding\\nbox. In our work, we try to leverage not only the object class labels but also\\nthe action labels associated with the data. We show that the action depicted in\\nthe image/video can provide strong cues about the location of the associated\\nobject. We learn a spatial prior for the object dependent on the action (e.g.\\n\"ball\" is closer to \"leg of the person\" in \"kicking ball\"), and incorporate\\nthis prior to simultaneously train a joint object detection and action\\nclassification model. We conducted experiments on both video datasets and image\\ndatasets to evaluate the performance of our weakly supervised object detection\\nmodel. Our approach outperformed the current state-of-the-art (SOTA) method by\\nmore than 6% in mAP on the Charades video dataset.\\n\\n    ', '\\nAbstract:  One-stage object detectors are trained by optimizing classification-loss and\\nlocalization-loss simultaneously, with the former suffering much from extreme\\nforeground-background class imbalance issue due to the large number of anchors.\\nThis paper alleviates this issue by proposing a novel framework to replace the\\nclassification task in one-stage detectors with a ranking task, and adopting\\nthe Average-Precision loss (AP-loss) for the ranking problem. Due to its\\nnon-differentiability and non-convexity, the AP-loss cannot be optimized\\ndirectly. For this purpose, we develop a novel optimization algorithm, which\\nseamlessly combines the error-driven update scheme in perceptron learning and\\nbackpropagation algorithm in deep networks. We verify good convergence property\\nof the proposed algorithm theoretically and empirically. Experimental results\\ndemonstrate notable performance improvement in state-of-the-art one-stage\\ndetectors based on AP-loss over different kinds of classification-losses on\\nvarious benchmarks, without changing the network architectures. Code is\\navailable at this https URL.\\n\\n    ', '\\nAbstract:  We propose an approach for unsupervised adaptation of object detectors from\\nlabel-rich to label-poor domains which can significantly reduce annotation\\ncosts associated with detection. Recently, approaches that align distributions\\nof source and target images using an adversarial loss have been proven\\neffective for adapting object classifiers. However, for object detection, fully\\nmatching the entire distributions of source and target images to each other at\\nthe global image level may fail, as domains could have distinct scene layouts\\nand different combinations of objects. On the other hand, strong matching of\\nlocal features such as texture and color makes sense, as it does not change\\ncategory level semantics. This motivates us to propose a novel method for\\ndetector adaptation based on strong local alignment and weak global alignment.\\nOur key contribution is the weak alignment model, which focuses the adversarial\\nalignment loss on images that are globally similar and puts less emphasis on\\naligning images that are globally dissimilar. Additionally, we design the\\nstrong domain alignment model to only look at local receptive fields of the\\nfeature map. We empirically verify the effectiveness of our method on four\\ndatasets comprising both large and small domain shifts. Our code is available\\nat \\\\url{this https URL}\\n\\n    ', '\\nAbstract:  Current state-of-the-art convolutional architectures for object detection are\\nmanually designed. Here we aim to learn a better architecture of feature\\npyramid network for object detection. We adopt Neural Architecture Search and\\ndiscover a new feature pyramid architecture in a novel scalable search space\\ncovering all cross-scale connections. The discovered architecture, named\\nNAS-FPN, consists of a combination of top-down and bottom-up connections to\\nfuse features across scales. NAS-FPN, combined with various backbone models in\\nthe RetinaNet framework, achieves better accuracy and latency tradeoff compared\\nto state-of-the-art object detection models. NAS-FPN improves mobile detection\\naccuracy by 2 AP compared to state-of-the-art SSDLite with MobileNetV2 model in\\n[32] and achieves 48.3 AP which surpasses Mask R-CNN [10] detection accuracy\\nwith less computation time.\\n\\n    ', '\\nAbstract:  Pedestrian detection in a crowd is a very challenging issue. This paper\\naddresses this problem by a novel Non-Maximum Suppression (NMS) algorithm to\\nbetter refine the bounding boxes given by detectors. The contributions are\\nthreefold: (1) we propose adaptive-NMS, which applies a dynamic suppression\\nthreshold to an instance, according to the target density; (2) we design an\\nefficient subnetwork to learn density scores, which can be conveniently\\nembedded into both the single-stage and two-stage detectors; and (3) we achieve\\nstate of the art results on the CityPersons and CrowdHuman benchmarks.\\n\\n    ', '\\nAbstract:  Modern crowd counting methods usually employ deep neural networks (DNN) to\\nestimate crowd counts via density regression. Despite their significant\\nimprovements, the regression-based methods are incapable of providing the\\ndetection of individuals in crowds. The detection-based methods, on the other\\nhand, have not been largely explored in recent trends of crowd counting due to\\nthe needs for expensive bounding box annotations. In this work, we instead\\npropose a new deep detection network with only point supervision required. It\\ncan simultaneously detect the size and location of human heads and count them\\nin crowds. We first mine useful person size information from point-level\\nannotations and initialize the pseudo ground truth bounding boxes. An online\\nupdating scheme is introduced to refine the pseudo ground truth during\\ntraining; while a locally-constrained regression loss is designed to provide\\nadditional constraints on the size of the predicted boxes in a local\\nneighborhood. In the end, we propose a curriculum learning strategy to train\\nthe network from images of relatively accurate and easy pseudo ground truth\\nfirst. Extensive experiments are conducted in both detection and counting tasks\\non several standard benchmarks, e.g. ShanghaiTech, UCF_CC_50, WiderFace, and\\nTRANCOS datasets, and the results show the superiority of our method over the\\nstate-of-the-art.\\n\\n    ', \"\\nAbstract:  Recent advances in convolutional neural networks (CNN) have achieved\\nremarkable results in locating objects in images. In these networks, the\\ntraining procedure usually requires providing bounding boxes or the maximum\\nnumber of expected objects. In this paper, we address the task of estimating\\nobject locations without annotated bounding boxes which are typically\\nhand-drawn and time consuming to label. We propose a loss function that can be\\nused in any fully convolutional network (FCN) to estimate object locations.\\nThis loss function is a modification of the average Hausdorff distance between\\ntwo unordered sets of points. The proposed method has no notion of bounding\\nboxes, region proposals, or sliding windows. We evaluate our method with three\\ndatasets designed to locate people's heads, pupil centers and plant centers. We\\noutperform state-of-the-art generic object detectors and methods fine-tuned for\\npupil tracking.\\n\\n    \", '\\nAbstract:  Efficient and reliable methods for training of object detectors are in higher\\ndemand than ever, and more and more data relevant to the field is becoming\\navailable. However, large datasets like Open Images Dataset v4 (OID) are\\nsparsely annotated, and some measure must be taken in order to ensure the\\ntraining of a reliable detector. In order to take the incompleteness of these\\ndatasets into account, one possibility is to use pretrained models to detect\\nthe presence of the unverified objects. However, the performance of such a\\nstrategy depends largely on the power of the pretrained model. In this study,\\nwe propose part-aware sampling, a method that uses human intuition for the\\nhierarchical relation between objects. In terse terms, our method works by\\nmaking assumptions like \"a bounding box for a car should contain a bounding box\\nfor a tire\". We demonstrate the power of our method on OID and compare the\\nperformance against a method based on a pretrained model. Our method also won\\nthe first and second place on the public and private test sets of the Google AI\\nOpen Images Competition 2018.\\n\\n    ', '\\nAbstract:  Despite increasing efforts on universal representations for visual\\nrecognition, few have addressed object detection. In this paper, we develop an\\neffective and efficient universal object detection system that is capable of\\nworking on various image domains, from human faces and traffic signs to medical\\nCT images. Unlike multi-domain models, this universal model does not require\\nprior knowledge of the domain of interest. This is achieved by the introduction\\nof a new family of adaptation layers, based on the principles of squeeze and\\nexcitation, and a new domain-attention mechanism. In the proposed universal\\ndetector, all parameters and computations are shared across domains, and a\\nsingle network processes all domains all the time. Experiments, on a newly\\nestablished universal object detection benchmark of 11 diverse datasets, show\\nthat the proposed detector outperforms a bank of individual detectors, a\\nmulti-domain detector, and a baseline universal detector, with a 1.3x parameter\\nincrease over a single-domain baseline detector. The code and benchmark will be\\nreleased at this http URL.\\n\\n    ', '\\nAbstract:  The recurring context in which objects appear holds valuable information that\\ncan be employed to predict their existence. This intuitive observation indeed\\nled many researchers to endow appearance-based detectors with explicit\\nreasoning about context. The underlying thesis suggests that stronger\\ncontextual relations would facilitate greater improvements in detection\\ncapacity. In practice, however, the observed improvement in many cases is\\nmodest at best, and often only marginal. In this work we seek to improve our\\nunderstanding of this phenomenon, in part by pursuing an opposite approach.\\nInstead of attempting to improve detection scores by employing context, we\\ntreat the utility of context as an optimization problem: to what extent can\\ndetection scores be improved by considering context or any other kind of\\nadditional information? With this approach we explore the bounds on improvement\\nby using contextual relations between objects and provide a tool for\\nidentifying the most helpful ones. We show that simple co-occurrence relations\\ncan often provide large gains, while in other cases a significant improvement\\nis simply impossible or impractical with either co-occurrence or more precise\\nspatial relations. To better understand these results we then analyze the\\nability of context to handle different types of false detections, revealing\\nthat tested contextual information cannot ameliorate localization errors,\\nseverely limiting its gains. These and additional insights further our\\nunderstanding on where and why utilization of context for object detection\\nsucceeds and fails.\\n\\n    ', '\\nAbstract:  When humans have to solve everyday tasks, they simply pick the objects that\\nare most suitable. While the question which object should one use for a\\nspecific task sounds trivial for humans, it is very difficult to answer for\\nrobots or other autonomous systems. This issue, however, is not addressed by\\ncurrent benchmarks for object detection that focus on detecting object\\ncategories. We therefore introduce the COCO-Tasks dataset which comprises about\\n40,000 images where the most suitable objects for 14 tasks have been annotated.\\nWe furthermore propose an approach that detects the most suitable objects for a\\ngiven task. The approach builds on a Gated Graph Neural Network to exploit the\\nappearance of each object as well as the global context of all present objects\\nin the scene. In our experiments, we show that the proposed approach\\noutperforms other approaches that are evaluated on the dataset like\\nclassification or ranking approaches.\\n\\n    ', '\\nAbstract:  We consider the problem of weakly supervised object detection, where the\\ntraining samples are annotated using only image-level labels that indicate the\\npresence or absence of an object category. In order to model the uncertainty in\\nthe location of the objects, we employ a dissimilarity coefficient based\\nprobabilistic learning objective. The learning objective minimizes the\\ndifference between an annotation agnostic prediction distribution and an\\nannotation aware conditional distribution. The main computational challenge is\\nthe complex nature of the conditional distribution, which consists of terms\\nover hundreds or thousands of variables. The complexity of the conditional\\ndistribution rules out the possibility of explicitly modeling it. Instead, we\\nexploit the fact that deep learning frameworks rely on stochastic optimization.\\nThis allows us to use a state of the art discrete generative model that can\\nprovide annotation consistent samples from the conditional distribution.\\nExtensive experiments on PASCAL VOC 2007 and 2012 data sets demonstrate the\\nefficacy of our proposed approach.\\n\\n    ', \"\\nAbstract:  State-of-the-art CNN based recognition models are often computationally\\nprohibitive to deploy on low-end devices. A promising high level approach\\ntackling this limitation is knowledge distillation, which let small student\\nmodel mimic cumbersome teacher model's output to get improved generalization.\\nHowever, related methods mainly focus on simple task of classification while do\\nnot consider complex tasks like object detection. We show applying the vanilla\\nknowledge distillation to detection model gets minor gain. To address the\\nchallenge of distilling knowledge in detection model, we propose a fine-grained\\nfeature imitation method exploiting the cross-location discrepancy of feature\\nresponse. Our intuition is that detectors care more about local near object\\nregions. Thus the discrepancy of feature response on the near object anchor\\nlocations reveals important information of how teacher model tends to\\ngeneralize. We design a novel mechanism to estimate those locations and let\\nstudent model imitate the teacher on them to get enhanced performance. We first\\nvalidate the idea on a developed lightweight toy detector which carries\\nsimplest notion of current state-of-the-art anchor based detection models on\\nchallenging KITTI dataset, our method generates up to 15% boost of mAP for the\\nstudent model compared to the non-imitated counterpart. We then extensively\\nevaluate the method with Faster R-CNN model under various scenarios with common\\nobject detection benchmark of Pascal VOC and COCO, imitation alleviates up to\\n74% performance drop of student model compared to teacher. Codes released at\\nthis https URL\\n\", '\\nAbstract:  We investigate methods for combining multiple self-supervised tasks--i.e.,\\nsupervised tasks where data can be collected without manual labeling--in order\\nto train a single visual representation. First, we provide an apples-to-apples\\ncomparison of four different self-supervised tasks using the very deep\\nResNet-101 architecture. We then combine tasks to jointly train a network. We\\nalso explore lasso regularization to encourage the network to factorize the\\ninformation in its representation, and methods for \"harmonizing\" network inputs\\nin order to learn a more unified representation. We evaluate all methods on\\nImageNet classification, PASCAL VOC detection, and NYU depth prediction. Our\\nresults show that deeper networks work better, and that combining tasks--even\\nvia a naive multi-head architecture--always improves performance. Our best\\njoint network nearly matches the PASCAL performance of a model pre-trained on\\nImageNet classification, and matches the ImageNet network on NYU depth\\nprediction.\\n\\n    ', '\\nAbstract:  Scene text detection attracts much attention in computer vision, because it\\ncan be widely used in many applications such as real-time text translation,\\nautomatic information entry, blind person assistance, robot sensing and so on.\\nThough many methods have been proposed for horizontal and oriented texts,\\ndetecting irregular shape texts such as curved texts is still a challenging\\nproblem. To solve the problem, we propose a robust scene text detection method\\nwith adaptive text region representation. Given an input image, a text region\\nproposal network is first used for extracting text proposals. Then, these\\nproposals are verified and refined with a refinement network. Here, recurrent\\nneural network based adaptive text region representation is proposed for text\\nregion refinement, where a pair of boundary points are predicted each time step\\nuntil no new points are found. In this way, text regions of arbitrary shapes\\nare detected and represented with adaptive number of boundary points. This\\ngives more accurate description of text regions. Experimental results on five\\nbenchmarks, namely, CTW1500, TotalText, ICDAR2013, ICDAR2015 and MSRATD500,\\nshow that the proposed method achieves state-of-the-art in scene text\\ndetection.\\n\\n    ', '\\nAbstract:  We present a simple and effective learning technique that significantly\\nimproves mAP of YOLO object detectors without compromising their speed. During\\nnetwork training, we carefully feed in localization information. We excite\\ncertain activations in order to help the network learn to better localize. In\\nthe later stages of training, we gradually reduce our assisted excitation to\\nzero. We reached a new state-of-the-art in the speed-accuracy trade-off. Our\\ntechnique improves the mAP of YOLOv2 by 3.8% and mAP of YOLOv3 by 2.2% on\\nMSCOCO dataset.This technique is inspired from curriculum learning. It is\\nsimple and effective and it is applicable to most single-stage object\\ndetectors.\\n\\n    ', '\\nAbstract:  Weakly supervised object detection aims at learning precise object detectors,\\ngiven image category labels. In recent prevailing works, this problem is\\ngenerally formulated as a multiple instance learning module guided by an image\\nclassification loss. The object bounding box is assumed to be the one\\ncontributing most to the classification among all proposals. However, the\\nregion contributing most is also likely to be a crucial part or the supporting\\ncontext of an object. To obtain a more accurate detector, in this work we\\npropose a novel end-to-end weakly supervised detection approach, where a newly\\nintroduced generative adversarial segmentation module interacts with the\\nconventional detection module in a collaborative loop. The collaboration\\nmechanism takes full advantages of the complementary interpretations of the\\nweakly supervised localization task, namely detection and segmentation tasks,\\nforming a more comprehensive solution. Consequently, our method obtains more\\nprecise object bounding boxes, rather than parts or irrelevant surroundings.\\nExpectedly, the proposed method achieves an accuracy of 51.0% on the PASCAL VOC\\n2007 dataset, outperforming the state-of-the-arts and demonstrating its\\nsuperiority for weakly supervised object detection.\\n\\n    ', '\\nAbstract:  We introduce a novel unsupervised domain adaptation approach for object\\ndetection. We aim to alleviate the imperfect translation problem of pixel-level\\nadaptations, and the source-biased discriminativity problem of feature-level\\nadaptations simultaneously. Our approach is composed of two stages, i.e.,\\nDomain Diversification (DD) and Multi-domain-invariant Representation Learning\\n(MRL). At the DD stage, we diversify the distribution of the labeled data by\\ngenerating various distinctive shifted domains from the source domain. At the\\nMRL stage, we apply adversarial learning with a multi-domain discriminator to\\nencourage feature to be indistinguishable among the domains. DD addresses the\\nsource-biased discriminativity, while MRL mitigates the imperfect image\\ntranslation. We construct a structured domain adaptation framework for our\\nlearning paradigm and introduce a practical way of DD for implementation. Our\\nmethod outperforms the state-of-the-art methods by a large margin of 3%~11% in\\nterms of mean average precision (mAP) on various datasets.\\n\\n    ', '\\nAbstract:  Access to parallel and distributed computation has enabled researchers and\\ndevelopers to improve algorithms and performance in many applications. Recent\\nresearch has focused on next generation special purpose systems with multiple\\nkinds of coprocessors, known as heterogeneous system-on-chips (SoC). In this\\npaper, we introduce a method to intelligently schedule--and learn to\\nschedule--a stream of tasks to available processing elements in such a system.\\nWe use deep reinforcement learning enabling complex sequential decision making\\nand empirically show that our reinforcement learning system provides for a\\nviable, better alternative to conventional scheduling heuristics with respect\\nto minimizing execution time.\\n\\n    ', '\\nAbstract:  In this paper, we propose a zoom-out-and-in network for generating object\\nproposals. We utilize different resolutions of feature maps in the network to\\ndetect object instances of various sizes. Specifically, we divide the anchor\\ncandidates into three clusters based on the scale size and place them on\\nfeature maps of distinct strides to detect small, medium and large objects,\\nrespectively. Deeper feature maps contain region-level semantics which can help\\nshallow counterparts to identify small objects. Therefore we design a zoom-in\\nsub-network to increase the resolution of high level features via a\\ndeconvolution operation. The high-level features with high resolution are then\\ncombined and merged with low-level features to detect objects. Furthermore, we\\ndevise a recursive training pipeline to consecutively regress region proposals\\nat the training stage in order to match the iterative regression at the testing\\nstage. We demonstrate the effectiveness of the proposed method on ILSVRC DET\\nand MS COCO datasets, where our algorithm performs better than the\\nstate-of-the-arts in various evaluation metrics. It also increases average\\nprecision by around 2% in the detection system.\\n\\n    ', '\\nAbstract:  Over recent years, deep reinforcement learning has shown strong successes in\\ncomplex single-agent tasks, and more recently this approach has also been\\napplied to multi-agent domains. In this paper, we propose a novel approach,\\ncalled MAGnet, to multi-agent reinforcement learning (MARL) that utilizes a\\nrelevance graph representation of the environment obtained by a self-attention\\nmechanism, and a message-generation technique inspired by the NerveNet\\narchitecture. We applied our MAGnet approach to the Pommerman game and the\\nresults show that it significantly outperforms state-of-the-art MARL solutions,\\nincluding DQN, MADDPG, and MCTS.\\n\\n    ', '\\nAbstract:  Unsupervised representation learning algorithms such as word2vec and ELMo\\nimprove the accuracy of many supervised NLP models, mainly because they can\\ntake advantage of large amounts of unlabeled text. However, the supervised\\nmodels only learn from task-specific labeled data during the main training\\nphase. We therefore propose Cross-View Training (CVT), a semi-supervised\\nlearning algorithm that improves the representations of a Bi-LSTM sentence\\nencoder using a mix of labeled and unlabeled data. On labeled examples,\\nstandard supervised learning is used. On unlabeled examples, CVT teaches\\nauxiliary prediction modules that see restricted views of the input (e.g., only\\npart of a sentence) to match the predictions of the full model seeing the whole\\ninput. Since the auxiliary modules and the full model share intermediate\\nrepresentations, this in turn improves the full model. Moreover, we show that\\nCVT is particularly effective when combined with multi-task learning. We\\nevaluate CVT on five sequence tagging tasks, machine translation, and\\ndependency parsing, achieving state-of-the-art results.\\n\\n    ', 'It is pdf', '\\nAbstract:  This paper explores a simple and efficient baseline for text classification.\\nOur experiments show that our fast text classifier fastText is often on par\\nwith deep learning classifiers in terms of accuracy, and many orders of\\nmagnitude faster for training and evaluation. We can train fastText on more\\nthan one billion words in less than ten minutes using a standard multicore~CPU,\\nand classify half a million sentences among~312K classes in less than a minute.\\n\\n    ', 'It is pdf', '\\nAbstract:  We study the problem of representation learning in goal-conditioned\\nhierarchical reinforcement learning. In such hierarchical structures, a\\nhigher-level controller solves tasks by iteratively communicating goals which a\\nlower-level policy is trained to reach. Accordingly, the choice of\\nrepresentation -- the mapping of observation space to goal space -- is crucial.\\nTo study this problem, we develop a notion of sub-optimality of a\\nrepresentation, defined in terms of expected reward of the optimal hierarchical\\npolicy using this representation. We derive expressions which bound the\\nsub-optimality and show how these expressions can be translated to\\nrepresentation learning objectives which may be optimized in practice. Results\\non a number of difficult continuous-control tasks show that our approach to\\nrepresentation learning yields qualitatively better representations as well as\\nquantitatively better hierarchical policies, compared to existing methods (see\\nvideos at this https URL).\\n\\n    ', '\\nAbstract:  A lot of the recent success in natural language processing (NLP) has been\\ndriven by distributed vector representations of words trained on large amounts\\nof text in an unsupervised manner. These representations are typically used as\\ngeneral purpose features for words across a range of NLP problems. However,\\nextending this success to learning representations of sequences of words, such\\nas sentences, remains an open problem. Recent work has explored unsupervised as\\nwell as supervised learning techniques with different training objectives to\\nlearn general purpose fixed-length sentence representations. In this work, we\\npresent a simple, effective multi-task learning framework for sentence\\nrepresentations that combines the inductive biases of diverse training\\nobjectives in a single model. We train this model on several data sources with\\nmultiple training objectives on over 100 million sentences. Extensive\\nexperiments demonstrate that sharing a single recurrent sentence encoder across\\nweakly related tasks leads to consistent improvements over previous methods. We\\npresent substantial improvements in the context of transfer learning and\\nlow-resource settings using our learned general-purpose representations.\\n\\n    ', '\\nAbstract:  We introduce a new representation learning approach for domain adaptation, in\\nwhich data at training and test time come from similar but different\\ndistributions. Our approach is directly inspired by the theory on domain\\nadaptation suggesting that, for effective domain transfer to be achieved,\\npredictions must be made based on features that cannot discriminate between the\\ntraining (source) and test (target) domains. The approach implements this idea\\nin the context of neural network architectures that are trained on labeled data\\nfrom the source domain and unlabeled data from the target domain (no labeled\\ntarget-domain data is necessary). As the training progresses, the approach\\npromotes the emergence of features that are (i) discriminative for the main\\nlearning task on the source domain and (ii) indiscriminate with respect to the\\nshift between the domains. We show that this adaptation behaviour can be\\nachieved in almost any feed-forward model by augmenting it with few standard\\nlayers and a new gradient reversal layer. The resulting augmented architecture\\ncan be trained using standard backpropagation and stochastic gradient descent,\\nand can thus be implemented with little effort using any of the deep learning\\npackages. We demonstrate the success of our approach for two distinct\\nclassification problems (document sentiment analysis and image classification),\\nwhere state-of-the-art domain adaptation performance on standard benchmarks is\\nachieved. We also validate the approach for descriptor learning task in the\\ncontext of person re-identification application.\\n\\n    ', '\\nAbstract:  In multi-task learning, multiple tasks are solved jointly, sharing inductive\\nbias between them. Multi-task learning is inherently a multi-objective problem\\nbecause different tasks may conflict, necessitating a trade-off. A common\\ncompromise is to optimize a proxy objective that minimizes a weighted linear\\ncombination of per-task losses. However, this workaround is only valid when the\\ntasks do not compete, which is rarely the case. In this paper, we explicitly\\ncast multi-task learning as multi-objective optimization, with the overall\\nobjective of finding a Pareto optimal solution. To this end, we use algorithms\\ndeveloped in the gradient-based multi-objective optimization literature. These\\nalgorithms are not directly applicable to large-scale learning problems since\\nthey scale poorly with the dimensionality of the gradients and the number of\\ntasks. We therefore propose an upper bound for the multi-objective loss and\\nshow that it can be optimized efficiently. We further prove that optimizing\\nthis upper bound yields a Pareto optimal solution under realistic assumptions.\\nWe apply our method to a variety of multi-task deep learning problems including\\ndigit classification, scene understanding (joint semantic segmentation,\\ninstance segmentation, and depth estimation), and multi-label classification.\\nOur method produces higher-performing models than recent multi-task learning\\nformulations or per-task training.\\n\\n    ', 'It is pdf', '\\nAbstract:  This paper introduces WaveNet, a deep neural network for generating raw audio\\nwaveforms. The model is fully probabilistic and autoregressive, with the\\npredictive distribution for each audio sample conditioned on all previous ones;\\nnonetheless we show that it can be efficiently trained on data with tens of\\nthousands of samples per second of audio. When applied to text-to-speech, it\\nyields state-of-the-art performance, with human listeners rating it as\\nsignificantly more natural sounding than the best parametric and concatenative\\nsystems for both English and Mandarin. A single WaveNet can capture the\\ncharacteristics of many different speakers with equal fidelity, and can switch\\nbetween them by conditioning on the speaker identity. When trained to model\\nmusic, we find that it generates novel and often highly realistic musical\\nfragments. We also show that it can be employed as a discriminative model,\\nreturning promising results for phoneme recognition.\\n\\n    ', '\\nAbstract:  We describe a neural network-based system for text-to-speech (TTS) synthesis\\nthat is able to generate speech audio in the voice of many different speakers,\\nincluding those unseen during training. Our system consists of three\\nindependently trained components: (1) a speaker encoder network, trained on a\\nspeaker verification task using an independent dataset of noisy speech from\\nthousands of speakers without transcripts, to generate a fixed-dimensional\\nembedding vector from seconds of reference speech from a target speaker; (2) a\\nsequence-to-sequence synthesis network based on Tacotron 2, which generates a\\nmel spectrogram from text, conditioned on the speaker embedding; (3) an\\nauto-regressive WaveNet-based vocoder that converts the mel spectrogram into a\\nsequence of time domain waveform samples. We demonstrate that the proposed\\nmodel is able to transfer the knowledge of speaker variability learned by the\\ndiscriminatively-trained speaker encoder to the new task, and is able to\\nsynthesize natural speech from speakers that were not seen during training. We\\nquantify the importance of training the speaker encoder on a large and diverse\\nspeaker set in order to obtain the best generalization performance. Finally, we\\nshow that randomly sampled speaker embeddings can be used to synthesize speech\\nin the voice of novel speakers dissimilar from those used in training,\\nindicating that the model has learned a high quality speaker representation.\\n\\n    ', '\\nAbstract:  Keyword spotting (KWS) is a critical component for enabling speech based user\\ninteractions on smart devices. It requires real-time response and high accuracy\\nfor good user experience. Recently, neural networks have become an attractive\\nchoice for KWS architecture because of their superior accuracy compared to\\ntraditional speech processing algorithms. Due to its always-on nature, KWS\\napplication has highly constrained power budget and typically runs on tiny\\nmicrocontrollers with limited memory and compute capability. The design of\\nneural network architecture for KWS must consider these constraints. In this\\nwork, we perform neural network architecture evaluation and exploration for\\nrunning KWS on resource-constrained microcontrollers. We train various neural\\nnetwork architectures for keyword spotting published in literature to compare\\ntheir accuracy and memory/compute requirements. We show that it is possible to\\noptimize these neural network architectures to fit within the memory and\\ncompute constraints of microcontrollers without sacrificing accuracy. We\\nfurther explore the depthwise separable convolutional neural network (DS-CNN)\\nand compare it against other neural network architectures. DS-CNN achieves an\\naccuracy of 95.4%, which is ~10% higher than the DNN model with similar number\\nof parameters.\\n\\n    ', '\\nAbstract:  This paper describes a new baseline system for automatic speech recognition\\n(ASR) in the CHiME-4 challenge to promote the development of noisy ASR in\\nspeech processing communities by providing 1) state-of-the-art system with a\\nsimplified single system comparable to the complicated top systems in the\\nchallenge, 2) publicly available and reproducible recipe through the main\\nrepository in the Kaldi speech recognition toolkit. The proposed system adopts\\ngeneralized eigenvalue beamforming with bidirectional long short-term memory\\n(LSTM) mask estimation. We also propose to use a time delay neural network\\n(TDNN) based on the lattice-free version of the maximum mutual information\\n(LF-MMI) trained with augmented all six microphones plus the enhanced data\\nafter beamforming. Finally, we use a LSTM language model for lattice and n-best\\nre-scoring. The final system achieved 2.74\\\\% WER for the real test set in the\\n6-channel track, which corresponds to the 2nd place in the challenge. In\\naddition, the proposed baseline recipe includes four different speech\\nenhancement measures, short-time objective intelligibility measure (STOI),\\nextended STOI (eSTOI), perceptual evaluation of speech quality (PESQ) and\\nspeech distortion ratio (SDR) for the simulation test set. Thus, the recipe\\nalso provides an experimental platform for speech enhancement studies with\\nthese performance measures.\\n\\n    ', '\\nAbstract:  Link prediction for knowledge graphs is the task of predicting missing\\nrelationships between entities. Previous work on link prediction has focused on\\nshallow, fast models which can scale to large knowledge graphs. However, these\\nmodels learn less expressive features than deep, multi-layer models -- which\\npotentially limits performance. In this work, we introduce ConvE, a multi-layer\\nconvolutional network model for link prediction, and report state-of-the-art\\nresults for several established datasets. We also show that the model is highly\\nparameter efficient, yielding the same performance as DistMult and R-GCN with\\n8x and 17x fewer parameters. Analysis of our model suggests that it is\\nparticularly effective at modelling nodes with high indegree -- which are\\ncommon in highly-connected, complex knowledge graphs such as Freebase and\\nYAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer\\nfrom test set leakage, due to inverse relations from the training set being\\npresent in the test set -- however, the extent of this issue has so far not\\nbeen quantified. We find this problem to be severe: a simple rule-based model\\ncan achieve state-of-the-art results on both WN18 and FB15k. To ensure that\\nmodels are evaluated on datasets where simply exploiting inverse relations\\ncannot yield competitive results, we investigate and validate several commonly\\nused datasets -- deriving robust variants where necessary. We then perform\\nexperiments on these robust datasets for our own and several previously\\nproposed models and find that ConvE achieves state-of-the-art Mean Reciprocal\\nRank across most datasets.\\n\\n    ', '\\nAbstract:  Convolutional neural networks (CNNs) have achieved great success on grid-like\\ndata such as images, but face tremendous challenges in learning from more\\ngeneric data such as graphs. In CNNs, the trainable local filters enable the\\nautomatic extraction of high-level features. The computation with filters\\nrequires a fixed number of ordered units in the receptive fields. However, the\\nnumber of neighboring units is neither fixed nor are they ordered in generic\\ngraphs, thereby hindering the applications of convolutional operations. Here,\\nwe address these challenges by proposing the learnable graph convolutional\\nlayer (LGCL). LGCL automatically selects a fixed number of neighboring nodes\\nfor each feature based on value ranking in order to transform graph data into\\ngrid-like structures in 1-D format, thereby enabling the use of regular\\nconvolutional operations on generic graphs. To enable model training on\\nlarge-scale graphs, we propose a sub-graph training method to reduce the\\nexcessive memory and computational resource requirements suffered by prior\\nmethods on graph convolutions. Our experimental results on node classification\\ntasks in both transductive and inductive learning settings demonstrate that our\\nmethods can achieve consistently better performance on the Cora, Citeseer,\\nPubmed citation network, and protein-protein interaction network datasets. Our\\nresults also indicate that the proposed methods using sub-graph training\\nstrategy are more efficient as compared to prior approaches.\\n\\n    ', '\\nAbstract:  For many applications the collection of labeled data is expensive laborious.\\nExploitation of unlabeled data during training is thus a long pursued objective\\nof machine learning. Self-supervised learning addresses this by positing an\\nauxiliary task (different, but related to the supervised task) for which data\\nis abundantly available. In this paper, we show how ranking can be used as a\\nproxy task for some regression problems. As another contribution, we propose an\\nefficient backpropagation technique for Siamese networks which prevents the\\nredundant computation introduced by the multi-branch network architecture. We\\napply our framework to two regression problems: Image Quality Assessment (IQA)\\nand Crowd Counting. For both we show how to automatically generate ranked image\\nsets from unlabeled data. Our results show that networks trained to regress to\\nthe ground truth targets for labeled data and to simultaneously learn to rank\\nunlabeled data obtain significantly better, state-of-the-art results for both\\nIQA and crowd counting. In addition, we show that measuring network uncertainty\\non the self-supervised proxy task is a good measure of informativeness of\\nunlabeled data. This can be used to drive an algorithm for active learning and\\nwe show that this reduces labeling effort by up to 50%.\\n\\n    ', '\\nAbstract:  The rise of graph-structured data such as social networks, regulatory\\nnetworks, citation graphs, and functional brain networks, in combination with\\nresounding success of deep learning in various applications, has brought the\\ninterest in generalizing deep learning models to non-Euclidean domains. In this\\npaper, we introduce a new spectral domain convolutional architecture for deep\\nlearning on graphs. The core ingredient of our model is a new class of\\nparametric rational complex functions (Cayley polynomials) allowing to\\nefficiently compute spectral filters on graphs that specialize on frequency\\nbands of interest. Our model generates rich spectral filters that are localized\\nin space, scales linearly with the size of the input data for\\nsparsely-connected graphs, and can handle different constructions of Laplacian\\noperators. Extensive experimental results show the superior performance of our\\napproach, in comparison to other spectral domain convolutional architectures,\\non spectral image classification, community detection, vertex classification\\nand matrix completion tasks.\\n\\n    ', '\\nAbstract:  The ability to predict depth from a single image - using recent advances in\\nCNNs - is of increasing interest to the vision community. Unsupervised\\nstrategies to learning are particularly appealing as they can utilize much\\nlarger and varied monocular video datasets during learning without the need for\\nground truth depth or stereo. In previous works, separate pose and depth CNN\\npredictors had to be determined such that their joint outputs minimized the\\nphotometric error. Inspired by recent advances in direct visual odometry (DVO),\\nwe argue that the depth CNN predictor can be learned without a pose CNN\\npredictor. Further, we demonstrate empirically that incorporation of a\\ndifferentiable implementation of DVO, along with a novel depth normalization\\nstrategy - substantially improves performance over state of the art that use\\nmonocular videos for training.\\n\\n    ', '\\nAbstract:  Learning to predict scene depth from RGB inputs is a challenging task both\\nfor indoor and outdoor robot navigation. In this work we address unsupervised\\nlearning of scene depth and robot ego-motion where supervision is provided by\\nmonocular videos, as cameras are the cheapest, least restrictive and most\\nubiquitous sensor for robotics.\\nPrevious work in unsupervised image-to-depth learning has established strong\\nbaselines in the domain. We propose a novel approach which produces higher\\nquality results, is able to model moving objects and is shown to transfer\\nacross data domains, e.g. from outdoors to indoor scenes. The main idea is to\\nintroduce geometric structure in the learning process, by modeling the scene\\nand the individual objects; camera ego-motion and object motions are learned\\nfrom monocular videos as input. Furthermore an online refinement method is\\nintroduced to adapt learning on the fly to unknown domains.\\nThe proposed approach outperforms all state-of-the-art approaches, including\\nthose that handle motion e.g. through learned flow. Our results are comparable\\nin quality to the ones which used stereo as supervision and significantly\\nimprove depth prediction on scenes and datasets which contain a lot of object\\nmotion. The approach is of practical relevance, as it allows transfer across\\nenvironments, by transferring models trained on data collected for robot\\nnavigation in urban scenes to indoor navigation settings. The code associated\\nwith this paper can be found at this https URL.\\n\\n    ', '\\nAbstract:  Planning has been very successful for control tasks with known environment\\ndynamics. To leverage planning in unknown environments, the agent needs to\\nlearn the dynamics from interactions with the world. However, learning dynamics\\nmodels that are accurate enough for planning has been a long-standing\\nchallenge, especially in image-based domains. We propose the Deep Planning\\nNetwork (PlaNet), a purely model-based agent that learns the environment\\ndynamics from images and chooses actions through fast online planning in latent\\nspace. To achieve high performance, the dynamics model must accurately predict\\nthe rewards ahead for multiple time steps. We approach this using a latent\\ndynamics model with both deterministic and stochastic transition components.\\nMoreover, we propose a multi-step variational inference objective that we name\\nlatent overshooting. Using only pixel observations, our agent solves continuous\\ncontrol tasks with contact dynamics, partial observability, and sparse rewards,\\nwhich exceed the difficulty of tasks that were previously solved by planning\\nwith learned models. PlaNet uses substantially fewer episodes and reaches final\\nperformance close to and sometimes higher than strong model-free algorithms.\\n\\n    ', \"\\nAbstract:  The task of estimating the fundamental frequency of a monophonic sound\\nrecording, also known as pitch tracking, is fundamental to audio processing\\nwith multiple applications in speech processing and music information\\nretrieval. To date, the best performing techniques, such as the pYIN algorithm,\\nare based on a combination of DSP pipelines and heuristics. While such\\ntechniques perform very well on average, there remain many cases in which they\\nfail to correctly estimate the pitch. In this paper, we propose a data-driven\\npitch tracking algorithm, CREPE, which is based on a deep convolutional neural\\nnetwork that operates directly on the time-domain waveform. We show that the\\nproposed model produces state-of-the-art results, performing equally or better\\nthan pYIN. Furthermore, we evaluate the model's generalizability in terms of\\nnoise robustness. A pre-trained version of CREPE is made freely available as an\\nopen-source Python module for easy application.\\n\\n    \", '\\nAbstract:  Recent work has shown that the end-to-end approach using convolutional neural\\nnetwork (CNN) is effective in various types of machine learning tasks. For\\naudio signals, the approach takes raw waveforms as input using an 1-D\\nconvolution layer. In this paper, we improve the 1-D CNN architecture for music\\nauto-tagging by adopting building blocks from state-of-the-art image\\nclassification models, ResNets and SENets, and adding multi-level feature\\naggregation to it. We compare different combinations of the modules in building\\nCNN architectures. The results show that they achieve significant improvements\\nover previous state-of-the-art models on the MagnaTagATune dataset and\\ncomparable results on Million Song Dataset. Furthermore, we analyze and\\nvisualize our model to show how the 1-D CNN operates.\\n\\n    ', '\\nAbstract:  Most of the currently successful source separation techniques use the\\nmagnitude spectrogram as input, and are therefore by default omitting part of\\nthe signal: the phase. To avoid omitting potentially useful information, we\\nstudy the viability of using end-to-end models for music source separation ---\\nwhich take into account all the information available in the raw audio signal,\\nincluding the phase. Although during the last decades end-to-end music source\\nseparation has been considered almost unattainable, our results confirm that\\nwaveform-based models can perform similarly (if not better) than a\\nspectrogram-based deep learning model. Namely: a Wavenet-based model we propose\\nand Wave-U-Net can outperform DeepConvSep, a recent spectrogram-based deep\\nlearning model.\\n\\n    ', '\\nAbstract:  We introduce a convolutional recurrent neural network (CRNN) for music\\ntagging. CRNNs take advantage of convolutional neural networks (CNNs) for local\\nfeature extraction and recurrent neural networks for temporal summarisation of\\nthe extracted features. We compare CRNN with three CNN structures that have\\nbeen used for music tagging while controlling the number of parameters with\\nrespect to their performance and training time per sample. Overall, we found\\nthat CRNNs show a strong performance with respect to the number of parameter\\nand training time, indicating the effectiveness of its hybrid structure in\\nmusic feature extraction and feature summarisation.\\n\\n    ', '\\nAbstract:  In many machine learning applications, labeled data is scarce and obtaining\\nmore labels is expensive. We introduce a new approach to supervising neural\\nnetworks by specifying constraints that should hold over the output space,\\nrather than direct examples of input-output pairs. These constraints are\\nderived from prior domain knowledge, e.g., from known laws of physics. We\\ndemonstrate the effectiveness of this approach on real world and simulated\\ncomputer vision tasks. We are able to train a convolutional neural network to\\ndetect and track objects without any labeled examples. Our approach can\\nsignificantly reduce the need for labeled training data, but introduces new\\nchallenges for encoding prior knowledge into appropriate loss functions.\\n\\n    ', '\\nAbstract:  We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\\nthat leads to a false sense of security in defenses against adversarial\\nexamples. While defenses that cause obfuscated gradients appear to defeat\\niterative optimization-based attacks, we find defenses relying on this effect\\ncan be circumvented. We describe characteristic behaviors of defenses\\nexhibiting the effect, and for each of the three types of obfuscated gradients\\nwe discover, we develop attack techniques to overcome it. In a case study,\\nexamining non-certified white-box-secure defenses at ICLR 2018, we find\\nobfuscated gradients are a common occurrence, with 7 of 9 defenses relying on\\nobfuscated gradients. Our new attacks successfully circumvent 6 completely, and\\n1 partially, in the original threat model each paper considers.\\n\\n    ', '\\nAbstract:  Motivated by applications in declarative data analysis, we study\\n$\\\\mathit{Datalog}_{\\\\mathbb{Z}}$---an extension of positive Datalog with\\narithmetic functions over integers. This language is known to be undecidable,\\nso we propose two fragments. In $\\\\mathit{limit}~\\\\mathit{Datalog}_{\\\\mathbb{Z}}$\\npredicates are axiomatised to keep minimal/maximal numeric values, allowing us\\nto show that fact entailment is coNExpTime-complete in combined, and\\ncoNP-complete in data complexity. Moreover, an additional $\\\\mathit{stability}$\\nrequirement causes the complexity to drop to ExpTime and PTime, respectively.\\nFinally, we show that stable $\\\\mathit{Datalog}_{\\\\mathbb{Z}}$ can express many\\nuseful data analysis tasks, and so our results provide a sound foundation for\\nthe development of advanced information systems.\\n\\n    ', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', '\\nAbstract:  Although recent work in AI has made great progress in solving large,\\nzero-sum, extensive-form games, the underlying assumption in most past work is\\nthat the parameters of the game itself are known to the agents. This paper\\ndeals with the relatively under-explored but equally important \"inverse\"\\nsetting, where the parameters of the underlying game are not known to all\\nagents, but must be learned through observations. We propose a differentiable,\\nend-to-end learning framework for addressing this task. In particular, we\\nconsider a regularized version of the game, equivalent to a particular form of\\nquantal response equilibrium, and develop 1) a primal-dual Newton method for\\nfinding such equilibrium points in both normal and extensive form games; and 2)\\na backpropagation method that lets us analytically compute gradients of all\\nrelevant game parameters through the solution itself. This ultimately lets us\\nlearn the game by training in an end-to-end fashion, effectively by integrating\\na \"differentiable game solver\" into the loop of larger deep network\\narchitectures. We demonstrate the effectiveness of the learning method in\\nseveral settings including poker and security game tasks.\\n\\n    ', \"\\nAbstract:  In imperfect-information games, the optimal strategy in a subgame may depend\\non the strategy in other, unreached subgames. Thus a subgame cannot be solved\\nin isolation and must instead consider the strategy for the entire game as a\\nwhole, unlike perfect-information games. Nevertheless, it is possible to first\\napproximate a solution for the whole game and then improve it by solving\\nindividual subgames. This is referred to as subgame solving. We introduce\\nsubgame-solving techniques that outperform prior methods both in theory and\\npractice. We also show how to adapt them, and past subgame-solving techniques,\\nto respond to opponent actions that are outside the original action\\nabstraction; this significantly outperforms the prior state-of-the-art\\napproach, action translation. Finally, we show that subgame solving can be\\nrepeated as the game progresses down the game tree, leading to far lower\\nexploitability. These techniques were a key component of Libratus, the first AI\\nto defeat top humans in heads-up no-limit Texas hold'em poker.\\n\\n    \", \"\\nAbstract:  We prove that $\\\\tilde{\\\\Theta}(k d^2 / \\\\varepsilon^2)$ samples are necessary\\nand sufficient for learning a mixture of $k$ Gaussians in $\\\\mathbb{R}^d$, up to\\nerror $\\\\varepsilon$ in total variation distance. This improves both the known\\nupper bounds and lower bounds for this problem. For mixtures of axis-aligned\\nGaussians, we show that $\\\\tilde{O}(k d / \\\\varepsilon^2)$ samples suffice,\\nmatching a known lower bound. Moreover, these results hold in the\\nagnostic-learning/robust-estimation setting as well, where the target\\ndistribution is only approximately a mixture of Gaussians.\\nThe upper bound is shown using a novel technique for distribution learning\\nbased on a notion of `compression.' Any class of distributions that allows such\\na compression scheme can also be learned with few samples. Moreover, if a class\\nof distributions has such a compression scheme, then so do the classes of\\nproducts and mixtures of those distributions. The core of our main result is\\nshowing that the class of Gaussians in $\\\\mathbb{R}^d$ admits a small-sized\\ncompression scheme.\\n\\n    \", 'It is pdf', 'It is pdf', '\\nAbstract:  This paper presents an efficient binarized algorithm for both learning and\\nclassification of human epileptic seizures from intracranial\\nelectroencephalography (iEEG). The algorithm combines local binary patterns\\nwith brain-inspired hyperdimensional computing to enable end-to-end learning\\nand inference with binary operations. The algorithm first transforms iEEG time\\nseries from each electrode into local binary pattern codes. Then atomic\\nhigh-dimensional binary vectors are used to construct composite representations\\nof seizures across all electrodes. For the majority of our patients (10 out of\\n16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot\\nlearning) and perfectly generalizes on 27 further seizures. For other patients,\\nthe algorithm requires three to six seizures for learning. Overall, our\\nalgorithm surpasses the state-of-the-art methods for detecting 65 novel\\nseizures with higher specificity and sensitivity, and lower memory footprint.\\n\\n    ', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', '\\nAbstract:  Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of\\ndata in human-interactive systems. While implicit feedback has many advantages\\n(e.g., it is inexpensive to collect, user centric, and timely), its inherent\\nbiases are a key obstacle to its effective use. For example, position bias in\\nsearch rankings strongly influences how many clicks a result receives, so that\\ndirectly using click data as a training signal in Learning-to-Rank (LTR)\\nmethods yields sub-optimal results. To overcome this bias problem, we present a\\ncounterfactual inference framework that provides the theoretical basis for\\nunbiased LTR via Empirical Risk Minimization despite biased data. Using this\\nframework, we derive a Propensity-Weighted Ranking SVM for discriminative\\nlearning from implicit feedback, where click models take the role of the\\npropensity estimator. In contrast to most conventional approaches to de-bias\\nthe data using click models, this allows training of ranking functions even in\\nsettings where queries do not repeat. Beyond the theoretical support, we show\\nempirically that the proposed learning method is highly effective in dealing\\nwith biases, that it is robust to noise and propensity model misspecification,\\nand that it scales efficiently. We also demonstrate the real-world\\napplicability of our approach on an operational search engine, where it\\nsubstantially improves retrieval performance.\\n\\n    ', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', '\\nAbstract:  Existing region-based object detectors are limited to regions with fixed box\\ngeometry to represent objects, even if those are highly non-rectangular. In\\nthis paper we introduce DP-FCN, a deep model for object detection which\\nexplicitly adapts to shapes of objects with deformable parts. Without\\nadditional annotations, it learns to focus on discriminative elements and to\\nalign them, and simultaneously brings more invariance for classification and\\ngeometric information to refine localization. DP-FCN is composed of three main\\nmodules: a Fully Convolutional Network to efficiently maintain spatial\\nresolution, a deformable part-based RoI pooling layer to optimize positions of\\nparts and build invariance, and a deformation-aware localization module\\nexplicitly exploiting displacements of parts to improve accuracy of bounding\\nbox regression. We experimentally validate our model and show significant\\ngains. DP-FCN achieves state-of-the-art performances of 83.1% and 80.9% on\\nPASCAL VOC 2007 and 2012 with VOC data only.\\n\\n    ', '\\nAbstract:  In this work we present a novel compact scene representation based on Stixels\\nthat infers geometric and semantic information. Our approach overcomes the\\nprevious rather restrictive geometric assumptions for Stixels by introducing a\\nnovel depth model to account for non-flat roads and slanted objects. Both\\nsemantic and depth cues are used jointly to infer the scene representation in a\\nsound global energy minimization formulation. Furthermore, a novel\\napproximation scheme is introduced that uses an extremely efficient\\nover-segmentation. In doing so, the computational complexity of the Stixel\\ninference algorithm is reduced significantly, achieving real-time computation\\ncapabilities with only a slight drop in accuracy. We evaluate the proposed\\napproach in terms of semantic and geometric accuracy as well as run-time on\\nfour publicly available benchmark datasets. Our approach maintains accuracy on\\nflat road scene datasets while improving substantially on a novel non-flat road\\ndataset.\\n\\n    ', '\\nAbstract:  Do visual tasks have a relationship, or are they unrelated? For instance,\\ncould having surface normals simplify estimating the depth of an image?\\nIntuition answers these questions positively, implying existence of a structure\\namong visual tasks. Knowing this structure has notable values; it is the\\nconcept underlying transfer learning and provides a principled way for\\nidentifying redundancies across tasks, e.g., to seamlessly reuse supervision\\namong related tasks or solve many tasks in one system without piling up the\\ncomplexity.\\nWe proposes a fully computational approach for modeling the structure of\\nspace of visual tasks. This is done via finding (first and higher-order)\\ntransfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\\nand semantic tasks in a latent space. The product is a computational taxonomic\\nmap for task transfer learning. We study the consequences of this structure,\\ne.g. nontrivial emerged relationships, and exploit them to reduce the demand\\nfor labeled data. For example, we show that the total number of labeled\\ndatapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\\n(compared to training independently) while keeping the performance nearly the\\nsame. We provide a set of tools for computing and probing this taxonomical\\nstructure including a solver that users can employ to devise efficient\\nsupervision policies for their use cases.\\n\\n    ', '\\nAbstract:  We propose a real-time RGB-based pipeline for object detection and 6D pose\\nestimation. Our novel 3D orientation estimation is based on a variant of the\\nDenoising Autoencoder that is trained on simulated views of a 3D model using\\nDomain Randomization. This so-called Augmented Autoencoder has several\\nadvantages over existing methods: It does not require real, pose-annotated\\ntraining data, generalizes to various test sensors and inherently handles\\nobject and view symmetries. Instead of learning an explicit mapping from input\\nimages to object poses, it provides an implicit representation of object\\norientations defined by samples in a latent space. Our pipeline achieves\\nstate-of-the-art performance on the T-LESS dataset both in the RGB and RGB-D\\ndomain. We also evaluate on the LineMOD dataset where we can compete with other\\nsynthetically trained approaches. We further increase performance by correcting\\n3D orientation estimates to account for perspective errors when the object\\ndeviates from the image center and show extended results.\\n\\n    ', 'It is pdf', '\\nAbstract:  We present a conceptually simple, flexible, and general framework for object\\ninstance segmentation. Our approach efficiently detects objects in an image\\nwhile simultaneously generating a high-quality segmentation mask for each\\ninstance. The method, called Mask R-CNN, extends Faster R-CNN by adding a\\nbranch for predicting an object mask in parallel with the existing branch for\\nbounding box recognition. Mask R-CNN is simple to train and adds only a small\\noverhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to\\ngeneralize to other tasks, e.g., allowing us to estimate human poses in the\\nsame framework. We show top results in all three tracks of the COCO suite of\\nchallenges, including instance segmentation, bounding-box object detection, and\\nperson keypoint detection. Without bells and whistles, Mask R-CNN outperforms\\nall existing, single-model entries on every task, including the COCO 2016\\nchallenge winners. We hope our simple and effective approach will serve as a\\nsolid baseline and help ease future research in instance-level recognition.\\nCode has been made available at: this https URL\\n', 'It is pdf', 'It is pdf', '\\nAbstract:  There are great demands for automatically regulating inappropriate appearance\\nof shocking firearm images in social media or identifying firearm types in\\nforensics. Image retrieval techniques have great potential to solve these\\nproblems. To facilitate research in this area, we introduce Firearm 14k, a\\nlarge dataset consisting of over 14,000 images in 167 categories. It can be\\nused for both fine-grained recognition and retrieval of firearm images. Recent\\nadvances in image retrieval are mainly driven by fine-tuning state-of-the-art\\nconvolutional neural networks for retrieval task. The conventional single\\nmargin contrastive loss, known for its simplicity and good performance, has\\nbeen widely used. We find that it performs poorly on the Firearm 14k dataset\\ndue to: (1) Loss contributed by positive and negative image pairs is unbalanced\\nduring training process. (2) A huge domain gap exists between this dataset and\\nImageNet. We propose to deal with the unbalanced loss by employing a double\\nmargin contrastive loss. We tackle the domain gap issue with a two-stage\\ntraining strategy, where we first fine-tune the network for classification, and\\nthen fine-tune it for retrieval. Experimental results show that our approach\\noutperforms the conventional single margin approach by a large margin (up to\\n88.5% relative improvement) and even surpasses the strong triplet-loss-based\\napproach.\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks (CNN) have been successfully applied to\\nautonomous driving tasks, many in an end-to-end manner. Previous end-to-end\\nsteering control methods take an image or an image sequence as the input and\\ndirectly predict the steering angle with CNN. Although single task learning on\\nsteering angles has reported good performances, the steering angle alone is not\\nsufficient for vehicle control. In this work, we propose a multi-task learning\\nframework to predict the steering angle and speed control simultaneously in an\\nend-to-end manner. Since it is nontrivial to predict accurate speed values with\\nonly visual inputs, we first propose a network to predict discrete speed\\ncommands and steering angles with image sequences. Moreover, we propose a\\nmulti-modal multi-task network to predict speed values and steering angles by\\ntaking previous feedback speeds and visual recordings as inputs. Experiments\\nare conducted on the public Udacity dataset and a newly collected SAIC dataset.\\nResults show that the proposed model predicts steering angles and speed values\\naccurately. Furthermore, we improve the failure data synthesis methods to solve\\nthe problem of error accumulation in real road tests.\\n\\n    ', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', \"\\nAbstract:  We present a novel method to reconstruct a fluid's 3D density and motion\\nbased on just a single sequence of images. This is rendered possible by using\\npowerful physical priors for this strongly under-determined problem. More\\nspecifically, we propose a novel strategy to infer density updates strongly\\ncoupled to previous and current estimates of the flow motion. Additionally, we\\nemploy an accurate discretization and depth-based regularizers to compute\\nstable solutions. Using only one view for the reconstruction reduces the\\ncomplexity of the capturing setup drastically and could even allow for online\\nvideo databases or smart-phone videos as inputs. The reconstructed 3D velocity\\ncan then be flexibly utilized, e.g., for re-simulation, domain modification or\\nguiding purposes. We will demonstrate the capacity of our method with a series\\nof synthetic test cases and the reconstruction of real smoke plumes captured\\nwith a Raspberry Pi camera.\\n\\n    \", \"\\nAbstract:  We show that the gradient descent algorithm provides an implicit\\nregularization effect in the learning of over-parameterized matrix\\nfactorization models and one-hidden-layer neural networks with quadratic\\nactivations. Concretely, we show that given $\\\\tilde{O}(dr^{2})$ random linear\\nmeasurements of a rank $r$ positive semidefinite matrix $X^{\\\\star}$, we can\\nrecover $X^{\\\\star}$ by parameterizing it by $UU^\\\\top$ with $U\\\\in \\\\mathbb\\nR^{d\\\\times d}$ and minimizing the squared loss, even if $r \\\\ll d$. We prove\\nthat starting from a small initialization, gradient descent recovers\\n$X^{\\\\star}$ in $\\\\tilde{O}(\\\\sqrt{r})$ iterations approximately. The results\\nsolve the conjecture of Gunasekar et al.'17 under the restricted isometry\\nproperty. The technique can be applied to analyzing neural networks with\\none-hidden-layer quadratic activations with some technical modifications.\\n\\n    \", \"\\nAbstract:  We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for\\nnon-convex optimization. The algorithm performs stochastic gradient descent,\\nwhere in each step it injects appropriately scaled Gaussian noise to the\\nupdate. We analyze the algorithm's hitting time to an arbitrary subset of the\\nparameter space. Two results follow from our general theory: First, we prove\\nthat for empirical risk minimization, if the empirical risk is point-wise close\\nto the (smooth) population risk, then the algorithm achieves an approximate\\nlocal minimum of the population risk in polynomial time, escaping suboptimal\\nlocal minima that only exist in the empirical risk. Second, we show that SGLD\\nimproves on one of the best known learnability results for learning linear\\nclassifiers under the zero-one loss.\\n\\n    \", '\\nAbstract:  Fairness in machine learning has predominantly been studied in static\\nclassification settings without concern for how decisions change the underlying\\npopulation over time. Conventional wisdom suggests that fairness criteria\\npromote the long-term well-being of those groups they aim to protect.\\nWe study how static fairness criteria interact with temporal indicators of\\nwell-being, such as long-term improvement, stagnation, and decline in a\\nvariable of interest. We demonstrate that even in a one-step feedback model,\\ncommon fairness criteria in general do not promote improvement over time, and\\nmay in fact cause harm in cases where an unconstrained objective would not.\\nWe completely characterize the delayed impact of three standard criteria,\\ncontrasting the regimes in which these exhibit qualitatively different\\nbehavior. In addition, we find that a natural form of measurement error\\nbroadens the regime in which fairness criteria perform favorably.\\nOur results highlight the importance of measurement and temporal modeling in\\nthe evaluation of fairness criteria, suggesting a range of new challenges and\\ntrade-offs.\\n\\n    ', 'It is pdf', '\\nAbstract:  In this work, we consider the distributed optimization of non-smooth convex\\nfunctions using a network of computing units. We investigate this problem under\\ntwo regularity assumptions: (1) the Lipschitz continuity of the global\\nobjective function, and (2) the Lipschitz continuity of local individual\\nfunctions. Under the local regularity assumption, we provide the first optimal\\nfirst-order decentralized algorithm called multi-step primal-dual (MSPD) and\\nits corresponding optimal convergence rate. A notable aspect of this result is\\nthat, for non-smooth functions, while the dominant term of the error is in\\n$O(1/\\\\sqrt{t})$, the structure of the communication network only impacts a\\nsecond-order term in $O(1/t)$, where $t$ is time. In other words, the error due\\nto limits in communication resources decreases at a fast rate even in the case\\nof non-strongly-convex objective functions. Under the global regularity\\nassumption, we provide a simple yet efficient algorithm called distributed\\nrandomized smoothing (DRS) based on a local smoothing of the objective\\nfunction, and show that DRS is within a $d^{1/4}$ multiplicative factor of the\\noptimal convergence rate, where $d$ is the underlying dimension.\\n\\n    ', '\\nAbstract:  We introduce a new family of deep neural network models. Instead of\\nspecifying a discrete sequence of hidden layers, we parameterize the derivative\\nof the hidden state using a neural network. The output of the network is\\ncomputed using a black-box differential equation solver. These continuous-depth\\nmodels have constant memory cost, adapt their evaluation strategy to each\\ninput, and can explicitly trade numerical precision for speed. We demonstrate\\nthese properties in continuous-depth residual networks and continuous-time\\nlatent variable models. We also construct continuous normalizing flows, a\\ngenerative model that can train by maximum likelihood, without partitioning or\\nordering the data dimensions. For training, we show how to scalably\\nbackpropagate through any ODE solver, without access to its internal\\noperations. This allows end-to-end training of ODEs within larger models.\\n\\n    ', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', '\\nAbstract:  In this work, we take a fresh look at some old and new algorithms for\\noff-policy, return-based reinforcement learning. Expressing these in a common\\nform, we derive a novel algorithm, Retrace($\\\\lambda$), with three desired\\nproperties: (1) it has low variance; (2) it safely uses samples collected from\\nany behaviour policy, whatever its degree of \"off-policyness\"; and (3) it is\\nefficient as it makes the best use of samples collected from near on-policy\\nbehaviour policies. We analyze the contractive nature of the related operator\\nunder both off-policy policy evaluation and control settings and derive online\\nsample-based algorithms. We believe this is the first return-based off-policy\\ncontrol algorithm converging a.s. to $Q^*$ without the GLIE assumption (Greedy\\nin the Limit with Infinite Exploration). As a corollary, we prove the\\nconvergence of Watkins\\' Q($\\\\lambda$), which was an open problem since 1989. We\\nillustrate the benefits of Retrace($\\\\lambda$) on a standard suite of Atari 2600\\ngames.\\n\\n    ', '\\nAbstract:  State of the art deep reinforcement learning algorithms take many millions of\\ninteractions to attain human-level performance. Humans, on the other hand, can\\nvery quickly exploit highly rewarding nuances of an environment upon first\\ndiscovery. In the brain, such rapid learning is thought to depend on the\\nhippocampus and its capacity for episodic memory. Here we investigate whether a\\nsimple model of hippocampal episodic control can learn to solve difficult\\nsequential decision-making tasks. We demonstrate that it not only attains a\\nhighly rewarding strategy significantly faster than state-of-the-art deep\\nreinforcement learning algorithms, but also achieves a higher overall reward on\\nsome of the more challenging domains.\\n\\n    ', '\\nAbstract:  Learning robust value functions given raw observations and rewards is now\\npossible with model-free and model-based deep reinforcement learning\\nalgorithms. There is a third alternative, called Successor Representations\\n(SR), which decomposes the value function into two components -- a reward\\npredictor and a successor map. The successor map represents the expected future\\nstate occupancy from any given state and the reward predictor maps states to\\nscalar rewards. The value function of a state can be computed as the inner\\nproduct between the successor map and the reward weights. In this paper, we\\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\\nlearning framework. DSR has several appealing properties including: increased\\nsensitivity to distal reward changes due to factorization of reward and world\\ndynamics, and the ability to extract bottleneck states (subgoals) given\\nsuccessor maps trained under a random policy. We show the efficacy of our\\napproach on two diverse environments given raw pixel observations -- simple\\ngrid-world domains (MazeBase) and the Doom game engine.\\n\\n    ', \"\\nAbstract:  We consider an agent's uncertainty about its environment and the problem of\\ngeneralizing this uncertainty across observations. Specifically, we focus on\\nthe problem of exploration in non-tabular reinforcement learning. Drawing\\ninspiration from the intrinsic motivation literature, we use density models to\\nmeasure uncertainty, and propose a novel algorithm for deriving a pseudo-count\\nfrom an arbitrary density model. This technique enables us to generalize\\ncount-based exploration algorithms to the non-tabular case. We apply our ideas\\nto Atari 2600 games, providing sensible pseudo-counts from raw pixels. We\\ntransform these pseudo-counts into intrinsic rewards and obtain significantly\\nimproved exploration in a number of hard games, including the infamously\\ndifficult Montezuma's Revenge.\\n\\n    \", '\\nAbstract:  Partially observed control problems are a challenging aspect of reinforcement\\nlearning. We extend two related, model-free algorithms for continuous control\\n-- deterministic policy gradient and stochastic value gradient -- to solve\\npartially observed domains using recurrent neural networks trained with\\nbackpropagation through time.\\nWe demonstrate that this approach, coupled with long-short term memory is\\nable to solve a variety of physical control problems exhibiting an assortment\\nof memory requirements. These include the short-term integration of information\\nfrom noisy sensors and the identification of system parameters, as well as\\nlong-term memory problems that require preserving information over many time\\nsteps. We also demonstrate success on a combined exploration and memory problem\\nin the form of a simplified version of the well-known Morris water maze task.\\nFinally, we show that our approach can deal with high-dimensional observations\\nby learning directly from pixels.\\nWe find that recurrent deterministic and stochastic policies are able to\\nlearn similarly good solutions to these tasks, including the water maze where\\nthe agent must learn effective search strategies.\\n\\n    ', '\\nAbstract:  In this paper, we introduce a new set of reinforcement learning (RL) tasks in\\nMinecraft (a flexible 3D world). We then use these tasks to systematically\\ncompare and contrast existing deep reinforcement learning (DRL) architectures\\nwith our new memory-based DRL architectures. These tasks are designed to\\nemphasize, in a controllable manner, issues that pose challenges for RL methods\\nincluding partial observability (due to first-person visual observations),\\ndelayed rewards, high-dimensional visual observations, and the need to use\\nactive perception in a correct manner so as to perform well in the tasks. While\\nthese tasks are conceptually simple to describe, by virtue of having all of\\nthese challenges simultaneously they are difficult for current DRL\\narchitectures. Additionally, we evaluate the generalization performance of the\\narchitectures on environments not used during training. The experimental\\nresults show that our new architectures generalize to unseen environments\\nbetter than existing DRL architectures.\\n\\n    ', '\\nAbstract:  Deep Reinforcement Learning methods have achieved state of the art\\nperformance in learning control policies for the games in the Atari 2600\\ndomain. One of the important parameters in the Arcade Learning Environment\\n(ALE) is the frame skip rate. It decides the granularity at which agents can\\ncontrol game play. A frame skip value of $k$ allows the agent to repeat a\\nselected action $k$ number of times. The current state of the art architectures\\nlike Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of\\na framework with a static frame skip rate, where the action output from the\\nnetwork is repeated for a fixed number of frames regardless of the current\\nstate. In this paper, we propose a new architecture, Dynamic Frame skip Deep\\nQ-Network (DFDQN) which makes the frame skip rate a dynamic learnable\\nparameter. This allows us to choose the number of times an action is to be\\nrepeated based on the current state. We show empirically that such a setting\\nimproves the performance on relatively harder games like Seaquest.\\n\\n    ', '\\nAbstract:  This paper introduces an automated skill acquisition framework in\\nreinforcement learning which involves identifying a hierarchical description of\\nthe given task in terms of abstract states and extended actions between\\nabstract states. Identifying such structures present in the task provides ways\\nto simplify and speed up reinforcement learning algorithms. These structures\\nalso help to generalize such algorithms over multiple tasks without relearning\\npolicies from scratch. We use ideas from dynamical systems to find metastable\\nregions in the state space and associate them with abstract states. The\\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\\naligned to the underlying structure. Skills are defined in terms of the\\nsequence of actions that lead to transitions between such abstract states. The\\nconnectivity information from PCCA+ is used to generate these skills or\\noptions. These skills are independent of the learning task and can be\\nefficiently reused across a variety of tasks defined over the same model. This\\napproach works well even without the exact model of the environment by using\\nsample trajectories to construct an approximate estimate. We also present our\\napproach to scaling the skill acquisition framework to complex tasks with large\\nstate spaces for which we perform state aggregation using the representation\\nlearned from an action conditional video prediction network and use the skill\\nacquisition framework on the aggregated state space.\\n\\n    ', '\\nAbstract:  Recently, researchers have made significant progress combining the advances\\nin deep learning for learning feature representations with reinforcement\\nlearning. Some notable examples include training agents to play Atari games\\nbased on raw pixel data and to acquire advanced manipulation skills using raw\\nsensory inputs. However, it has been difficult to quantify progress in the\\ndomain of continuous control due to the lack of a commonly adopted benchmark.\\nIn this work, we present a benchmark suite of continuous control tasks,\\nincluding classic tasks like cart-pole swing-up, tasks with very high state and\\naction dimensionality such as 3D humanoid locomotion, tasks with partial\\nobservations, and tasks with hierarchical structure. We report novel findings\\nbased on the systematic evaluation of a range of implemented reinforcement\\nlearning algorithms. Both the benchmark and reference implementations are\\nreleased at this https URL in order to facilitate experimental\\nreproducibility and to encourage adoption by other researchers.\\n\\n    ', \"\\nAbstract:  Learning goal-directed behavior in environments with sparse feedback is a\\nmajor challenge for reinforcement learning algorithms. The primary difficulty\\narises due to insufficient exploration, resulting in an agent being unable to\\nlearn robust value functions. Intrinsically motivated agents can explore new\\nbehavior for its own sake rather than to directly solve problems. Such\\nintrinsic behaviors could eventually help the agent solve tasks posed by the\\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\\nhierarchical value functions, operating at different temporal scales, with\\nintrinsically motivated deep reinforcement learning. A top-level value function\\nlearns a policy over intrinsic goals, and a lower-level function learns a\\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\\nflexible goal specifications, such as functions over entities and relations.\\nThis provides an efficient space for exploration in complicated environments.\\nWe demonstrate the strength of our approach on two problems with very sparse,\\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\\nthe classic ATARI game `Montezuma's Revenge'.\\n\\n    \", '\\nAbstract:  We describe a learning-based approach to hand-eye coordination for robotic\\ngrasping from monocular images. To learn hand-eye coordination for grasping, we\\ntrained a large convolutional neural network to predict the probability that\\ntask-space motion of the gripper will result in successful grasps, using only\\nmonocular camera images and independently of camera calibration or the current\\nrobot pose. This requires the network to observe the spatial relationship\\nbetween the gripper and objects in the scene, thus learning hand-eye\\ncoordination. We then use this network to servo the gripper in real time to\\nachieve successful grasps. To train our network, we collected over 800,000\\ngrasp attempts over the course of two months, using between 6 and 14 robotic\\nmanipulators at any given time, with differences in camera placement and\\nhardware. Our experimental evaluation demonstrates that our method achieves\\neffective real-time control, can successfully grasp novel objects, and corrects\\nmistakes by continuous servoing.\\n\\n    ', '\\nAbstract:  Model-free reinforcement learning has been successfully applied to a range of\\nchallenging problems, and has recently been extended to handle large neural\\nnetwork policies and value functions. However, the sample complexity of\\nmodel-free algorithms, particularly when using high-dimensional function\\napproximators, tends to limit their applicability to physical systems. In this\\npaper, we explore algorithms and representations to reduce the sample\\ncomplexity of deep reinforcement learning for continuous control tasks. We\\npropose two complementary techniques for improving the efficiency of such\\nalgorithms. First, we derive a continuous variant of the Q-learning algorithm,\\nwhich we call normalized adantage functions (NAF), as an alternative to the\\nmore commonly used policy gradient and actor-critic methods. NAF representation\\nallows us to apply Q-learning with experience replay to continuous tasks, and\\nsubstantially improves performance on a set of simulated robotic control tasks.\\nTo further improve the efficiency of our approach, we explore the use of\\nlearned models for accelerating model-free reinforcement learning. We show that\\niteratively refitted local linear models are especially effective for this, and\\ndemonstrate substantially faster learning on domains where such models are\\napplicable.\\n\\n    ', '\\nAbstract:  Reinforcement learning can acquire complex behaviors from high-level\\nspecifications. However, defining a cost function that can be optimized\\neffectively and encodes the correct task is challenging in practice. We explore\\nhow inverse optimal control (IOC) can be used to learn behaviors from\\ndemonstrations, with applications to torque control of high-dimensional robotic\\nsystems. Our method addresses two key challenges in inverse optimal control:\\nfirst, the need for informative features and effective regularization to impose\\nstructure on the cost, and second, the difficulty of learning the cost function\\nunder unknown dynamics for high-dimensional continuous systems. To address the\\nformer challenge, we present an algorithm capable of learning arbitrary\\nnonlinear cost functions, such as neural networks, without meticulous feature\\nengineering. To address the latter challenge, we formulate an efficient\\nsample-based approximation for MaxEnt IOC. We evaluate our method on a series\\nof simulated tasks and real-world robotic manipulation problems, demonstrating\\nsubstantial improvement over prior methods both in terms of task complexity and\\nsample efficiency.\\n\\n    ', '\\nAbstract:  Efficient exploration in complex environments remains a major challenge for\\nreinforcement learning. We propose bootstrapped DQN, a simple algorithm that\\nexplores in a computationally and statistically efficient manner through use of\\nrandomized value functions. Unlike dithering strategies such as epsilon-greedy\\nexploration, bootstrapped DQN carries out temporally-extended (or deep)\\nexploration; this can lead to exponentially faster learning. We demonstrate\\nthese benefits in complex stochastic MDPs and in the large-scale Arcade\\nLearning Environment. Bootstrapped DQN substantially improves learning times\\nand performance across most Atari games.\\n\\n    ', \"\\nAbstract:  We introduce the value iteration network (VIN): a fully differentiable neural\\nnetwork with a `planning module' embedded within. VINs can learn to plan, and\\nare suitable for predicting outcomes that involve planning-based reasoning,\\nsuch as policies for reinforcement learning. Key to our approach is a novel\\ndifferentiable approximation of the value-iteration algorithm, which can be\\nrepresented as a convolutional neural network, and trained end-to-end using\\nstandard backpropagation. We evaluate VIN based policies on discrete and\\ncontinuous path-planning domains, and on a natural-language based search task.\\nWe show that by learning an explicit planning computation, VIN policies\\ngeneralize better to new, unseen domains.\\n\\n    \", '\\nAbstract:  We propose deep distributed recurrent Q-networks (DDRQN), which enable teams\\nof agents to learn to solve communication-based coordination tasks. In these\\ntasks, the agents are not given any pre-designed communication protocol.\\nTherefore, in order to successfully communicate, they must first automatically\\ndevelop and agree upon their own communication protocol. We present empirical\\nresults on two multi-agent learning problems based on well-known riddles,\\ndemonstrating that DDRQN can successfully solve such tasks and discover elegant\\ncommunication protocols to do so. To our knowledge, this is the first time deep\\nreinforcement learning has succeeded in learning communication protocols. In\\naddition, we present ablation experiments that confirm that each of the main\\ncomponents of the DDRQN architecture are critical to its success.\\n\\n    ', '\\nAbstract:  We propose a conceptually simple and lightweight framework for deep\\nreinforcement learning that uses asynchronous gradient descent for optimization\\nof deep neural network controllers. We present asynchronous variants of four\\nstandard reinforcement learning algorithms and show that parallel\\nactor-learners have a stabilizing effect on training allowing all four methods\\nto successfully train neural network controllers. The best performing method,\\nan asynchronous variant of actor-critic, surpasses the current state-of-the-art\\non the Atari domain while training for half the time on a single multi-core CPU\\ninstead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds\\non a wide variety of continuous motor control problems as well as on a new task\\nof navigating random 3D mazes using a visual input.\\n\\n    ', 'It is pdf', \"\\nAbstract:  This paper introduces new optimality-preserving operators on Q-functions. We\\nfirst describe an operator for tabular representations, the consistent Bellman\\noperator, which incorporates a notion of local policy consistency. We show that\\nthis local consistency leads to an increase in the action gap at each state;\\nincreasing this gap, we argue, mitigates the undesirable effects of\\napproximation and estimation errors on the induced greedy policies. This\\noperator can also be applied to discretized continuous space and time problems,\\nand we provide empirical results evidencing superior performance in this\\ncontext. Extending the idea of a locally consistent operator, we then derive\\nsufficient conditions for an operator to preserve optimality, leading to a\\nfamily of operators which includes our consistent Bellman operator. As\\ncorollaries we provide a proof of optimality for Baird's advantage learning\\nalgorithm and derive other gap-increasing operators with interesting\\nproperties. We conclude with an empirical study on 60 Atari 2600 games\\nillustrating the strong potential of these new operators.\\n\\n    \", 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', 'It is pdf', '\\nAbstract:  Recently, Neural Architecture Search has achieved great success in\\nlarge-scale image classification. In contrast, there have been limited works\\nfocusing on architecture search for object detection, mainly because the costly\\nImageNet pre-training is always required for detectors. Training from scratch,\\nas a substitute, demands more epochs to converge and brings no computation\\nsaving. To overcome this obstacle, we introduce a practical neural architecture\\ntransformation search(NATS)algorithm for object detection in this paper.\\nInstead of searching and constructing an entire network, NATS explores the\\narchitecture space on the base of existing network and reusing its weights. We\\npropose a novel neural architecture search strategy in channel-level instead of\\npath-level and devise a search space specially targeting at object detection.\\nWith the combination of these two designs, an architecture transformation\\nscheme could be discovered to adapt a network designed for image classification\\nto task of object detection. Since our method is gradient-based and only\\nsearches for a transformation scheme, the weights of models pretrained\\ninImageNet could be utilized in both searching and retraining stage, which\\nmakes the whole process very efficient. The transformed network requires no\\nextra parameters and FLOPs, and is friendly to hardware optimization, which is\\npractical to use in real-time application. In experiments, we demonstrate the\\neffectiveness of NATSon networks like ResNet and ResNeXt. Our transformed\\nnetworks, combined with various detection frameworks, achieve significant\\nimprovements on the COCO dataset while keeping fast.\\n\\n    ', '\\nAbstract:  Rendering synthetic data (e.g., 3D CAD-rendered images) to generate\\nannotations for learning deep models in vision tasks has attracted increasing\\nattention in recent years. However, simply applying the models learnt on\\nsynthetic images may lead to high generalization error on real images due to\\ndomain shift. To address this issue, recent progress in cross-domain\\nrecognition has featured the Mean Teacher, which directly simulates\\nunsupervised domain adaptation as semi-supervised learning. The domain gap is\\nthus naturally bridged with consistency regularization in a teacher-student\\nscheme. In this work, we advance this Mean Teacher paradigm to be applicable\\nfor cross-domain detection. Specifically, we present Mean Teacher with Object\\nRelations (MTOR) that novelly remolds Mean Teacher under the backbone of Faster\\nR-CNN by integrating the object relations into the measure of consistency cost\\nbetween teacher and student modules. Technically, MTOR firstly learns\\nrelational graphs that capture similarities between pairs of regions for\\nteacher and student respectively. The whole architecture is then optimized with\\nthree consistency regularizations: 1) region-level consistency to align the\\nregion-level predictions between teacher and student, 2) inter-graph\\nconsistency for matching the graph structures between teacher and student, and\\n3) intra-graph consistency to enhance the similarity between regions of same\\nclass within the graph of student. Extensive experiments are conducted on the\\ntransfers across Cityscapes, Foggy Cityscapes, and SIM10k, and superior results\\nare reported when comparing to state-of-the-art approaches. More remarkably, we\\nobtain a new record of single model: 22.8% of mAP on Syn2Real detection\\ndataset.\\n\\n    ', '\\nAbstract:  Object detectors are usually equipped with backbone networks designed for\\nimage classification. It might be sub-optimal because of the gap between the\\ntasks of image classification and object detection. In this work, we present\\nDetNAS to use Neural Architecture Search (NAS) for the design of better\\nbackbones for object detection. It is non-trivial because detection training\\ntypically needs ImageNet pre-training while NAS systems require accuracies on\\nthe target detection task as supervisory signals. Based on the technique of\\none-shot supernet, which contains all possible networks in the search space, we\\npropose a framework for backbone search on object detection. We train the\\nsupernet under the typical detector training schedule: ImageNet pre-training\\nand detection fine-tuning. Then, the architecture search is performed on the\\ntrained supernet, using the detection task as the guidance. This framework\\nmakes NAS on backbones very efficient. In experiments, we show the\\neffectiveness of DetNAS on various detectors, for instance, one-stage RetinaNet\\nand the two-stage FPN. We empirically find that networks searched on object\\ndetection shows consistent superiority compared to those searched on ImageNet\\nclassification. The resulting architecture achieves superior performance than\\nhand-crafted networks on COCO with much less FLOPs complexity.\\n\\n    ', '\\nAbstract:  Conventional methods for object detection typically require a substantial\\namount of training data and preparing such high-quality training data is very\\nlabor-intensive. In this paper, we propose a novel few-shot object detection\\nnetwork that aims at detecting objects of unseen categories with only a few\\nannotated examples. Central to our method are our Attention-RPN, Multi-Relation\\nDetector and Contrastive Training strategy, which exploit the similarity\\nbetween the few shot support set and query set to detect novel objects while\\nsuppressing false detection in the background. To train our network, we\\ncontribute a new dataset that contains 1000 categories of various objects with\\nhigh-quality annotations. To the best of our knowledge, this is one of the\\nfirst datasets specifically designed for few-shot object detection. Once our\\nfew-shot network is trained, it can detect objects of unseen categories without\\nfurther training or fine-tuning. Our method is general and has a wide range of\\npotential applications. We produce a new state-of-the-art performance on\\ndifferent datasets in the few-shot setting. The dataset link is\\nthis https URL.\\n\\n    ', '\\nAbstract:  Modern CNN-based object detectors assign anchors for ground-truth objects\\nunder the restriction of object-anchor Intersection-over-Unit (IoU). In this\\nstudy, we propose a learning-to-match approach to break IoU restriction,\\nallowing objects to match anchors in a flexible manner. Our approach, referred\\nto as FreeAnchor, updates hand-crafted anchor assignment to \"free\" anchor\\nmatching by formulating detector training as a maximum likelihood estimation\\n(MLE) procedure. FreeAnchor targets at learning features which best explain a\\nclass of objects in terms of both classification and localization. FreeAnchor\\nis implemented by optimizing detection customized likelihood and can be fused\\nwith CNN-based detectors in a plug-and-play manner. Experiments on COCO\\ndemonstrate that FreeAnchor consistently outperforms their counterparts with\\nsignificant margins.\\n\\n    ', '\\nAbstract:  The use of object detection algorithms is becoming increasingly important in\\nautonomous vehicles, and object detection at high accuracy and a fast inference\\nspeed is essential for safe autonomous driving. A false positive (FP) from a\\nfalse localization during autonomous driving can lead to fatal accidents and\\nhinder safe and efficient driving. Therefore, a detection algorithm that can\\ncope with mislocalizations is required in autonomous driving applications. This\\npaper proposes a method for improving the detection accuracy while supporting a\\nreal-time operation by modeling the bounding box (bbox) of YOLOv3, which is the\\nmost representative of one-stage detectors, with a Gaussian parameter and\\nredesigning the loss function. In addition, this paper proposes a method for\\npredicting the localization uncertainty that indicates the reliability of bbox.\\nBy using the predicted localization uncertainty during the detection process,\\nthe proposed schemes can significantly reduce the FP and increase the true\\npositive (TP), thereby improving the accuracy. Compared to a conventional\\nYOLOv3, the proposed algorithm, Gaussian YOLOv3, improves the mean average\\nprecision (mAP) by 3.09 and 3.5 on the KITTI and Berkeley deep drive (BDD)\\ndatasets, respectively. Nevertheless, the proposed algorithm is capable of\\nreal-time detection at faster than 42 frames per second (fps) and shows a\\nhigher accuracy than previous approaches with a similar fps. Therefore, the\\nproposed algorithm is the most suitable for autonomous driving applications.\\n\\n    ', '\\nAbstract:  Learning to localize and name object instances is a fundamental problem in\\nvision, but state-of-the-art approaches rely on expensive bounding box\\nsupervision. While weakly supervised detection (WSOD) methods relax the need\\nfor boxes to that of image-level annotations, even cheaper supervision is\\nnaturally available in the form of unstructured textual descriptions that users\\nmay freely provide when uploading image content. However, straightforward\\napproaches to using such data for WSOD wastefully discard captions that do not\\nexactly match object names. Instead, we show how to squeeze the most\\ninformation out of these captions by training a text-only classifier that\\ngeneralizes beyond dataset boundaries. Our discovery provides an opportunity\\nfor learning detection models from noisy but more abundant and freely-available\\ncaption data. We also validate our model on three classic object detection\\nbenchmarks and achieve state-of-the-art WSOD performance. Our code is available\\nat this https URL.\\n\\n    ', '\\nAbstract:  Recent advances in deep learning greatly boost the performance of object\\ndetection. State-of-the-art methods such as Faster-RCNN, FPN and R-FCN have\\nachieved high accuracy in challenging benchmark datasets. However, these\\nmethods require fully annotated object bounding boxes for training, which are\\nincredibly hard to scale up due to the high annotation cost. Weakly-supervised\\nmethods, on the other hand, only require image-level labels for training, but\\nthe performance is far below their fully-supervised counterparts. In this\\npaper, we propose a semi-supervised large scale fine-grained detection method,\\nwhich only needs bounding box annotations of a smaller number of coarse-grained\\nclasses and image-level labels of large scale fine-grained classes, and can\\ndetect all classes at nearly fully-supervised accuracy. We achieve this by\\nutilizing the correlations between coarse-grained and fine-grained classes with\\nshared backbone, soft-attention based proposal re-ranking, and a dual-level\\nmemory module. Experiment results show that our methods can achieve close\\naccuracy on object detection to state-of-the-art fully-supervised methods on\\ntwo large scale datasets, ImageNet and OpenImages, with only a small fraction\\nof fully annotated classes.\\n\\n    ', '\\nAbstract:  Modern object detectors rely heavily on rectangular bounding boxes, such as\\nanchors, proposals and the final predictions, to represent objects at various\\nrecognition stages. The bounding box is convenient to use but provides only a\\ncoarse localization of objects and leads to a correspondingly coarse extraction\\nof object features. In this paper, we present \\\\textbf{RepPoints}\\n(representative points), a new finer representation of objects as a set of\\nsample points useful for both localization and recognition. Given ground truth\\nlocalization and recognition targets for training, RepPoints learn to\\nautomatically arrange themselves in a manner that bounds the spatial extent of\\nan object and indicates semantically significant local areas. They furthermore\\ndo not require the use of anchors to sample a space of bounding boxes. We show\\nthat an anchor-free object detector based on RepPoints can be as effective as\\nthe state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4\\n$AP_{50}$ on the COCO test-dev detection benchmark, using ResNet-101 model.\\nCode is available at this https URL.\\n\\n    ', '\\nAbstract:  We propose a fully convolutional one-stage object detector (FCOS) to solve\\nobject detection in a per-pixel prediction fashion, analogue to semantic\\nsegmentation. Almost all state-of-the-art object detectors such as RetinaNet,\\nSSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast,\\nour proposed detector FCOS is anchor box free, as well as proposal free. By\\neliminating the predefined set of anchor boxes, FCOS completely avoids the\\ncomplicated computation related to anchor boxes such as calculating overlapping\\nduring training. More importantly, we also avoid all hyper-parameters related\\nto anchor boxes, which are often very sensitive to the final detection\\nperformance. With the only post-processing non-maximum suppression (NMS), FCOS\\nwith ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale\\ntesting, surpassing previous one-stage detectors with the advantage of being\\nmuch simpler. For the first time, we demonstrate a much simpler and flexible\\ndetection framework achieving improved detection accuracy. We hope that the\\nproposed FCOS framework can serve as a simple and strong alternative for many\\nother instance-level tasks. Code is available at:Code is available at:\\nthis https URL\\n', '\\nAbstract:  Scale-sensitive object detection remains a challenging task, where most of\\nthe existing methods could not learn it explicitly and are not robust to scale\\nvariance. In addition, the most existing methods are less efficient during\\ntraining or slow during inference, which are not friendly to real-time\\napplications. In this paper, we propose a practical object detection method\\nwith scale-sensitive network.Our method first predicts a global continuous\\nscale ,which is shared by all position, for each convolution filter of each\\nnetwork stage. To effectively learn the scale, we average the spatial features\\nand distill the scale from channels. For fast-deployment, we propose a scale\\ndecomposition method that transfers the robust fractional scale into\\ncombination of fixed integral scales for each convolution filter, which\\nexploits the dilated convolution. We demonstrate it on one-stage and two-stage\\nalgorithms under different configurations. For practical applications, training\\nof our method is of efficiency and simplicity which gets rid of complex data\\nsampling or optimize strategy. During test-ing, the proposed method requires no\\nextra operation and is very supportive of hardware acceleration like TensorRT\\nand TVM. On the COCO test-dev, our model could achieve a 41.5 mAP on one-stage\\ndetector and 42.1 mAP on two-stage detectors based on ResNet-101, outperforming\\nbase-lines by 2.4 and 2.1 respectively without extra FLOPS.\\n\\n    ', '\\nAbstract:  The labeling cost of large number of bounding boxes is one of the main\\nchallenges for training modern object detectors. To reduce the dependence on\\nexpensive bounding box annotations, we propose a new semi-supervised object\\ndetection formulation, in which a few seed box level annotations and a large\\nscale of image level annotations are used to train the detector. We adopt a\\ntraining-mining framework, which is widely used in weakly supervised object\\ndetection tasks. However, the mining process inherently introduces various\\nkinds of labelling noises: false negatives, false positives and inaccurate\\nboundaries, which can be harmful for training the standard object detectors\\n(e.g. Faster RCNN). We propose a novel NOise Tolerant Ensemble RCNN (NOTE-RCNN)\\nobject detector to handle such noisy labels. Comparing to standard Faster RCNN,\\nit contains three highlights: an ensemble of two classification heads and a\\ndistillation head to avoid overfitting on noisy labels and improve the mining\\nprecision, masking the negative sample loss in box predictor to avoid the harm\\nof false negative labels, and training box regression head only on seed\\nannotations to eliminate the harm from inaccurate boundaries of mined bounding\\nboxes. We evaluate the methods on ILSVRC 2013 and MSCOCO 2017 dataset; we\\nobserve that the detection accuracy consistently improves as we iterate between\\nmining and training steps, and state-of-the-art performance is achieved.\\n\\n    ', '\\nAbstract:  Video objection detection (VID) has been a rising research direction in\\nrecent years. A central issue of VID is the appearance degradation of video\\nframes caused by fast motion. This problem is essentially ill-posed for a\\nsingle frame. Therefore, aggregating features from other frames becomes a\\nnatural choice. Existing methods rely heavily on optical flow or recurrent\\nneural networks for feature aggregation. However, these methods emphasize more\\non the temporally nearby frames. In this work, we argue that aggregating\\nfeatures in the full-sequence level will lead to more discriminative and robust\\nfeatures for video object detection. To achieve this goal, we devise a novel\\nSequence Level Semantics Aggregation (SELSA) module. We further demonstrate the\\nclose relationship between the proposed method and the classic spectral\\nclustering method, providing a novel view for understanding the VID problem. We\\ntest the proposed method on the ImageNet VID and the EPIC KITCHENS dataset and\\nachieve new state-of-the-art results. Our method does not need complicated\\npostprocessing methods such as Seq-NMS or Tubelet rescoring, which keeps the\\npipeline simple and clean.\\n\\n    ', '\\nAbstract:  Current CNN-based solutions to salient object detection (SOD) mainly rely on\\nthe optimization of cross-entropy loss (CELoss). Then the quality of detected\\nsaliency maps is often evaluated in terms of F-measure. In this paper, we\\ninvestigate an interesting issue: can we consistently use the F-measure\\nformulation in both training and evaluation for SOD? By reformulating the\\nstandard F-measure we propose the relaxed F-measure which is differentiable\\nw.r.t the posterior and can be easily appended to the back of CNNs as the loss\\nfunction. Compared to the conventional cross-entropy loss of which the\\ngradients decrease dramatically in the saturated area, our loss function, named\\nFLoss, holds considerable gradients even when the activation approaches the\\ntarget. Consequently, the FLoss can continuously force the network to produce\\npolarized activations. Comprehensive benchmarks on several popular datasets\\nshow that FLoss outperforms the state-of-the-art with a considerable margin.\\nMore specifically, due to the polarized predictions, our method is able to\\nobtain high-quality saliency maps without carefully tuning the optimal\\nthreshold, showing significant advantages in real-world applications.\\n\\n    ', '\\nAbstract:  Fully convolutional neural networks (FCNs) have shown their advantages in the\\nsalient object detection task. However, most existing FCNs-based methods still\\nsuffer from coarse object boundaries. In this paper, to solve this problem, we\\nfocus on the complementarity between salient edge information and salient\\nobject information. Accordingly, we present an edge guidance network (EGNet)\\nfor salient object detection with three steps to simultaneously model these two\\nkinds of complementary information in a single network. In the first step, we\\nextract the salient object features by a progressive fusion way. In the second\\nstep, we integrate the local edge information and global location information\\nto obtain the salient edge features. Finally, to sufficiently leverage these\\ncomplementary features, we couple the same salient edge features with salient\\nobject features at various resolutions. Benefiting from the rich edge\\ninformation and location information in salient edge features, the fused\\nfeatures can help locate salient objects, especially their boundaries more\\naccurately. Experimental results demonstrate that the proposed method performs\\nfavorably against the state-of-the-art methods on six widely used datasets\\nwithout any pre-processing and post-processing. The source code is available at\\nhttp: //mmcheng.net/egnet/.\\n\\n    ', '\\nAbstract:  Conventional training of a deep CNN based object detector demands a large\\nnumber of bounding box annotations, which may be unavailable for rare\\ncategories. In this work we develop a few-shot object detector that can learn\\nto detect novel objects from only a few annotated examples. Our proposed model\\nleverages fully labeled base classes and quickly adapts to novel classes, using\\na meta feature learner and a reweighting module within a one-stage detection\\narchitecture. The feature learner extracts meta features that are generalizable\\nto detect novel object classes, using training data from base classes with\\nsufficient samples. The reweighting module transforms a few support examples\\nfrom the novel classes to a global vector that indicates the importance or\\nrelevance of meta features for detecting the corresponding objects. These two\\nmodules, together with a detection prediction module, are trained end-to-end\\nbased on an episodic few-shot learning scheme and a carefully designed loss\\nfunction. Through extensive experiments we demonstrate that our model\\noutperforms well-established baselines by a large margin for few-shot object\\ndetection, on multiple datasets and settings. We also present analysis on\\nvarious aspects of our proposed model, aiming to provide some inspiration for\\nfuture few-shot detection works.\\n\\n    ', '\\nAbstract:  Detecting objects in aerial images is challenging for at least two reasons:\\n(1) target objects like pedestrians are very small in pixels, making them\\nhardly distinguished from surrounding background; and (2) targets are in\\ngeneral sparsely and non-uniformly distributed, making the detection very\\ninefficient. In this paper, we address both issues inspired by observing that\\nthese targets are often clustered. In particular, we propose a Clustered\\nDetection (ClusDet) network that unifies object clustering and detection in an\\nend-to-end framework. The key components in ClusDet include a cluster proposal\\nsub-network (CPNet), a scale estimation sub-network (ScaleNet), and a dedicated\\ndetection network (DetecNet). Given an input image, CPNet produces object\\ncluster regions and ScaleNet estimates object scales for these regions. Then,\\neach scale-normalized cluster region is fed into DetecNet for object detection.\\nClusDet has several advantages over previous solutions: (1) it greatly reduces\\nthe number of chips for final object detection and hence achieves high running\\ntime efficiency, (2) the cluster-based scale estimation is more accurate than\\npreviously used single-object based ones, hence effectively improves the\\ndetection for small objects, and (3) the final DetecNet is dedicated for\\nclustered regions and implicitly models the prior context information so as to\\nboost detection accuracy. The proposed method is tested on three popular aerial\\nimage datasets including VisDrone, UAVDT and DOTA. In all experiments, ClusDet\\nachieves promising performance in comparison with state-of-the-art detectors.\\nCode will be available in \\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  Deep learning-based video salient object detection has recently achieved\\ngreat success with its performance significantly outperforming any other\\nunsupervised methods. However, existing data-driven approaches heavily rely on\\na large quantity of pixel-wise annotated video frames to deliver such promising\\nresults. In this paper, we address the semi-supervised video salient object\\ndetection task using pseudo-labels. Specifically, we present an effective video\\nsaliency detector that consists of a spatial refinement network and a\\nspatiotemporal module. Based on the same refinement network and motion\\ninformation in terms of optical flow, we further propose a novel method for\\ngenerating pixel-level pseudo-labels from sparsely annotated frames. By\\nutilizing the generated pseudo-labels together with a part of manual\\nannotations, our video saliency detector learns spatial and temporal cues for\\nboth contrast inference and coherence enhancement, thus producing accurate\\nsaliency maps. Experimental results demonstrate that our proposed\\nsemi-supervised method even greatly outperforms all the state-of-the-art fully\\nsupervised methods across three public benchmarks of VOS, DAVIS, and FBMS.\\n\\n    ', '\\nAbstract:  Video salient object detection aims at discovering the most visually\\ndistinctive objects in a video. How to effectively take object motion into\\nconsideration during video salient object detection is a critical issue.\\nExisting state-of-the-art methods either do not explicitly model and harvest\\nmotion cues or ignore spatial contexts within optical flow images. In this\\npaper, we develop a multi-task motion guided video salient object detection\\nnetwork, which learns to accomplish two sub-tasks using two sub-networks, one\\nsub-network for salient object detection in still images and the other for\\nmotion saliency detection in optical flow images. We further introduce a series\\nof novel motion guided attention modules, which utilize the motion saliency\\nsub-network to attend and enhance the sub-network for still images. These two\\nsub-networks learn to adapt to each other by end-to-end training. Experimental\\nresults demonstrate that the proposed method significantly outperforms existing\\nstate-of-the-art algorithms on a wide range of benchmarks. We hope our simple\\nand effective approach will serve as a solid baseline and help ease future\\nresearch in video salient object detection. Code and models will be made\\navailable.\\n\\n    ', '\\nAbstract:  Deep neural network based methods have made a significant breakthrough in\\nsalient object detection. However, they are typically limited to input images\\nwith low resolutions ($400\\\\times400$ pixels or less). Little effort has been\\nmade to train deep neural networks to directly handle salient object detection\\nin very high-resolution images. This paper pushes forward high-resolution\\nsaliency detection, and contributes a new dataset, named High-Resolution\\nSalient Object Detection (HRSOD). To our best knowledge, HRSOD is the first\\nhigh-resolution saliency detection dataset to date. As another contribution, we\\nalso propose a novel approach, which incorporates both global semantic\\ninformation and local high-resolution details, to address this challenging\\ntask. More specifically, our approach consists of a Global Semantic Network\\n(GSN), a Local Refinement Network (LRN) and a Global-Local Fusion Network\\n(GLFN). GSN extracts the global semantic information based on down-sampled\\nentire image. Guided by the results of GSN, LRN focuses on some local regions\\nand progressively produces high-resolution predictions. GLFN is further\\nproposed to enforce spatial consistency and boost performance. Experiments\\nillustrate that our method outperforms existing state-of-the-art methods on\\nhigh-resolution saliency datasets by a large margin, and achieves comparable or\\neven better performance than them on widely-used saliency benchmarks. The HRSOD\\ndataset is available at this https URL.\\n\\n    ', '\\nAbstract:  State-of-the-art named entity recognition systems rely heavily on\\nhand-crafted features and domain-specific knowledge in order to learn\\neffectively from the small, supervised training corpora that are available. In\\nthis paper, we introduce two new neural architectures---one based on\\nbidirectional LSTMs and conditional random fields, and the other that\\nconstructs and labels segments using a transition-based approach inspired by\\nshift-reduce parsers. Our models rely on two sources of information about\\nwords: character-based word representations learned from the supervised corpus\\nand unsupervised word representations learned from unannotated corpora. Our\\nmodels obtain state-of-the-art performance in NER in four languages without\\nresorting to any language-specific knowledge or resources such as gazetteers.\\n\\n    ', '\\nAbstract:  In this work we explore recent advances in Recurrent Neural Networks for\\nlarge scale Language Modeling, a task central to language understanding. We\\nextend current models to deal with two key challenges present in this task:\\ncorpora and vocabulary sizes, and complex, long term structure of language. We\\nperform an exhaustive study on techniques such as character Convolutional\\nNeural Networks or Long-Short Term Memory, on the One Billion Word Benchmark.\\nOur best single model significantly improves state-of-the-art perplexity from\\n51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20),\\nwhile an ensemble of models sets a new record by improving perplexity from 41.0\\ndown to 23.7. We also release these models for the NLP and ML community to\\nstudy and improve upon.\\n\\n    ', '\\nAbstract:  Teaching machines to read natural language documents remains an elusive\\nchallenge. Machine reading systems can be tested on their ability to answer\\nquestions posed on the contents of documents that they have seen, but until now\\nlarge scale training and test datasets have been missing for this type of\\nevaluation. In this work we define a new methodology that resolves this\\nbottleneck and provides large scale supervised reading comprehension data. This\\nallows us to develop a class of attention based deep neural networks that learn\\nto read real documents and answer complex questions with minimal prior\\nknowledge of language structure.\\n\\n    ', \"\\nAbstract:  An attentional mechanism has lately been used to improve neural machine\\ntranslation (NMT) by selectively focusing on parts of the source sentence\\nduring translation. However, there has been little work exploring useful\\narchitectures for attention-based NMT. This paper examines two simple and\\neffective classes of attentional mechanism: a global approach which always\\nattends to all source words and a local one that only looks at a subset of\\nsource words at a time. We demonstrate the effectiveness of both approaches\\nover the WMT translation tasks between English and German in both directions.\\nWith local attention, we achieve a significant gain of 5.0 BLEU points over\\nnon-attentional systems which already incorporate known techniques such as\\ndropout. Our ensemble model using different attention architectures has\\nestablished a new state-of-the-art result in the WMT'15 English to German\\ntranslation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over\\nthe existing best system backed by NMT and an n-gram reranker.\\n\\n    \", '\\nAbstract:  Pixel-level labelling tasks, such as semantic segmentation, play a central\\nrole in image understanding. Recent approaches have attempted to harness the\\ncapabilities of deep learning techniques for image recognition to tackle\\npixel-level labelling tasks. One central issue in this methodology is the\\nlimited capacity of deep learning techniques to delineate visual objects. To\\nsolve this problem, we introduce a new form of convolutional neural network\\nthat combines the strengths of Convolutional Neural Networks (CNNs) and\\nConditional Random Fields (CRFs)-based probabilistic graphical modelling. To\\nthis end, we formulate mean-field approximate inference for the Conditional\\nRandom Fields with Gaussian pairwise potentials as Recurrent Neural Networks.\\nThis network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a\\ndeep network that has desirable properties of both CNNs and CRFs. Importantly,\\nour system fully integrates CRF modelling with CNNs, making it possible to\\ntrain the whole deep network end-to-end with the usual back-propagation\\nalgorithm, avoiding offline post-processing methods for object delineation. We\\napply the proposed method to the problem of semantic image segmentation,\\nobtaining top results on the challenging Pascal VOC 2012 segmentation\\nbenchmark.\\n\\n    ', '\\nAbstract:  We extend the capabilities of neural networks by coupling them to external\\nmemory resources, which they can interact with by attentional processes. The\\ncombined system is analogous to a Turing Machine or Von Neumann architecture\\nbut is differentiable end-to-end, allowing it to be efficiently trained with\\ngradient descent. Preliminary results demonstrate that Neural Turing Machines\\ncan infer simple algorithms such as copying, sorting, and associative recall\\nfrom input and output examples.\\n\\n    ', '\\nAbstract:  We describe a new class of learning models called memory networks. Memory\\nnetworks reason with inference components combined with a long-term memory\\ncomponent; they learn how to use these jointly. The long-term memory can be\\nread and written to, with the goal of using it for prediction. We investigate\\nthese models in the context of question answering (QA) where the long-term\\nmemory effectively acts as a (dynamic) knowledge base, and the output is a\\ntextual response. We evaluate them on a large-scale QA task, and a smaller, but\\nmore complex, toy task generated from a simulated world. In the latter, we show\\nthe reasoning power of such models by chaining multiple supporting sentences to\\nanswer questions that require understanding the intension of verbs.\\n\\n    ', '\\nAbstract:  Neural machine translation is a recently proposed approach to machine\\ntranslation. Unlike the traditional statistical machine translation, the neural\\nmachine translation aims at building a single neural network that can be\\njointly tuned to maximize the translation performance. The models proposed\\nrecently for neural machine translation often belong to a family of\\nencoder-decoders and consists of an encoder that encodes a source sentence into\\na fixed-length vector from which a decoder generates a translation. In this\\npaper, we conjecture that the use of a fixed-length vector is a bottleneck in\\nimproving the performance of this basic encoder-decoder architecture, and\\npropose to extend this by allowing a model to automatically (soft-)search for\\nparts of a source sentence that are relevant to predicting a target word,\\nwithout having to form these parts as a hard segment explicitly. With this new\\napproach, we achieve a translation performance comparable to the existing\\nstate-of-the-art phrase-based system on the task of English-to-French\\ntranslation. Furthermore, qualitative analysis reveals that the\\n(soft-)alignments found by the model agree well with our intuition.\\n\\n    ', \"\\nAbstract:  Deep Neural Networks (DNNs) are powerful models that have achieved excellent\\nperformance on difficult learning tasks. Although DNNs work well whenever large\\nlabeled training sets are available, they cannot be used to map sequences to\\nsequences. In this paper, we present a general end-to-end approach to sequence\\nlearning that makes minimal assumptions on the sequence structure. Our method\\nuses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to\\na vector of a fixed dimensionality, and then another deep LSTM to decode the\\ntarget sequence from the vector. Our main result is that on an English to\\nFrench translation task from the WMT'14 dataset, the translations produced by\\nthe LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's\\nBLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did\\nnot have difficulty on long sentences. For comparison, a phrase-based SMT\\nsystem achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM\\nto rerank the 1000 hypotheses produced by the aforementioned SMT system, its\\nBLEU score increases to 36.5, which is close to the previous best result on\\nthis task. The LSTM also learned sensible phrase and sentence representations\\nthat are sensitive to word order and are relatively invariant to the active and\\nthe passive voice. Finally, we found that reversing the order of the words in\\nall source sentences (but not target sentences) improved the LSTM's performance\\nmarkedly, because doing so introduced many short term dependencies between the\\nsource and the target sentence which made the optimization problem easier.\\n\\n    \", '\\nAbstract:  In this paper, we propose a novel neural network model called RNN\\nEncoder-Decoder that consists of two recurrent neural networks (RNN). One RNN\\nencodes a sequence of symbols into a fixed-length vector representation, and\\nthe other decodes the representation into another sequence of symbols. The\\nencoder and decoder of the proposed model are jointly trained to maximize the\\nconditional probability of a target sequence given a source sequence. The\\nperformance of a statistical machine translation system is empirically found to\\nimprove by using the conditional probabilities of phrase pairs computed by the\\nRNN Encoder-Decoder as an additional feature in the existing log-linear model.\\nQualitatively, we show that the proposed model learns a semantically and\\nsyntactically meaningful representation of linguistic phrases.\\n\\n    ', '\\nAbstract:  The ability to accurately represent sentences is central to language\\nunderstanding. We describe a convolutional architecture dubbed the Dynamic\\nConvolutional Neural Network (DCNN) that we adopt for the semantic modelling of\\nsentences. The network uses Dynamic k-Max Pooling, a global pooling operation\\nover linear sequences. The network handles input sentences of varying length\\nand induces a feature graph over the sentence that is capable of explicitly\\ncapturing short and long-range relations. The network does not rely on a parse\\ntree and is easily applicable to any language. We test the DCNN in four\\nexperiments: small scale binary and multi-class sentiment prediction, six-way\\nquestion classification and Twitter sentiment prediction by distant\\nsupervision. The network achieves excellent performance in the first three\\ntasks and a greater than 25% error reduction in the last task with respect to\\nthe strongest baseline.\\n\\n    ', '\\nAbstract:  Many machine learning algorithms require the input to be represented as a\\nfixed-length feature vector. When it comes to texts, one of the most common\\nfixed-length features is bag-of-words. Despite their popularity, bag-of-words\\nfeatures have two major weaknesses: they lose the ordering of the words and\\nthey also ignore semantics of the words. For example, \"powerful,\" \"strong\" and\\n\"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an\\nunsupervised algorithm that learns fixed-length feature representations from\\nvariable-length pieces of texts, such as sentences, paragraphs, and documents.\\nOur algorithm represents each document by a dense vector which is trained to\\npredict words in the document. Its construction gives our algorithm the\\npotential to overcome the weaknesses of bag-of-words models. Empirical results\\nshow that Paragraph Vectors outperform bag-of-words models as well as other\\ntechniques for text representations. Finally, we achieve new state-of-the-art\\nresults on several text classification and sentiment analysis tasks.\\n\\n    ', '\\nAbstract:  The recently introduced continuous Skip-gram model is an efficient method for\\nlearning high-quality distributed vector representations that capture a large\\nnumber of precise syntactic and semantic word relationships. In this paper we\\npresent several extensions that improve both the quality of the vectors and the\\ntraining speed. By subsampling of the frequent words we obtain significant\\nspeedup and also learn more regular word representations. We also describe a\\nsimple alternative to the hierarchical softmax called negative sampling. An\\ninherent limitation of word representations is their indifference to word order\\nand their inability to represent idiomatic phrases. For example, the meanings\\nof \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\".\\nMotivated by this example, we present a simple method for finding phrases in\\ntext, and show that learning good vector representations for millions of\\nphrases is possible.\\n\\n    ', '\\nAbstract:  We propose two novel model architectures for computing continuous vector\\nrepresentations of words from very large data sets. The quality of these\\nrepresentations is measured in a word similarity task, and the results are\\ncompared to the previously best performing techniques based on different types\\nof neural networks. We observe large improvements in accuracy at much lower\\ncomputational cost, i.e. it takes less than a day to learn high quality word\\nvectors from a 1.6 billion words data set. Furthermore, we show that these\\nvectors provide state-of-the-art performance on our test set for measuring\\nsyntactic and semantic word similarities.\\n\\n    ', '\\nAbstract:  This paper shows how Long Short-term Memory recurrent neural networks can be\\nused to generate complex sequences with long-range structure, simply by\\npredicting one data point at a time. The approach is demonstrated for text\\n(where the data are discrete) and online handwriting (where the data are\\nreal-valued). It is then extended to handwriting synthesis by allowing the\\nnetwork to condition its predictions on a text sequence. The resulting system\\nis able to generate highly realistic cursive handwriting in a wide variety of\\nstyles.\\n\\n    ', '\\nAbstract:  Many of the current state-of-the-art Large Vocabulary Continuous Speech\\nRecognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov\\nModels (HMMs). Most of these systems contain separate components that deal with\\nthe acoustic modelling, language modelling and sequence decoding. We\\ninvestigate a more direct approach in which the HMM is replaced with a\\nRecurrent Neural Network (RNN) that performs sequence prediction directly at\\nthe character level. Alignment between the input features and the desired\\ncharacter sequence is learned automatically by an attention mechanism built\\ninto the RNN. For each predicted character, the attention mechanism scans the\\ninput sequence and chooses relevant frames. We propose two methods to speed up\\nthis operation: limiting the scan to a subset of most promising frames and\\npooling over time the information contained in neighboring frames, thereby\\nreducing source sequence length. Integrating an n-gram language model into the\\ndecoding process yields recognition accuracies similar to other HMM-free\\nRNN-based approaches.\\n\\n    ', '\\nAbstract:  We show that an end-to-end deep learning approach can be used to recognize\\neither English or Mandarin Chinese speech--two vastly different languages.\\nBecause it replaces entire pipelines of hand-engineered components with neural\\nnetworks, end-to-end learning allows us to handle a diverse variety of speech\\nincluding noisy environments, accents and different languages. Key to our\\napproach is our application of HPC techniques, resulting in a 7x speedup over\\nour previous system. Because of this efficiency, experiments that previously\\ntook weeks now run in days. This enables us to iterate more quickly to identify\\nsuperior architectures and algorithms. As a result, in several cases, our\\nsystem is competitive with the transcription of human workers when benchmarked\\non standard datasets. Finally, using a technique called Batch Dispatch with\\nGPUs in the data center, we show that our system can be inexpensively deployed\\nin an online setting, delivering low latency when serving users at scale.\\n\\n    ', '\\nAbstract:  Recurrent neural networks (RNNs) are a powerful model for sequential data.\\nEnd-to-end training methods such as Connectionist Temporal Classification make\\nit possible to train RNNs for sequence labelling problems where the\\ninput-output alignment is unknown. The combination of these methods with the\\nLong Short-term Memory RNN architecture has proved particularly fruitful,\\ndelivering state-of-the-art results in cursive handwriting recognition. However\\nRNN performance in speech recognition has so far been disappointing, with\\nbetter results returned by deep feedforward networks. This paper investigates\\n\\\\emph{deep recurrent neural networks}, which combine the multiple levels of\\nrepresentation that have proved so effective in deep networks with the flexible\\nuse of long range context that empowers RNNs. When trained end-to-end with\\nsuitable regularisation, we find that deep Long Short-term Memory RNNs achieve\\na test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to\\nour knowledge is the best recorded score.\\n\\n    ', 'It is pdf', 'It is pdf', \"\\nAbstract:  Policy search methods can allow robots to learn control policies for a wide\\nrange of tasks, but practical applications of policy search often require\\nhand-engineered components for perception, state estimation, and low-level\\ncontrol. In this paper, we aim to answer the following question: does training\\nthe perception and control systems jointly end-to-end provide better\\nperformance than training each component separately? To this end, we develop a\\nmethod that can be used to learn policies that map raw image observations\\ndirectly to torques at the robot's motors. The policies are represented by deep\\nconvolutional neural networks (CNNs) with 92,000 parameters, and are trained\\nusing a partially observed guided policy search method, which transforms policy\\nsearch into supervised learning, with supervision provided by a simple\\ntrajectory-centric reinforcement learning method. We evaluate our method on a\\nrange of real-world manipulation tasks that require close coordination between\\nvision and control, such as screwing a cap onto a bottle, and present simulated\\ncomparisons to a range of prior policy search methods.\\n\\n    \", '\\nAbstract:  We adapt the ideas underlying the success of Deep Q-Learning to the\\ncontinuous action domain. We present an actor-critic, model-free algorithm\\nbased on the deterministic policy gradient that can operate over continuous\\naction spaces. Using the same learning algorithm, network architecture and\\nhyper-parameters, our algorithm robustly solves more than 20 simulated physics\\ntasks, including classic problems such as cartpole swing-up, dexterous\\nmanipulation, legged locomotion and car driving. Our algorithm is able to find\\npolicies whose performance is competitive with those found by a planning\\nalgorithm with full access to the dynamics of the domain and its derivatives.\\nWe further demonstrate that for many of the tasks the algorithm can learn\\npolicies end-to-end: directly from raw pixel inputs.\\n\\n    ', '\\nAbstract:  We consider the problem of detecting robotic grasps in an RGB-D view of a\\nscene containing objects. In this work, we apply a deep learning approach to\\nsolve this problem, which avoids time-consuming hand-design of features. This\\npresents two main challenges. First, we need to evaluate a huge number of\\ncandidate grasps. In order to make detection fast, as well as robust, we\\npresent a two-step cascaded structure with two deep networks, where the top\\ndetections from the first are re-evaluated by the second. The first network has\\nfewer features, is faster to run, and can effectively prune out unlikely\\ncandidate grasps. The second, with more features, is slower but has to run only\\non the top few detections. Second, we need to handle multimodal inputs well,\\nfor which we present a method to apply structured regularization on the weights\\nbased on multimodal group regularization. We demonstrate that our method\\noutperforms the previous state-of-the-art methods in robotic grasp detection,\\nand can be used to successfully execute grasps on two different robotic\\nplatforms.\\n\\n    ', '\\nAbstract:  We present the first deep learning model to successfully learn control\\npolicies directly from high-dimensional sensory input using reinforcement\\nlearning. The model is a convolutional neural network, trained with a variant\\nof Q-learning, whose input is raw pixels and whose output is a value function\\nestimating future rewards. We apply our method to seven Atari 2600 games from\\nthe Arcade Learning Environment, with no adjustment of the architecture or\\nlearning algorithm. We find that it outperforms all previous approaches on six\\nof the games and surpasses a human expert on three of them.\\n\\n    ', 'It is pdf', '\\nAbstract:  In fine art, especially painting, humans have mastered the skill to create\\nunique visual experiences through composing a complex interplay between the\\ncontent and style of an image. Thus far the algorithmic basis of this process\\nis unknown and there exists no artificial system with similar capabilities.\\nHowever, in other key areas of visual perception such as object and face\\nrecognition near-human performance was recently demonstrated by a class of\\nbiologically inspired vision models called Deep Neural Networks. Here we\\nintroduce an artificial system based on a Deep Neural Network that creates\\nartistic images of high perceptual quality. The system uses neural\\nrepresentations to separate and recombine content and style of arbitrary\\nimages, providing a neural algorithm for the creation of artistic images.\\nMoreover, in light of the striking similarities between performance-optimised\\nartificial neural networks and biological vision, our work offers a path\\nforward to an algorithmic understanding of how humans create and perceive\\nartistic imagery.\\n\\n    ', '\\nAbstract:  We present a model that generates natural language descriptions of images and\\ntheir regions. Our approach leverages datasets of images and their sentence\\ndescriptions to learn about the inter-modal correspondences between language\\nand visual data. Our alignment model is based on a novel combination of\\nConvolutional Neural Networks over image regions, bidirectional Recurrent\\nNeural Networks over sentences, and a structured objective that aligns the two\\nmodalities through a multimodal embedding. We then describe a Multimodal\\nRecurrent Neural Network architecture that uses the inferred alignments to\\nlearn to generate novel descriptions of image regions. We demonstrate that our\\nalignment model produces state of the art results in retrieval experiments on\\nFlickr8K, Flickr30K and MSCOCO datasets. We then show that the generated\\ndescriptions significantly outperform retrieval baselines on both full images\\nand on a new dataset of region-level annotations.\\n\\n    ', '\\nAbstract:  Inspired by recent work in machine translation and object detection, we\\nintroduce an attention based model that automatically learns to describe the\\ncontent of images. We describe how we can train this model in a deterministic\\nmanner using standard backpropagation techniques and stochastically by\\nmaximizing a variational lower bound. We also show through visualization how\\nthe model is able to automatically learn to fix its gaze on salient objects\\nwhile generating the corresponding words in the output sequence. We validate\\nthe use of attention with state-of-the-art performance on three benchmark\\ndatasets: Flickr8k, Flickr30k and MS COCO.\\n\\n    ', '\\nAbstract:  Automatically describing the content of an image is a fundamental problem in\\nartificial intelligence that connects computer vision and natural language\\nprocessing. In this paper, we present a generative model based on a deep\\nrecurrent architecture that combines recent advances in computer vision and\\nmachine translation and that can be used to generate natural sentences\\ndescribing an image. The model is trained to maximize the likelihood of the\\ntarget description sentence given the training image. Experiments on several\\ndatasets show the accuracy of the model and the fluency of the language it\\nlearns solely from image descriptions. Our model is often quite accurate, which\\nwe verify both qualitatively and quantitatively. For instance, while the\\ncurrent state-of-the-art BLEU-1 score (the higher the better) on the Pascal\\ndataset is 25, our approach yields 59, to be compared to human performance\\naround 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66,\\nand on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we\\nachieve a BLEU-4 of 27.7, which is the current state-of-the-art.\\n\\n    ', '\\nAbstract:  We propose the task of free-form and open-ended Visual Question Answering\\n(VQA). Given an image and a natural language question about the image, the task\\nis to provide an accurate natural language answer. Mirroring real-world\\nscenarios, such as helping the visually impaired, both the questions and\\nanswers are open-ended. Visual questions selectively target different areas of\\nan image, including background details and underlying context. As a result, a\\nsystem that succeeds at VQA typically needs a more detailed understanding of\\nthe image and complex reasoning than a system producing generic image captions.\\nMoreover, VQA is amenable to automatic evaluation, since many open-ended\\nanswers contain only a few words or a closed set of answers that can be\\nprovided in a multiple-choice format. We provide a dataset containing ~0.25M\\nimages, ~0.76M questions, and ~10M answers (this http URL), and discuss the\\ninformation it provides. Numerous baselines and methods for VQA are provided\\nand compared with human performance. Our VQA demo is available on CloudCV\\n(this http URL).\\n\\n    ', 'It is pdf', 'It is pdf', '\\nAbstract:  We investigate architectures of discriminatively trained deep Convolutional\\nNetworks (ConvNets) for action recognition in video. The challenge is to\\ncapture the complementary information on appearance from still frames and\\nmotion between frames. We also aim to generalise the best performing\\nhand-crafted features within a data-driven learning framework.\\nOur contribution is three-fold. First, we propose a two-stream ConvNet\\narchitecture which incorporates spatial and temporal networks. Second, we\\ndemonstrate that a ConvNet trained on multi-frame dense optical flow is able to\\nachieve very good performance in spite of limited training data. Finally, we\\nshow that multi-task learning, applied to two different action classification\\ndatasets, can be used to increase the amount of training data and improve the\\nperformance on both.\\nOur architecture is trained and evaluated on the standard video actions\\nbenchmarks of UCF-101 and HMDB-51, where it is competitive with the state of\\nthe art. It also exceeds by a large margin previous attempts to use deep nets\\nfor video classification.\\n\\n    ', 'It is pdf', '\\nAbstract:  Convolutional networks are powerful visual models that yield hierarchies of\\nfeatures. We show that convolutional networks by themselves, trained\\nend-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic\\nsegmentation. Our key insight is to build \"fully convolutional\" networks that\\ntake input of arbitrary size and produce correspondingly-sized output with\\nefficient inference and learning. We define and detail the space of fully\\nconvolutional networks, explain their application to spatially dense prediction\\ntasks, and draw connections to prior models. We adapt contemporary\\nclassification networks (AlexNet, the VGG net, and GoogLeNet) into fully\\nconvolutional networks and transfer their learned representations by\\nfine-tuning to the segmentation task. We then define a novel architecture that\\ncombines semantic information from a deep, coarse layer with appearance\\ninformation from a shallow, fine layer to produce accurate and detailed\\nsegmentations. Our fully convolutional network achieves state-of-the-art\\nsegmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012),\\nNYUDv2, and SIFT Flow, while inference takes one third of a second for a\\ntypical image.\\n\\n    ', \"\\nAbstract:  State-of-the-art object detection networks depend on region proposal\\nalgorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN\\nhave reduced the running time of these detection networks, exposing region\\nproposal computation as a bottleneck. In this work, we introduce a Region\\nProposal Network (RPN) that shares full-image convolutional features with the\\ndetection network, thus enabling nearly cost-free region proposals. An RPN is a\\nfully convolutional network that simultaneously predicts object bounds and\\nobjectness scores at each position. The RPN is trained end-to-end to generate\\nhigh-quality region proposals, which are used by Fast R-CNN for detection. We\\nfurther merge RPN and Fast R-CNN into a single network by sharing their\\nconvolutional features---using the recently popular terminology of neural\\nnetworks with 'attention' mechanisms, the RPN component tells the unified\\nnetwork where to look. For the very deep VGG-16 model, our detection system has\\na frame rate of 5fps (including all steps) on a GPU, while achieving\\nstate-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS\\nCOCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015\\ncompetitions, Faster R-CNN and RPN are the foundations of the 1st-place winning\\nentries in several tracks. Code has been made publicly available.\\n\\n    \", '\\nAbstract:  Object detection performance, as measured on the canonical PASCAL VOC\\ndataset, has plateaued in the last few years. The best-performing methods are\\ncomplex ensemble systems that typically combine multiple low-level image\\nfeatures with high-level context. In this paper, we propose a simple and\\nscalable detection algorithm that improves mean average precision (mAP) by more\\nthan 30% relative to the previous best result on VOC 2012---achieving a mAP of\\n53.3%. Our approach combines two key insights: (1) one can apply high-capacity\\nconvolutional neural networks (CNNs) to bottom-up region proposals in order to\\nlocalize and segment objects and (2) when labeled training data is scarce,\\nsupervised pre-training for an auxiliary task, followed by domain-specific\\nfine-tuning, yields a significant performance boost. Since we combine region\\nproposals with CNNs, we call our method R-CNN: Regions with CNN features. We\\nalso compare R-CNN to OverFeat, a recently proposed sliding-window detector\\nbased on a similar CNN architecture. We find that R-CNN outperforms OverFeat by\\na large margin on the 200-class ILSVRC2013 detection dataset. Source code for\\nthe complete system is available at this http URL.\\n\\n    ', '\\nAbstract:  Existing deep convolutional neural networks (CNNs) require a fixed-size\\n(e.g., 224x224) input image. This requirement is \"artificial\" and may reduce\\nthe recognition accuracy for the images or sub-images of an arbitrary\\nsize/scale. In this work, we equip the networks with another pooling strategy,\\n\"spatial pyramid pooling\", to eliminate the above requirement. The new network\\nstructure, called SPP-net, can generate a fixed-length representation\\nregardless of image size/scale. Pyramid pooling is also robust to object\\ndeformations. With these advantages, SPP-net should in general improve all\\nCNN-based image classification methods. On the ImageNet 2012 dataset, we\\ndemonstrate that SPP-net boosts the accuracy of a variety of CNN architectures\\ndespite their different designs. On the Pascal VOC 2007 and Caltech101\\ndatasets, SPP-net achieves state-of-the-art classification results using a\\nsingle full-image representation and no fine-tuning.\\nThe power of SPP-net is also significant in object detection. Using SPP-net,\\nwe compute the feature maps from the entire image only once, and then pool\\nfeatures in arbitrary regions (sub-images) to generate fixed-length\\nrepresentations for training the detectors. This method avoids repeatedly\\ncomputing the convolutional features. In processing test images, our method is\\n24-102x faster than the R-CNN method, while achieving better or comparable\\naccuracy on Pascal VOC 2007.\\nIn ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our\\nmethods rank #2 in object detection and #3 in image classification among all 38\\nteams. This manuscript also introduces the improvement made for this\\ncompetition.\\n\\n    ', '\\nAbstract:  Deep Convolutional Neural Networks (DCNNs) have recently shown state of the\\nart performance in high level vision tasks, such as image classification and\\nobject detection. This work brings together methods from DCNNs and\\nprobabilistic graphical models for addressing the task of pixel-level\\nclassification (also called \"semantic image segmentation\"). We show that\\nresponses at the final layer of DCNNs are not sufficiently localized for\\naccurate object segmentation. This is due to the very invariance properties\\nthat make DCNNs good for high level tasks. We overcome this poor localization\\nproperty of deep networks by combining the responses at the final DCNN layer\\nwith a fully connected Conditional Random Field (CRF). Qualitatively, our\\n\"DeepLab\" system is able to localize segment boundaries at a level of accuracy\\nwhich is beyond previous methods. Quantitatively, our method sets the new\\nstate-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching\\n71.6% IOU accuracy in the test set. We show how these results can be obtained\\nefficiently: Careful network re-purposing and a novel application of the \\'hole\\'\\nalgorithm from the wavelet community allow dense computation of neural net\\nresponses at 8 frames per second on a modern GPU.\\n\\n    ', 'It is pdf', '\\nAbstract:  Convolutional networks are at the core of most state-of-the-art computer\\nvision solutions for a wide variety of tasks. Since 2014 very deep\\nconvolutional networks started to become mainstream, yielding substantial gains\\nin various benchmarks. Although increased model size and computational cost\\ntend to translate to immediate quality gains for most tasks (as long as enough\\nlabeled data is provided for training), computational efficiency and low\\nparameter count are still enabling factors for various use cases such as mobile\\nvision and big-data scenarios. Here we explore ways to scale up networks in\\nways that aim at utilizing the added computation as efficiently as possible by\\nsuitably factorized convolutions and aggressive regularization. We benchmark\\nour methods on the ILSVRC 2012 classification challenge validation set\\ndemonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%\\ntop-5 error for single frame evaluation using a network with a computational\\ncost of 5 billion multiply-adds per inference and with using less than 25\\nmillion parameters. With an ensemble of 4 models and multi-crop evaluation, we\\nreport 3.5% top-5 error on the validation set (3.6% error on the test set) and\\n17.3% top-1 error on the validation set.\\n\\n    ', '\\nAbstract:  Very deep convolutional networks have been central to the largest advances in\\nimage recognition performance in recent years. One example is the Inception\\narchitecture that has been shown to achieve very good performance at relatively\\nlow computational cost. Recently, the introduction of residual connections in\\nconjunction with a more traditional architecture has yielded state-of-the-art\\nperformance in the 2015 ILSVRC challenge; its performance was similar to the\\nlatest generation Inception-v3 network. This raises the question of whether\\nthere are any benefit in combining the Inception architecture with residual\\nconnections. Here we give clear empirical evidence that training with residual\\nconnections accelerates the training of Inception networks significantly. There\\nis also some evidence of residual Inception networks outperforming similarly\\nexpensive Inception networks without residual connections by a thin margin. We\\nalso present several new streamlined architectures for both residual and\\nnon-residual Inception networks. These variations improve the single-frame\\nrecognition performance on the ILSVRC 2012 classification task significantly.\\nWe further demonstrate how proper activation scaling stabilizes the training of\\nvery wide residual Inception networks. With an ensemble of three residual and\\none Inception-v4, we achieve 3.08 percent top-5 error on the test set of the\\nImageNet classification (CLS) challenge\\n\\n    ', '\\nAbstract:  Deep residual networks have emerged as a family of extremely deep\\narchitectures showing compelling accuracy and nice convergence behaviors. In\\nthis paper, we analyze the propagation formulations behind the residual\\nbuilding blocks, which suggest that the forward and backward signals can be\\ndirectly propagated from one block to any other block, when using identity\\nmappings as the skip connections and after-addition activation. A series of\\nablation experiments support the importance of these identity mappings. This\\nmotivates us to propose a new residual unit, which makes training easier and\\nimproves generalization. We report improved results using a 1001-layer ResNet\\non CIFAR-10 (4.62% error) and CIFAR-100, and a 200-layer ResNet on ImageNet.\\nCode is available at: this https URL\\n', '\\nAbstract:  Deeper neural networks are more difficult to train. We present a residual\\nlearning framework to ease the training of networks that are substantially\\ndeeper than those used previously. We explicitly reformulate the layers as\\nlearning residual functions with reference to the layer inputs, instead of\\nlearning unreferenced functions. We provide comprehensive empirical evidence\\nshowing that these residual networks are easier to optimize, and can gain\\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\\nstill having lower complexity. An ensemble of these residual nets achieves\\n3.57% error on the ImageNet test set. This result won the 1st place on the\\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\\nand 1000 layers.\\nThe depth of representations is of central importance for many visual\\nrecognition tasks. Solely due to our extremely deep representations, we obtain\\na 28% relative improvement on the COCO object detection dataset. Deep residual\\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\\nlocalization, COCO detection, and COCO segmentation.\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks define an exceptionally powerful class of\\nmodels, but are still limited by the lack of ability to be spatially invariant\\nto the input data in a computationally and parameter efficient manner. In this\\nwork we introduce a new learnable module, the Spatial Transformer, which\\nexplicitly allows the spatial manipulation of data within the network. This\\ndifferentiable module can be inserted into existing convolutional\\narchitectures, giving neural networks the ability to actively spatially\\ntransform feature maps, conditional on the feature map itself, without any\\nextra training supervision or modification to the optimisation process. We show\\nthat the use of spatial transformers results in models which learn invariance\\nto translation, scale, rotation and more generic warping, resulting in\\nstate-of-the-art performance on several benchmarks, and for a number of classes\\nof transformations.\\n\\n    ', '\\nAbstract:  We propose a deep convolutional neural network architecture codenamed\\n\"Inception\", which was responsible for setting the new state of the art for\\nclassification and detection in the ImageNet Large-Scale Visual Recognition\\nChallenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the\\nimproved utilization of the computing resources inside the network. This was\\nachieved by a carefully crafted design that allows for increasing the depth and\\nwidth of the network while keeping the computational budget constant. To\\noptimize quality, the architectural decisions were based on the Hebbian\\nprinciple and the intuition of multi-scale processing. One particular\\nincarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22\\nlayers deep network, the quality of which is assessed in the context of\\nclassification and detection.\\n\\n    ', '\\nAbstract:  In this work we investigate the effect of the convolutional network depth on\\nits accuracy in the large-scale image recognition setting. Our main\\ncontribution is a thorough evaluation of networks of increasing depth using an\\narchitecture with very small (3x3) convolution filters, which shows that a\\nsignificant improvement on the prior-art configurations can be achieved by\\npushing the depth to 16-19 weight layers. These findings were the basis of our\\nImageNet Challenge 2014 submission, where our team secured the first and the\\nsecond places in the localisation and classification tracks respectively. We\\nalso show that our representations generalise well to other datasets, where\\nthey achieve state-of-the-art results. We have made our two best-performing\\nConvNet models publicly available to facilitate further research on the use of\\ndeep visual representations in computer vision.\\n\\n    ', '\\nAbstract:  The latest generation of Convolutional Neural Networks (CNN) have achieved\\nimpressive results in challenging benchmarks on image recognition and object\\ndetection, significantly raising the interest of the community in these\\nmethods. Nevertheless, it is still unclear how different CNN methods compare\\nwith each other and with previous state-of-the-art shallow representations such\\nas the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts\\na rigorous evaluation of these new techniques, exploring different deep\\narchitectures and comparing them on a common ground, identifying and disclosing\\nimportant implementation details. We identify several useful properties of\\nCNN-based representations, including the fact that the dimensionality of the\\nCNN output layer can be reduced significantly without having an adverse effect\\non performance. We also identify aspects of deep and shallow methods that can\\nbe successfully shared. In particular, we show that the data augmentation\\ntechniques commonly applied to CNN-based methods can also be applied to shallow\\nmethods, and result in an analogous performance boost. Source code and models\\nto reproduce the experiments in the paper is made publicly available.\\n\\n    ', '\\nAbstract:  We present an integrated framework for using Convolutional Networks for\\nclassification, localization and detection. We show how a multiscale and\\nsliding window approach can be efficiently implemented within a ConvNet. We\\nalso introduce a novel deep learning approach to localization by learning to\\npredict object boundaries. Bounding boxes are then accumulated rather than\\nsuppressed in order to increase detection confidence. We show that different\\ntasks can be learned simultaneously using a single shared network. This\\nintegrated framework is the winner of the localization task of the ImageNet\\nLarge Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very\\ncompetitive results for the detection and classifications tasks. In\\npost-competition work, we establish a new state of the art for the detection\\ntask. Finally, we release a feature extractor from our best model called\\nOverFeat.\\n\\n    ', \"\\nAbstract:  We consider the problem of designing models to leverage a recently introduced\\napproximate model averaging technique called dropout. We define a simple new\\nmodel called maxout (so named because its output is the max of a set of inputs,\\nand because it is a natural companion to dropout) designed to both facilitate\\noptimization by dropout and improve the accuracy of dropout's fast approximate\\nmodel averaging technique. We empirically verify that the model successfully\\naccomplishes both of these tasks. We use maxout and dropout to demonstrate\\nstate of the art classification performance on four benchmark datasets: MNIST,\\nCIFAR-10, CIFAR-100, and SVHN.\\n\\n    \", '\\nAbstract:  We propose a novel deep network structure called \"Network In Network\" (NIN)\\nto enhance model discriminability for local patches within the receptive field.\\nThe conventional convolutional layer uses linear filters followed by a\\nnonlinear activation function to scan the input. Instead, we build micro neural\\nnetworks with more complex structures to abstract the data within the receptive\\nfield. We instantiate the micro neural network with a multilayer perceptron,\\nwhich is a potent function approximator. The feature maps are obtained by\\nsliding the micro networks over the input in a similar manner as CNN; they are\\nthen fed into the next layer. Deep NIN can be implemented by stacking mutiple\\nof the above described structure. With enhanced local modeling via the micro\\nnetwork, we are able to utilize global average pooling over feature maps in the\\nclassification layer, which is easier to interpret and less prone to\\noverfitting than traditional fully connected layers. We demonstrated the\\nstate-of-the-art classification performances with NIN on CIFAR-10 and\\nCIFAR-100, and reasonable performances on SVHN and MNIST datasets.\\n\\n    ', '\\nAbstract:  Modeling the distribution of natural images is a landmark problem in\\nunsupervised learning. This task requires an image model that is at once\\nexpressive, tractable and scalable. We present a deep neural network that\\nsequentially predicts the pixels in an image along the two spatial dimensions.\\nOur method models the discrete probability of the raw pixel values and encodes\\nthe complete set of dependencies in the image. Architectural novelties include\\nfast two-dimensional recurrent layers and an effective use of residual\\nconnections in deep recurrent networks. We achieve log-likelihood scores on\\nnatural images that are considerably better than the previous state of the art.\\nOur main results also provide benchmarks on the diverse ImageNet dataset.\\nSamples generated from the model appear crisp, varied and globally coherent.\\n\\n    ', '\\nAbstract:  We present a variety of new architectural features and training procedures\\nthat we apply to the generative adversarial networks (GANs) framework. We focus\\non two applications of GANs: semi-supervised learning, and the generation of\\nimages that humans find visually realistic. Unlike most work on generative\\nmodels, our primary goal is not to train a model that assigns high likelihood\\nto test data, nor do we require the model to be able to learn well without\\nusing any labels. Using our new techniques, we achieve state-of-the-art results\\nin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated\\nimages are of high quality as confirmed by a visual Turing test: our model\\ngenerates MNIST samples that humans cannot distinguish from real data, and\\nCIFAR-10 samples that yield a human error rate of 21.3%. We also present\\nImageNet samples with unprecedented resolution and show that our methods enable\\nthe model to learn recognizable features of ImageNet classes.\\n\\n    ', '\\nAbstract:  In recent years, supervised learning with convolutional networks (CNNs) has\\nseen huge adoption in computer vision applications. Comparatively, unsupervised\\nlearning with CNNs has received less attention. In this work we hope to help\\nbridge the gap between the success of CNNs for supervised learning and\\nunsupervised learning. We introduce a class of CNNs called deep convolutional\\ngenerative adversarial networks (DCGANs), that have certain architectural\\nconstraints, and demonstrate that they are a strong candidate for unsupervised\\nlearning. Training on various image datasets, we show convincing evidence that\\nour deep convolutional adversarial pair learns a hierarchy of representations\\nfrom object parts to scenes in both the generator and discriminator.\\nAdditionally, we use the learned features for novel tasks - demonstrating their\\napplicability as general image representations.\\n\\n    ', '\\nAbstract:  This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural\\nnetwork architecture for image generation. DRAW networks combine a novel\\nspatial attention mechanism that mimics the foveation of the human eye, with a\\nsequential variational auto-encoding framework that allows for the iterative\\nconstruction of complex images. The system substantially improves on the state\\nof the art for generative models on MNIST, and, when trained on the Street View\\nHouse Numbers dataset, it generates images that cannot be distinguished from\\nreal data with the naked eye.\\n\\n    ', '\\nAbstract:  We propose a new framework for estimating generative models via an\\nadversarial process, in which we simultaneously train two models: a generative\\nmodel G that captures the data distribution, and a discriminative model D that\\nestimates the probability that a sample came from the training data rather than\\nG. The training procedure for G is to maximize the probability of D making a\\nmistake. This framework corresponds to a minimax two-player game. In the space\\nof arbitrary functions G and D, a unique solution exists, with G recovering the\\ntraining data distribution and D equal to 1/2 everywhere. In the case where G\\nand D are defined by multilayer perceptrons, the entire system can be trained\\nwith backpropagation. There is no need for any Markov chains or unrolled\\napproximate inference networks during either training or generation of samples.\\nExperiments demonstrate the potential of the framework through qualitative and\\nquantitative evaluation of the generated samples.\\n\\n    ', '\\nAbstract:  How can we perform efficient inference and learning in directed probabilistic\\nmodels, in the presence of continuous latent variables with intractable\\nposterior distributions, and large datasets? We introduce a stochastic\\nvariational inference and learning algorithm that scales to large datasets and,\\nunder some mild differentiability conditions, even works in the intractable\\ncase. Our contributions is two-fold. First, we show that a reparameterization\\nof the variational lower bound yields a lower bound estimator that can be\\nstraightforwardly optimized using standard stochastic gradient methods. Second,\\nwe show that for i.i.d. datasets with continuous latent variables per\\ndatapoint, posterior inference can be made especially efficient by fitting an\\napproximate inference model (also called a recognition model) to the\\nintractable posterior using the proposed lower bound estimator. Theoretical\\nadvantages are reflected in experimental results.\\n\\n    ', '\\nAbstract:  We consider the problem of building high-level, class-specific feature\\ndetectors from only unlabeled data. For example, is it possible to learn a face\\ndetector using only unlabeled images? To answer this, we train a 9-layered\\nlocally connected sparse autoencoder with pooling and local contrast\\nnormalization on a large dataset of images (the model has 1 billion\\nconnections, the dataset has 10 million 200x200 pixel images downloaded from\\nthe Internet). We train this network using model parallelism and asynchronous\\nSGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to\\nwhat appears to be a widely-held intuition, our experimental results reveal\\nthat it is possible to train a face detector without having to label images as\\ncontaining a face or not. Control experiments show that this feature detector\\nis robust not only to translation but also to scaling and out-of-plane\\nrotation. We also find that the same network is sensitive to other high-level\\nconcepts such as cat faces and human bodies. Starting with these learned\\nfeatures, we trained our network to obtain 15.8% accuracy in recognizing 20,000\\nobject categories from ImageNet, a leap of 70% relative improvement over the\\nprevious state-of-the-art.\\n\\n    ', '\\nAbstract:  Theoretical and empirical evidence indicates that the depth of neural\\nnetworks is crucial for their success. However, training becomes more difficult\\nas depth increases, and training of very deep networks remains an open problem.\\nHere we introduce a new architecture designed to overcome this. Our so-called\\nhighway networks allow unimpeded information flow across many layers on\\ninformation highways. They are inspired by Long Short-Term Memory recurrent\\nnetworks and use adaptive gating units to regulate the information flow. Even\\nwith hundreds of layers, highway networks can be trained directly through\\nsimple gradient descent. This enables the study of extremely deep and efficient\\narchitectures.\\n\\n    ', \"\\nAbstract:  Training Deep Neural Networks is complicated by the fact that the\\ndistribution of each layer's inputs changes during training, as the parameters\\nof the previous layers change. This slows down the training by requiring lower\\nlearning rates and careful parameter initialization, and makes it notoriously\\nhard to train models with saturating nonlinearities. We refer to this\\nphenomenon as internal covariate shift, and address the problem by normalizing\\nlayer inputs. Our method draws its strength from making normalization a part of\\nthe model architecture and performing the normalization for each training\\nmini-batch. Batch Normalization allows us to use much higher learning rates and\\nbe less careful about initialization. It also acts as a regularizer, in some\\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\\nclassification model, Batch Normalization achieves the same accuracy with 14\\ntimes fewer training steps, and beats the original model by a significant\\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\\nbest published result on ImageNet classification: reaching 4.9% top-5\\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters.\\n\\n    \", '\\nAbstract:  Rectified activation units (rectifiers) are essential for state-of-the-art\\nneural networks. In this work, we study rectifier neural networks for image\\nclassification from two aspects. First, we propose a Parametric Rectified\\nLinear Unit (PReLU) that generalizes the traditional rectified unit. PReLU\\nimproves model fitting with nearly zero extra computational cost and little\\noverfitting risk. Second, we derive a robust initialization method that\\nparticularly considers the rectifier nonlinearities. This method enables us to\\ntrain extremely deep rectified models directly from scratch and to investigate\\ndeeper or wider network architectures. Based on our PReLU networks\\n(PReLU-nets), we achieve 4.94% top-5 test error on the ImageNet 2012\\nclassification dataset. This is a 26% relative improvement over the ILSVRC 2014\\nwinner (GoogLeNet, 6.66%). To our knowledge, our result is the first to surpass\\nhuman-level performance (5.1%, Russakovsky et al.) on this visual recognition\\nchallenge.\\n\\n    ', '\\nAbstract:  We introduce Adam, an algorithm for first-order gradient-based optimization\\nof stochastic objective functions, based on adaptive estimates of lower-order\\nmoments. The method is straightforward to implement, is computationally\\nefficient, has little memory requirements, is invariant to diagonal rescaling\\nof the gradients, and is well suited for problems that are large in terms of\\ndata and/or parameters. The method is also appropriate for non-stationary\\nobjectives and problems with very noisy and/or sparse gradients. The\\nhyper-parameters have intuitive interpretations and typically require little\\ntuning. Some connections to related algorithms, on which Adam was inspired, are\\ndiscussed. We also analyze the theoretical convergence properties of the\\nalgorithm and provide a regret bound on the convergence rate that is comparable\\nto the best known results under the online convex optimization framework.\\nEmpirical results demonstrate that Adam works well in practice and compares\\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\\na variant of Adam based on the infinity norm.\\n\\n    ', '\\nAbstract:  When a large feedforward neural network is trained on a small training set,\\nit typically performs poorly on held-out test data. This \"overfitting\" is\\ngreatly reduced by randomly omitting half of the feature detectors on each\\ntraining case. This prevents complex co-adaptations in which a feature detector\\nis only helpful in the context of several other specific feature detectors.\\nInstead, each neuron learns to detect a feature that is generally helpful for\\nproducing the correct answer given the combinatorially large variety of\\ninternal contexts in which it must operate. Random \"dropout\" gives big\\nimprovements on many benchmark tasks and sets new records for speech and object\\nrecognition.\\n\\n    ', '\\nAbstract:  Training state-of-the-art, deep neural networks is computationally expensive.\\nOne way to reduce the training time is to normalize the activities of the\\nneurons. A recently introduced technique called batch normalization uses the\\ndistribution of the summed input to a neuron over a mini-batch of training\\ncases to compute a mean and variance which are then used to normalize the\\nsummed input to that neuron on each training case. This significantly reduces\\nthe training time in feed-forward neural networks. However, the effect of batch\\nnormalization is dependent on the mini-batch size and it is not obvious how to\\napply it to recurrent neural networks. In this paper, we transpose batch\\nnormalization into layer normalization by computing the mean and variance used\\nfor normalization from all of the summed inputs to the neurons in a layer on a\\nsingle training case. Like batch normalization, we also give each neuron its\\nown adaptive bias and gain which are applied after the normalization but before\\nthe non-linearity. Unlike batch normalization, layer normalization performs\\nexactly the same computation at training and test times. It is also\\nstraightforward to apply to recurrent neural networks by computing the\\nnormalization statistics separately at each time step. Layer normalization is\\nvery effective at stabilizing the hidden state dynamics in recurrent networks.\\nEmpirically, we show that layer normalization can substantially reduce the\\ntraining time compared with previously published techniques.\\n\\n    ', '\\nAbstract:  The move from hand-designed features to learned features in machine learning\\nhas been wildly successful. In spite of this, optimization algorithms are still\\ndesigned by hand. In this paper we show how the design of an optimization\\nalgorithm can be cast as a learning problem, allowing the algorithm to learn to\\nexploit structure in the problems of interest in an automatic way. Our learned\\nalgorithms, implemented by LSTMs, outperform generic, hand-designed competitors\\non the tasks for which they are trained, and also generalize well to new tasks\\nwith similar structure. We demonstrate this on a number of tasks, including\\nsimple convex problems, training neural networks, and styling images with\\nneural art.\\n\\n    ', '\\nAbstract:  Given a grayscale photograph as input, this paper attacks the problem of\\nhallucinating a plausible color version of the photograph. This problem is\\nclearly underconstrained, so previous approaches have either relied on\\nsignificant user interaction or resulted in desaturated colorizations. We\\npropose a fully automatic approach that produces vibrant and realistic\\ncolorizations. We embrace the underlying uncertainty of the problem by posing\\nit as a classification task and use class-rebalancing at training time to\\nincrease the diversity of colors in the result. The system is implemented as a\\nfeed-forward pass in a CNN at test time and is trained on over a million color\\nimages. We evaluate our algorithm using a \"colorization Turing test,\" asking\\nhuman participants to choose between a generated and ground truth color image.\\nOur method successfully fools humans on 32% of the trials, significantly higher\\nthan previous methods. Moreover, we show that colorization can be a powerful\\npretext task for self-supervised feature learning, acting as a cross-channel\\nencoder. This approach results in state-of-the-art performance on several\\nfeature learning benchmarks.\\n\\n    ', '\\nAbstract:  Realistic image manipulation is challenging because it requires modifying the\\nimage appearance in a user-controlled way, while preserving the realism of the\\nresult. Unless the user has considerable artistic skill, it is easy to \"fall\\noff\" the manifold of natural images while editing. In this paper, we propose to\\nlearn the natural image manifold directly from data using a generative\\nadversarial neural network. We then define a class of image editing operations,\\nand constrain their output to lie on that learned manifold at all times. The\\nmodel automatically adjusts the output keeping all edits as realistic as\\npossible. All our manipulations are expressed in terms of constrained\\noptimization and are applied in near-real time. We evaluate our algorithm on\\nthe task of realistic photo manipulation of shape and color. The presented\\nmethod can further be used for changing one image to look like the other, as\\nwell as generating novel imagery from scratch based on user\\'s scribbles.\\n\\n    ', '\\nAbstract:  Gatys et al. recently demonstrated that deep networks can generate beautiful\\ntextures and stylized images from a single texture example. However, their\\nmethods requires a slow and memory-consuming optimization process. We propose\\nhere an alternative approach that moves the computational burden to a learning\\nstage. Given a single example of a texture, our approach trains compact\\nfeed-forward convolutional networks to generate multiple samples of the same\\ntexture of arbitrary size and to transfer artistic style from a given image to\\nany other image. The resulting networks are remarkably light-weight and can\\ngenerate textures of quality comparable to Gatys~et~al., but hundreds of times\\nfaster. More generally, our approach highlights the power and flexibility of\\ngenerative feed-forward models trained with complex and expressive loss\\nfunctions.\\n\\n    ', '\\nAbstract:  Recent research on deep neural networks has focused primarily on improving\\naccuracy. For a given accuracy level, it is typically possible to identify\\nmultiple DNN architectures that achieve that accuracy level. With equivalent\\naccuracy, smaller DNN architectures offer at least three advantages: (1)\\nSmaller DNNs require less communication across servers during distributed\\ntraining. (2) Smaller DNNs require less bandwidth to export a new model from\\nthe cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on\\nFPGAs and other hardware with limited memory. To provide all of these\\nadvantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet\\nachieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.\\nAdditionally, with model compression techniques we are able to compress\\nSqueezeNet to less than 0.5MB (510x smaller than AlexNet).\\nThe SqueezeNet architecture is available for download here:\\nthis https URL\\n', \"\\nAbstract:  State-of-the-art deep neural networks (DNNs) have hundreds of millions of\\nconnections and are both computationally and memory intensive, making them\\ndifficult to deploy on embedded systems with limited hardware resources and\\npower budgets. While custom hardware helps the computation, fetching weights\\nfrom DRAM is two orders of magnitude more expensive than ALU operations, and\\ndominates the required power.\\nPreviously proposed 'Deep Compression' makes it possible to fit large DNNs\\n(AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by\\npruning the redundant connections and having multiple connections share the\\nsame weight. We propose an energy efficient inference engine (EIE) that\\nperforms inference on this compressed network model and accelerates the\\nresulting sparse matrix-vector multiplication with weight sharing. Going from\\nDRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x;\\nWeight sharing gives 8x; Skipping zero activations from ReLU saves another 3x.\\nEvaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to\\nCPU and GPU implementations of the same DNN without compression. EIE has a\\nprocessing power of 102GOPS/s working directly on a compressed network,\\ncorresponding to 3TOPS/s on an uncompressed network, and processes FC layers of\\nAlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is\\n24,000x and 3,400x more energy efficient than a CPU and GPU respectively.\\nCompared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy\\nefficiency and area efficiency.\\n\\n    \", '\\nAbstract:  We introduce a method to train Binarized Neural Networks (BNNs) - neural\\nnetworks with binary weights and activations at run-time. At training-time the\\nbinary weights and activations are used for computing the parameters gradients.\\nDuring the forward pass, BNNs drastically reduce memory size and accesses, and\\nreplace most arithmetic operations with bit-wise operations, which is expected\\nto substantially improve power-efficiency. To validate the effectiveness of\\nBNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On\\nboth, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10\\nand SVHN datasets. Last but not least, we wrote a binary matrix multiplication\\nGPU kernel with which it is possible to run our MNIST BNN 7 times faster than\\nwith an unoptimized GPU kernel, without suffering any loss in classification\\naccuracy. The code for training and running our BNNs is available on-line.\\n\\n    ', '\\nAbstract:  Neural network architectures with memory and attention mechanisms exhibit\\ncertain reasoning capabilities required for question answering. One such\\narchitecture, the dynamic memory network (DMN), obtained high accuracy on a\\nvariety of language tasks. However, it was not shown whether the architecture\\nachieves strong results for question answering when supporting facts are not\\nmarked during training or whether it could be applied to other modalities such\\nas images. Based on an analysis of the DMN, we propose several improvements to\\nits memory and input modules. Together with these changes we introduce a novel\\ninput module for images in order to be able to answer visual questions. Our new\\nDMN+ model improves the state of the art on both the Visual Question Answering\\ndataset and the \\\\babi-10k text question-answering dataset without supporting\\nfact supervision.\\n\\n    ', '\\nAbstract:  This paper presents stacked attention networks (SANs) that learn to answer\\nnatural language questions from images. SANs use semantic representation of a\\nquestion as query to search for the regions in an image that are related to the\\nanswer. We argue that image question answering (QA) often requires multiple\\nsteps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\\nimage multiple times to infer the answer progressively. Experiments conducted\\non four image QA data sets demonstrate that the proposed SANs significantly\\noutperform previous state-of-the-art approaches. The visualization of the\\nattention layers illustrates the progress that the SAN locates the relevant\\nvisual clues that lead to the answer of the question layer-by-layer.\\n\\n    ', '\\nAbstract:  Neural Machine Translation (NMT) is an end-to-end learning approach for\\nautomated translation, with the potential to overcome many of the weaknesses of\\nconventional phrase-based translation systems. Unfortunately, NMT systems are\\nknown to be computationally expensive both in training and in translation\\ninference. Also, most NMT systems have difficulty with rare words. These issues\\nhave hindered NMT\\'s use in practical deployments and services, where both\\naccuracy and speed are essential. In this work, we present GNMT, Google\\'s\\nNeural Machine Translation system, which attempts to address many of these\\nissues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder\\nlayers using attention and residual connections. To improve parallelism and\\ntherefore decrease training time, our attention mechanism connects the bottom\\nlayer of the decoder to the top layer of the encoder. To accelerate the final\\ntranslation speed, we employ low-precision arithmetic during inference\\ncomputations. To improve handling of rare words, we divide words into a limited\\nset of common sub-word units (\"wordpieces\") for both input and output. This\\nmethod provides a good balance between the flexibility of \"character\"-delimited\\nmodels and the efficiency of \"word\"-delimited models, naturally handles\\ntranslation of rare words, and ultimately improves the overall accuracy of the\\nsystem. Our beam search technique employs a length-normalization procedure and\\nuses a coverage penalty, which encourages generation of an output sentence that\\nis most likely to cover all the words in the source sentence. On the WMT\\'14\\nEnglish-to-French and English-to-German benchmarks, GNMT achieves competitive\\nresults to state-of-the-art. Using a human side-by-side evaluation on a set of\\nisolated simple sentences, it reduces translation errors by an average of 60%\\ncompared to Google\\'s phrase-based production system.\\n\\n    ', '\\nAbstract:  We present a class of efficient models called MobileNets for mobile and\\nembedded vision applications. MobileNets are based on a streamlined\\narchitecture that uses depth-wise separable convolutions to build light weight\\ndeep neural networks. We introduce two simple global hyper-parameters that\\nefficiently trade off between latency and accuracy. These hyper-parameters\\nallow the model builder to choose the right sized model for their application\\nbased on the constraints of the problem. We present extensive experiments on\\nresource and accuracy tradeoffs and show strong performance compared to other\\npopular models on ImageNet classification. We then demonstrate the\\neffectiveness of MobileNets across a wide range of applications and use cases\\nincluding object detection, finegrain classification, face attributes and large\\nscale geo-localization.\\n\\n    ', \"\\nAbstract:  The prevalent approach to sequence to sequence learning maps an input\\nsequence to a variable length output sequence via recurrent neural networks. We\\nintroduce an architecture based entirely on convolutional neural networks.\\nCompared to recurrent models, computations over all elements can be fully\\nparallelized during training and optimization is easier since the number of\\nnon-linearities is fixed and independent of the input length. Our use of gated\\nlinear units eases gradient propagation and we equip each decoder layer with a\\nseparate attention module. We outperform the accuracy of the deep LSTM setup of\\nWu et al. (2016) on both WMT'14 English-German and WMT'14 English-French\\ntranslation at an order of magnitude faster speed, both on GPU and CPU.\\n\\n    \", '\\nAbstract:  Neural network models are capable of generating extremely natural sounding\\nconversational interactions. Nevertheless, these models have yet to demonstrate\\nthat they can incorporate content in the form of factual information or\\nentity-grounded opinion that would enable them to serve in more task-oriented\\nconversational applications. This paper presents a novel, fully data-driven,\\nand knowledge-grounded neural conversation model aimed at producing more\\ncontentful responses without slot filling. We generalize the widely-used\\nSeq2Seq approach by conditioning responses on both conversation history and\\nexternal \"facts\", allowing the model to be versatile and applicable in an\\nopen-domain setting. Our approach yields significant improvements over a\\ncompetitive Seq2Seq baseline. Human judges found that our outputs are\\nsignificantly more informative.\\n\\n    ', '\\nAbstract:  Transfer learning, where a model is first pre-trained on a data-rich task\\nbefore being fine-tuned on a downstream task, has emerged as a powerful\\ntechnique in natural language processing (NLP). The effectiveness of transfer\\nlearning has given rise to a diversity of approaches, methodology, and\\npractice. In this paper, we explore the landscape of transfer learning\\ntechniques for NLP by introducing a unified framework that converts every\\nlanguage problem into a text-to-text format. Our systematic study compares\\npre-training objectives, architectures, unlabeled datasets, transfer\\napproaches, and other factors on dozens of language understanding tasks. By\\ncombining the insights from our exploration with scale and our new \"Colossal\\nClean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks\\ncovering summarization, question answering, text classification, and more. To\\nfacilitate future work on transfer learning for NLP, we release our dataset,\\npre-trained models, and code.\\n\\n    ', \"\\nAbstract:  A text-to-speech synthesis system typically consists of multiple stages, such\\nas a text analysis frontend, an acoustic model and an audio synthesis module.\\nBuilding these components often requires extensive domain expertise and may\\ncontain brittle design choices. In this paper, we present Tacotron, an\\nend-to-end generative text-to-speech model that synthesizes speech directly\\nfrom characters. Given <text, audio> pairs, the model can be trained completely\\nfrom scratch with random initialization. We present several key techniques to\\nmake the sequence-to-sequence framework perform well for this challenging task.\\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\\noutperforming a production parametric system in terms of naturalness. In\\naddition, since Tacotron generates speech at the frame level, it's\\nsubstantially faster than sample-level autoregressive methods.\\n\\n    \", '\\nAbstract:  This paper introduces a deep-learning approach to photographic style transfer\\nthat handles a large variety of image content while faithfully transferring the\\nreference style. Our approach builds upon the recent work on painterly transfer\\nthat separates style from the content of an image by considering different\\nlayers of a neural network. However, as is, this approach is not suitable for\\nphotorealistic style transfer. Even when both the input and reference images\\nare photographs, the output still exhibits distortions reminiscent of a\\npainting. Our contribution is to constrain the transformation from the input to\\nthe output to be locally affine in colorspace, and to express this constraint\\nas a custom fully differentiable energy term. We show that this approach\\nsuccessfully suppresses distortion and yields satisfying photorealistic style\\ntransfers in a broad variety of scenarios, including transfer of the time of\\nday, weather, season, and artistic edits.\\n\\n    ', '\\nAbstract:  We explore the use of Evolution Strategies (ES), a class of black box\\noptimization algorithms, as an alternative to popular MDP-based RL techniques\\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\\nthat ES is a viable solution strategy that scales extremely well with the\\nnumber of CPUs available: By using a novel communication strategy based on\\ncommon random numbers, our ES implementation only needs to communicate scalars,\\nmaking it possible to scale to over a thousand parallel workers. This allows us\\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\\nmost Atari games after one hour of training. In addition, we highlight several\\nadvantages of ES as a black box optimization technique: it is invariant to\\naction frequency and delayed rewards, tolerant of extremely long horizons, and\\ndoes not need temporal discounting or value function approximation.\\n\\n    ', '\\nAbstract:  Convolutional neural networks (CNNs) are inherently limited to model\\ngeometric transformations due to the fixed geometric structures in its building\\nmodules. In this work, we introduce two new modules to enhance the\\ntransformation modeling capacity of CNNs, namely, deformable convolution and\\ndeformable RoI pooling. Both are based on the idea of augmenting the spatial\\nsampling locations in the modules with additional offsets and learning the\\noffsets from target tasks, without additional supervision. The new modules can\\nreadily replace their plain counterparts in existing CNNs and can be easily\\ntrained end-to-end by standard back-propagation, giving rise to deformable\\nconvolutional networks. Extensive experiments validate the effectiveness of our\\napproach on sophisticated vision tasks of object detection and semantic\\nsegmentation. The code would be released.\\n\\n    ', '\\nAbstract:  While humans easily recognize relations between data from different domains\\nwithout any supervision, learning to automatically discover them is in general\\nvery challenging and needs many ground-truth pairs that illustrate the\\nrelations. To avoid costly pairing, we address the task of discovering\\ncross-domain relations given unpaired data. We propose a method based on\\ngenerative adversarial networks that learns to discover relations between\\ndifferent domains (DiscoGAN). Using the discovered relations, our proposed\\nnetwork successfully transfers style from one domain to another while\\npreserving key attributes such as orientation and face identity. Source code\\nfor official implementation is publicly available\\nthis https URL\\n', '\\nAbstract:  We present Deep Voice, a production-quality text-to-speech system constructed\\nentirely from deep neural networks. Deep Voice lays the groundwork for truly\\nend-to-end neural speech synthesis. The system comprises five major building\\nblocks: a segmentation model for locating phoneme boundaries, a\\ngrapheme-to-phoneme conversion model, a phoneme duration prediction model, a\\nfundamental frequency prediction model, and an audio synthesis model. For the\\nsegmentation model, we propose a novel way of performing phoneme boundary\\ndetection with deep neural networks using connectionist temporal classification\\n(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet\\nthat requires fewer parameters and trains faster than the original. By using a\\nneural network for each component, our system is simpler and more flexible than\\ntraditional text-to-speech systems, where each component requires laborious\\nfeature engineering and extensive domain expertise. Finally, we show that\\ninference with our system can be performed faster than real time and describe\\noptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x\\nspeedups over existing implementations.\\n\\n    ', '\\nAbstract:  We explore design principles for general pixel-level prediction problems,\\nfrom low-level edge detection to mid-level surface normal estimation to\\nhigh-level semantic segmentation. Convolutional predictors, such as the\\nfully-convolutional network (FCN), have achieved remarkable success by\\nexploiting the spatial redundancy of neighboring pixels through convolutional\\nprocessing. Though computationally efficient, we point out that such approaches\\nare not statistically efficient during learning precisely because spatial\\nredundancy limits the information learned from neighboring pixels. We\\ndemonstrate that stratified sampling of pixels allows one to (1) add diversity\\nduring batch updates, speeding up learning; (2) explore complex nonlinear\\npredictors, improving accuracy; and (3) efficiently train state-of-the-art\\nmodels tabula rasa (i.e., \"from scratch\") for diverse pixel-labeling tasks. Our\\nsingle architecture produces state-of-the-art results for semantic segmentation\\non PASCAL-Context dataset, surface normal estimation on NYUDv2 depth dataset,\\nand edge detection on BSDS.\\n\\n    ', '\\nAbstract:  Batch Normalization is quite effective at accelerating and improving the\\ntraining of deep models. However, its effectiveness diminishes when the\\ntraining minibatches are small, or do not consist of independent samples. We\\nhypothesize that this is due to the dependence of model layer inputs on all the\\nexamples in the minibatch, and different activations being produced between\\ntraining and inference. We propose Batch Renormalization, a simple and\\neffective extension to ensure that the training and inference models generate\\nthe same outputs that depend on individual examples rather than the entire\\nminibatch. Models trained with Batch Renormalization perform substantially\\nbetter than batchnorm when training with small or non-i.i.d. minibatches. At\\nthe same time, Batch Renormalization retains the benefits of batchnorm such as\\ninsensitivity to initialization and training efficiency.\\n\\n    ', '\\nAbstract:  Despite their massive size, successful deep artificial neural networks can\\nexhibit a remarkably small difference between training and test performance.\\nConventional wisdom attributes small generalization error either to properties\\nof the model family, or to the regularization techniques used during training.\\nThrough extensive systematic experiments, we show how these traditional\\napproaches fail to explain why large neural networks generalize well in\\npractice. Specifically, our experiments establish that state-of-the-art\\nconvolutional networks for image classification trained with stochastic\\ngradient methods easily fit a random labeling of the training data. This\\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\\neven if we replace the true images by completely unstructured random noise. We\\ncorroborate these experimental findings with a theoretical construction showing\\nthat simple depth two neural networks already have perfect finite sample\\nexpressivity as soon as the number of parameters exceeds the number of data\\npoints as it usually does in practice.\\nWe interpret our experimental findings by comparison with traditional models.\\n\\n    ', '\\nAbstract:  Scale variation is one of the key challenges in object detection. In this\\nwork, we first present a controlled experiment to investigate the effect of\\nreceptive fields for scale variation in object detection. Based on the findings\\nfrom the exploration experiments, we propose a novel Trident Network\\n(TridentNet) aiming to generate scale-specific feature maps with a uniform\\nrepresentational power. We construct a parallel multi-branch architecture in\\nwhich each branch shares the same transformation parameters but with different\\nreceptive fields. Then, we adopt a scale-aware training scheme to specialize\\neach branch by sampling object instances of proper scales for training. As a\\nbonus, a fast approximation version of TridentNet could achieve significant\\nimprovements without any additional parameters and computational cost compared\\nwith the vanilla detector. On the COCO dataset, our TridentNet with ResNet-101\\nbackbone achieves state-of-the-art single-model results of 48.4 mAP. Codes are\\navailable at this https URL.\\n\\n    ', '\\nAbstract:  Unsupervised learning with generative adversarial networks (GANs) has proven\\nhugely successful. Regular GANs hypothesize the discriminator as a classifier\\nwith the sigmoid cross entropy loss function. However, we found that this loss\\nfunction may lead to the vanishing gradients problem during the learning\\nprocess. To overcome such a problem, we propose in this paper the Least Squares\\nGenerative Adversarial Networks (LSGANs) which adopt the least squares loss\\nfunction for the discriminator. We show that minimizing the objective function\\nof LSGAN yields minimizing the Pearson $\\\\chi^2$ divergence. There are two\\nbenefits of LSGANs over regular GANs. First, LSGANs are able to generate higher\\nquality images than regular GANs. Second, LSGANs perform more stable during the\\nlearning process. We evaluate LSGANs on five scene datasets and the\\nexperimental results show that the images generated by LSGANs are of better\\nquality than the ones generated by regular GANs. We also conduct two comparison\\nexperiments between LSGANs and regular GANs to illustrate the stability of\\nLSGANs.\\n\\n    ', '\\nAbstract:  We present the Stanford Question Answering Dataset (SQuAD), a new reading\\ncomprehension dataset consisting of 100,000+ questions posed by crowdworkers on\\na set of Wikipedia articles, where the answer to each question is a segment of\\ntext from the corresponding reading passage. We analyze the dataset to\\nunderstand the types of reasoning required to answer the questions, leaning\\nheavily on dependency and constituency trees. We build a strong logistic\\nregression model, which achieves an F1 score of 51.0%, a significant\\nimprovement over a simple baseline (20%). However, human performance (86.8%) is\\nmuch higher, indicating that the dataset presents a good challenge problem for\\nfuture research.\\nThe dataset is freely available at this https URL\\n', \"\\nAbstract:  The existing machine translation systems, whether phrase-based or neural,\\nhave relied almost exclusively on word-level modelling with explicit\\nsegmentation. In this paper, we ask a fundamental question: can neural machine\\ntranslation generate a character sequence without any explicit segmentation? To\\nanswer this question, we evaluate an attention-based encoder-decoder with a\\nsubword-level encoder and a character-level decoder on four language\\npairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15.\\nOur experiments show that the models with a character-level decoder outperform\\nthe ones with a subword-level decoder on all of the four language pairs.\\nFurthermore, the ensembles of neural models with a character-level decoder\\noutperform the state-of-the-art non-neural machine translation systems on\\nEn-Cs, En-De and En-Fi and perform comparably on En-Ru.\\n\\n    \", '\\nAbstract:  Object category localization is a challenging problem in computer vision.\\nStandard supervised training requires bounding box annotations of object\\ninstances. This time-consuming annotation process is sidestepped in weakly\\nsupervised learning. In this case, the supervised information is restricted to\\nbinary labels that indicate the absence/presence of object instances in the\\nimage, without their locations. We follow a multiple-instance learning approach\\nthat iteratively trains the detector and infers the object locations in the\\npositive training images. Our main contribution is a multi-fold multiple\\ninstance learning procedure, which prevents training from prematurely locking\\nonto erroneous object locations. This procedure is particularly important when\\nusing high-dimensional representations, such as Fisher vectors and\\nconvolutional neural network features. We also propose a window refinement\\nmethod, which improves the localization accuracy by incorporating an objectness\\nprior. We present a detailed experimental evaluation using the PASCAL VOC 2007\\ndataset, which verifies the effectiveness of our approach.\\n\\n    ', \"\\nAbstract:  In this paper, we present a fully automatic brain tumor segmentation method\\nbased on Deep Neural Networks (DNNs). The proposed networks are tailored to\\nglioblastomas (both low and high grade) pictured in MR images. By their very\\nnature, these tumors can appear anywhere in the brain and have almost any kind\\nof shape, size, and contrast. These reasons motivate our exploration of a\\nmachine learning solution that exploits a flexible, high capacity DNN while\\nbeing extremely efficient. Here, we give a description of different model\\nchoices that we've found to be necessary for obtaining competitive performance.\\nWe explore in particular different architectures based on Convolutional Neural\\nNetworks (CNN), i.e. DNNs specifically adapted to image data.\\nWe present a novel CNN architecture which differs from those traditionally\\nused in computer vision. Our CNN exploits both local features as well as more\\nglobal contextual features simultaneously. Also, different from most\\ntraditional uses of CNNs, our networks use a final layer that is a\\nconvolutional implementation of a fully connected layer which allows a 40 fold\\nspeed up. We also describe a 2-phase training procedure that allows us to\\ntackle difficulties related to the imbalance of tumor labels. Finally, we\\nexplore a cascade architecture in which the output of a basic CNN is treated as\\nan additional source of information for a subsequent CNN. Results reported on\\nthe 2013 BRATS test dataset reveal that our architecture improves over the\\ncurrently published state-of-the-art while being over 30 times faster.\\n\\n    \", \"\\nAbstract:  The Teacher Forcing algorithm trains recurrent networks by supplying observed\\nsequence values as inputs during training and using the network's own\\none-step-ahead predictions to do multi-step sampling. We introduce the\\nProfessor Forcing algorithm, which uses adversarial domain adaptation to\\nencourage the dynamics of the recurrent network to be the same when training\\nthe network and when sampling from the network over multiple time steps. We\\napply Professor Forcing to language modeling, vocal synthesis on raw waveforms,\\nhandwriting generation, and image generation. Empirically we find that\\nProfessor Forcing acts as a regularizer, improving test likelihood on character\\nlevel Penn Treebank and sequential MNIST. We also find that the model\\nqualitatively improves samples, especially when sampling for a large number of\\ntime steps. This is supported by human evaluation of sample quality. Trade-offs\\nbetween Professor Forcing and Scheduled Sampling are discussed. We produce\\nT-SNEs showing that Professor Forcing successfully makes the dynamics of the\\nnetwork during training and sampling more similar.\\n\\n    \", \"\\nAbstract:  The matrix-based Renyi's \\\\alpha-entropy functional and its multivariate\\nextension were recently developed in terms of the normalized eigenspectrum of a\\nHermitian matrix of the projected data in a reproducing kernel Hilbert space\\n(RKHS). However, the utility and possible applications of these new estimators\\nare rather new and mostly unknown to practitioners. In this paper, we first\\nshow that our estimators enable straightforward measurement of information flow\\nin realistic convolutional neural networks (CNN) without any approximation.\\nThen, we introduce the partial information decomposition (PID) framework and\\ndevelop three quantities to analyze the synergy and redundancy in convolutional\\nlayer representations. Our results validate two fundamental data processing\\ninequalities and reveal some fundamental properties concerning the training of\\nCNN.\\n\\n    \", 'It is pdf', '\\nAbstract:  This paper introduces Adaptive Computation Time (ACT), an algorithm that\\nallows recurrent neural networks to learn how many computational steps to take\\nbetween receiving an input and emitting an output. ACT requires minimal changes\\nto the network architecture, is deterministic and differentiable, and does not\\nadd any noise to the parameter gradients. Experimental results are provided for\\nfour synthetic problems: determining the parity of binary vectors, applying\\nbinary logic operations, adding integers, and sorting real numbers. Overall,\\nperformance is dramatically improved by the use of ACT, which successfully\\nadapts the number of computational steps to the requirements of the problem. We\\nalso present character-level language modelling results on the Hutter prize\\nWikipedia dataset. In this case ACT does not yield large gains in performance;\\nhowever it does provide intriguing insight into the structure of the data, with\\nmore computation allocated to harder-to-predict transitions, such as spaces\\nbetween words and ends of sentences. This suggests that ACT or other adaptive\\ncomputation methods could provide a generic method for inferring segment\\nboundaries in sequence data.\\n\\n    ', '\\nAbstract:  Recent work has shown that convolutional networks can be substantially\\ndeeper, more accurate, and efficient to train if they contain shorter\\nconnections between layers close to the input and those close to the output. In\\nthis paper, we embrace this observation and introduce the Dense Convolutional\\nNetwork (DenseNet), which connects each layer to every other layer in a\\nfeed-forward fashion. Whereas traditional convolutional networks with L layers\\nhave L connections - one between each layer and its subsequent layer - our\\nnetwork has L(L+1)/2 direct connections. For each layer, the feature-maps of\\nall preceding layers are used as inputs, and its own feature-maps are used as\\ninputs into all subsequent layers. DenseNets have several compelling\\nadvantages: they alleviate the vanishing-gradient problem, strengthen feature\\npropagation, encourage feature reuse, and substantially reduce the number of\\nparameters. We evaluate our proposed architecture on four highly competitive\\nobject recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).\\nDenseNets obtain significant improvements over the state-of-the-art on most of\\nthem, whilst requiring less computation to achieve high performance. Code and\\npre-trained models are available at this https URL .\\n\\n    ', 'It is pdf', '\\nAbstract:  We introduce the adversarially learned inference (ALI) model, which jointly\\nlearns a generation network and an inference network using an adversarial\\nprocess. The generation network maps samples from stochastic latent variables\\nto the data space while the inference network maps training examples in data\\nspace to the space of latent variables. An adversarial game is cast between\\nthese two networks and a discriminative network is trained to distinguish\\nbetween joint latent/data-space samples from the generative network and joint\\nsamples from the inference network. We illustrate the ability of the model to\\nlearn mutually coherent inference and generation networks through the\\ninspections of model samples and reconstructions and confirm the usefulness of\\nthe learned representations by obtaining a performance competitive with\\nstate-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.\\n\\n    ', '\\nAbstract:  Training recurrent neural networks to model long term dependencies is\\ndifficult. Hence, we propose to use external linguistic knowledge as an\\nexplicit signal to inform the model which memories it should utilize.\\nSpecifically, external knowledge is used to augment a sequence with typed edges\\nbetween arbitrarily distant elements, and the resulting graph is decomposed\\ninto directed acyclic subgraphs. We introduce a model that encodes such graphs\\nas explicit memory in recurrent neural networks, and use it to model\\ncoreference relations in text. We apply our model to several text comprehension\\ntasks and achieve new state-of-the-art results on all considered benchmarks,\\nincluding CNN, bAbi, and LAMBADA. On the bAbi QA tasks, our model solves 15 out\\nof the 20 tasks with only 1000 training examples per task. Analysis of the\\nlearned representations further demonstrates the ability of our model to encode\\nfine-grained entity information across a document.\\n\\n    ', '\\nAbstract:  Human pose estimation plays an important role in many computer vision tasks\\nand has been studied for many decades. However, due to complex appearance\\nvariations from poses, illuminations, occlusions and low resolutions, it still\\nremains a challenging problem. Taking the advantage of high-level semantic\\ninformation from deep convolutional neural networks is an effective way to\\nimprove the accuracy of human pose estimation. In this paper, we propose a\\nnovel Cascade Feature Aggregation (CFA) method, which cascades several\\nhourglass networks for robust human pose estimation. Features from different\\nstages are aggregated to obtain abundant contextual information, leading to\\nrobustness to poses, partial occlusions and low resolution. Moreover, results\\nfrom different stages are fused to further improve the localization accuracy.\\nThe extensive experiments on MPII datasets and LIP datasets demonstrate that\\nour proposed CFA outperforms the state-of-the-art and achieves the best\\nperformance on the state-of-the-art benchmark MPII.\\n\\n    ', \"\\nAbstract:  Random data augmentation is a critical technique to avoid overfitting in\\ntraining deep neural network models. However, data augmentation and network\\ntraining are usually treated as two isolated processes, limiting the\\neffectiveness of network training. Why not jointly optimize the two? We propose\\nadversarial data augmentation to address this limitation. The main idea is to\\ndesign an augmentation network (generator) that competes against a target\\nnetwork (discriminator) by generating `hard' augmentation operations online.\\nThe augmentation network explores the weaknesses of the target network, while\\nthe latter learns from `hard' augmentations to achieve better performance. We\\nalso design a reward/penalty strategy for effective joint training. We\\ndemonstrate our approach on the problem of human pose estimation and carry out\\na comprehensive experimental analysis, showing that our method can\\nsignificantly improve state-of-the-art models without additional data efforts.\\n\\n    \", '\\nAbstract:  Most of the existing deep learning-based methods for 3D hand and human pose\\nestimation from a single depth map are based on a common framework that takes a\\n2D depth map and directly regresses the 3D coordinates of keypoints, such as\\nhand or human body joints, via 2D convolutional neural networks (CNNs). The\\nfirst weakness of this approach is the presence of perspective distortion in\\nthe 2D depth map. While the depth map is intrinsically 3D data, many previous\\nmethods treat depth maps as 2D images that can distort the shape of the actual\\nobject through projection from 3D to 2D space. This compels the network to\\nperform perspective distortion-invariant estimation. The second weakness of the\\nconventional approach is that directly regressing 3D coordinates from a 2D\\nimage is a highly non-linear mapping, which causes difficulty in the learning\\nprocedure. To overcome these weaknesses, we firstly cast the 3D hand and human\\npose estimation problem from a single depth map into a voxel-to-voxel\\nprediction that uses a 3D voxelized grid and estimates the per-voxel likelihood\\nfor each keypoint. We design our model as a 3D CNN that provides accurate\\nestimates while running in real-time. Our system outperforms previous methods\\nin almost all publicly available 3D hand and human pose estimation datasets and\\nplaced first in the HANDS 2017 frame-based 3D hand pose estimation challenge.\\nThe code is available in this https URL.\\n\\n    ', '\\nAbstract:  This is an official pytorch implementation of Deep High-Resolution\\nRepresentation Learning for Human Pose Estimation. In this work, we are\\ninterested in the human pose estimation problem with a focus on learning\\nreliable high-resolution representations. Most existing methods recover\\nhigh-resolution representations from low-resolution representations produced by\\na high-to-low resolution network. Instead, our proposed network maintains\\nhigh-resolution representations through the whole process. We start from a\\nhigh-resolution subnetwork as the first stage, gradually add high-to-low\\nresolution subnetworks one by one to form more stages, and connect the\\nmutli-resolution subnetworks in parallel. We conduct repeated multi-scale\\nfusions such that each of the high-to-low resolution representations receives\\ninformation from other parallel representations over and over, leading to rich\\nhigh-resolution representations. As a result, the predicted keypoint heatmap is\\npotentially more accurate and spatially more precise. We empirically\\ndemonstrate the effectiveness of our network through the superior pose\\nestimation results over two benchmark datasets: the COCO keypoint detection\\ndataset and the MPII Human Pose dataset. The code and models have been publicly\\navailable at\\n\\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  Instance-level human analysis is common in real-life scenarios and has\\nmultiple manifestations, such as human part segmentation, dense pose\\nestimation, human-object interactions, etc. Models need to distinguish\\ndifferent human instances in the image panel and learn rich features to\\nrepresent the details of each instance. In this paper, we present an end-to-end\\npipeline for solving the instance-level human analysis, named Parsing R-CNN. It\\nprocesses a set of human instances simultaneously through comprehensive\\nconsidering the characteristics of region-based approach and the appearance of\\na human, thus allowing representing the details of instances. Parsing R-CNN is\\nvery flexible and efficient, which is applicable to many issues in human\\ninstance analysis. Our approach outperforms all state-of-the-art methods on\\nCIHP (Crowd Instance-level Human Parsing), MHP v2.0 (Multi-Human Parsing) and\\nDensePose-COCO datasets. Based on the proposed Parsing R-CNN, we reach the 1st\\nplace in the COCO 2018 Challenge DensePose Estimation task. Code and models are\\npublic available.\\n\\n    ', '\\nAbstract:  This work introduces a novel convolutional network architecture for the task\\nof human pose estimation. Features are processed across all scales and\\nconsolidated to best capture the various spatial relationships associated with\\nthe body. We show how repeated bottom-up, top-down processing used in\\nconjunction with intermediate supervision is critical to improving the\\nperformance of the network. We refer to the architecture as a \"stacked\\nhourglass\" network based on the successive steps of pooling and upsampling that\\nare done to produce a final set of predictions. State-of-the-art results are\\nachieved on the FLIC and MPII benchmarks outcompeting all recent methods.\\n\\n    ', \"\\nAbstract:  For 3D hand and body pose estimation task in depth image, a novel\\nanchor-based approach termed Anchor-to-Joint regression network (A2J) with the\\nend-to-end learning ability is proposed. Within A2J, anchor points able to\\ncapture global-local spatial context information are densely set on depth image\\nas local regressors for the joints. They contribute to predict the positions of\\nthe joints in ensemble way to enhance generalization ability. The proposed 3D\\narticulated pose estimation paradigm is different from the state-of-the-art\\nencoder-decoder based FCN, 3D CNN and point-set based manners. To discover\\ninformative anchor points towards certain joint, anchor proposal procedure is\\nalso proposed for A2J. Meanwhile 2D CNN (i.e., ResNet-50) is used as backbone\\nnetwork to drive A2J, without using time-consuming 3D convolutional or\\ndeconvolutional layers. The experiments on 3 hand datasets and 2 body datasets\\nverify A2J's superiority. Meanwhile, A2J is of high running speed around 100\\nFPS on single NVIDIA 1080Ti GPU.\\n\\n    \", '\\nAbstract:  We introduce a new generative model where samples are produced via Langevin\\ndynamics using gradients of the data distribution estimated with score\\nmatching. Because gradients might be ill-defined when the data resides on\\nlow-dimensional manifolds, we perturb the data with different levels of\\nGaussian noise and jointly estimate the corresponding scores, i.e., the vector\\nfields of gradients of the perturbed data distribution for all noise levels.\\nFor sampling, we propose an annealed Langevin dynamics where we use gradients\\ncorresponding to gradually decreasing noise levels as the sampling process gets\\ncloser to the data manifold. Our framework allows flexible model architectures,\\nrequires no sampling during training or the use of adversarial methods, and\\nprovides a learning objective that can be used for principled model\\ncomparisons. Our models produce samples comparable to GANs on MNIST, CelebA and\\nCIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.91 on\\nCIFAR-10. Additionally, we demonstrate that our models learn effective\\nrepresentations via image inpainting experiments.\\n\\n    ', 'It is pdf', '\\nAbstract:  Humans can only interact with part of the surrounding environment due to\\nbiological restrictions. Therefore, we learn to reason the spatial\\nrelationships across a series of observations to piece together the surrounding\\nenvironment. Inspired by such behavior and the fact that machines also have\\ncomputational constraints, we propose \\\\underline{CO}nditional\\n\\\\underline{CO}ordinate GAN (COCO-GAN) of which the generator generates images\\nby parts based on their spatial coordinates as the condition. On the other\\nhand, the discriminator learns to justify realism across multiple assembled\\npatches by global coherence, local appearance, and edge-crossing continuity.\\nDespite the full images are never generated during training, we show that\\nCOCO-GAN can produce \\\\textbf{state-of-the-art-quality} full images during\\ninference. We further demonstrate a variety of novel applications enabled by\\nteaching the network to be aware of coordinates. First, we perform\\nextrapolation to the learned coordinate manifold and generate off-the-boundary\\npatches. Combining with the originally generated full image, COCO-GAN can\\nproduce images that are larger than training samples, which we called\\n\"beyond-boundary generation\". We then showcase panorama generation within a\\ncylindrical coordinate system that inherently preserves horizontally cyclic\\ntopology. On the computation side, COCO-GAN has a built-in divide-and-conquer\\nparadigm that reduces memory requisition during training and inference,\\nprovides high-parallelism, and can generate parts of images on-demand.\\n\\n    ', '\\nAbstract:  Flow-based generative models parameterize probability distributions through\\nan invertible transformation and can be trained by maximum likelihood.\\nInvertible residual networks provide a flexible family of transformations where\\nonly Lipschitz conditions rather than strict architectural constraints are\\nneeded for enforcing invertibility. However, prior work trained invertible\\nresidual networks for density estimation by relying on biased log-density\\nestimates whose bias increased with the network\\'s expressiveness. We give a\\ntractable unbiased estimate of the log density using a \"Russian roulette\"\\nestimator, and reduce the memory required during training by using an\\nalternative infinite series for the gradient. Furthermore, we improve\\ninvertible residual blocks by proposing the use of activation functions that\\navoid derivative saturation and generalizing the Lipschitz condition to induced\\nmixed norms. The resulting approach, called Residual Flows, achieves\\nstate-of-the-art performance on density estimation amongst flow-based models,\\nand outperforms networks that use coupling blocks at joint generative and\\ndiscriminative modeling.\\n\\n    ', '\\nAbstract:  The ability to automatically estimate the quality and coverage of the samples\\nproduced by a generative model is a vital requirement for driving algorithm\\nresearch. We present an evaluation metric that can separately and reliably\\nmeasure both of these aspects in image generation tasks by forming explicit,\\nnon-parametric representations of the manifolds of real and generated data. We\\ndemonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing\\nseveral illustrative examples where existing metrics yield uninformative or\\ncontradictory results. Furthermore, we analyze multiple design variants of\\nStyleGAN to better understand the relationships between the model architecture,\\ntraining methods, and the properties of the resulting sample distribution. In\\nthe process, we identify new variants that improve the state-of-the-art. We\\nalso perform the first principled analysis of truncation methods and identify\\nan improved method. Finally, we extend our metric to estimate the perceptual\\nquality of individual samples, and use this to study latent space\\ninterpolations.\\n\\n    ', '\\nAbstract:  In standard generative adversarial network (SGAN), the discriminator\\nestimates the probability that the input data is real. The generator is trained\\nto increase the probability that fake data is real. We argue that it should\\nalso simultaneously decrease the probability that real data is real because 1)\\nthis would account for a priori knowledge that half of the data in the\\nmini-batch is fake, 2) this would be observed with divergence minimization, and\\n3) in optimal settings, SGAN would be equivalent to integral probability metric\\n(IPM) GANs.\\nWe show that this property can be induced by using a relativistic\\ndiscriminator which estimate the probability that the given real data is more\\nrealistic than a randomly sampled fake data. We also present a variant in which\\nthe discriminator estimate the probability that the given real data is more\\nrealistic than fake data, on average. We generalize both approaches to\\nnon-standard GAN loss functions and we refer to them respectively as\\nRelativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that\\nIPM-based GANs are a subset of RGANs which use the identity function.\\nEmpirically, we observe that 1) RGANs and RaGANs are significantly more\\nstable and generate higher quality data samples than their non-relativistic\\ncounterparts, 2) Standard RaGAN with gradient penalty generate data of better\\nquality than WGAN-GP while only requiring a single discriminator update per\\ngenerator update (reducing the time taken for reaching the state-of-the-art by\\n400%), and 3) RaGANs are able to generate plausible high resolutions images\\n(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these\\nimages are of significantly better quality than the ones generated by WGAN-GP\\nand SGAN with spectral normalization.\\n\\n    ', '\\nAbstract:  TorchBeast is a platform for reinforcement learning (RL) research in PyTorch.\\nIt implements a version of the popular IMPALA algorithm for fast, asynchronous,\\nparallel training of RL agents. Additionally, TorchBeast has simplicity as an\\nexplicit design goal: We provide both a pure-Python implementation\\n(\"MonoBeast\") as well as a multi-machine high-performance version\\n(\"PolyBeast\"). In the latter, parts of the implementation are written in C++,\\nbut all parts pertaining to machine learning are kept in simple Python using\\nPyTorch, with the environments provided using the OpenAI Gym interface. This\\nenables researchers to conduct scalable RL research using TorchBeast without\\nany programming knowledge beyond Python and PyTorch. In this paper, we describe\\nthe TorchBeast design principles and implementation and demonstrate that it\\nperforms on-par with IMPALA on Atari. TorchBeast is released as an open-source\\npackage under the Apache 2.0 license and is available at\\n\\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  We present two novel solutions for multi-view 3D human pose estimation based\\non new learnable triangulation methods that combine 3D information from\\nmultiple 2D views. The first (baseline) solution is a basic differentiable\\nalgebraic triangulation with an addition of confidence weights estimated from\\nthe input images. The second solution is based on a novel method of volumetric\\naggregation from intermediate 2D backbone feature maps. The aggregated volume\\nis then refined via 3D convolutions that produce final 3D joint heatmaps and\\nallow modelling a human pose prior. Crucially, both approaches are end-to-end\\ndifferentiable, which allows us to directly optimize the target metric. We\\ndemonstrate transferability of the solutions across datasets and considerably\\nimprove the multi-view state of the art on the Human3.6M dataset. Video\\ndemonstration, annotations and additional materials will be posted on our\\nproject page (this https URL).\\n\\n    ', '\\nAbstract:  Automatically determining three-dimensional human pose from monocular RGB\\nimage data is a challenging problem. The two-dimensional nature of the input\\nresults in intrinsic ambiguities which make inferring depth particularly\\ndifficult. Recently, researchers have demonstrated that the flexible\\nstatistical modelling capabilities of deep neural networks are sufficient to\\nmake such inferences with reasonable accuracy. However, many of these models\\nuse coordinate output techniques which are memory-intensive, not\\ndifferentiable, and/or do not spatially generalise well. We propose\\nimprovements to 3D coordinate prediction which avoid the aforementioned\\nundesirable traits by predicting 2D marginal heatmaps under an augmented\\nsoft-argmax scheme. Our resulting model, MargiPose, produces visually coherent\\nheatmaps whilst maintaining differentiability. We are also able to achieve\\nstate-of-the-art accuracy on publicly available 3D human pose estimation data.\\n\\n    ', 'It is pdf', '\\nAbstract:  We present an approach to recover absolute 3D human poses from multi-view\\nimages by incorporating multi-view geometric priors in our model. It consists\\nof two separate steps: (1) estimating the 2D poses in multi-view images and (2)\\nrecovering the 3D poses from the multi-view 2D poses. First, we introduce a\\ncross-view fusion scheme into CNN to jointly estimate 2D poses for multiple\\nviews. Consequently, the 2D pose estimation for each view already benefits from\\nother views. Second, we present a recursive Pictorial Structure Model to\\nrecover the 3D pose from the multi-view 2D poses. It gradually improves the\\naccuracy of 3D pose with affordable computational cost. We test our method on\\ntwo public datasets H36M and Total Capture. The Mean Per Joint Position Errors\\non the two datasets are 26mm and 29mm, which outperforms the state-of-the-arts\\nremarkably (26mm vs 52mm, 29mm vs 35mm). Our code is released at\\n\\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  Following the success of deep convolutional networks, state-of-the-art\\nmethods for 3d human pose estimation have focused on deep end-to-end systems\\nthat predict 3d joint locations given raw image pixels. Despite their excellent\\nperformance, it is often not easy to understand whether their remaining error\\nstems from a limited 2d pose (visual) understanding, or from a failure to map\\n2d poses into 3-dimensional positions. With the goal of understanding these\\nsources of error, we set out to build a system that given 2d joint locations\\npredicts 3d positions. Much to our surprise, we have found that, with current\\ntechnology, \"lifting\" ground truth 2d joint locations to 3d space is a task\\nthat can be solved with a remarkably low error rate: a relatively simple deep\\nfeed-forward network outperforms the best reported result by about 30\\\\% on\\nHuman3.6M, the largest publicly available 3d pose estimation benchmark.\\nFurthermore, training our system on the output of an off-the-shelf\\nstate-of-the-art 2d detector (\\\\ie, using images as input) yields state of the\\nart results -- this includes an array of systems that have been trained\\nend-to-end specifically for this task. Our results indicate that a large\\nportion of the error of modern deep 3d pose estimation systems stems from their\\nvisual analysis, and suggests directions to further advance the state of the\\nart in 3d human pose estimation.\\n\\n    ', '\\nAbstract:  Model-based human pose estimation is currently approached through two\\ndifferent paradigms. Optimization-based methods fit a parametric body model to\\n2D observations in an iterative manner, leading to accurate image-model\\nalignments, but are often slow and sensitive to the initialization. In\\ncontrast, regression-based methods, that use a deep network to directly\\nestimate the model parameters from pixels, tend to provide reasonable, but not\\npixel accurate, results while requiring huge amounts of supervision. In this\\nwork, instead of investigating which approach is better, our key insight is\\nthat the two paradigms can form a strong collaboration. A reasonable, directly\\nregressed estimate from the network can initialize the iterative optimization\\nmaking the fitting faster and more accurate. Similarly, a pixel accurate fit\\nfrom iterative optimization can act as strong supervision for the network. This\\nis the core of our proposed approach SPIN (SMPL oPtimization IN the loop). The\\ndeep network initializes an iterative optimization routine that fits the body\\nmodel to 2D joints within the training loop, and the fitted estimate is\\nsubsequently used to supervise the network. Our approach is self-improving by\\nnature, since better network estimates can lead the optimization to better\\nsolutions, while more accurate optimization fits provide better supervision for\\nthe network. We demonstrate the effectiveness of our approach in different\\nsettings, where 3D ground truth is scarce, or not available, and we\\nconsistently outperform the state-of-the-art model-based pose estimation\\napproaches by significant margins. The project website with videos, results,\\nand code can be found at this https URL.\\n\\n    ', '\\nAbstract:  For the ECCV 2018 PoseTrack Challenge, we present a 3D human pose estimation\\nsystem based mainly on the integral human pose regression method. We show a\\ncomprehensive ablation study to examine the key performance factors of the\\nproposed system. Our system obtains 47mm MPJPE on the CHALL_H80K test dataset,\\nplacing second in the ECCV2018 3D human pose estimation challenge. Code will be\\nreleased to facilitate future work.\\n\\n    ', '\\nAbstract:  This paper addresses the problem of 3D human pose estimation from a single\\nimage. We follow a standard two-step pipeline by first detecting the 2D\\nposition of the $N$ body joints, and then using these observations to infer 3D\\npose. For the first step, we use a recent CNN-based detector. For the second\\nstep, most existing approaches perform 2$N$-to-3$N$ regression of the Cartesian\\njoint coordinates. We show that more precise pose estimates can be obtained by\\nrepresenting both the 2D and 3D human poses using $N\\\\times N$ distance\\nmatrices, and formulating the problem as a 2D-to-3D distance matrix regression.\\nFor learning such a regressor we leverage on simple Neural Network\\narchitectures, which by construction, enforce positivity and symmetry of the\\npredicted matrices. The approach has also the advantage to naturally handle\\nmissing observations and allowing to hypothesize the position of non-observed\\njoints. Quantitative results on Humaneva and Human3.6M datasets demonstrate\\nconsistent performance gains over state-of-the-art. Qualitative evaluation on\\nthe images in-the-wild of the LSP dataset, using the regressor learned on\\nHuman3.6M, reveals very promising generalization results.\\n\\n    ', '\\nAbstract:  Multi-person pose estimation from a 2D image is an essential technique for\\nhuman behavior understanding. In this paper, we propose a human pose refinement\\nnetwork that estimates a refined pose from a tuple of an input image and input\\npose. The pose refinement was performed mainly through an end-to-end trainable\\nmulti-stage architecture in previous methods. However, they are highly\\ndependent on pose estimation models and require careful model design. By\\ncontrast, we propose a model-agnostic pose refinement method. According to a\\nrecent study, state-of-the-art 2D human pose estimation methods have similar\\nerror distributions. We use this error statistics as prior information to\\ngenerate synthetic poses and use the synthesized poses to train our model. In\\nthe testing stage, pose estimation results of any other methods can be input to\\nthe proposed method. Moreover, the proposed model does not require code or\\nknowledge about other methods, which allows it to be easily used in the\\npost-processing step. We show that the proposed approach achieves better\\nperformance than the conventional multi-stage refinement models and\\nconsistently improves the performance of various state-of-the-art pose\\nestimation methods on the commonly used benchmark. The code is available in\\nthis https URL\\\\footnote{\\\\url{this https URL}}.\\n\\n    ', '\\nAbstract:  This paper presents a novel approach to estimating the continuous six degree\\nof freedom (6-DoF) pose (3D translation and rotation) of an object from a\\nsingle RGB image. The approach combines semantic keypoints predicted by a\\nconvolutional network (convnet) with a deformable shape model. Unlike prior\\nwork, we are agnostic to whether the object is textured or textureless, as the\\nconvnet learns the optimal representation from the available training image\\ndata. Furthermore, the approach can be applied to instance- and class-based\\npose recovery. Empirically, we show that the proposed approach can accurately\\nrecover the 6-DoF object pose for both instance- and class-based scenarios with\\na cluttered background. For class-based object pose estimation,\\nstate-of-the-art accuracy is shown on the large-scale PASCAL3D+ dataset.\\n\\n    ', '\\nAbstract:  We present a simple and effective method for 3D hand pose estimation from a\\nsingle depth frame. As opposed to previous state-of-the-art methods based on\\nholistic 3D regression, our method works on dense pixel-wise estimation. This\\nis achieved by careful design choices in pose parameterization, which leverages\\nboth 2D and 3D properties of depth map. Specifically, we decompose the pose\\nparameters into a set of per-pixel estimations, i.e., 2D heat maps, 3D heat\\nmaps and unit 3D directional vector fields. The 2D/3D joint heat maps and 3D\\njoint offsets are estimated via multi-task network cascades, which is trained\\nend-to-end. The pixel-wise estimations can be directly translated into a vote\\ncasting scheme. A variant of mean shift is then used to aggregate local votes\\nwhile enforcing consensus between the the estimated 3D pose and the pixel-wise\\n2D and 3D estimations by design. Our method is efficient and highly accurate.\\nOn MSRA and NYU hand dataset, our method outperforms all previous\\nstate-of-the-art approaches by a large margin. On the ICVL hand dataset, our\\nmethod achieves similar accuracy compared to the currently proposed nearly\\nsaturated result and outperforms various other proposed methods. Code is\\navailable $\\\\href{\"this https URL\"}{\\\\text{online}}$.\\n\\n    ', '\\nAbstract:  This paper presents KeypointNet, an end-to-end geometric reasoning framework\\nto learn an optimal set of category-specific 3D keypoints, along with their\\ndetectors. Given a single image, KeypointNet extracts 3D keypoints that are\\noptimized for a downstream task. We demonstrate this framework on 3D pose\\nestimation by proposing a differentiable objective that seeks the optimal set\\nof keypoints for recovering the relative pose between two views of an object.\\nOur model discovers geometrically and semantically consistent keypoints across\\nviewing angles and instances of an object category. Importantly, we find that\\nour end-to-end framework using no ground-truth keypoint annotations outperforms\\na fully supervised baseline using the same neural network architecture on the\\ntask of pose estimation. The discovered 3D keypoints on the car, chair, and\\nplane categories of ShapeNet are visualized at this http URL.\\n\\n    ', '\\nAbstract:  Multi-person pose estimation in the wild is challenging. Although\\nstate-of-the-art human detectors have demonstrated good performance, small\\nerrors in localization and recognition are inevitable. These errors can cause\\nfailures for a single-person pose estimator (SPPE), especially for methods that\\nsolely depend on human detection results. In this paper, we propose a novel\\nregional multi-person pose estimation (RMPE) framework to facilitate pose\\nestimation in the presence of inaccurate human bounding boxes. Our framework\\nconsists of three components: Symmetric Spatial Transformer Network (SSTN),\\nParametric Pose Non-Maximum-Suppression (NMS), and Pose-Guided Proposals\\nGenerator (PGPG). Our method is able to handle inaccurate bounding boxes and\\nredundant detections, allowing it to achieve a 17% increase in mAP over the\\nstate-of-the-art methods on the MPII (multi person) dataset.Our model and\\nsource codes are publicly available.\\n\\n    ', '\\nAbstract:  TensorFlow is an interface for expressing machine learning algorithms, and an\\nimplementation for executing such algorithms. A computation expressed using\\nTensorFlow can be executed with little or no change on a wide variety of\\nheterogeneous systems, ranging from mobile devices such as phones and tablets\\nup to large-scale distributed systems of hundreds of machines and thousands of\\ncomputational devices such as GPU cards. The system is flexible and can be used\\nto express a wide variety of algorithms, including training and inference\\nalgorithms for deep neural network models, and it has been used for conducting\\nresearch and for deploying machine learning systems into production across more\\nthan a dozen areas of computer science and other fields, including speech\\nrecognition, computer vision, robotics, information retrieval, natural language\\nprocessing, geographic information extraction, and computational drug\\ndiscovery. This paper describes the TensorFlow interface and an implementation\\nof that interface that we have built at Google. The TensorFlow API and a\\nreference implementation were released as an open-source package under the\\nApache 2.0 license in November, 2015 and are available at this http URL.\\n\\n    ', '\\nAbstract:  The goal of this paper is to advance the state-of-the-art of articulated pose\\nestimation in scenes with multiple people. To that end we contribute on three\\nfronts. We propose (1) improved body part detectors that generate effective\\nbottom-up proposals for body parts; (2) novel image-conditioned pairwise terms\\nthat allow to assemble the proposals into a variable number of consistent body\\npart configurations; and (3) an incremental optimization strategy that explores\\nthe search space more efficiently thus leading both to better performance and\\nsignificant speed-up factors. Evaluation is done on two single-person and two\\nmulti-person pose estimation benchmarks. The proposed approach significantly\\noutperforms best known multi-person pose estimation results while demonstrating\\ncompetitive performance on the task of single person pose estimation. Models\\nand code available at this http URL\\n', '\\nAbstract:  Multi-person pose estimation is fundamental to many computer vision tasks and\\nhas made significant progress in recent years. However, few previous methods\\nexplored the problem of pose estimation in crowded scenes while it remains\\nchallenging and inevitable in many scenarios. Moreover, current benchmarks\\ncannot provide an appropriate evaluation for such cases. In this paper, we\\npropose a novel and efficient method to tackle the problem of pose estimation\\nin the crowd and a new dataset to better evaluate algorithms. Our model\\nconsists of two key components: joint-candidate single person pose estimation\\n(SPPE) and global maximum joints association. With multi-peak prediction for\\neach joint and global association using graph model, our method is robust to\\ninevitable interference in crowded scenes and very efficient in inference. The\\nproposed method surpasses the state-of-the-art methods on CrowdPose dataset by\\n5.2 mAP and results on MSCOCO dataset demonstrate the generalization ability of\\nour method. Source code and dataset will be made publicly available.\\n\\n    ', '\\nAbstract:  We describe a new training methodology for generative adversarial networks.\\nThe key idea is to grow both the generator and discriminator progressively:\\nstarting from a low resolution, we add new layers that model increasingly fine\\ndetails as training progresses. This both speeds the training up and greatly\\nstabilizes it, allowing us to produce images of unprecedented quality, e.g.,\\nCelebA images at 1024^2. We also propose a simple way to increase the variation\\nin generated images, and achieve a record inception score of 8.80 in\\nunsupervised CIFAR10. Additionally, we describe several implementation details\\nthat are important for discouraging unhealthy competition between the generator\\nand discriminator. Finally, we suggest a new metric for evaluating GAN results,\\nboth in terms of image quality and variation. As an additional contribution, we\\nconstruct a higher-quality version of the CelebA dataset.\\n\\n    ', '\\nAbstract:  Recent advances in Generative Adversarial Networks (GANs) have shown\\nimpressive results for task of facial expression synthesis. The most successful\\narchitecture is StarGAN, that conditions GANs generation process with images of\\na specific domain, namely a set of images of persons sharing the same\\nexpression. While effective, this approach can only generate a discrete number\\nof expressions, determined by the content of the dataset. To address this\\nlimitation, in this paper, we introduce a novel GAN conditioning scheme based\\non Action Units (AU) annotations, which describes in a continuous manifold the\\nanatomical facial movements defining a human expression. Our approach allows\\ncontrolling the magnitude of activation of each AU and combine several of them.\\nAdditionally, we propose a fully unsupervised strategy to train the model, that\\nonly requires images annotated with their activated AUs, and exploit attention\\nmechanisms that make our network robust to changing backgrounds and lighting\\nconditions. Extensive evaluation show that our approach goes beyond competing\\nconditional generators both in the capability to synthesize a much wider range\\nof expressions ruled by anatomically feasible muscle movements, as in the\\ncapacity of dealing with images in the wild.\\n\\n    ', '\\nAbstract:  This paper describes InfoGAN, an information-theoretic extension to the\\nGenerative Adversarial Network that is able to learn disentangled\\nrepresentations in a completely unsupervised manner. InfoGAN is a generative\\nadversarial network that also maximizes the mutual information between a small\\nsubset of the latent variables and the observation. We derive a lower bound to\\nthe mutual information objective that can be optimized efficiently, and show\\nthat our training procedure can be interpreted as a variation of the Wake-Sleep\\nalgorithm. Specifically, InfoGAN successfully disentangles writing styles from\\ndigit shapes on the MNIST dataset, pose from lighting of 3D rendered images,\\nand background digits from the central digit on the SVHN dataset. It also\\ndiscovers visual concepts that include hair styles, presence/absence of\\neyeglasses, and emotions on the CelebA face dataset. Experiments show that\\nInfoGAN learns interpretable representations that are competitive with\\nrepresentations learned by existing fully supervised methods.\\n\\n    ', '\\nAbstract:  In this paper we tackle the problem of unsupervised domain adaptation for the\\ntask of semantic segmentation, where we attempt to transfer the knowledge\\nlearned upon synthetic datasets with ground-truth labels to real-world images\\nwithout any annotation. With the hypothesis that the structural content of\\nimages is the most informative and decisive factor to semantic segmentation and\\ncan be readily shared across domains, we propose a Domain Invariant Structure\\nExtraction (DISE) framework to disentangle images into domain-invariant\\nstructure and domain-specific texture representations, which can further\\nrealize image-translation across domains and enable label transfer to improve\\nsegmentation performance. Extensive experiments verify the effectiveness of our\\nproposed DISE model and demonstrate its superiority over several\\nstate-of-the-art approaches.\\n\\n    ', \"\\nAbstract:  Self-attention is a useful mechanism to build generative models for language\\nand images. It determines the importance of context elements by comparing each\\nelement to the current time step. In this paper, we show that a very\\nlightweight convolution can perform competitively to the best reported\\nself-attention results. Next, we introduce dynamic convolutions which are\\nsimpler and more efficient than self-attention. We predict separate convolution\\nkernels based solely on the current time-step in order to determine the\\nimportance of context elements. The number of operations required by this\\napproach scales linearly in the input length, whereas self-attention is\\nquadratic. Experiments on large-scale machine translation, language modeling\\nand abstractive summarization show that dynamic convolutions improve over\\nstrong self-attention models. On the WMT'14 English-German test set dynamic\\nconvolutions achieve a new state of the art of 29.7 BLEU.\\n\\n    \", '\\nAbstract:  Domain adaptation is critical for success in new, unseen environments.\\nAdversarial adaptation models applied in feature spaces discover domain\\ninvariant representations, but are difficult to visualize and sometimes fail to\\ncapture pixel-level and low-level domain shifts. Recent work has shown that\\ngenerative adversarial networks combined with cycle-consistency constraints are\\nsurprisingly effective at mapping images between domains, even without the use\\nof aligned image pairs. We propose a novel discriminatively-trained\\nCycle-Consistent Adversarial Domain Adaptation model. CyCADA adapts\\nrepresentations at both the pixel-level and feature-level, enforces\\ncycle-consistency while leveraging a task loss, and does not require aligned\\npairs. Our model can be applied in a variety of visual recognition and\\nprediction settings. We show new state-of-the-art results across multiple\\nadaptation tasks, including digit classification and semantic segmentation of\\nroad scenes demonstrating transfer from synthetic to real world domains.\\n\\n    ', '\\nAbstract:  We investigate conditional adversarial networks as a general-purpose solution\\nto image-to-image translation problems. These networks not only learn the\\nmapping from input image to output image, but also learn a loss function to\\ntrain this mapping. This makes it possible to apply the same generic approach\\nto problems that traditionally would require very different loss formulations.\\nWe demonstrate that this approach is effective at synthesizing photos from\\nlabel maps, reconstructing objects from edge maps, and colorizing images, among\\nother tasks. Indeed, since the release of the pix2pix software associated with\\nthis paper, a large number of internet users (many of them artists) have posted\\ntheir own experiments with our system, further demonstrating its wide\\napplicability and ease of adoption without the need for parameter tweaking. As\\na community, we no longer hand-engineer our mapping functions, and this work\\nsuggests we can achieve reasonable results without hand-engineering our loss\\nfunctions either.\\n\\n    ', '\\nAbstract:  We propose a novel method for unsupervised image-to-image translation, which\\nincorporates a new attention module and a new learnable normalization function\\nin an end-to-end manner. The attention module guides our model to focus on more\\nimportant regions distinguishing between source and target domains based on the\\nattention map obtained by the auxiliary classifier. Unlike previous\\nattention-based methods which cannot handle the geometric changes between\\ndomains, our model can translate both images requiring holistic changes and\\nimages requiring large shape changes. Moreover, our new AdaLIN (Adaptive\\nLayer-Instance Normalization) function helps our attention-guided model to\\nflexibly control the amount of change in shape and texture by learned\\nparameters depending on datasets. Experimental results show the superiority of\\nthe proposed method compared to the existing state-of-the-art models with a\\nfixed network architecture and hyper-parameters.\\n\\n    ', '\\nAbstract:  Despite recent progress in generative image modeling, successfully generating\\nhigh-resolution, diverse samples from complex datasets such as ImageNet remains\\nan elusive goal. To this end, we train Generative Adversarial Networks at the\\nlargest scale yet attempted, and study the instabilities specific to such\\nscale. We find that applying orthogonal regularization to the generator renders\\nit amenable to a simple \"truncation trick,\" allowing fine control over the\\ntrade-off between sample fidelity and variety by reducing the variance of the\\nGenerator\\'s input. Our modifications lead to models which set the new state of\\nthe art in class-conditional image synthesis. When trained on ImageNet at\\n128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of\\n166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous\\nbest IS of 52.52 and FID of 18.6.\\n\\n    ', 'It is pdf', '\\nAbstract:  We evaluate whether features extracted from the activation of a deep\\nconvolutional network trained in a fully supervised fashion on a large, fixed\\nset of object recognition tasks can be re-purposed to novel generic tasks. Our\\ngeneric tasks may differ significantly from the originally trained tasks and\\nthere may be insufficient labeled or unlabeled data to conventionally train or\\nadapt a deep architecture to the new tasks. We investigate and visualize the\\nsemantic clustering of deep convolutional features with respect to a variety of\\nsuch tasks, including scene recognition, domain adaptation, and fine-grained\\nrecognition challenges. We compare the efficacy of relying on various network\\nlevels to define a fixed feature, and report novel results that significantly\\noutperform the state-of-the-art on several important vision challenges. We are\\nreleasing DeCAF, an open-source implementation of these deep convolutional\\nactivation features, along with all associated network parameters to enable\\nvision researchers to be able to conduct experimentation with deep\\nrepresentations across a range of visual concept learning paradigms.\\n\\n    ', '\\nAbstract:  Although various image-based domain adaptation (DA) techniques have been\\nproposed in recent years, domain shift in videos is still not well-explored.\\nMost previous works only evaluate performance on small-scale datasets which are\\nsaturated. Therefore, we first propose two large-scale video DA datasets with\\nmuch larger domain discrepancy: UCF-HMDB_full and Kinetics-Gameplay. Second, we\\ninvestigate different DA integration methods for videos, and show that\\nsimultaneously aligning and learning temporal dynamics achieves effective\\nalignment even without sophisticated DA methods. Finally, we propose Temporal\\nAttentive Adversarial Adaptation Network (TA3N), which explicitly attends to\\nthe temporal dynamics using domain discrepancy for more effective domain\\nalignment, achieving state-of-the-art performance on four video DA datasets\\n(e.g. 7.9% accuracy gain over \"Source only\" from 73.9% to 81.8% on \"HMDB -->\\nUCF\", and 10.3% gain on \"Kinetics --> Gameplay\"). The code and data are\\nreleased at this http URL.\\n\\n    ', '\\nAbstract:  Visual domain adaptation aims to learn robust classifiers for the target\\ndomain by leveraging knowledge from a source domain. Existing methods either\\nattempt to align the cross-domain distributions, or perform manifold subspace\\nlearning. However, there are two significant challenges: (1) degenerated\\nfeature transformation, which means that distribution alignment is often\\nperformed in the original feature space, where feature distortions are hard to\\novercome. On the other hand, subspace learning is not sufficient to reduce the\\ndistribution divergence. (2) unevaluated distribution alignment, which means\\nthat existing distribution alignment methods only align the marginal and\\nconditional distributions with equal importance, while they fail to evaluate\\nthe different importance of these two distributions in real applications. In\\nthis paper, we propose a Manifold Embedded Distribution Alignment (MEDA)\\napproach to address these challenges. MEDA learns a domain-invariant classifier\\nin Grassmann manifold with structural risk minimization, while performing\\ndynamic distribution alignment to quantitatively account for the relative\\nimportance of marginal and conditional distributions. To the best of our\\nknowledge, MEDA is the first attempt to perform dynamic distribution alignment\\nfor manifold domain adaptation. Extensive experiments demonstrate that MEDA\\nshows significant improvements in classification accuracy compared to\\nstate-of-the-art traditional and deep methods.\\n\\n    ', '\\nAbstract:  In this work, we connect two distinct concepts for unsupervised domain\\nadaptation: feature distribution alignment between domains by utilizing the\\ntask-specific decision boundary and the Wasserstein metric. Our proposed sliced\\nWasserstein discrepancy (SWD) is designed to capture the natural notion of\\ndissimilarity between the outputs of task-specific classifiers. It provides a\\ngeometrically meaningful guidance to detect target samples that are far from\\nthe support of the source and enables efficient distribution alignment in an\\nend-to-end trainable fashion. In the experiments, we validate the effectiveness\\nand genericness of our method on digit and sign recognition, image\\nclassification, semantic segmentation, and object detection.\\n\\n    ', '\\nAbstract:  In this paper, we aim to solve for unsupervised domain adaptation of\\nclassifiers where we have access to label information for the source domain\\nwhile these are not available for a target domain. While various methods have\\nbeen proposed for solving these including adversarial discriminator based\\nmethods, most approaches have focused on the entire image based domain\\nadaptation. In an image, there would be regions that can be adapted better, for\\ninstance, the foreground object may be similar in nature. To obtain such\\nregions, we propose methods that consider the probabilistic certainty estimate\\nof various regions and specify focus on these during classification for\\nadaptation. We observe that just by incorporating the probabilistic certainty\\nof the discriminator while training the classifier, we are able to obtain state\\nof the art results on various datasets as compared against all the recent\\nmethods. We provide a thorough empirical analysis of the method by providing\\nablation analysis, statistical significance test, and visualization of the\\nattention maps and t-SNE embeddings. These evaluations convincingly demonstrate\\nthe effectiveness of the proposed approach.\\n\\n    ', '\\nAbstract:  Deep convolutional neural networks demonstrate impressive results in the\\nsuper-resolution domain. A series of studies concentrate on improving peak\\nsignal noise ratio (PSNR) by using much deeper layers, which are not friendly\\nto constrained resources. Pursuing a trade-off between the restoration capacity\\nand the simplicity of models is still non-trivial. Recent contributions are\\nstruggling to manually maximize this balance, while our work achieves the same\\ngoal automatically with neural architecture search. Specifically, we handle\\nsuper-resolution with a multi-objective approach. We also propose an elastic\\nsearch tactic at both micro and macro level, based on a hybrid controller that\\nprofits from evolutionary computation and reinforcement learning. Quantitative\\nexperiments help us to draw a conclusion that our generated models dominate\\nmost of the state-of-the-art methods with respect to the individual FLOPS.\\n\\n    ', '\\nAbstract:  We propose a simple, interpretable framework for solving a wide range of\\nimage reconstruction problems such as denoising and deconvolution. Given a\\ncorrupted input image, the model synthesizes a spatially varying linear filter\\nwhich, when applied to the input image, reconstructs the desired output. The\\nmodel parameters are learned using supervised or self-supervised training. We\\ntest this model on three tasks: non-uniform motion blur removal,\\nlossy-compression artifact reduction and single image super resolution. We\\ndemonstrate that our model substantially outperforms state-of-the-art methods\\non all these tasks and is significantly faster than optimization-based\\napproaches to deconvolution. Unlike models that directly predict output pixel\\nvalues, the predicted filter flow is controllable and interpretable, which we\\ndemonstrate by visualizing the space of predicted filters for different tasks.\\n\\n    ', 'It is pdf', '\\nAbstract:  The recent increase in the extensive use of digital imaging technologies has\\nbrought with it a simultaneous demand for higher-resolution images. We develop\\na novel edge-informed approach to single image super-resolution (SISR). The\\nSISR problem is reformulated as an image inpainting task. We use a two-stage\\ninpainting model as a baseline for super-resolution and show its effectiveness\\nfor different scale factors (x2, x4, x8) compared to basic interpolation\\nschemes. This model is trained using a joint optimization of image contents\\n(texture and color) and structures (edges). Quantitative and qualitative\\ncomparisons are included and the proposed model is compared with current\\nstate-of-the-art techniques. We show that our method of decoupling structure\\nand texture reconstruction improves the quality of the final reconstructed\\nhigh-resolution image. Code and models available at:\\nthis https URL\\n', '\\nAbstract:  Video restoration tasks, including super-resolution, deblurring, etc, are\\ndrawing increasing attention in the computer vision community. A challenging\\nbenchmark named REDS is released in the NTIRE19 Challenge. This new benchmark\\nchallenges existing methods from two aspects: (1) how to align multiple frames\\ngiven large motions, and (2) how to effectively fuse different frames with\\ndiverse motion and blur. In this work, we propose a novel Video Restoration\\nframework with Enhanced Deformable networks, termed EDVR, to address these\\nchallenges. First, to handle large motions, we devise a Pyramid, Cascading and\\nDeformable (PCD) alignment module, in which frame alignment is done at the\\nfeature level using deformable convolutions in a coarse-to-fine manner. Second,\\nwe propose a Temporal and Spatial Attention (TSA) fusion module, in which\\nattention is applied both temporally and spatially, so as to emphasize\\nimportant features for subsequent restoration. Thanks to these modules, our\\nEDVR wins the champions and outperforms the second place by a large margin in\\nall four tracks in the NTIRE19 video restoration and enhancement challenges.\\nEDVR also demonstrates superior performance to state-of-the-art published\\nmethods on video super-resolution and deblurring. The code is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Recently, several models based on deep neural networks have achieved great\\nsuccess in terms of both reconstruction accuracy and computational performance\\nfor single image super-resolution. In these methods, the low resolution (LR)\\ninput image is upscaled to the high resolution (HR) space using a single\\nfilter, commonly bicubic interpolation, before reconstruction. This means that\\nthe super-resolution (SR) operation is performed in HR space. We demonstrate\\nthat this is sub-optimal and adds computational complexity. In this paper, we\\npresent the first convolutional neural network (CNN) capable of real-time SR of\\n1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN\\narchitecture where the feature maps are extracted in the LR space. In addition,\\nwe introduce an efficient sub-pixel convolution layer which learns an array of\\nupscaling filters to upscale the final LR feature maps into the HR output. By\\ndoing so, we effectively replace the handcrafted bicubic filter in the SR\\npipeline with more complex upscaling filters specifically trained for each\\nfeature map, whilst also reducing the computational complexity of the overall\\nSR operation. We evaluate the proposed approach using images and videos from\\npublicly available datasets and show that it performs significantly better\\n(+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster\\nthan previous CNN-based methods.\\n\\n    ', '\\nAbstract:  Despite the breakthroughs in accuracy and speed of single image\\nsuper-resolution using faster and deeper convolutional neural networks, one\\ncentral problem remains largely unsolved: how do we recover the finer texture\\ndetails when we super-resolve at large upscaling factors? The behavior of\\noptimization-based super-resolution methods is principally driven by the choice\\nof the objective function. Recent work has largely focused on minimizing the\\nmean squared reconstruction error. The resulting estimates have high peak\\nsignal-to-noise ratios, but they are often lacking high-frequency details and\\nare perceptually unsatisfying in the sense that they fail to match the fidelity\\nexpected at the higher resolution. In this paper, we present SRGAN, a\\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\\nknowledge, it is the first framework capable of inferring photo-realistic\\nnatural images for 4x upscaling factors. To achieve this, we propose a\\nperceptual loss function which consists of an adversarial loss and a content\\nloss. The adversarial loss pushes our solution to the natural image manifold\\nusing a discriminator network that is trained to differentiate between the\\nsuper-resolved images and original photo-realistic images. In addition, we use\\na content loss motivated by perceptual similarity instead of similarity in\\npixel space. Our deep residual network is able to recover photo-realistic\\ntextures from heavily downsampled images on public benchmarks. An extensive\\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\\nthe original high-resolution images than to those obtained with any\\nstate-of-the-art method.\\n\\n    ', '\\nAbstract:  We propose an image super-resolution method (SR) using a deeply-recursive\\nconvolutional network (DRCN). Our network has a very deep recursive layer (up\\nto 16 recursions). Increasing recursion depth can improve performance without\\nintroducing new parameters for additional convolutions. Albeit advantages,\\nlearning a DRCN is very hard with a standard gradient descent method due to\\nexploding/vanishing gradients. To ease the difficulty of training, we propose\\ntwo extensions: recursive-supervision and skip-connection. Our method\\noutperforms previous methods by a large margin.\\n\\n    ', '\\nAbstract:  The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work\\nthat is capable of generating realistic textures during single image\\nsuper-resolution. However, the hallucinated details are often accompanied with\\nunpleasant artifacts. To further enhance the visual quality, we thoroughly\\nstudy three key components of SRGAN - network architecture, adversarial loss\\nand perceptual loss, and improve each of them to derive an Enhanced SRGAN\\n(ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block\\n(RRDB) without batch normalization as the basic network building unit.\\nMoreover, we borrow the idea from relativistic GAN to let the discriminator\\npredict relative realness instead of the absolute value. Finally, we improve\\nthe perceptual loss by using the features before activation, which could\\nprovide stronger supervision for brightness consistency and texture recovery.\\nBenefiting from these improvements, the proposed ESRGAN achieves consistently\\nbetter visual quality with more realistic and natural textures than SRGAN and\\nwon the first place in the PIRM2018-SR Challenge. The code is available at\\nthis https URL .\\n\\n    ', '\\nAbstract:  Video restoration tasks, including super-resolution, deblurring, etc, are\\ndrawing increasing attention in the computer vision community. A challenging\\nbenchmark named REDS is released in the NTIRE19 Challenge. This new benchmark\\nchallenges existing methods from two aspects: (1) how to align multiple frames\\ngiven large motions, and (2) how to effectively fuse different frames with\\ndiverse motion and blur. In this work, we propose a novel Video Restoration\\nframework with Enhanced Deformable networks, termed EDVR, to address these\\nchallenges. First, to handle large motions, we devise a Pyramid, Cascading and\\nDeformable (PCD) alignment module, in which frame alignment is done at the\\nfeature level using deformable convolutions in a coarse-to-fine manner. Second,\\nwe propose a Temporal and Spatial Attention (TSA) fusion module, in which\\nattention is applied both temporally and spatially, so as to emphasize\\nimportant features for subsequent restoration. Thanks to these modules, our\\nEDVR wins the champions and outperforms the second place by a large margin in\\nall four tracks in the NTIRE19 video restoration and enhancement challenges.\\nEDVR also demonstrates superior performance to state-of-the-art published\\nmethods on video super-resolution and deblurring. The code is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  The tradeoff between receptive field size and efficiency is a crucial issue\\nin low level vision. Plain convolutional networks (CNNs) generally enlarge the\\nreceptive field at the expense of computational cost. Recently, dilated\\nfiltering has been adopted to address this issue. But it suffers from gridding\\neffect, and the resulting receptive field is only a sparse sampling of input\\nimage with checkerboard patterns. In this paper, we present a novel multi-level\\nwavelet CNN (MWCNN) model for better tradeoff between receptive field size and\\ncomputational efficiency. With the modified U-Net architecture, wavelet\\ntransform is introduced to reduce the size of feature maps in the contracting\\nsubnetwork. Furthermore, another convolutional layer is further used to\\ndecrease the channels of feature maps. In the expanding subnetwork, inverse\\nwavelet transform is then deployed to reconstruct the high resolution feature\\nmaps. Our MWCNN can also be explained as the generalization of dilated\\nfiltering and subsampling, and can be applied to many image restoration tasks.\\nThe experimental results clearly show the effectiveness of MWCNN for image\\ndenoising, single image super-resolution, and JPEG image artifacts removal.\\n\\n    ', '\\nAbstract:  Many classic methods have shown non-local self-similarity in natural images\\nto be an effective prior for image restoration. However, it remains unclear and\\nchallenging to make use of this intrinsic property via deep networks. In this\\npaper, we propose a non-local recurrent network (NLRN) as the first attempt to\\nincorporate non-local operations into a recurrent neural network (RNN) for\\nimage restoration. The main contributions of this work are: (1) Unlike existing\\nmethods that measure self-similarity in an isolated manner, the proposed\\nnon-local module can be flexibly integrated into existing deep networks for\\nend-to-end training to capture deep feature correlation between each location\\nand its neighborhood. (2) We fully employ the RNN structure for its parameter\\nefficiency and allow deep feature correlation to be propagated along adjacent\\nrecurrent states. This new design boosts robustness against inaccurate\\ncorrelation estimation due to severely degraded images. (3) We show that it is\\nessential to maintain a confined neighborhood for computing deep feature\\ncorrelation given degraded images. This is in contrast to existing practice\\nthat deploys the whole image. Extensive experiments on both image denoising and\\nsuper-resolution tasks are conducted. Thanks to the recurrent non-local\\noperations and correlation propagation, the proposed NLRN achieves superior\\nresults to state-of-the-art methods with much fewer parameters.\\n\\n    ', '\\nAbstract:  Convolutional neural network has recently achieved great success for image\\nrestoration (IR) and also offered hierarchical features. However, most deep CNN\\nbased IR models do not make full use of the hierarchical features from the\\noriginal low-quality images, thereby achieving relatively-low performance. In\\nthis paper, we propose a novel residual dense network (RDN) to address this\\nproblem in IR. We fully exploit the hierarchical features from all the\\nconvolutional layers. Specifically, we propose residual dense block (RDB) to\\nextract abundant local features via densely connected convolutional layers. RDB\\nfurther allows direct connections from the state of preceding RDB to all the\\nlayers of current RDB, leading to a contiguous memory mechanism. To adaptively\\nlearn more effective features from preceding and current local features and\\nstabilize the training of wider network, we proposed local feature fusion in\\nRDB. After fully obtaining dense local features, we use global feature fusion\\nto jointly and adaptively learn global hierarchical features in a holistic way.\\nWe demonstrate the effectiveness of RDN with three representative IR\\napplications, single image super-resolution, Gaussian image denoising, and\\nimage compression artifact reduction. Experiments on benchmark datasets show\\nthat our RDN achieves favorable performance against state-of-the-art methods\\nfor each IR task.\\n\\n    ', '\\nAbstract:  Non-local self-similarity is well-known to be an effective prior for the\\nimage denoising problem. However, little work has been done to incorporate it\\nin convolutional neural networks, which surpass non-local model-based methods\\ndespite only exploiting local information. In this paper, we propose a novel\\nend-to-end trainable neural network architecture employing layers based on\\ngraph convolution operations, thereby creating neurons with non-local receptive\\nfields. The graph convolution operation generalizes the classic convolution to\\narbitrary graphs. In this work, the graph is dynamically computed from\\nsimilarities among the hidden features of the network, so that the powerful\\nrepresentation learning capabilities of the network are exploited to uncover\\nself-similar patterns. We introduce a lightweight Edge-Conditioned Convolution\\nwhich addresses vanishing gradient and over-parameterization issues of this\\nparticular graph convolution. Extensive experiments show state-of-the-art\\nperformance with improved qualitative and quantitative results on both\\nsynthetic Gaussian noise and real noise.\\n\\n    ', '\\nAbstract:  Image restoration, including image denoising, super resolution, inpainting,\\nand so on, is a well-studied problem in computer vision and image processing,\\nas well as a test bed for low-level image modeling algorithms. In this work, we\\npropose a very deep fully convolutional auto-encoder network for image\\nrestoration, which is a encoding-decoding framework with symmetric\\nconvolutional-deconvolutional layers. In other words, the network is composed\\nof multiple layers of convolution and de-convolution operators, learning\\nend-to-end mappings from corrupted images to the original ones. The\\nconvolutional layers capture the abstraction of image contents while\\neliminating corruptions. Deconvolutional layers have the capability to upsample\\nthe feature maps and recover the image details. To deal with the problem that\\ndeeper networks tend to be more difficult to train, we propose to symmetrically\\nlink convolutional and deconvolutional layers with skip-layer connections, with\\nwhich the training converges much faster and attains better results.\\n\\n    ', '\\nAbstract:  Object detection and instance recognition play a central role in many AI\\napplications like autonomous driving, video surveillance and medical image\\nanalysis. However, training object detection models on large scale datasets\\nremains computationally expensive and time consuming. This paper presents an\\nefficient and open source object detection framework called SimpleDet which\\nenables the training of state-of-the-art detection models on consumer grade\\nhardware at large scale. SimpleDet supports up-to-date detection models with\\nbest practice. SimpleDet also supports distributed training with near linear\\nscaling out of box. Codes, examples and documents of SimpleDet can be found at\\nthis https URL .\\n\\n    ', \"\\nAbstract:  Accurate state estimation is a fundamental module for various intelligent\\napplications, such as robot navigation, autonomous driving, virtual and\\naugmented reality. Visual and inertial fusion is a popular technology for 6-DOF\\nstate estimation in recent years. Time instants at which different sensors'\\nmeasurements are recorded are of crucial importance to the system's robustness\\nand accuracy. In practice, timestamps of each sensor typically suffer from\\ntriggering and transmission delays, leading to temporal misalignment (time\\noffsets) among different sensors. Such temporal offset dramatically influences\\nthe performance of sensor fusion. To this end, we propose an online approach\\nfor calibrating temporal offset between visual and inertial measurements. Our\\napproach achieves temporal offset calibration by jointly optimizing time\\noffset, camera and IMU states, as well as feature locations in a SLAM system.\\nFurthermore, the approach is a general model, which can be easily employed in\\nseveral feature-based optimization frameworks. Simulation and experimental\\nresults demonstrate the high accuracy of our calibration approach even compared\\nwith other state-of-art offline tools. The VIO comparison against other methods\\nproves that the online temporal calibration significantly benefits\\nvisual-inertial systems. The source code of temporal calibration is integrated\\ninto our public project, VINS-Mono.\\n\\n    \", '\\nAbstract:  We present a traffic simulation named DeepTraffic where the planning systems\\nfor a subset of the vehicles are handled by a neural network as part of a\\nmodel-free, off-policy reinforcement learning process. The primary goal of\\nDeepTraffic is to make the hands-on study of deep reinforcement learning\\naccessible to thousands of students, educators, and researchers in order to\\ninspire and fuel the exploration and evaluation of deep Q-learning network\\nvariants and hyperparameter configurations through large-scale, open\\ncompetition. This paper investigates the crowd-sourced hyperparameter tuning of\\nthe policy network that resulted from the first iteration of the DeepTraffic\\ncompetition where thousands of participants actively searched through the\\nhyperparameter space.\\n\\n    ', '\\nAbstract:  Developing and testing algorithms for autonomous vehicles in real world is an\\nexpensive and time consuming process. Also, in order to utilize recent advances\\nin machine intelligence and deep learning we need to collect a large amount of\\nannotated training data in a variety of conditions and environments. We present\\na new simulator built on Unreal Engine that offers physically and visually\\nrealistic simulations for both of these goals. Our simulator includes a physics\\nengine that can operate at a high frequency for real-time hardware-in-the-loop\\n(HITL) simulations with support for popular protocols (e.g. MavLink). The\\nsimulator is designed from the ground up to be extensible to accommodate new\\ntypes of vehicles, hardware platforms and software protocols. In addition, the\\nmodular design enables various components to be easily usable independently in\\nother projects. We demonstrate the simulator by first implementing a quadrotor\\nas an autonomous vehicle and then experimentally comparing the software\\ncomponents with real-world flights.\\n\\n    ', \"\\nAbstract: this http URL's approach to Artificial Intelligence for self-driving cars is based\\non an agent that learns to clone driver behaviors and plans maneuvers by\\nsimulating future events in the road. This paper illustrates one of our\\nresearch approaches for driving simulation. One where we learn to simulate.\\nHere we investigate variational autoencoders with classical and learned cost\\nfunctions using generative adversarial networks for embedding road frames.\\nAfterwards, we learn a transition model in the embedded space using action\\nconditioned Recurrent Neural Networks. We show that our approach can keep\\npredicting realistic looking video for several frames despite the transition\\nmodel being optimized without a cost function in the pixel space.\\n\\n    \", '\\nAbstract:  Human detection has witnessed impressive progress in recent years. However,\\nthe occlusion issue of detecting human in highly crowded environments is far\\nfrom solved. To make matters worse, crowd scenarios are still under-represented\\nin current human detection benchmarks. In this paper, we introduce a new\\ndataset, called CrowdHuman, to better evaluate detectors in crowd scenarios.\\nThe CrowdHuman dataset is large, rich-annotated and contains high diversity.\\nThere are a total of $470K$ human instances from the train and validation\\nsubsets, and $~22.6$ persons per image, with various kinds of occlusions in the\\ndataset. Each human instance is annotated with a head bounding-box, human\\nvisible-region bounding-box and human full-body bounding-box. Baseline\\nperformance of state-of-the-art detection frameworks on CrowdHuman is\\npresented. The cross-dataset generalization results of CrowdHuman dataset\\ndemonstrate state-of-the-art performance on previous dataset including\\nCaltech-USA, CityPersons, and Brainwash without bells and whistles. We hope our\\ndataset will serve as a solid baseline and help promote future research in\\nhuman detection tasks.\\n\\n    ', \"\\nAbstract:  Deep convolutional neural networks take GPU days of compute time to train on\\nlarge data sets. Pedestrian detection for self driving cars requires very low\\nlatency. Image recognition for mobile phones is constrained by limited\\nprocessing resources. The success of convolutional neural networks in these\\nsituations is limited by how fast we can compute them. Conventional FFT based\\nconvolution is fast for large filters, but state of the art convolutional\\nneural networks use small, 3x3 filters. We introduce a new class of fast\\nalgorithms for convolutional neural networks using Winograd's minimal filtering\\nalgorithms. The algorithms compute minimal complexity convolution over small\\ntiles, which makes them fast with small filters and small batch sizes. We\\nbenchmark a GPU implementation of our algorithm with the VGG network and show\\nstate of the art throughput at batch sizes from 1 to 64.\\n\\n    \", '\\nAbstract:  One of the most difficult speech recognition tasks is accurate recognition of\\nhuman to human communication. Advances in deep learning over the last few years\\nhave produced major speech recognition improvements on the representative\\nSwitchboard conversational corpus. Word error rates that just a few years ago\\nwere 14% have dropped to 8.0%, then 6.6% and most recently 5.8%, and are now\\nbelieved to be within striking range of human performance. This then raises two\\nissues - what IS human performance, and how far down can we still drive speech\\nrecognition error rates? A recent paper by Microsoft suggests that we have\\nalready achieved human performance. In trying to verify this statement, we\\nperformed an independent set of human performance measurements on two\\nconversational tasks and found that human performance may be considerably\\nbetter than what was earlier reported, giving the community a significantly\\nharder goal to achieve. We also report on our own efforts in this area,\\npresenting a set of acoustic and language modeling techniques that lowered the\\nword error rate of our own English conversational telephone LVCSR system to the\\nlevel of 5.5%/10.3% on the Switchboard/CallHome subsets of the Hub5 2000\\nevaluation, which - at least at the writing of this paper - is a new\\nperformance milestone (albeit not at what we measure to be human performance!).\\nOn the acoustic side, we use a score fusion of three models: one LSTM with\\nmultiple feature inputs, a second LSTM trained with speaker-adversarial\\nmulti-task learning and a third residual net (ResNet) with 25 convolutional\\nlayers and time-dilated convolutions. On the language modeling side, we use\\nword and character LSTMs and convolutional WaveNet-style language models.\\n\\n    ', '\\nAbstract:  Self-attention has been a huge success for many downstream tasks in NLP,\\nwhich led to exploration of applying self-attention to speech problems as well.\\nThe efficacy of self-attention in speech applications, however, seems not fully\\nblown yet since it is challenging to handle highly correlated speech frames in\\nthe context of self-attention. In this paper we propose a new neural network\\nmodel architecture, namely multi-stream self-attention, to address the issue\\nthus make the self-attention mechanism more effective for speech recognition.\\nThe proposed model architecture consists of parallel streams of self-attention\\nencoders, and each stream has layers of 1D convolutions with dilated kernels\\nwhose dilation rates are unique given stream, followed by a self-attention\\nlayer. The self-attention mechanism in each stream pays attention to only one\\nresolution of input speech frames and the attentive computation can be more\\nefficient. In a later stage, outputs from all the streams are concatenated then\\nlinearly projected to the final embedding. By stacking the proposed\\nmulti-stream self-attention encoder blocks and rescoring the resultant lattices\\nwith neural network language models, we achieve the word error rate of 2.2% on\\nthe test-clean dataset of the LibriSpeech corpus, the best number reported thus\\nfar on the dataset.\\n\\n    ', '\\nAbstract:  The availability of open-source software is playing a remarkable role in the\\npopularization of speech recognition and deep learning. Kaldi, for instance, is\\nnowadays an established framework used to develop state-of-the-art speech\\nrecognizers. PyTorch is used to build neural networks with the Python language\\nand has recently spawn tremendous interest within the machine learning\\ncommunity thanks to its simplicity and flexibility.\\nThe PyTorch-Kaldi project aims to bridge the gap between these popular\\ntoolkits, trying to inherit the efficiency of Kaldi and the flexibility of\\nPyTorch. PyTorch-Kaldi is not only a simple interface between these software,\\nbut it embeds several useful features for developing modern speech recognizers.\\nFor instance, the code is specifically designed to naturally plug-in\\nuser-defined acoustic models. As an alternative, users can exploit several\\npre-implemented neural networks that can be customized using intuitive\\nconfiguration files. PyTorch-Kaldi supports multiple feature and label streams\\nas well as combinations of neural networks, enabling the use of complex neural\\narchitectures. The toolkit is publicly-released along with a rich documentation\\nand is designed to properly work locally or on HPC clusters.\\nExperiments, that are conducted on several datasets and tasks, show that\\nPyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech\\nrecognizers.\\n\\n    ', '\\nAbstract:  We present state-of-the-art automatic speech recognition (ASR) systems\\nemploying a standard hybrid DNN/HMM architecture compared to an attention-based\\nencoder-decoder design for the LibriSpeech task. Detailed descriptions of the\\nsystem development, including model design, pretraining schemes, training\\nschedules, and optimization approaches are provided for both system\\narchitectures. Both hybrid DNN/HMM and attention-based systems employ\\nbi-directional LSTMs for acoustic modeling/encoding. For language modeling, we\\nemploy both LSTM and Transformer based architectures. All our systems are built\\nusing RWTHs open-source toolkits RASR and RETURNN. To the best knowledge of the\\nauthors, the results obtained when training on the full LibriSpeech training\\nset, are the best published currently, both for the hybrid DNN/HMM and the\\nattention-based systems. Our single hybrid system even outperforms previous\\nresults obtained from combining eight single systems. Our comparison shows that\\non the LibriSpeech 960h task, the hybrid DNN/HMM system outperforms the\\nattention-based system by 15% relative on the clean and 40% relative on the\\nother test sets in terms of word error rate. Moreover, experiments on a reduced\\n100h-subset of the LibriSpeech training corpus even show a more pronounced\\nmargin between the hybrid DNN/HMM and attention-based architectures.\\n\\n    ', 'It is pdf', 'It is pdf', \"\\nAbstract:  We present SpecAugment, a simple data augmentation method for speech\\nrecognition. SpecAugment is applied directly to the feature inputs of a neural\\nnetwork (i.e., filter bank coefficients). The augmentation policy consists of\\nwarping the features, masking blocks of frequency channels, and masking blocks\\nof time steps. We apply SpecAugment on Listen, Attend and Spell networks for\\nend-to-end speech recognition tasks. We achieve state-of-the-art performance on\\nthe LibriSpeech 960h and Swichboard 300h tasks, outperforming all prior work.\\nOn LibriSpeech, we achieve 6.8% WER on test-other without the use of a language\\nmodel, and 5.8% WER with shallow fusion with a language model. This compares to\\nthe previous state-of-the-art hybrid system of 7.5% WER. For Switchboard, we\\nachieve 7.2%/14.6% on the Switchboard/CallHome portion of the Hub5'00 test set\\nwithout the use of a language model, and 6.8%/14.1% with shallow fusion, which\\ncompares to the previous state-of-the-art hybrid system at 8.3%/17.3% WER.\\n\\n    \", '\\nAbstract:  We present a state-of-the-art speech recognition system developed using\\nend-to-end deep learning. Our architecture is significantly simpler than\\ntraditional speech systems, which rely on laboriously engineered processing\\npipelines; these traditional systems also tend to perform poorly when used in\\nnoisy environments. In contrast, our system does not need hand-designed\\ncomponents to model background noise, reverberation, or speaker variation, but\\ninstead directly learns a function that is robust to such effects. We do not\\nneed a phoneme dictionary, nor even the concept of a \"phoneme.\" Key to our\\napproach is a well-optimized RNN training system that uses multiple GPUs, as\\nwell as a set of novel data synthesis techniques that allow us to efficiently\\nobtain a large amount of varied data for training. Our system, called Deep\\nSpeech, outperforms previously published results on the widely studied\\nSwitchboard Hub5\\'00, achieving 16.0% error on the full test set. Deep Speech\\nalso handles challenging noisy environments better than widely used,\\nstate-of-the-art commercial speech systems.\\n\\n    ', '\\nAbstract:  We describe a deep learning based method for estimating 3D facial expression\\ncoefficients. Unlike previous work, our process does not relay on facial\\nlandmark detection methods as a proxy step. Recent methods have shown that a\\nCNN can be trained to regress accurate and discriminative 3D morphable model\\n(3DMM) representations, directly from image intensities. By foregoing facial\\nlandmark detection, these methods were able to estimate shapes for occluded\\nfaces appearing in unprecedented in-the-wild viewing conditions. We build on\\nthose methods by showing that facial expressions can also be estimated by a\\nrobust, deep, landmark-free approach. Our ExpNet CNN is applied directly to the\\nintensities of a face image and regresses a 29D vector of 3D expression\\ncoefficients. We propose a unique method for collecting data to train this\\nnetwork, leveraging on the robustness of deep networks to training label noise.\\nWe further offer a novel means of evaluating the accuracy of estimated\\nexpression coefficients: by measuring how well they capture facial emotions on\\nthe CK+ and EmotiW-17 emotion recognition benchmarks. We show that our ExpNet\\nproduces expression coefficients which better discriminate between facial\\nemotions than those obtained using state of the art, facial landmark detection\\ntechniques. Moreover, this advantage grows as image scales drop, demonstrating\\nthat our ExpNet is more robust to scale changes than landmark detection\\nmethods. Finally, at the same level of accuracy, our ExpNet is orders of\\nmagnitude faster than its alternatives.\\n\\n    ', '\\nAbstract:  Multimodal sentiment analysis is a very actively growing field of research. A\\npromising area of opportunity in this field is to improve the multimodal fusion\\nmechanism. We present a novel feature fusion strategy that proceeds in a\\nhierarchical fashion, first fusing the modalities two in two and only then\\nfusing all three modalities. On multimodal sentiment analysis of individual\\nutterances, our strategy outperforms conventional concatenation of features by\\n1%, which amounts to 5% reduction in error rate. On utterance-level multimodal\\nsentiment analysis of multi-utterance video clips, for which current\\nstate-of-the-art techniques incorporate contextual information from other\\nutterances of the same clip, our hierarchical fusion gives up to 2.4% (almost\\n10% error rate reduction) over currently used concatenation. The implementation\\nof our method is publicly available in the form of open-source code.\\n\\n    ', 'AbstractMultimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.', '\\nAbstract:  Emotion recognition has become an important field of research in Human\\nComputer Interactions as we improve upon the techniques for modelling the\\nvarious aspects of behaviour. With the advancement of technology our\\nunderstanding of emotions are advancing, there is a growing need for automatic\\nemotion recognition systems. One of the directions the research is heading is\\nthe use of Neural Networks which are adept at estimating complex functions that\\ndepend on a large number and diverse source of input data. In this paper we\\nattempt to exploit this effectiveness of Neural networks to enable us to\\nperform multimodal Emotion recognition on IEMOCAP dataset using data from\\nSpeech, Text, and Motion capture data from face expressions, rotation and hand\\nmovements. Prior research has concentrated on Emotion detection from Speech on\\nthe IEMOCAP dataset, but our approach is the first that uses the multiple modes\\nof data offered by IEMOCAP for a more robust and accurate emotion detection.\\n\\n    ', '\\nAbstract:  Emotion detection in conversations is a necessary step for a number of\\napplications, including opinion mining over chat history, social media threads,\\ndebates, argumentation mining, understanding consumer feedback in live\\nconversations, etc. Currently, systems do not treat the parties in the\\nconversation individually by adapting to the speaker of each utterance. In this\\npaper, we describe a new method based on recurrent neural networks that keeps\\ntrack of the individual party states throughout the conversation and uses this\\ninformation for emotion classification. Our model outperforms the state of the\\nart by a significant margin on two different datasets.\\n\\n    ', '\\nAbstract:  This paper describes Tacotron 2, a neural network architecture for speech\\nsynthesis directly from text. The system is composed of a recurrent\\nsequence-to-sequence feature prediction network that maps character embeddings\\nto mel-scale spectrograms, followed by a modified WaveNet model acting as a\\nvocoder to synthesize timedomain waveforms from those spectrograms. Our model\\nachieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\\nprofessionally recorded speech. To validate our design choices, we present\\nablation studies of key components of our system and evaluate the impact of\\nusing mel spectrograms as the input to WaveNet instead of linguistic, duration,\\nand $F_0$ features. We further demonstrate that using a compact acoustic\\nintermediate representation enables significant simplification of the WaveNet\\narchitecture.\\n\\n    ', \"\\nAbstract:  In this paper, we address the problem of enhancing the speech of a speaker of\\ninterest in a cocktail party scenario when visual information of the speaker of\\ninterest is available. Contrary to most previous studies, we do not learn\\nvisual features on the typically small audio-visual datasets, but use an\\nalready available face landmark detector (trained on a separate image dataset).\\nThe landmarks are used by LSTM-based models to generate time-frequency masks\\nwhich are applied to the acoustic mixed-speech spectrogram. Results show that:\\n(i) landmark motion features are very effective features for this task, (ii)\\nsimilarly to previous work, reconstruction of the target speaker's spectrogram\\nmediated by masking is significantly more accurate than direct spectrogram\\nreconstruction, and (iii) the best masks depend on both motion landmark\\nfeatures and the input mixed-speech spectrogram. To the best of our knowledge,\\nour proposed models are the first models trained and evaluated on the limited\\nsize GRID and TCD-TIMIT datasets, that achieve speaker-independent speech\\nenhancement in a multi-talker setting.\\n\\n    \", '\\nAbstract:  Grapheme-to-phoneme (G2P) conversion is an important task in automatic speech\\nrecognition and text-to-speech systems. Recently, G2P conversion is viewed as a\\nsequence to sequence task and modeled by RNN or CNN based encoder-decoder\\nframework. However, previous works do not consider the practical issues when\\ndeploying G2P model in the production system, such as how to leverage\\nadditional unlabeled data to boost the accuracy, as well as reduce model size\\nfor online deployment. In this work, we propose token-level ensemble\\ndistillation for G2P conversion, which can (1) boost the accuracy by distilling\\nthe knowledge from additional unlabeled data, and (2) reduce the model size but\\nmaintain the high accuracy, both of which are very practical and helpful in the\\nonline production system. We use token-level knowledge distillation, which\\nresults in better accuracy than the sequence-level counterpart. What is more,\\nwe adopt the Transformer instead of RNN or CNN based models to further boost\\nthe accuracy of G2P conversion. Experiments on the publicly available CMUDict\\ndataset and an internal English dataset demonstrate the effectiveness of our\\nproposed method. Particularly, our method achieves 19.88% WER on CMUDict\\ndataset, outperforming the previous works by more than 4.22% WER, and setting\\nthe new state-of-the-art results.\\n\\n    ', '\\nAbstract:  Time series with non-uniform intervals occur in many applications, and are\\ndifficult to model using standard recurrent neural networks (RNNs). We\\ngeneralize RNNs to have continuous-time hidden dynamics defined by ordinary\\ndifferential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use\\nODE-RNNs to replace the recognition network of the recently-proposed Latent ODE\\nmodel. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps\\nbetween observations, and can explicitly model the probability of observation\\ntimes using Poisson processes. We show experimentally that these ODE-based\\nmodels outperform their RNN-based counterparts on irregularly-sampled data.\\n\\n    ', '\\nAbstract:  Learning compressed representations of multivariate time series (MTS)\\nfacilitates data analysis in the presence of noise and redundant information,\\nand for a large number of variates and time steps. However, classical\\ndimensionality reduction approaches are designed for vectorial data and cannot\\ndeal explicitly with missing values. In this work, we propose a novel\\nautoencoder architecture based on recurrent neural networks to generate\\ncompressed representations of MTS. The proposed model can process inputs\\ncharacterized by variable lengths and it is specifically designed to handle\\nmissing data. Our autoencoder learns fixed-length vectorial representations,\\nwhose pairwise similarities are aligned to a kernel function that operates in\\ninput space and that handles missing values. This allows to learn good\\nrepresentations, even in the presence of a significant amount of missing data.\\nTo show the effectiveness of the proposed approach, we evaluate the quality of\\nthe learned representations in several classification tasks, including those\\ninvolving medical data, and we compare to other methods for dimensionality\\nreduction. Successively, we design two frameworks based on the proposed\\narchitecture: one for imputing missing data and another for one-class\\nclassification. Finally, we analyze under what circumstances an autoencoder\\nwith recurrent layers can learn better compressed representations of MTS than\\nfeed-forward architectures.\\n\\n    ', '\\nAbstract:  The all-relevant problem of feature selection is the identification of all\\nstrongly and weakly relevant attributes. This problem is especially hard to\\nsolve for time series classification and regression in industrial applications\\nsuch as predictive maintenance or production line optimization, for which each\\nlabel or regression target is associated with several time series and\\nmeta-information simultaneously. Here, we are proposing an efficient, scalable\\nfeature extraction algorithm for time series, which filters the available\\nfeatures in an early stage of the machine learning pipeline with respect to\\ntheir significance for the classification or regression task, while controlling\\nthe expected percentage of selected but irrelevant features. The proposed\\nalgorithm combines established feature extraction methods with a feature\\nimportance filter. It has a low computational complexity, allows to start on a\\nproblem with only limited domain knowledge available, can be trivially\\nparallelized, is highly scalable and based on well studied non-parametric\\nhypothesis tests. We benchmark our proposed algorithm on all binary\\nclassification problems of the UCR time series classification archive as well\\nas time series from a production line optimization project and simulated\\nstochastic processes with underlying qualitative change of dynamics.\\n\\n    ', '\\nAbstract:  We introduce Gluon Time Series (GluonTS, available at\\nthis https URL), a library for deep-learning-based time series\\nmodeling. GluonTS simplifies the development of and experimentation with time\\nseries models for common tasks such as forecasting or anomaly detection. It\\nprovides all necessary components and tools that scientists need for quickly\\nbuilding new models, for efficiently running and analyzing experiments and for\\nevaluating model accuracy.\\n\\n    ', '\\nAbstract:  Neural sequence models are widely used to model time-series data. Equally\\nubiquitous is the usage of beam search (BS) as an approximate inference\\nalgorithm to decode output sequences from these models. BS explores the search\\nspace in a greedy left-right fashion retaining only the top-B candidates -\\nresulting in sequences that differ only slightly from each other. Producing\\nlists of nearly identical sequences is not only computationally wasteful but\\nalso typically fails to capture the inherent ambiguity of complex AI tasks. To\\novercome this problem, we propose Diverse Beam Search (DBS), an alternative to\\nBS that decodes a list of diverse outputs by optimizing for a\\ndiversity-augmented objective. We observe that our method finds better top-1\\nsolutions by controlling for the exploration and exploitation of the search\\nspace - implying that DBS is a better search algorithm. Moreover, these gains\\nare achieved with minimal computational or memory over- head as compared to\\nbeam search. To demonstrate the broad applicability of our method, we present\\nresults on image captioning, machine translation and visual question generation\\nusing both standard quantitative metrics and qualitative human studies.\\nFurther, we study the role of diversity for image-grounded language generation\\ntasks as the complexity of the image changes. We observe that our method\\nconsistently outperforms BS and previously proposed techniques for diverse\\ndecoding from neural sequence models.\\n\\n    ', '\\nAbstract:  The spatio-temporal graph learning is becoming an increasingly important\\nobject of graph study. Many application domains involve highly dynamic graphs\\nwhere temporal information is crucial, e.g. traffic networks and financial\\ntransaction graphs. Despite the constant progress made on learning structured\\ndata, there is still a lack of effective means to extract dynamic complex\\nfeatures from spatio-temporal structures. Particularly, conventional models\\nsuch as convolutional networks or recurrent neural networks are incapable of\\nrevealing the temporal patterns in short or long terms and exploring the\\nspatial properties in local or global scope from spatio-temporal graphs\\nsimultaneously. To tackle this problem, we design a novel multi-scale\\narchitecture, Spatio-Temporal U-Net (ST-UNet), for graph-structured time series\\nmodeling. In this U-shaped network, a paired sampling operation is proposed in\\nspacetime domain accordingly: the pooling (ST-Pool) coarsens the input graph in\\nspatial from its deterministic partition while abstracts multi-resolution\\ntemporal dependencies through dilated recurrent skip connections; based on\\nprevious settings in the downsampling, the unpooling (ST-Unpool) restores the\\noriginal structure of spatio-temporal graphs and resumes regular intervals\\nwithin graph sequences. Experiments on spatio-temporal prediction tasks\\ndemonstrate that our model effectively captures comprehensive features in\\nmultiple scales and achieves substantial improvements over mainstream methods\\non several real-world datasets.\\n\\n    ', '\\nAbstract:  Increasing model size when pretraining natural language representations often\\nresults in improved performance on downstream tasks. However, at some point\\nfurther model increases become harder due to GPU/TPU memory limitations, longer\\ntraining times, and unexpected model degradation. To address these problems, we\\npresent two parameter-reduction techniques to lower memory consumption and\\nincrease the training speed of BERT. Comprehensive empirical evidence shows\\nthat our proposed methods lead to models that scale much better compared to the\\noriginal BERT. We also use a self-supervised loss that focuses on modeling\\ninter-sentence coherence, and show it consistently helps downstream tasks with\\nmulti-sentence inputs. As a result, our best model establishes new\\nstate-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having\\nfewer parameters compared to BERT-large.\\n\\n    ', \"\\nAbstract:  We present the design and implementation of a visual search system for real\\ntime image retrieval on this http URL, the world's third largest and China's largest\\ne-commerce site. We demonstrate that our system can support real time visual\\nsearch with hundreds of billions of product images at sub-second timescales and\\nhandle frequent image updates through distributed hierarchical architecture and\\nefficient indexing methods. We hope that sharing our practice with our real\\nproduction system will inspire the middleware community's interest and\\nappreciation for building practical large scale systems for emerging\\napplications, such as ecommerce visual search.\\n\\n    \", '\\nAbstract:  Localization of salient facial landmark points, such as eye corners or the\\ntip of the nose, is still considered a challenging computer vision problem\\ndespite recent efforts. This is especially evident in unconstrained\\nenvironments, i.e., in the presence of background clutter and large head pose\\nvariations. Most methods that achieve state-of-the-art accuracy are slow, and,\\nthus, have limited applications. We describe a method that can accurately\\nestimate the positions of relevant facial landmarks in real-time even on\\nhardware with limited processing power, such as mobile devices. This is\\nachieved with a sequence of estimators based on ensembles of regression trees.\\nThe trees use simple pixel intensity comparisons in their internal nodes and\\nthis makes them able to process image regions very fast. We test the developed\\nsystem on several publicly available datasets and analyse its processing speed\\non various devices. Experimental results show that our method has practical\\nvalue.\\n\\n    ', '\\nAbstract:  We describe a method for visual object detection based on an ensemble of\\noptimized decision trees organized in a cascade of rejectors. The trees use\\npixel intensity comparisons in their internal nodes and this makes them able to\\nprocess image regions very fast. Experimental analysis is provided through a\\nface detection problem. The obtained results are encouraging and demonstrate\\nthat the method has practical value. Additionally, we analyse its sensitivity\\nto noise and show how to perform fast rotation invariant object detection.\\nComplete source code is provided at this https URL.\\n\\n    ', \"\\nAbstract:  Bayesian optimization provides sample-efficient global optimization for a\\nbroad range of applications, including automatic machine learning, molecular\\nchemistry, and experimental design. We introduce BoTorch, a modern programming\\nframework for Bayesian optimization. Enabled by Monte-Carlo (MC) acquisition\\nfunctions and auto-differentiation, BoTorch's modular design facilitates\\nflexible specification and optimization of probabilistic models written in\\nPyTorch, radically simplifying implementation of novel acquisition functions.\\nOur MC approach is made practical by a distinctive algorithmic foundation that\\nleverages fast predictive distributions and hardware acceleration. In\\nexperiments, we demonstrate the improved sample efficiency of BoTorch relative\\nto other popular libraries. BoTorch is open source and available at\\nthis https URL.\\n\\n    \", '\\nAbstract:  Binary neural networks have attracted numerous attention in recent years.\\nHowever, mainly due to the information loss stemming from the biased\\nbinarization, how to preserve the accuracy of networks still remains a critical\\nissue. In this paper, we attempt to maintain the information propagated in the\\nforward process and propose a Balanced Binary Neural Networks with Gated\\nResidual (BBG for short). First, a weight balanced binarization is introduced\\nto maximize information entropy of binary weights, and thus the informative\\nbinary weights can capture more information contained in the activations.\\nSecond, for binary activations, a gated residual is further appended to\\ncompensate their information loss during the forward process, with a slight\\noverhead. Both techniques can be wrapped as a generic network module that\\nsupports various network architectures for different tasks including\\nclassification and detection. We evaluate our BBG on image classification tasks\\nover CIFAR-10/100 and ImageNet and on detection task over Pascal VOC. The\\nexperimental results show that BBG-Net performs remarkably well across various\\nnetwork architectures such as VGG, ResNet and SSD with the superior performance\\nover state-of-the-art methods in terms of memory consumption, inference speed\\nand accuracy.\\n\\n    ', '\\nAbstract:  Chinese word segmentation (CWS) is a fundamental step of Chinese natural\\nlanguage processing. In this paper, we build a new toolkit, named PKUSEG, for\\nmulti-domain word segmentation. Unlike existing single-model toolkits, PKUSEG\\ntargets at multi-domain word segmentation and provides separate models for\\ndifferent domains, such as web, medicine, and tourism. The new toolkit also\\nsupports POS tagging and model training to adapt to various application\\nscenarios. Experiments show that PKUSEG achieves high performance on multiple\\ndomains. The toolkit is now freely and publicly available for the usage of\\nresearch and industry.\\n\\n    ', '\\nAbstract:  Data augmentation is a commonly used technique for increasing both the size\\nand the diversity of labeled training sets by leveraging input transformations\\nthat preserve output labels. In computer vision domain, image augmentations\\nhave become a common implicit regularization technique to combat overfitting in\\ndeep convolutional neural networks and are ubiquitously used to improve\\nperformance. While most deep learning frameworks implement basic image\\ntransformations, the list is typically limited to some variations and\\ncombinations of flipping, rotating, scaling, and cropping. Moreover, the image\\nprocessing speed varies in existing tools for image augmentation. We present\\nAlbumentations, a fast and flexible library for image augmentations with many\\nvarious image transform operations available, that is also an easy-to-use\\nwrapper around other augmentation libraries. We provide examples of image\\naugmentations for different computer vision tasks and show that Albumentations\\nis faster than other commonly used image augmentation tools on the most of\\ncommonly used image transformations. The source code for Albumentations is made\\npublicly available online at this https URL\\n', 'It is pdf', 'It is pdf', '\\nAbstract:  Caffe provides multimedia scientists and practitioners with a clean and\\nmodifiable framework for state-of-the-art deep learning algorithms and a\\ncollection of reference models. The framework is a BSD-licensed C++ library\\nwith Python and MATLAB bindings for training and deploying general-purpose\\nconvolutional neural networks and other deep models efficiently on commodity\\narchitectures. Caffe fits industry and internet-scale media needs by CUDA GPU\\ncomputation, processing over 40 million images a day on a single K40 or Titan\\nGPU ($\\\\approx$ 2.5 ms per image). By separating model representation from\\nactual implementation, Caffe allows experimentation and seamless switching\\namong platforms for ease of development and deployment from prototyping\\nmachines to cloud environments. Caffe is maintained and developed by the\\nBerkeley Vision and Learning Center (BVLC) with the help of an active community\\nof contributors on GitHub. It powers ongoing research projects, large-scale\\nindustrial applications, and startup prototypes in vision, speech, and\\nmultimedia.\\n\\n    ', '\\nAbstract:  The highest accuracy object detectors to date are based on a two-stage\\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\\ncandidate object locations. In contrast, one-stage detectors that are applied\\nover a regular, dense sampling of possible object locations have the potential\\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\\nthus far. In this paper, we investigate why this is the case. We discover that\\nthe extreme foreground-background class imbalance encountered during training\\nof dense detectors is the central cause. We propose to address this class\\nimbalance by reshaping the standard cross entropy loss such that it\\ndown-weights the loss assigned to well-classified examples. Our novel Focal\\nLoss focuses training on a sparse set of hard examples and prevents the vast\\nnumber of easy negatives from overwhelming the detector during training. To\\nevaluate the effectiveness of our loss, we design and train a simple dense\\ndetector we call RetinaNet. Our results show that when trained with the focal\\nloss, RetinaNet is able to match the speed of previous one-stage detectors\\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\\ndetectors. Code is at: this https URL.\\n\\n    ', '\\nAbstract:  We investigate omni-supervised learning, a special regime of semi-supervised\\nlearning in which the learner exploits all available labeled data plus\\ninternet-scale sources of unlabeled data. Omni-supervised learning is\\nlower-bounded by performance on existing labeled datasets, offering the\\npotential to surpass state-of-the-art fully supervised methods. To exploit the\\nomni-supervised setting, we propose data distillation, a method that ensembles\\npredictions from multiple transformations of unlabeled data, using a single\\nmodel, to automatically generate new training annotations. We argue that visual\\nrecognition models have recently become accurate enough that it is now possible\\nto apply classic ideas about self-training to challenging real-world data. Our\\nexperimental results show that in the cases of human keypoint detection and\\ngeneral object detection, state-of-the-art models trained with data\\ndistillation surpass the performance of using labeled data from the COCO\\ndataset alone.\\n\\n    ', '\\nAbstract:  Most methods for object instance segmentation require all training examples\\nto be labeled with segmentation masks. This requirement makes it expensive to\\nannotate new categories and has restricted instance segmentation models to ~100\\nwell-annotated classes. The goal of this paper is to propose a new partially\\nsupervised training paradigm, together with a novel weight transfer function,\\nthat enables training instance segmentation models on a large set of categories\\nall of which have box annotations, but only a small fraction of which have mask\\nannotations. These contributions allow us to train Mask R-CNN to detect and\\nsegment 3000 visual concepts using box annotations from the Visual Genome\\ndataset and mask annotations from the 80 classes in the COCO dataset. We\\nevaluate our approach in a controlled study on the COCO dataset. This work is a\\nfirst step towards instance segmentation models that have broad comprehension\\nof the visual world.\\n\\n    ', \"\\nAbstract:  Batch Normalization (BN) is a milestone technique in the development of deep\\nlearning, enabling various networks to train. However, normalizing along the\\nbatch dimension introduces problems --- BN's error increases rapidly when the\\nbatch size becomes smaller, caused by inaccurate batch statistics estimation.\\nThis limits BN's usage for training larger models and transferring features to\\ncomputer vision tasks including detection, segmentation, and video, which\\nrequire small batches constrained by memory consumption. In this paper, we\\npresent Group Normalization (GN) as a simple alternative to BN. GN divides the\\nchannels into groups and computes within each group the mean and variance for\\nnormalization. GN's computation is independent of batch sizes, and its accuracy\\nis stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN\\nhas 10.6% lower error than its BN counterpart when using a batch size of 2;\\nwhen using typical batch sizes, GN is comparably good with BN and outperforms\\nother normalization variants. Moreover, GN can be naturally transferred from\\npre-training to fine-tuning. GN can outperform its BN-based counterparts for\\nobject detection and segmentation in COCO, and for video classification in\\nKinetics, showing that GN can effectively replace the powerful BN in a variety\\nof tasks. GN can be easily implemented by a few lines of code in modern\\nlibraries.\\n\\n    \", '\\nAbstract:  To understand the visual world, a machine must not only recognize individual\\nobject instances but also how they interact. Humans are often at the center of\\nsuch interactions and detecting human-object interactions is an important\\npractical and scientific problem. In this paper, we address the task of\\ndetecting <human, verb, object> triplets in challenging everyday photos. We\\npropose a novel model that is driven by a human-centric approach. Our\\nhypothesis is that the appearance of a person -- their pose, clothing, action\\n-- is a powerful cue for localizing the objects they are interacting with. To\\nexploit this cue, our model learns to predict an action-specific density over\\ntarget object locations based on the appearance of a detected person. Our model\\nalso jointly learns to detect people and objects, and by fusing these\\npredictions it efficiently infers interaction triplets in a clean, jointly\\ntrained end-to-end system we call InteractNet. We validate our approach on the\\nrecently introduced Verbs in COCO (V-COCO) and HICO-DET datasets, where we show\\nquantitatively compelling results.\\n\\n    ', '\\nAbstract:  Both convolutional and recurrent operations are building blocks that process\\none local neighborhood at a time. In this paper, we present non-local\\noperations as a generic family of building blocks for capturing long-range\\ndependencies. Inspired by the classical non-local means method in computer\\nvision, our non-local operation computes the response at a position as a\\nweighted sum of the features at all positions. This building block can be\\nplugged into many computer vision architectures. On the task of video\\nclassification, even without any bells and whistles, our non-local models can\\ncompete or outperform current competition winners on both Kinetics and Charades\\ndatasets. In static image recognition, our non-local models improve object\\ndetection/segmentation and pose estimation on the COCO suite of tasks. Code is\\navailable at this https URL .\\n\\n    ', '\\nAbstract:  OpenAI Gym is a toolkit for reinforcement learning research. It includes a\\ngrowing collection of benchmark problems that expose a common interface, and a\\nwebsite where people can share their results and compare the performance of\\nalgorithms. This whitepaper discusses the components of OpenAI Gym and the\\ndesign decisions that went into the software.\\n\\n    ', '\\nAbstract:  MXNet is a multi-language machine learning (ML) library to ease the\\ndevelopment of ML algorithms, especially for deep neural networks. Embedded in\\nthe host language, it blends declarative symbolic expression with imperative\\ntensor computation. It offers auto differentiation to derive gradients. MXNet\\nis computation and memory efficient and runs on various heterogeneous systems,\\nranging from mobile devices to distributed GPU clusters.\\nThis paper describes both the API design and the system implementation of\\nMXNet, and explains how embedding of both symbolic expression and tensor\\noperation is handled in a unified fashion. Our preliminary experiments reveal\\npromising results on large scale deep neural network applications using\\nmultiple GPU machines.\\n\\n    ', '\\nAbstract:  Tree boosting is a highly effective and widely used machine learning method.\\nIn this paper, we describe a scalable end-to-end tree boosting system called\\nXGBoost, which is used widely by data scientists to achieve state-of-the-art\\nresults on many machine learning challenges. We propose a novel sparsity-aware\\nalgorithm for sparse data and weighted quantile sketch for approximate tree\\nlearning. More importantly, we provide insights on cache access patterns, data\\ncompression and sharding to build a scalable tree boosting system. By combining\\nthese insights, XGBoost scales beyond billions of examples using far fewer\\nresources than existing systems.\\n\\n    ', 'It is pdf', '\\nAbstract:  We propose an approximate strategy to efficiently train neural network based\\nlanguage models over very large vocabularies. Our approach, called adaptive\\nsoftmax, circumvents the linear dependency on the vocabulary size by exploiting\\nthe unbalanced word distribution to form clusters that explicitly minimize the\\nexpectation of computation time. Our approach further reduces the computational\\ntime by exploiting the specificities of modern architectures and matrix-matrix\\nvector operations, making it particularly suited for graphical processing\\nunits. Our experiments carried out on standard benchmarks, such as EuroParl and\\nOne Billion Word, show that our approach brings a large gain in efficiency over\\nstandard approximations while achieving an accuracy close to that of the full\\nsoftmax. The code of our method is available at\\nthis https URL.\\n\\n    ', \"\\nAbstract:  Recent advances in modern Natural Language Processing (NLP) research have\\nbeen dominated by the combination of Transfer Learning methods with large-scale\\nlanguage models, in particular based on the Transformer architecture. With them\\ncame a paradigm shift in NLP with the starting point for training a model on a\\ndownstream task moving from a blank specific model to a general-purpose\\npretrained architecture. Still, creating these general-purpose models remains\\nan expensive and time-consuming process restricting the use of these methods to\\na small sub-set of the wider NLP community. In this paper, we present\\nHuggingFace's Transformers library, a library for state-of-the-art NLP, making\\nthese developments available to the community by gathering state-of-the-art\\ngeneral-purpose pretrained models under a unified API together with an\\necosystem of libraries, examples, tutorials and scripts targeting many\\ndownstream NLP tasks. HuggingFace's Transformers library features carefully\\ncrafted model implementations and high-performance pretrained weights for two\\nmain deep learning frameworks, PyTorch and TensorFlow, while supporting all the\\nnecessary tools to analyze, evaluate and use these models in downstream tasks\\nsuch as text/token classification, questions answering and language generation\\namong others. The library has gained significant organic traction and adoption\\namong both the researcher and practitioner communities. We are committed at\\nHuggingFace to pursue the efforts to develop this toolkit with the ambition of\\ncreating the standard library for building NLP systems.\\n\\n    \", '\\nAbstract:  As Transfer Learning from large-scale pre-trained models becomes more\\nprevalent in Natural Language Processing (NLP), operating these large models in\\non-the-edge and/or under constrained computational training or inference\\nbudgets remains challenging. In this work, we propose a method to pre-train a\\nsmaller general-purpose language representation model, called DistilBERT, which\\ncan then be fine-tuned with good performances on a wide range of tasks like its\\nlarger counterparts. While most prior work investigated the use of distillation\\nfor building task-specific models, we leverage knowledge distillation during\\nthe pre-training phase and show that it is possible to reduce the size of a\\nBERT model by 40%, while retaining 97% of its language understanding\\ncapabilities and being 60% faster. To leverage the inductive biases learned by\\nlarger models during pre-training, we introduce a triple loss combining\\nlanguage modeling, distillation and cosine-distance losses. Our smaller, faster\\nand lighter model is cheaper to pre-train and we demonstrate its capabilities\\nfor on-device computations in a proof-of-concept experiment and a comparative\\non-device study.\\n\\n    ', '\\nAbstract:  We present an approach that uses a multi-camera system to train fine-grained\\ndetectors for keypoints that are prone to occlusion, such as the joints of a\\nhand. We call this procedure multiview bootstrapping: first, an initial\\nkeypoint detector is used to produce noisy labels in multiple views of the\\nhand. The noisy detections are then triangulated in 3D using multiview geometry\\nor marked as outliers. Finally, the reprojected triangulations are used as new\\nlabeled training data to improve the detector. We repeat this process,\\ngenerating more labeled data in each iteration. We derive a result analytically\\nrelating the minimum number of views to achieve target true and false positive\\nrates for a given detector. The method is used to train a hand keypoint\\ndetector for single images. The resulting keypoint detector runs in realtime on\\nRGB images and has accuracy comparable to methods that use depth sensors. The\\nsingle view detector, triangulated over multiple views, enables 3D markerless\\nhand motion capture with complex object interactions.\\n\\n    ', '\\nAbstract:  We present an approach to efficiently detect the 2D pose of multiple people\\nin an image. The approach uses a nonparametric representation, which we refer\\nto as Part Affinity Fields (PAFs), to learn to associate body parts with\\nindividuals in the image. The architecture encodes global context, allowing a\\ngreedy bottom-up parsing step that maintains high accuracy while achieving\\nrealtime performance, irrespective of the number of people in the image. The\\narchitecture is designed to jointly learn part locations and their association\\nvia two branches of the same sequential prediction process. Our method placed\\nfirst in the inaugural COCO 2016 keypoints challenge, and significantly exceeds\\nthe previous state-of-the-art result on the MPII Multi-Person benchmark, both\\nin performance and efficiency.\\n\\n    ', '\\nAbstract:  Realtime multi-person 2D pose estimation is a key component in enabling\\nmachines to have an understanding of people in images and videos. In this work,\\nwe present a realtime approach to detect the 2D pose of multiple people in an\\nimage. The proposed method uses a nonparametric representation, which we refer\\nto as Part Affinity Fields (PAFs), to learn to associate body parts with\\nindividuals in the image. This bottom-up system achieves high accuracy and\\nrealtime performance, regardless of the number of people in the image. In\\nprevious work, PAFs and body part location estimation were refined\\nsimultaneously across training stages. We demonstrate that a PAF-only\\nrefinement rather than both PAF and body part location refinement results in a\\nsubstantial increase in both runtime performance and accuracy. We also present\\nthe first combined body and foot keypoint detector, based on an internal\\nannotated foot dataset that we have publicly released. We show that the\\ncombined detector not only reduces the inference time compared to running them\\nsequentially, but also maintains the accuracy of each component individually.\\nThis work has culminated in the release of OpenPose, the first open-source\\nrealtime system for multi-person 2D pose detection, including body, foot, hand,\\nand facial keypoints.\\n\\n    ', '\\nAbstract:  Pose Machines provide a sequential prediction framework for learning rich\\nimplicit spatial models. In this work we show a systematic design for how\\nconvolutional networks can be incorporated into the pose machine framework for\\nlearning image features and image-dependent spatial models for the task of pose\\nestimation. The contribution of this paper is to implicitly model long-range\\ndependencies between variables in structured prediction tasks such as\\narticulated pose estimation. We achieve this by designing a sequential\\narchitecture composed of convolutional networks that directly operate on belief\\nmaps from previous stages, producing increasingly refined estimates for part\\nlocations, without the need for explicit graphical model-style inference. Our\\napproach addresses the characteristic difficulty of vanishing gradients during\\ntraining by providing a natural learning objective function that enforces\\nintermediate supervision, thereby replenishing back-propagated gradients and\\nconditioning the learning procedure. We demonstrate state-of-the-art\\nperformance and outperform competing methods on standard benchmarks including\\nthe MPII, LSP, and FLIC datasets.\\n\\n    ', '\\nAbstract:  We consider the problem of producing compact architectures for text\\nclassification, such that the full model fits in a limited amount of memory.\\nAfter considering different solutions inspired by the hashing literature, we\\npropose a method built upon product quantization to store word embeddings.\\nWhile the original technique leads to a loss in accuracy, we adapt this method\\nto circumvent quantization artefacts. Our experiments carried out on several\\nbenchmarks show that our approach typically requires two orders of magnitude\\nless memory than fastText while being only slightly inferior with respect to\\naccuracy. As a result, it outperforms the state of the art by a good margin in\\nterms of the compromise between memory usage and accuracy.\\n\\n    ', '\\nAbstract:  Continuous word representations, trained on large unlabeled corpora are\\nuseful for many natural language processing tasks. Popular models that learn\\nsuch representations ignore the morphology of words, by assigning a distinct\\nvector to each word. This is a limitation, especially for languages with large\\nvocabularies and many rare words. In this paper, we propose a new approach\\nbased on the skipgram model, where each word is represented as a bag of\\ncharacter $n$-grams. A vector representation is associated to each character\\n$n$-gram; words being represented as the sum of these representations. Our\\nmethod is fast, allowing to train models on large corpora quickly and allows us\\nto compute word representations for words that did not appear in the training\\ndata. We evaluate our word representations on nine different languages, both on\\nword similarity and analogy tasks. By comparing to recently proposed\\nmorphological word representations, we show that our vectors achieve\\nstate-of-the-art performance on these tasks.\\n\\n    ', '\\nAbstract:  Transforming a graphical user interface screenshot created by a designer into\\ncomputer code is a typical task conducted by a developer in order to build\\ncustomized software, websites, and mobile applications. In this paper, we show\\nthat deep learning methods can be leveraged to train a model end-to-end to\\nautomatically generate code from a single input image with over 77% of accuracy\\nfor three different platforms (i.e. iOS, Android and web-based technologies).\\n\\n    ', 'It is pdf', '\\nAbstract:  Photorealistic image stylization concerns transferring style of a reference\\nphoto to a content photo with the constraint that the stylized photo should\\nremain photorealistic. While several photorealistic image stylization methods\\nexist, they tend to generate spatially inconsistent stylizations with\\nnoticeable artifacts. In this paper, we propose a method to address these\\nissues. The proposed method consists of a stylization step and a smoothing\\nstep. While the stylization step transfers the style of the reference photo to\\nthe content photo, the smoothing step ensures spatially consistent\\nstylizations. Each of the steps has a closed-form solution and can be computed\\nefficiently. We conduct extensive experimental validations. The results show\\nthat the proposed method generates photorealistic stylization outputs that are\\nmore preferred by human subjects as compared to those by the competing methods\\nwhile running much faster. Source code and additional results are available at\\nthis https URL .\\n\\n    ', 'It is pdf', '\\nAbstract:  This article describes our experiments in neural machine translation using\\nthe recent Tensor2Tensor framework and the Transformer sequence-to-sequence\\nmodel (Vaswani et al., 2017). We examine some of the critical parameters that\\naffect the final translation quality, memory usage, training stability and\\ntraining time, concluding each experiment with a set of recommendations for\\nfellow researchers. In addition to confirming the general mantra \"more data and\\nlarger models\", we address scaling to multiple GPUs and provide practical tips\\nfor improved training regarding batch size, learning rate, warmup steps,\\nmaximum sentence length and checkpoint averaging. We hope that our observations\\nwill allow others to get better results given their particular hardware and\\ndata constraints.\\n\\n    ', '\\nAbstract:  Recent works have highlighted the strength of the Transformer architecture on\\nsequence tasks while, at the same time, neural architecture search (NAS) has\\nbegun to outperform human-designed models. Our goal is to apply NAS to search\\nfor a better alternative to the Transformer. We first construct a large search\\nspace inspired by the recent advances in feed-forward sequence models and then\\nrun evolutionary architecture search with warm starting by seeding our initial\\npopulation with the Transformer. To directly search on the computationally\\nexpensive WMT 2014 English-German translation task, we develop the Progressive\\nDynamic Hurdles method, which allows us to dynamically allocate more resources\\nto more promising candidate models. The architecture found in our experiments\\n-- the Evolved Transformer -- demonstrates consistent improvement over the\\nTransformer on four well-established language tasks: WMT 2014 English-German,\\nWMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,\\nthe Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8\\non WMT\\'14 English-German; at smaller sizes, it achieves the same quality as the\\noriginal \"big\" Transformer with 37.6% less parameters and outperforms the\\nTransformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.\\n\\n    ', '\\nAbstract:  We show that generating English Wikipedia articles can be approached as a\\nmulti- document summarization of source documents. We use extractive\\nsummarization to coarsely identify salient information and a neural abstractive\\nmodel to generate the article. For the abstractive model, we introduce a\\ndecoder-only architecture that can scalably attend to very long sequences, much\\nlonger than typical encoder- decoder architectures used in sequence\\ntransduction. We show that this model can generate fluent, coherent\\nmulti-sentence paragraphs and even whole Wikipedia articles. When given\\nreference documents, we show it can extract relevant factual information as\\nreflected in perplexity, ROUGE scores and human evaluations.\\n\\n    ', '\\nAbstract:  Recurrent neural networks (RNNs) sequentially process data by updating their\\nstate with each new data point, and have long been the de facto choice for\\nsequence modeling tasks. However, their inherently sequential computation makes\\nthem slow to train. Feed-forward and convolutional architectures have recently\\nbeen shown to achieve superior results on some sequence modeling tasks such as\\nmachine translation, with the added advantage that they concurrently process\\nall inputs in the sequence, leading to easy parallelization and faster training\\ntimes. Despite these successes, however, popular feed-forward sequence models\\nlike the Transformer fail to generalize in many simple tasks that recurrent\\nmodels handle with ease, e.g. copying strings or even simple logical inference\\nwhen the string or formula lengths exceed those observed at training time. We\\npropose the Universal Transformer (UT), a parallel-in-time self-attentive\\nrecurrent sequence model which can be cast as a generalization of the\\nTransformer model and which addresses these issues. UTs combine the\\nparallelizability and global receptive field of feed-forward sequence models\\nlike the Transformer with the recurrent inductive bias of RNNs. We also add a\\ndynamic per-position halting mechanism and find that it improves accuracy on\\nseveral tasks. In contrast to the standard Transformer, under certain\\nassumptions, UTs can be shown to be Turing-complete. Our experiments show that\\nUTs outperform standard Transformers on a wide range of algorithmic and\\nlanguage understanding tasks, including the challenging LAMBADA language\\nmodeling task where UTs achieve a new state of the art, and machine translation\\nwhere UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De\\ndataset.\\n\\n    ', '\\nAbstract:  Relying entirely on an attention mechanism, the Transformer introduced by\\nVaswani et al. (2017) achieves state-of-the-art results for machine\\ntranslation. In contrast to recurrent and convolutional neural networks, it\\ndoes not explicitly model relative or absolute position information in its\\nstructure. Instead, it requires adding representations of absolute positions to\\nits inputs. In this work we present an alternative approach, extending the\\nself-attention mechanism to efficiently consider representations of the\\nrelative positions, or distances between sequence elements. On the WMT 2014\\nEnglish-to-German and English-to-French translation tasks, this approach yields\\nimprovements of 1.3 BLEU and 0.3 BLEU over absolute position representations,\\nrespectively. Notably, we observe that combining relative and absolute position\\nrepresentations yields no further improvement in translation quality. We\\ndescribe an efficient implementation of our method and cast it as an instance\\nof relation-aware self-attention mechanisms that can generalize to arbitrary\\ngraph-labeled inputs.\\n\\n    ', '\\nAbstract:  Mathematical expressions were generated, evaluated and used to train neural\\nnetwork models based on the transformer architecture. The expressions and their\\ntargets were analyzed as a character-level sequence transduction task in which\\nthe encoder and decoder are built on attention mechanisms. Three models were\\ntrained to understand and evaluate symbolic variables and expressions in\\nmathematics: (1) the self-attentive and feed-forward transformer without\\nrecurrence or convolution, (2) the universal transformer with recurrence, and\\n(3) the adaptive universal transformer with recurrence and adaptive computation\\ntime. The models respectively achieved test accuracies as high as 76.1%, 78.8%\\nand 84.9% in evaluating the expressions to match the target values. For the\\ncases inferred incorrectly, the results differed from the targets by only one\\nor two characters. The models notably learned to add, subtract and multiply\\nboth positive and negative decimal numbers of variable digits assigned to\\nsymbolic variables.\\n\\n    ', '\\nAbstract:  Depthwise separable convolutions reduce the number of parameters and\\ncomputation used in convolutional operations while increasing representational\\nefficiency. They have been shown to be successful in image classification\\nmodels, both in obtaining better models than previously possible for a given\\nparameter count (the Xception architecture) and considerably reducing the\\nnumber of parameters required to perform at a given level (the MobileNets\\nfamily of architectures). Recently, convolutional sequence-to-sequence networks\\nhave been applied to machine translation tasks with good results. In this work,\\nwe study how depthwise separable convolutions can be applied to neural machine\\ntranslation. We introduce a new architecture inspired by Xception and ByteNet,\\ncalled SliceNet, which enables a significant reduction of the parameter count\\nand amount of computation needed to obtain results like ByteNet, and, with a\\nsimilar parameter count, achieves new state-of-the-art results. In addition to\\nshowing that depthwise separable convolutions perform well for machine\\ntranslation, we investigate the architectural changes that they enable: we\\nobserve that thanks to depthwise separability, we can increase the length of\\nconvolution windows, removing the need for filter dilation. We also introduce a\\nnew \"super-separable\" convolution operation that further reduces the number of\\nparameters and computational cost for obtaining state-of-the-art results.\\n\\n    ', '\\nAbstract:  Modern machine learning algorithms are increasingly computationally\\ndemanding, requiring specialized hardware and distributed computation to\\nachieve high performance in a reasonable time frame. Many hyperparameter search\\nalgorithms have been proposed for improving the efficiency of model selection,\\nhowever their adaptation to the distributed compute environment is often\\nad-hoc. We propose Tune, a unified framework for model selection and training\\nthat provides a narrow-waist interface between training scripts and search\\nalgorithms. We show that this interface meets the requirements for a broad\\nrange of hyperparameter search algorithms, allows straightforward scaling of\\nsearch to large clusters, and simplifies algorithm implementation. We\\ndemonstrate the implementation of several state-of-the-art hyperparameter\\nsearch algorithms in Tune. Tune is available at\\nthis http URL.\\n\\n    ', '\\nAbstract:  In this paper, we propose the Self-Attention Generative Adversarial Network\\n(SAGAN) which allows attention-driven, long-range dependency modeling for image\\ngeneration tasks. Traditional convolutional GANs generate high-resolution\\ndetails as a function of only spatially local points in lower-resolution\\nfeature maps. In SAGAN, details can be generated using cues from all feature\\nlocations. Moreover, the discriminator can check that highly detailed features\\nin distant portions of the image are consistent with each other. Furthermore,\\nrecent work has shown that generator conditioning affects GAN performance.\\nLeveraging this insight, we apply spectral normalization to the GAN generator\\nand find that this improves training dynamics. The proposed SAGAN achieves the\\nstate-of-the-art results, boosting the best published Inception score from 36.8\\nto 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the\\nchallenging ImageNet dataset. Visualization of the attention layers shows that\\nthe generator leverages neighborhoods that correspond to object shapes rather\\nthan local regions of fixed shape.\\n\\n    ', '\\nAbstract:  It this paper we revisit the fast stylization method introduced in Ulyanov\\net. al. (2016). We show how a small change in the stylization architecture\\nresults in a significant qualitative improvement in the generated images. The\\nchange is limited to swapping batch normalization with instance normalization,\\nand to apply the latter both at training and testing times. The resulting\\nmethod can be used to train high-performance architectures for real-time image\\ngeneration. The code will is made available on github at\\nthis https URL. Full paper can be found at\\narXiv:1701.02096.\\n\\n    ', '\\nAbstract:  Generative Adversarial Networks (GANs) excel at creating realistic images\\nwith complex models for which maximum likelihood is infeasible. However, the\\nconvergence of GAN training has still not been proved. We propose a two\\ntime-scale update rule (TTUR) for training GANs with stochastic gradient\\ndescent on arbitrary GAN loss functions. TTUR has an individual learning rate\\nfor both the discriminator and the generator. Using the theory of stochastic\\napproximation, we prove that the TTUR converges under mild assumptions to a\\nstationary local Nash equilibrium. The convergence carries over to the popular\\nAdam optimization, for which we prove that it follows the dynamics of a heavy\\nball with friction and thus prefers flat minima in the objective landscape. For\\nthe evaluation of the performance of GANs at image generation, we introduce the\\n\"Fréchet Inception Distance\" (FID) which captures the similarity of generated\\nimages to real ones better than the Inception Score. In experiments, TTUR\\nimproves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)\\noutperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN\\nBedrooms, and the One Billion Word Benchmark.\\n\\n    ', \"\\nAbstract:  We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE)\\nmodels for large scale image generation. To this end, we scale and enhance the\\nautoregressive priors used in VQ-VAE to generate synthetic samples of much\\nhigher coherence and fidelity than possible before. We use simple feed-forward\\nencoder and decoder networks, making our model an attractive candidate for\\napplications where the encoding and/or decoding speed is critical.\\nAdditionally, VQ-VAE requires sampling an autoregressive model only in the\\ncompressed latent space, which is an order of magnitude faster than sampling in\\nthe pixel space, especially for large images. We demonstrate that a multi-scale\\nhierarchical organization of VQ-VAE, augmented with powerful priors over the\\nlatent codes, is able to generate samples with quality that rivals that of\\nstate of the art Generative Adversarial Networks on multifaceted datasets such\\nas ImageNet, while not suffering from GAN's known shortcomings such as mode\\ncollapse and lack of diversity.\\n\\n    \", '\\nAbstract:  Similarity search approaches based on graph walks have recently attained\\noutstanding speed-accuracy trade-offs, taking aside the memory requirements. In\\nthis paper, we revisit these approaches by considering, additionally, the\\nmemory constraint required to index billions of images on a single server. This\\nleads us to propose a method based both on graph traversal and compact\\nrepresentations. We encode the indexed vectors using quantization and exploit\\nthe graph structure to refine the similarity estimation.\\nIn essence, our method takes the best of these two worlds: the search\\nstrategy is based on nested graphs, thereby providing high precision with a\\nrelatively small set of comparisons. At the same time it offers a significant\\nmemory compression. As a result, our approach outperforms the state of the art\\non operating points considering 64-128 bytes per vector, as demonstrated by our\\nresults on two billion-scale public benchmarks.\\n\\n    ', '\\nAbstract:  Similarity search finds application in specialized database systems handling\\ncomplex data such as images or videos, which are typically represented by\\nhigh-dimensional features and require specific indexing structures. This paper\\ntackles the problem of better utilizing GPUs for this task. While GPUs excel at\\ndata-parallel tasks, prior approaches are bottlenecked by algorithms that\\nexpose less parallelism, such as k-min selection, or make poor use of the\\nmemory hierarchy.\\nWe propose a design for k-selection that operates at up to 55% of theoretical\\npeak performance, enabling a nearest neighbor implementation that is 8.5x\\nfaster than prior GPU state of the art. We apply it in different similarity\\nsearch scenarios, by proposing optimized design for brute-force, approximate\\nand compressed-domain search based on product quantization. In all these\\nsetups, we outperform the state of the art by large margins. Our implementation\\nenables the construction of a high accuracy k-NN graph on 95 million images\\nfrom the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion\\nvectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced\\nour approach for the sake of comparison and reproducibility.\\n\\n    ', '\\nAbstract:  We introduce a guide to help deep learning practitioners understand and\\nmanipulate convolutional neural network architectures. The guide clarifies the\\nrelationship between various properties (input shape, kernel shape, zero\\npadding, strides and output shape) of convolutional, pooling and transposed\\nconvolutional layers, as well as the relationship between convolutional and\\ntransposed convolutional layers. Relationships are derived for various cases,\\nand are illustrated in order to make them intuitive.\\n\\n    ', '\\nAbstract:  Recent advances in Deep Reinforcement Learning and Robotics have been driven\\nby the presence of increasingly realistic and complex simulation environments.\\nMany of the existing platforms, however, provide either unrealistic visuals,\\ninaccurate physics, low task complexity, or a limited capacity for interaction\\namong artificial agents. Furthermore, many platforms lack the ability to\\nflexibly configure the simulation, hence turning the simulation environment\\ninto a black-box from the perspective of the learning system. Here we describe\\na new open source toolkit for creating and interacting with simulation\\nenvironments using the Unity platform: Unity ML-Agents Toolkit. By taking\\nadvantage of Unity as a simulation platform, the toolkit enables the\\ndevelopment of learning environments which are rich in sensory and physical\\ncomplexity, provide compelling cognitive challenges, and support dynamic\\nmulti-agent interaction. We detail the platform design, communication protocol,\\nset of example environments, and variety of training scenarios made possible\\nvia the toolkit.\\n\\n    ', '\\nAbstract:  Hierarchical reinforcement learning (HRL) is a promising approach to extend\\ntraditional reinforcement learning (RL) methods to solve more complex tasks.\\nYet, the majority of current HRL methods require careful task-specific design\\nand on-policy training, making them difficult to apply in real-world scenarios.\\nIn this paper, we study how we can develop HRL algorithms that are general, in\\nthat they do not make onerous additional assumptions beyond standard RL\\nalgorithms, and efficient, in the sense that they can be used with modest\\nnumbers of interaction samples, making them suitable for real-world problems\\nsuch as robotic control. For generality, we develop a scheme where lower-level\\ncontrollers are supervised with goals that are learned and proposed\\nautomatically by the higher-level controllers. To address efficiency, we\\npropose to use off-policy experience for both higher and lower-level training.\\nThis poses a considerable challenge, since changes to the lower-level behaviors\\nchange the action space for the higher-level policy, and we introduce an\\noff-policy correction to remedy this challenge. This allows us to take\\nadvantage of recent advances in off-policy model-free RL to learn both higher-\\nand lower-level policies using substantially fewer environment interactions\\nthan on-policy algorithms. We term the resulting HRL agent HIRO and find that\\nit is generally applicable and highly sample-efficient. Our experiments show\\nthat HIRO can be used to learn highly complex behaviors for simulated robots,\\nsuch as pushing objects and utilizing them to reach target locations, learning\\nfrom only a few million samples, equivalent to a few days of real-time\\ninteraction. In comparisons with a number of prior HRL methods, we find that\\nour approach substantially outperforms previous state-of-the-art techniques.\\n\\n    ', '\\nAbstract:  We present a tutorial on Bayesian optimization, a method of finding the\\nmaximum of expensive cost functions. Bayesian optimization employs the Bayesian\\ntechnique of setting a prior over the objective function and combining it with\\nevidence to get a posterior function. This permits a utility-based selection of\\nthe next observation to make on the objective function, which must take into\\naccount both exploration (sampling from areas of high uncertainty) and\\nexploitation (sampling areas likely to offer improvement over the current best\\nobservation). We also present two detailed extensions of Bayesian optimization,\\nwith experiments---active user modelling with preferences, and hierarchical\\nreinforcement learning---and a discussion of the pros and cons of Bayesian\\noptimization based on our experiences.\\n\\n    ', '\\nAbstract:  In many real-world scenarios, an autonomous agent often encounters various\\ntasks within a single complex environment. We propose to build a graph\\nabstraction over the environment structure to accelerate the learning of these\\ntasks. Here, nodes are important points of interest (pivotal states) and edges\\nrepresent feasible traversals between them. Our approach has two stages. First,\\nwe jointly train a latent pivotal state model and a curiosity-driven\\ngoal-conditioned policy in a task-agnostic manner. Second, provided with the\\ninformation from the world graph, a high-level Manager quickly finds solution\\nto new tasks and expresses subgoals in reference to pivotal states to a\\nlow-level Worker. The Worker can then also leverage the graph to easily\\ntraverse to the pivotal states of interest, even across long distance, and\\nexplore non-locally. We perform a thorough ablation study to evaluate our\\napproach on a suite of challenging maze tasks, demonstrating significant\\nadvantages from the proposed framework over baselines that lack world graph\\nknowledge in terms of performance and efficiency.\\n\\n    ', '\\nAbstract:  Most existing methods determine relation types only after all the entities\\nhave been recognized, thus the interaction between relation types and entity\\nmentions is not fully modeled. This paper presents a novel paradigm to deal\\nwith relation extraction by regarding the related entities as the arguments of\\na relation. We apply a hierarchical reinforcement learning (HRL) framework in\\nthis paradigm to enhance the interaction between entity mentions and relation\\ntypes. The whole extraction process is decomposed into a hierarchy of two-level\\nRL policies for relation detection and entity extraction respectively, so that\\nit is more feasible and natural to deal with overlapping relations. Our model\\nwas evaluated on public datasets collected via distant supervision, and results\\nshow that it gains better performance than existing methods and is more\\npowerful for extracting overlapping relations.\\n\\n    ', '\\nAbstract:  Deep reinforcement learning has achieved many impressive results in recent\\nyears. However, tasks with sparse rewards or long horizons continue to pose\\nsignificant challenges. To tackle these important problems, we propose a\\ngeneral framework that first learns useful skills in a pre-training\\nenvironment, and then leverages the acquired skills for learning faster in\\ndownstream tasks. Our approach brings together some of the strengths of\\nintrinsic motivation and hierarchical methods: the learning of useful skill is\\nguided by a single proxy reward, the design of which requires very minimal\\ndomain knowledge about the downstream tasks. Then a high-level policy is\\ntrained on top of these skills, providing a significant improvement of the\\nexploration and allowing to tackle sparse rewards in the downstream tasks. To\\nefficiently pre-train a large span of skills, we use Stochastic Neural Networks\\ncombined with an information-theoretic regularizer. Our experiments show that\\nthis combination is effective in learning a wide span of interpretable skills\\nin a sample-efficient way, and can significantly boost the learning performance\\nuniformly across a wide range of downstream tasks.\\n\\n    ', '\\nAbstract:  Hierarchical agents have the potential to solve sequential decision making\\ntasks with greater sample efficiency than their non-hierarchical counterparts\\nbecause hierarchical agents can break down tasks into sets of subtasks that\\nonly require short sequences of decisions. In order to realize this potential\\nof faster learning, hierarchical agents need to be able to learn their multiple\\nlevels of policies in parallel so these simpler subproblems can be solved\\nsimultaneously. Yet, learning multiple levels of policies in parallel is hard\\nbecause it is inherently unstable: changes in a policy at one level of the\\nhierarchy may cause changes in the transition and reward functions at higher\\nlevels in the hierarchy, making it difficult to jointly learn multiple levels\\nof policies. In this paper, we introduce a new Hierarchical Reinforcement\\nLearning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome\\nthe instability issues that arise when agents try to jointly learn multiple\\nlevels of policies. The main idea behind HAC is to train each level of the\\nhierarchy independently of the lower levels by training each level as if the\\nlower level policies are already optimal. We demonstrate experimentally in both\\ngrid world and simulated robotics domains that our approach can significantly\\naccelerate learning relative to other non-hierarchical and hierarchical\\nmethods. Indeed, our framework is the first to successfully learn 3-level\\nhierarchies in parallel in tasks with continuous state and action spaces.\\n\\n    ', '\\nAbstract:  Open-domain dialog generation is a challenging problem; maximum likelihood\\ntraining can lead to repetitive outputs, models have difficulty tracking\\nlong-term conversational goals, and training on standard movie or online\\ndatasets may lead to the generation of inappropriate, biased, or offensive\\ntext. Reinforcement Learning (RL) is a powerful framework that could\\npotentially address these issues, for example by allowing a dialog model to\\noptimize for reducing toxicity and repetitiveness. However, previous approaches\\nwhich apply RL to open-domain dialog generation do so at the word level, making\\nit difficult for the model to learn proper credit assignment for long-term\\nconversational rewards. In this paper, we propose a novel approach to\\nhierarchical reinforcement learning, VHRL, which uses policy gradients to tune\\nthe utterance-level embedding of a variational sequence model. This\\nhierarchical approach provides greater flexibility for learning long-term,\\nconversational rewards. We use self-play and RL to optimize for a set of\\nhuman-centered conversation metrics, and show that our approach provides\\nsignificant improvements -- in terms of both human evaluation and automatic\\nmetrics -- over state-of-the-art dialog models, including Transformers.\\n\\n    ', '\\nAbstract:  Hierarchical reinforcement learning (HRL) has recently shown promising\\nadvances on speeding up learning, improving the exploration, and discovering\\nintertask transferable skills. Most recent works focus on HRL with two levels,\\ni.e., a master policy manipulates subpolicies, which in turn manipulate\\nprimitive actions. However, HRL with multiple levels is usually needed in many\\nreal-world scenarios, whose ultimate goals are highly abstract, while their\\nactions are very primitive. Therefore, in this paper, we propose a\\ndiversity-driven extensible HRL (DEHRL), where an extensible and scalable\\nframework is built and learned levelwise to realize HRL with multiple levels.\\nDEHRL follows a popular assumption: diverse subpolicies are useful, i.e.,\\nsubpolicies are believed to be more useful if they are more diverse. However,\\nexisting implementations of this diversity assumption usually have their own\\ndrawbacks, which makes them inapplicable to HRL with multiple levels.\\nConsequently, we further propose a novel diversity-driven solution to achieve\\nthis assumption in DEHRL. Experimental studies evaluate DEHRL with five\\nbaselines from four perspectives in two domains; the results show that DEHRL\\noutperforms the state-of-the-art baselines in all four aspects.\\n\\n    ', '\\nAbstract:  Given a text description, most existing semantic parsers synthesize a program\\nin one shot. However, it is quite challenging to produce a correct program\\nsolely based on the description, which in reality is often ambiguous or\\nincomplete. In this paper, we investigate interactive semantic parsing, where\\nthe agent can ask the user clarification questions to resolve ambiguities via a\\nmulti-turn dialogue, on an important type of programs called \"If-Then recipes.\"\\nWe develop a hierarchical reinforcement learning (HRL) based agent that\\nsignificantly improves the parsing performance with minimal questions to the\\nuser. Results under both simulation and human evaluation show that our agent\\nsubstantially outperforms non-interactive semantic parsers and rule-based\\nagents.\\n\\n    ', '\\nAbstract:  In hierarchical reinforcement learning a major challenge is determining\\nappropriate low-level policies. We propose an unsupervised learning scheme,\\nbased on asymmetric self-play from Sukhbaatar et al. (2018), that automatically\\nlearns a good representation of sub-goals in the environment and a low-level\\npolicy that can execute them. A high-level policy can then direct the lower one\\nby generating a sequence of continuous sub-goal vectors. We evaluate our model\\nusing Mazebase and Mujoco environments, including the challenging AntGather\\ntask. Visualizations of the sub-goal embeddings reveal a logical decomposition\\nof tasks within the environment. Quantitatively, our approach obtains\\ncompelling performance gains over non-hierarchical approaches.\\n\\n    ', \"\\nAbstract:  Designing hierarchical reinforcement learning algorithms that induce a notion\\nof safety is not only vital for safety-critical applications, but also, brings\\nbetter understanding of an artificially intelligent agent's decisions. While\\nlearning end-to-end options automatically has been fully realized recently, we\\npropose a solution to learning safe options. We introduce the idea of\\ncontrollability of states based on the temporal difference errors in the\\noption-critic framework. We then derive the policy-gradient theorem with\\ncontrollability and propose a novel framework called safe option-critic. We\\ndemonstrate the effectiveness of our approach in the four-rooms grid-world,\\ncartpole, and three games in the Arcade Learning Environment (ALE): MsPacman,\\nAmidar and Q*Bert. Learning of end-to-end options with the proposed notion of\\nsafety achieves reduction in the variance of return and boosts the performance\\nin environments with intrinsic variability in the reward structure. More\\nimportantly, the proposed algorithm outperforms the vanilla options in all the\\nenvironments and primitive actions in two out of three ALE games.\\n\\n    \", '\\nAbstract:  Deep reinforcement learning can match and exceed human performance, but if\\neven minor changes are introduced to the environment artificial networks often\\ncan\\'t adapt. Humans meanwhile are quite adaptable. We hypothesize that this is\\npartly because of how humans use heuristics, and partly because humans can\\nimagine new and more challenging environments to learn from. We\\'ve developed a\\nmodel of hierarchical reinforcement learning that combines both these elements\\ninto a stumbler-strategist network. We test transfer performance of this\\nnetwork using Wythoff\\'s game, a gridworld environment with a known optimal\\nstrategy. We show that combining imagined play with a heuristic--labeling each\\nposition as \"good\" or \"bad\"\\'--both accelerates learning and promotes transfer\\nto novel games, while also improving model interpretability.\\n\\n    ', '\\nAbstract:  We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical\\nreinforcement learning. Our approach is inspired by the feudal reinforcement\\nlearning proposal of Dayan and Hinton, and gains power and efficacy by\\ndecoupling end-to-end learning across multiple levels -- allowing it to utilise\\ndifferent resolutions of time. Our framework employs a Manager module and a\\nWorker module. The Manager operates at a lower temporal resolution and sets\\nabstract goals which are conveyed to and enacted by the Worker. The Worker\\ngenerates primitive actions at every tick of the environment. The decoupled\\nstructure of FuN conveys several benefits -- in addition to facilitating very\\nlong timescale credit assignment it also encourages the emergence of\\nsub-policies associated with different goals set by the Manager. These\\nproperties allow FuN to dramatically outperform a strong baseline agent on\\ntasks that involve long-term credit assignment or memorisation. We demonstrate\\nthe performance of our proposed system on a range of tasks from the ATARI suite\\nand also from a 3D DeepMind Lab environment.\\n\\n    ', '\\nAbstract:  We introduce a new RL problem where the agent is required to generalize to a\\npreviously-unseen environment characterized by a subtask graph which describes\\na set of subtasks and their dependencies. Unlike existing hierarchical\\nmultitask RL approaches that explicitly describe what the agent should do at a\\nhigh level, our problem only describes properties of subtasks and relationships\\namong them, which requires the agent to perform complex reasoning to find the\\noptimal subtask to execute. To solve this problem, we propose a neural subtask\\ngraph solver (NSGS) which encodes the subtask graph using a recursive neural\\nnetwork embedding. To overcome the difficulty of training, we propose a novel\\nnon-parametric gradient-based policy, graph reward propagation, to pre-train\\nour NSGS agent and further finetune it through actor-critic method. The\\nexperimental results on two 2D visual domains show that our agent can perform\\ncomplex reasoning to find a near-optimal way of executing the subtask graph and\\ngeneralize well to the unseen subtask graphs. In addition, we compare our agent\\nwith a Monte-Carlo tree search (MCTS) method showing that our method is much\\nmore efficient than MCTS, and the performance of NSGS can be further improved\\nby combining it with MCTS.\\n\\n    ', '\\nAbstract:  This paper presents the Crossmodal Attentive Skill Learner (CASL), integrated\\nwith the recently-introduced Asynchronous Advantage Option-Critic (A2OC)\\narchitecture [Harb et al., 2017] to enable hierarchical reinforcement learning\\nacross multiple sensory inputs. We provide concrete examples where the approach\\nnot only improves performance in a single task, but accelerates transfer to new\\ntasks. We demonstrate the attention mechanism anticipates and identifies useful\\nlatent features, while filtering irrelevant sensor modalities during execution.\\nWe modify the Arcade Learning Environment [Bellemare et al., 2013] to support\\naudio queries, and conduct evaluations of crossmodal learning in the Atari 2600\\ngame Amidar. Finally, building on the recent work of Babaeizadeh et al. [2017],\\nwe open-source a fast hybrid CPU-GPU implementation of CASL.\\n\\n    ', '\\nAbstract:  A common strategy to deal with the expensive reinforcement learning (RL) of\\ncomplex tasks is to decompose them into a collection of subtasks that are\\nusually simpler to learn as well as reusable for new problems. However, when a\\nrobot learns the policies for these subtasks, common approaches treat every\\npolicy learning process separately. Therefore, all these individual\\n(composable) policies need to be learned before tackling the learning process\\nof the complex task through policies composition. Moreover, such composition of\\nindividual policies is usually performed sequentially, which is not suitable\\nfor tasks that require to perform the subtasks concurrently. In this paper, we\\npropose to combine a set of composable Gaussian policies corresponding to these\\nsubtasks using a set of activation vectors, resulting in a complex Gaussian\\npolicy that is a function of the means and covariances matrices of the\\ncomposable policies. Moreover, we propose an algorithm for learning both\\ncompound and composable policies within the same learning process by exploiting\\nthe off-policy data generated from the compound policy. The algorithm is built\\non a maximum entropy RL approach to favor exploration during the learning\\nprocess. The results of the experiments show that the experience collected with\\nthe compound policy permits not only to solve the complex task but also to\\nobtain useful composable policies that successfully perform in their\\ncorresponding subtasks.\\n\\n    ', '\\nAbstract:  Learning interpretable and transferable subpolicies and performing task\\ndecomposition from a single, complex task is difficult. Some traditional\\nhierarchical reinforcement learning techniques enforce this decomposition in a\\ntop-down manner, while meta-learning techniques require a task distribution at\\nhand to learn such decompositions. This paper presents a framework for using\\ndiverse suboptimal world models to decompose complex task solutions into\\nsimpler modular subpolicies. This framework performs automatic decomposition of\\na single source task in a bottom up manner, concurrently learning the required\\nmodular subpolicies as well as a controller to coordinate them. We perform a\\nseries of experiments on high dimensional continuous action control tasks to\\ndemonstrate the effectiveness of this approach at both complex single task\\nlearning and lifelong learning. Finally, we perform ablation studies to\\nunderstand the importance and robustness of different elements in the framework\\nand limitations to this approach.\\n\\n    ', '\\nAbstract:  Real-world tasks are often highly structured. Hierarchical reinforcement\\nlearning (HRL) has attracted research interest as an approach for leveraging\\nthe hierarchical structure of a given task in reinforcement learning (RL).\\nHowever, identifying the hierarchical policy structure that enhances the\\nperformance of RL is not a trivial task. In this paper, we propose an HRL\\nmethod that learns a latent variable of a hierarchical policy using mutual\\ninformation maximization. Our approach can be interpreted as a way to learn a\\ndiscrete and latent representation of the state-action space. To learn option\\npolicies that correspond to modes of the advantage function, we introduce\\nadvantage-weighted importance sampling. In our HRL method, the gating policy\\nlearns to select option policies based on an option-value function, and these\\noption policies are optimized based on the deterministic policy gradient\\nmethod. This framework is derived by leveraging the analogy between a\\nmonolithic policy in standard RL and a hierarchical policy in HRL by using a\\ndeterministic option policy. Experimental results indicate that our HRL\\napproach can learn a diversity of options and that it can enhance the\\nperformance of RL in continuous control tasks.\\n\\n    ', '\\nAbstract:  This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.\\n\\n    ', '\\nAbstract:  We present the first massively distributed architecture for deep\\nreinforcement learning. This architecture uses four main components: parallel\\nactors that generate new behaviour; parallel learners that are trained from\\nstored experience; a distributed neural network to represent the value function\\nor behaviour policy; and a distributed store of experience. We used our\\narchitecture to implement the Deep Q-Network algorithm (DQN). Our distributed\\nalgorithm was applied to 49 games from Atari 2600 games from the Arcade\\nLearning Environment, using identical hyperparameters. Our performance\\nsurpassed non-distributed DQN in 41 of the 49 games and also reduced the\\nwall-time required to achieve these results by an order of magnitude on most\\ngames.\\n\\n    ', '\\nAbstract:  In this paper, we consider the task of learning control policies for\\ntext-based games. In these games, all interactions in the virtual world are\\nthrough text and the underlying state is not observed. The resulting language\\nbarrier makes such environments challenging for automatic game players. We\\nemploy a deep reinforcement learning framework to jointly learn state\\nrepresentations and action policies using game rewards as feedback. This\\nframework enables us to map text descriptions into vector representations that\\ncapture the semantics of the game states. We evaluate our approach on two game\\nworlds, comparing against baselines using bag-of-words and bag-of-bigrams for\\nstate representations. Our algorithm outperforms the baselines on both worlds\\ndemonstrating the importance of learning expressive representations.\\n\\n    ', \"\\nAbstract:  Deep Reinforcement Learning has yielded proficient controllers for complex\\ntasks. However, these controllers have limited memory and rely on being able to\\nperceive the complete game screen at each decision point. To address these\\nshortcomings, this article investigates the effects of adding recurrency to a\\nDeep Q-Network (DQN) by replacing the first post-convolutional fully-connected\\nlayer with a recurrent LSTM. The resulting \\\\textit{Deep Recurrent Q-Network}\\n(DRQN), although capable of seeing only a single frame at each timestep,\\nsuccessfully integrates information through time and replicates DQN's\\nperformance on standard Atari games and partially observed equivalents\\nfeaturing flickering game screens. Additionally, when trained with partial\\nobservations and evaluated with incrementally more complete observations,\\nDRQN's performance scales as a function of observability. Conversely, when\\ntrained with full observations and evaluated with partial observations, DRQN's\\nperformance degrades less than DQN's. Thus, given the same length of history,\\nrecurrency is a viable alternative to stacking a history of frames in the DQN's\\ninput layer and while recurrency confers no systematic advantage when learning\\nto play the game, the recurrent net can better adapt at evaluation time if the\\nquality of observations changes.\\n\\n    \", \"\\nAbstract:  This report presents Giraffe, a chess engine that uses self-play to discover\\nall its domain-specific knowledge, with minimal hand-crafted knowledge given by\\nthe programmer. Unlike previous attempts using machine learning only to perform\\nparameter-tuning on hand-crafted evaluation functions, Giraffe's learning\\nsystem also performs automatic feature extraction and pattern recognition. The\\ntrained evaluation function performs comparably to the evaluation functions of\\nstate-of-the-art chess engines - all of which containing thousands of lines of\\ncarefully hand-crafted pattern recognizers, tuned over many years by both\\ncomputer chess experts and human chess masters. Giraffe is the most successful\\nattempt thus far at using end-to-end machine learning to play chess.\\n\\n    \", '\\nAbstract:  The popular Q-learning algorithm is known to overestimate action values under\\ncertain conditions. It was not previously known whether, in practice, such\\noverestimations are common, whether they harm performance, and whether they can\\ngenerally be prevented. In this paper, we answer all these questions\\naffirmatively. In particular, we first show that the recent DQN algorithm,\\nwhich combines Q-learning with a deep neural network, suffers from substantial\\noverestimations in some games in the Atari 2600 domain. We then show that the\\nidea behind the Double Q-learning algorithm, which was introduced in a tabular\\nsetting, can be generalized to work with large-scale function approximation. We\\npropose a specific adaptation to the DQN algorithm and show that the resulting\\nalgorithm not only reduces the observed overestimations, as hypothesized, but\\nthat this also leads to much better performance on several games.\\n\\n    ', '\\nAbstract:  This paper introduces a machine learning based system for controlling a\\nrobotic manipulator with visual perception only. The capability to autonomously\\nlearn robot controllers solely from raw-pixel images and without any prior\\nknowledge of configuration is shown for the first time. We build upon the\\nsuccess of recent deep reinforcement learning and develop a system for learning\\ntarget reaching with a three-joint robot manipulator using external visual\\nobservation. A Deep Q Network (DQN) was demonstrated to perform target reaching\\nafter training in simulation. Transferring the network to real hardware and\\nreal observation in a naive approach failed, but experiments show that the\\nnetwork works when replacing camera images with synthetic images.\\n\\n    ', '\\nAbstract:  Experience replay lets online reinforcement learning agents remember and\\nreuse experiences from the past. In prior work, experience transitions were\\nuniformly sampled from a replay memory. However, this approach simply replays\\ntransitions at the same frequency that they were originally experienced,\\nregardless of their significance. In this paper we develop a framework for\\nprioritizing experience, so as to replay important transitions more frequently,\\nand therefore learn more efficiently. We use prioritized experience replay in\\nDeep Q-Networks (DQN), a reinforcement learning algorithm that achieved\\nhuman-level performance across many Atari games. DQN with prioritized\\nexperience replay achieves a new state-of-the-art, outperforming DQN with\\nuniform replay on 41 out of 49 games.\\n\\n    ', '\\nAbstract:  In recent years there have been many successes of using deep representations\\nin reinforcement learning. Still, many of these applications use conventional\\narchitectures, such as convolutional networks, LSTMs, or auto-encoders. In this\\npaper, we present a new neural network architecture for model-free\\nreinforcement learning. Our dueling network represents two separate estimators:\\none for the state value function and one for the state-dependent action\\nadvantage function. The main benefit of this factoring is to generalize\\nlearning across actions without imposing any change to the underlying\\nreinforcement learning algorithm. Our results show that this architecture leads\\nto better policy evaluation in the presence of many similar-valued actions.\\nMoreover, the dueling architecture enables our RL agent to outperform the\\nstate-of-the-art on the Atari 2600 domain.\\n\\n    ', '\\nAbstract:  Using deep neural nets as function approximator for reinforcement learning\\ntasks have recently been shown to be very powerful for solving problems\\napproaching real-world complexity. Using these results as a benchmark, we\\ndiscuss the role that the discount factor may play in the quality of the\\nlearning process of a deep Q-network (DQN). When the discount factor\\nprogressively increases up to its final value, we empirically show that it is\\npossible to significantly reduce the number of learning steps. When used in\\nconjunction with a varying learning rate, we empirically show that it\\noutperforms original DQN on several experiments. We relate this phenomenon with\\nthe instabilities of neural networks when they are used in an approximate\\nDynamic Programming setting. We also describe the possibility to fall within a\\nlocal optimum during the learning process, thus connecting our discussion with\\nthe exploration/exploitation dilemma.\\n\\n    ', '\\nAbstract:  A deep learning approach to reinforcement learning led to a general learner\\nable to train on visual input to play a variety of arcade games at the human\\nand superhuman levels. Its creators at the Google DeepMind\\'s team called the\\napproach: Deep Q-Network (DQN). We present an extension of DQN by \"soft\" and\\n\"hard\" attention mechanisms. Tests of the proposed Deep Attention Recurrent\\nQ-Network (DARQN) algorithm on multiple Atari 2600 games show level of\\nperformance superior to that of DQN. Moreover, built-in attention mechanisms\\nallow a direct online monitoring of the training process by highlighting the\\nregions of the game screen the agent is focusing on when making decisions.\\n\\n    ', '\\nAbstract:  Policies for complex visual tasks have been successfully learned with deep\\nreinforcement learning, using an approach called deep Q-networks (DQN), but\\nrelatively large (task-specific) networks and extensive training are needed to\\nachieve good performance. In this work, we present a novel method called policy\\ndistillation that can be used to extract the policy of a reinforcement learning\\nagent and train a new network that performs at the expert level while being\\ndramatically smaller and more efficient. Furthermore, the same method can be\\nused to consolidate multiple task-specific policies into a single policy. We\\ndemonstrate these claims using the Atari domain and show that the multi-task\\ndistilled agent outperforms the single-task teachers as well as a\\njointly-trained DQN agent.\\n\\n    ', '\\nAbstract:  In recent years there is a growing interest in using deep representations for\\nreinforcement learning. In this paper, we present a methodology and tools to\\nanalyze Deep Q-networks (DQNs) in a non-blind matter. Moreover, we propose a\\nnew model, the Semi Aggregated Markov Decision Process (SAMDP), and an\\nalgorithm that learns it automatically. The SAMDP model allows us to identify\\nspatio-temporal abstractions directly from features and may be used as a\\nsub-goal detector in future work. Using our tools we reveal that the features\\nlearned by DQNs aggregate the state space in a hierarchical fashion, explaining\\nits success. Moreover, we are able to understand and describe the policies\\nlearned by DQNs for three different Atari2600 games and suggest ways to\\ninterpret, debug and optimize deep neural networks in reinforcement learning.\\n\\n    ', '\\nAbstract:  Many real-world applications can be described as large-scale games of\\nimperfect information. To deal with these challenging domains, prior work has\\nfocused on computing Nash equilibria in a handcrafted abstraction of the\\ndomain. In this paper we introduce the first scalable end-to-end approach to\\nlearning approximate Nash equilibria without prior domain knowledge. Our method\\ncombines fictitious self-play with deep reinforcement learning. When applied to\\nLeduc poker, Neural Fictitious Self-Play (NFSP) approached a Nash equilibrium,\\nwhereas common reinforcement learning methods diverged. In Limit Texas Holdem,\\na poker game of real-world scale, NFSP learnt a strategy that approached the\\nperformance of state-of-the-art, superhuman algorithms based on significant\\ndomain expertise.\\n\\n    ', '\\nAbstract:  We describe an iterative procedure for optimizing policies, with guaranteed\\nmonotonic improvement. By making several approximations to the\\ntheoretically-justified procedure, we develop a practical algorithm, called\\nTrust Region Policy Optimization (TRPO). This algorithm is similar to natural\\npolicy gradient methods and is effective for optimizing large nonlinear\\npolicies such as neural networks. Our experiments demonstrate its robust\\nperformance on a wide variety of tasks: learning simulated robotic swimming,\\nhopping, and walking gaits; and playing Atari games using images of the screen\\nas input. Despite its approximations that deviate from the theory, TRPO tends\\nto give monotonic improvement, with little tuning of hyperparameters.\\n\\n    ', \"\\nAbstract:  Model predictive control (MPC) is an effective method for controlling robotic\\nsystems, particularly autonomous aerial vehicles such as quadcopters. However,\\napplication of MPC can be computationally demanding, and typically requires\\nestimating the state of the system, which can be challenging in complex,\\nunstructured environments. Reinforcement learning can in principle forego the\\nneed for explicit state estimation and acquire a policy that directly maps\\nsensor readings to actions, but is difficult to apply to unstable systems that\\nare liable to fail catastrophically during training before an effective policy\\nhas been found. We propose to combine MPC with reinforcement learning in the\\nframework of guided policy search, where MPC is used to generate data at\\ntraining time, under full state observations provided by an instrumented\\ntraining environment. This data is used to train a deep neural network policy,\\nwhich is allowed to access only the raw observations from the vehicle's onboard\\nsensors. After training, the neural network policy can successfully control the\\nrobot without knowledge of the full state, and at a fraction of the\\ncomputational cost of MPC. We evaluate our method by learning obstacle\\navoidance policies for a simulated quadrotor, using simulated onboard sensors\\nand no explicit state estimation at test time.\\n\\n    \", '\\nAbstract:  Policy gradient methods are an appealing approach in reinforcement learning\\nbecause they directly optimize the cumulative reward and can straightforwardly\\nbe used with nonlinear function approximators such as neural networks. The two\\nmain challenges are the large number of samples typically required, and the\\ndifficulty of obtaining stable and steady improvement despite the\\nnonstationarity of the incoming data. We address the first challenge by using\\nvalue functions to substantially reduce the variance of policy gradient\\nestimates at the cost of some bias, with an exponentially-weighted estimator of\\nthe advantage function that is analogous to TD(lambda). We address the second\\nchallenge by using trust region optimization procedure for both the policy and\\nthe value function, which are represented by neural networks.\\nOur approach yields strong empirical results on highly challenging 3D\\nlocomotion tasks, learning running gaits for bipedal and quadrupedal simulated\\nrobots, and learning a policy for getting the biped to stand up from starting\\nout lying on the ground. In contrast to a body of prior work that uses\\nhand-crafted policy representations, our neural network policies map directly\\nfrom raw kinematics to joint torques. Our algorithm is fully model-free, and\\nthe amount of simulated experience required for the learning tasks on 3D bipeds\\ncorresponds to 1-2 weeks of real time.\\n\\n    ', \"\\nAbstract:  This paper proposes GProp, a deep reinforcement learning algorithm for\\ncontinuous policies with compatible function approximation. The algorithm is\\nbased on two innovations. Firstly, we present a temporal-difference based\\nmethod for learning the gradient of the value-function. Secondly, we present\\nthe deviator-actor-critic (DAC) model, which comprises three neural networks\\nthat estimate the value function, its gradient, and determine the actor's\\npolicy respectively. We evaluate GProp on two challenging tasks: a contextual\\nbandit problem constructed from nonparametric regression datasets that is\\ndesigned to probe the ability of reinforcement learning algorithms to\\naccurately estimate gradients; and the octopus arm, a challenging reinforcement\\nlearning benchmark. GProp is competitive with fully supervised methods on the\\nbandit task and achieves the best performance to date on the octopus arm.\\n\\n    \", '\\nAbstract:  Recent work has shown that deep neural networks are capable of approximating\\nboth value functions and policies in reinforcement learning domains featuring\\ncontinuous state and action spaces. However, to the best of our knowledge no\\nprevious work has succeeded at using deep neural networks in structured\\n(parameterized) continuous action spaces. To fill this gap, this paper focuses\\non learning within the domain of simulated RoboCup soccer, which features a\\nsmall set of discrete action types, each of which is parameterized with\\ncontinuous variables. The best learned agent can score goals more reliably than\\nthe 2012 RoboCup champion agent. As such, this paper represents a successful\\nextension of deep reinforcement learning to the class of parameterized action\\nspace MDPs.\\n\\n    ', '\\nAbstract:  Achieving efficient and scalable exploration in complex domains poses a major\\nchallenge in reinforcement learning. While Bayesian and PAC-MDP approaches to\\nthe exploration problem offer strong formal guarantees, they are often\\nimpractical in higher dimensions due to their reliance on enumerating the\\nstate-action space. Hence, exploration in complex domains is often performed\\nwith simple epsilon-greedy methods. In this paper, we consider the challenging\\nAtari games domain, which requires processing raw pixel inputs and delayed\\nrewards. We evaluate several more sophisticated exploration strategies,\\nincluding Thompson sampling and Boltzman exploration, and propose a new\\nexploration method based on assigning exploration bonuses from a concurrently\\nlearned model of the system dynamics. By parameterizing our learned model with\\na neural network, we are able to develop a scalable and efficient approach to\\nexploration bonuses that can be applied to tasks with complex, high-dimensional\\nstate spaces. In the Atari domain, our method provides the most consistent\\nimprovement across a range of games that pose a major challenge for prior\\nmethods. In addition to raw game-scores, we also develop an AUC-100 metric for\\nthe Atari Learning domain to evaluate the impact of exploration on this\\nbenchmark.\\n\\n    ', '\\nAbstract:  Motivated by vision-based reinforcement learning (RL) problems, in particular\\nAtari games from the recent benchmark Aracade Learning Environment (ALE), we\\nconsider spatio-temporal prediction problems where future (image-)frames are\\ndependent on control variables or actions as well as previous frames. While not\\ncomposed of natural scenes, frames in Atari games are high-dimensional in size,\\ncan involve tens of objects with one or more objects being controlled by the\\nactions directly and many other objects being influenced indirectly, can\\ninvolve entry and departure of objects, and can involve deep partial\\nobservability. We propose and evaluate two deep neural network architectures\\nthat consist of encoding, action-conditional transformation, and decoding\\nlayers based on convolutional neural networks and recurrent neural networks.\\nExperimental results show that the proposed architectures are able to generate\\nvisually-realistic frames that are also useful for control over approximately\\n100-step action-conditional futures in some games. To the best of our\\nknowledge, this paper is the first to make and evaluate long-term predictions\\non high-dimensional video conditioned by control inputs.\\n\\n    ', '\\nAbstract:  Data-efficient reinforcement learning (RL) in continuous state-action spaces\\nusing very high-dimensional observations remains a key challenge in developing\\nfully autonomous systems. We consider a particularly important instance of this\\nchallenge, the pixels-to-torques problem, where an RL agent learns a\\nclosed-loop control policy (\"torques\") from pixel information only. We\\nintroduce a data-efficient, model-based reinforcement learning algorithm that\\nlearns such a closed-loop policy directly from pixel information. The key\\ningredient is a deep dynamical model for learning a low-dimensional feature\\nembedding of images jointly with a predictive model in this low-dimensional\\nfeature space. Joint learning is crucial for long-term predictions, which lie\\nat the core of the adaptive nonlinear model predictive control strategy that we\\nuse for closed-loop control. Compared to state-of-the-art RL methods for\\ncontinuous states and actions, our approach learns quickly, scales to\\nhigh-dimensional state spaces, is lightweight and an important step toward\\nfully autonomous end-to-end learning from pixels to torques.\\n\\n    ', '\\nAbstract:  We present a unified framework for learning continuous control policies using\\nbackpropagation. It supports stochastic control by treating stochasticity in\\nthe Bellman equation as a deterministic function of exogenous noise. The\\nproduct is a spectrum of general policy gradient algorithms that range from\\nmodel-free methods with value functions to model-based methods without value\\nfunctions. We use learned models but only require observations from the\\nenvironment in- stead of observations from model-predicted trajectories,\\nminimizing the impact of compounded model errors. We apply these algorithms\\nfirst to a toy stochastic control problem and then to several physics-based\\ncontrol problems in simulation. One of these variants, SVG(1), shows the\\neffectiveness of learning models, value functions, and policies simultaneously\\nin continuous domains.\\n\\n    ', '\\nAbstract:  This paper addresses the general problem of reinforcement learning (RL) in\\npartially observable environments. In 2013, our large RL recurrent neural\\nnetworks (RNNs) learned from scratch to drive simulated cars from\\nhigh-dimensional video input. However, real brains are more powerful in many\\nways. In particular, they learn a predictive model of their initially unknown\\nenvironment, and somehow use it for abstract (e.g., hierarchical) planning and\\nreasoning. Guided by algorithmic information theory, we describe RNN-based AIs\\n(RNNAIs) designed to do the same. Such an RNNAI can be trained on never-ending\\nsequences of tasks, some of them provided by the user, others invented by the\\nRNNAI itself in a curious, playful fashion, to improve its RNN-based world\\nmodel. Unlike our previous model-building RNN-based RL machines dating back to\\n1990, the RNNAI learns to actively query its model for abstract reasoning and\\nplanning and decision making, essentially \"learning to think.\" The basic ideas\\nof this report can be applied to many other cases where one RNN-like system\\nexploits the algorithmic information content of another. They are taken from a\\ngrant proposal submitted in Fall 2014, and also explain concepts such as\\n\"mirror neurons.\" Experimental results will be described in separate papers.\\n\\n    ', '\\nAbstract:  The ability to plan and execute goal specific actions in varied, unexpected\\nsettings is a central requirement of intelligent agents. In this paper, we\\nexplore how an agent can be equipped with an internal model of the dynamics of\\nthe external world, and how it can use this model to plan novel actions by\\nrunning multiple internal simulations (\"visual imagination\"). Our models\\ndirectly process raw visual input, and use a novel object-centric prediction\\nformulation based on visual glimpses centered on objects (fixations) to enforce\\ntranslational invariance of the learned physical laws. The agent gathers\\ntraining data through random interaction with a collection of different\\nenvironments, and the resulting model can then be used to plan goal-directed\\nactions in novel environments that the agent has not seen before. We\\ndemonstrate that our agent can accurately plan actions for playing a simulated\\nbilliards game, which requires pushing a ball into a target position or into\\ncollision with another ball.\\n\\n    ', '\\nAbstract:  We present an active detection model for localizing objects in scenes. The\\nmodel is class-specific and allows an agent to focus attention on candidate\\nregions for identifying the correct location of a target object. This agent\\nlearns to deform a bounding box using simple transformation actions, with the\\ngoal of determining the most specific location of target objects following\\ntop-down reasoning. The proposed localization agent is trained using deep\\nreinforcement learning, and evaluated on the Pascal VOC 2007 dataset. We show\\nthat agents guided by the proposed model are able to localize a single instance\\nof an object after analyzing only between 11 and 25 regions in an image, and\\nobtain the best detection results among systems that do not use object\\nproposals for object localization.\\n\\n    ', \"\\nAbstract:  We introduce a novel schema for sequence to sequence learning with a Deep\\nQ-Network (DQN), which decodes the output sequence iteratively. The aim here is\\nto enable the decoder to first tackle easier portions of the sequences, and\\nthen turn to cope with difficult parts. Specifically, in each iteration, an\\nencoder-decoder Long Short-Term Memory (LSTM) network is employed to, from the\\ninput sequence, automatically create features to represent the internal states\\nof and formulate a list of potential actions for the DQN. Take rephrasing a\\nnatural sentence as an example. This list can contain ranked potential words.\\nNext, the DQN learns to make decision on which action (e.g., word) will be\\nselected from the list to modify the current decoded sequence. The newly\\nmodified output sequence is subsequently used as the input to the DQN for the\\nnext decoding iteration. In each iteration, we also bias the reinforcement\\nlearning's attention to explore sequence portions which are previously\\ndifficult to be decoded. For evaluation, the proposed strategy was trained to\\ndecode ten thousands natural sentences. Our experiments indicate that, when\\ncompared to a left-to-right greedy beam search LSTM decoder, the proposed\\nmethod performed competitively well when decoding sentences from the training\\nset, but significantly outperformed the baseline when decoding unseen\\nsentences, in terms of BLEU score obtained.\\n\\n    \", \"\\nAbstract:  We present a novel definition of the reinforcement learning state, actions\\nand reward function that allows a deep Q-network (DQN) to learn to control an\\noptimization hyperparameter. Using Q-learning with experience replay, we train\\ntwo DQNs to accept a state representation of an objective function as input and\\noutput the expected discounted return of rewards, or q-values, connected to the\\nactions of either adjusting the learning rate or leaving it unchanged. The two\\nDQNs learn a policy similar to a line search, but differ in the number of\\nallowed actions. The trained DQNs in combination with a gradient-based update\\nroutine form the basis of the Q-gradient descent algorithms. To demonstrate the\\nviability of this framework, we show that the DQN's q-values associated with\\noptimal action converge and that the Q-gradient descent algorithms outperform\\ngradient descent with an Armijo or nonmonotone line search. Unlike traditional\\noptimization methods, Q-gradient descent can incorporate any objective\\nstatistic and by varying the actions we gain insight into the type of learning\\nrate adjustment strategies that are successful for neural network optimization.\\n\\n    \", '\\nAbstract:  The mutual information is a core statistical quantity that has applications\\nin all areas of machine learning, whether this is in training of density models\\nover multiple data modalities, in maximising the efficiency of noisy\\ntransmission channels, or when learning behaviour policies for exploration by\\nartificial agents. Most learning algorithms that involve optimisation of the\\nmutual information rely on the Blahut-Arimoto algorithm --- an enumerative\\nalgorithm with exponential complexity that is not suitable for modern machine\\nlearning applications. This paper provides a new approach for scalable\\noptimisation of the mutual information by merging techniques from variational\\ninference and deep learning. We develop our approach by focusing on the problem\\nof intrinsically-motivated learning, where the mutual information forms the\\ndefinition of a well-known internal drive known as empowerment. Using a\\nvariational lower bound on the mutual information, combined with convolutional\\nnetworks for handling visual input streams, we develop a stochastic\\noptimisation algorithm that allows for scalable information maximisation and\\nempowerment-based reasoning directly from pixels to actions.\\n\\n    ', \"\\nAbstract:  The recently introduced Deep Q-Networks (DQN) algorithm has gained attention\\nas one of the first successful combinations of deep neural networks and\\nreinforcement learning. Its promise was demonstrated in the Arcade Learning\\nEnvironment (ALE), a challenging framework composed of dozens of Atari 2600\\ngames used to evaluate general competency in AI. It achieved dramatically\\nbetter results than earlier approaches, showing that its ability to learn good\\nrepresentations is quite robust and general. This paper attempts to understand\\nthe principles that underlie DQN's impressive performance and to better\\ncontextualize its success. We systematically evaluate the importance of key\\nrepresentational biases encoded by DQN's network by proposing simple linear\\nrepresentations that make use of these concepts. Incorporating these\\ncharacteristics, we obtain a computationally practical feature set that\\nachieves competitive performance to DQN in the ALE. Besides offering insight\\ninto the strengths and weaknesses of DQN, we provide a generic representation\\nfor the ALE, significantly reducing the burden of learning a representation for\\neach game. Moreover, we also provide a simple, reproducible benchmark for the\\nsake of comparison to future work in the ALE.\\n\\n    \", '\\nAbstract:  State of the art deep reinforcement learning algorithms take many millions of\\ninteractions to attain human-level performance. Humans, on the other hand, can\\nvery quickly exploit highly rewarding nuances of an environment upon first\\ndiscovery. In the brain, such rapid learning is thought to depend on the\\nhippocampus and its capacity for episodic memory. Here we investigate whether a\\nsimple model of hippocampal episodic control can learn to solve difficult\\nsequential decision-making tasks. We demonstrate that it not only attains a\\nhighly rewarding strategy significantly faster than state-of-the-art deep\\nreinforcement learning algorithms, but also achieves a higher overall reward on\\nsome of the more challenging domains.\\n\\n    ', \"\\nAbstract:  Intelligent creatures can explore their environments and learn useful skills\\nwithout supervision. In this paper, we propose DIAYN ('Diversity is All You\\nNeed'), a method for learning useful skills without a reward function. Our\\nproposed method learns skills by maximizing an information theoretic objective\\nusing a maximum entropy policy. On a variety of simulated robotic tasks, we\\nshow that this simple objective results in the unsupervised emergence of\\ndiverse skills, such as walking and jumping. In a number of reinforcement\\nlearning benchmark environments, our method is able to learn a skill that\\nsolves the benchmark task despite never receiving the true task reward. We show\\nhow pretrained skills can provide a good parameter initialization for\\ndownstream tasks, and can be composed hierarchically to solve complex, sparse\\nreward tasks. Our results suggest that unsupervised discovery of skills can\\nserve as an effective pretraining mechanism for overcoming challenges of\\nexploration and data efficiency in reinforcement learning.\\n\\n    \", '\\nAbstract:  This paper describes AllenNLP, a platform for research on deep learning\\nmethods in natural language understanding. AllenNLP is designed to support\\nresearchers who want to build novel language understanding models quickly and\\neasily. It is built on top of PyTorch, allowing for dynamic computation graphs,\\nand provides (1) a flexible data API that handles intelligent batching and\\npadding, (2) high-level abstractions for common operations in working with\\ntext, and (3) a modular and extensible experiment framework that makes doing\\ngood science easy. It also includes reference implementations of high quality\\napproaches for both core semantic problems (e.g. semantic role labeling (Palmer\\net al., 2005)) and language understanding applications (e.g. machine\\ncomprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source\\neffort maintained by engineers and researchers at the Allen Institute for\\nArtificial Intelligence.\\n\\n    ', '\\nAbstract:  We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images\\nof 70,000 fashion products from 10 categories, with 7,000 images per category.\\nThe training set has 60,000 images and the test set has 10,000 images.\\nFashion-MNIST is intended to serve as a direct drop-in replacement for the\\noriginal MNIST dataset for benchmarking machine learning algorithms, as it\\nshares the same image size, data format and the structure of training and\\ntesting splits. The dataset is freely available at\\nthis https URL\\n', '\\nAbstract:  We present a new algorithm for the contextual bandit learning problem, where\\nthe learner repeatedly takes one of $K$ actions in response to the observed\\ncontext, and observes the reward only for that chosen action. Our method\\nassumes access to an oracle for solving fully supervised cost-sensitive\\nclassification problems and achieves the statistically optimal regret guarantee\\nwith only $\\\\tilde{O}(\\\\sqrt{KT/\\\\log N})$ oracle calls across all $T$ rounds,\\nwhere $N$ is the number of policies in the policy class we compete against. By\\ndoing so, we obtain the most practical contextual bandit learning algorithm\\namongst approaches that work for general policy classes. We further conduct a\\nproof-of-concept experiment which demonstrates the excellent computational and\\nprediction performance of (an online variant of) our algorithm relative to\\nseveral baselines.\\n\\n    ', 'It is pdf', '\\nAbstract:  Despite widespread adoption, machine learning models remain mostly black\\nboxes. Understanding the reasons behind predictions is, however, quite\\nimportant in assessing trust, which is fundamental if one plans to take action\\nbased on a prediction, or when choosing whether to deploy a new model. Such\\nunderstanding also provides insights into the model, which can be used to\\ntransform an untrustworthy model or prediction into a trustworthy one. In this\\nwork, we propose LIME, a novel explanation technique that explains the\\npredictions of any classifier in an interpretable and faithful manner, by\\nlearning an interpretable model locally around the prediction. We also propose\\na method to explain models by presenting representative individual predictions\\nand their explanations in a non-redundant way, framing the task as a submodular\\noptimization problem. We demonstrate the flexibility of these methods by\\nexplaining different models for text (e.g. random forests) and image\\nclassification (e.g. neural networks). We show the utility of explanations via\\nnovel experiments, both simulated and with human subjects, on various scenarios\\nthat require trust: deciding if one should trust a prediction, choosing between\\nmodels, improving an untrustworthy classifier, and identifying why a classifier\\nshould not be trusted.\\n\\n    ', '\\nAbstract:  We consider the problem of how a teacher algorithm can enable an unknown Deep\\nReinforcement Learning (DRL) student to become good at a skill over a wide\\nrange of diverse environments. To do so, we study how a teacher algorithm can\\nlearn to generate a learning curriculum, whereby it sequentially samples\\nparameters controlling a stochastic procedural generation of environments.\\nBecause it does not initially know the capacities of its student, a key\\nchallenge for the teacher is to discover which environments are easy, difficult\\nor unlearnable, and in what order to propose them to maximize the efficiency of\\nlearning over the learnable ones. To achieve this, this problem is transformed\\ninto a surrogate continuous bandit problem where the teacher samples\\nenvironments in order to maximize absolute learning progress of its student. We\\npresent a new algorithm modeling absolute learning progress with Gaussian\\nmixture models (ALP-GMM). We also adapt existing algorithms and provide a\\ncomplete study in the context of DRL. Using parameterized variants of the\\nBipedalWalker environment, we study their efficiency to personalize a learning\\ncurriculum for different learners (embodiments), their robustness to the ratio\\nof learnable/unlearnable environments, and their scalability to non-linear and\\nhigh-dimensional parameter spaces. Videos and code are available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Soft Actor-Critic is a state-of-the-art reinforcement learning algorithm for\\ncontinuous action settings that is not applicable to discrete action settings.\\nMany important settings involve discrete actions, however, and so here we\\nderive an alternative version of the Soft Actor-Critic algorithm that is\\napplicable to discrete action settings. We then show that, even without any\\nhyperparameter tuning, it is competitive with the tuned model-free\\nstate-of-the-art on a selection of games from the Atari suite.\\n\\n    ', '\\nAbstract:  State-of-the-art computer vision approaches rely on huge amounts of annotated\\ndata. The collection of such data is a time consuming process since it is\\nmainly performed by humans. The literature shows that semi-automatic annotation\\napproaches can significantly speed up the annotation process by the automatic\\ngeneration of annotation proposals to support the annotator. In this paper we\\npresent a framework that allows for a quick and flexible design of\\nsemi-automatic annotation pipelines. We show that a good design of the process\\nwill speed up the collection of annotations. Our contribution is a new approach\\nto image annotation that allows for the combination of different annotation\\ntools and machine learning algorithms in one process. We further present\\npotential applications of our approach. The source code of our framework called\\nLOST (Label Objects and Save Time) is available at:\\nthis https URL.\\n\\n    ', '\\nAbstract:  This paper proposes an upgraded electro-magnetic side-channel attack that\\nautomatically reconstructs the intercepted data. A novel system is introduced,\\nrunning in parallel with leakage signal interception and catching compromising\\ndata in real-time. Based on deep learning and character recognition the\\nproposed system retrieves more than 57% of characters present in intercepted\\nsignals regardless of signal type: analog or digital. The approach is also\\nextended to a protection system that triggers an alarm if the system is\\ncompromised, demonstrating a success rate over 95%. Based on software-defined\\nradio and graphics processing unit architectures, this solution can be easily\\ndeployed onto existing information systems where information shall be kept\\nsecret.\\n\\n    ', '\\nAbstract:  Question answering (QA) models have shown rapid progress enabled by the\\navailability of large, high-quality benchmark datasets. Such annotated datasets\\nare difficult and costly to collect, and rarely exist in languages other than\\nEnglish, making training QA systems in other languages challenging. An\\nalternative to building large monolingual training datasets is to develop\\ncross-lingual systems which can transfer to a target language without requiring\\ntraining data in that language. In order to develop such systems, it is crucial\\nto invest in high quality multilingual evaluation benchmarks to measure\\nprogress. We present MLQA, a multi-way aligned extractive QA evaluation\\nbenchmark intended to spur research in this area. MLQA contains QA instances in\\n7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and\\nSimplified Chinese. It consists of over 12K QA instances in English and 5K in\\neach other language, with each QA instance being parallel between 4 languages\\non average. MLQA is built using a novel alignment context strategy on Wikipedia\\narticles, and serves as a cross-lingual extension to existing extractive QA\\ndatasets. We evaluate current state-of-the-art cross-lingual representations on\\nMLQA, and also provide machine-translation-based baselines. In all cases,\\ntransfer results are shown to be significantly behind training-language\\nperformance.\\n\\n    ', '\\nAbstract:  Layer normalization (LayerNorm) has been successfully applied to various deep\\nneural networks to help stabilize training and boost model convergence because\\nof its capability in handling re-centering and re-scaling of both inputs and\\nweight matrix. However, the computational overhead introduced by LayerNorm\\nmakes these improvements expensive and significantly slows the underlying\\nnetwork, e.g. RNN in particular. In this paper, we hypothesize that\\nre-centering invariance in LayerNorm is dispensable and propose root mean\\nsquare layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs\\nto a neuron in one layer according to root mean square (RMS), giving the model\\nre-scaling invariance property and implicit learning rate adaptation ability.\\nRMSNorm is computationally simpler and thus more efficient than LayerNorm. We\\nalso present partial RMSNorm, or pRMSNorm where the RMS is estimated from p% of\\nthe summed inputs without breaking the above properties. Extensive experiments\\non several tasks using diverse network architectures show that RMSNorm achieves\\ncomparable performance against LayerNorm but reduces the running time by 7%~64%\\non different models. Source code is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  We explore the impact of learning paradigms on training deep neural networks\\nfor the Travelling Salesman Problem. We design controlled experiments to train\\nsupervised learning (SL) and reinforcement learning (RL) models on fixed graph\\nsizes up to 100 nodes, and evaluate them on variable sized graphs up to 500\\nnodes. Beyond not needing labelled data, out results reveal favorable\\nproperties of RL over SL: RL training leads to better emergent generalization\\nto variable graph sizes and is a key component for learning scale-invariant\\nsolvers for novel combinatorial problems.\\n\\n    ', '\\nAbstract:  We generalize the concept of maximum-margin classifiers (MMCs) to arbitrary\\nnorms and non-linear functions. Support Vector Machines (SVMs) are a special\\ncase of MMC. We find that MMCs can be formulated as Integral Probability\\nMetrics (IPMs) or classifiers with some form of gradient norm penalty. This\\nimplies a direct link to a class of Generative adversarial networks (GANs)\\nwhich penalize a gradient norm. We show that the Discriminator in Wasserstein,\\nStandard, Least-Squares, and Hinge GAN with Gradient Penalty is an MMC. We\\nexplain why maximizing a margin may be helpful in GANs. We hypothesize and\\nconfirm experimentally that $L^\\\\infty$-norm penalties with Hinge loss produce\\nbetter GANs than $L^2$-norm penalties (based on common evaluation metrics). We\\nderive the margins of Relativistic paired (Rp) and average (Ra) GANs.\\n\\n    ', '\\nAbstract:  Modern applications of machine learning (ML) deal with increasingly\\nheterogeneous datasets comprised of data collected from overlapping latent\\nsubpopulations. As a result, traditional models trained over large datasets may\\nfail to recognize highly predictive localized effects in favour of weakly\\npredictive global patterns. This is a problem because localized effects are\\ncritical to developing individualized policies and treatment plans in\\napplications ranging from precision medicine to advertising. To address this\\nchallenge, we propose to estimate sample-specific models that tailor inference\\nand prediction at the individual level. In contrast to classical ML models that\\nestimate a single, complex model (or only a few complex models), our approach\\nproduces a model personalized to each sample. These sample-specific models can\\nbe studied to understand subgroup dynamics that go beyond coarse-grained class\\nlabels. Crucially, our approach does not assume that relationships between\\nsamples (e.g. a similarity network) are known a priori. Instead, we use\\nunmodeled covariates to learn a latent distance metric over the samples. We\\napply this approach to financial, biomedical, and electoral data as well as\\nsimulated data and show that sample-specific models provide fine-grained\\ninterpretations of complicated phenomena without sacrificing predictive\\naccuracy compared to state-of-the-art models such as deep neural networks.\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks (CNNs) have been very successful at solving a\\nvariety of computer vision tasks such as object classification and detection,\\nsemantic segmentation, activity understanding, to name just a few. One key\\nenabling factor for their great performance has been the ability to train very\\ndeep CNNs. Despite their huge success in many tasks, CNNs do not work well with\\nnon-Euclidean data which is prevalent in many real-world applications. Graph\\nConvolutional Networks (GCNs) offer an alternative that allows for\\nnon-Eucledian data as input to a neural network similar to CNNs. While GCNs\\nalready achieve encouraging results, they are currently limited to shallow\\narchitectures with 2-4 layers due to vanishing gradients during training. This\\nwork transfers concepts such as residual/dense connections and dilated\\nconvolutions from CNNs to GCNs in order to successfully train very deep GCNs.\\nWe show the benefit of deep GCNs with as many as 112 layers experimentally\\nacross various datasets and tasks. Specifically, we achieve state-of-the-art\\nperformance in part segmentation and semantic segmentation on point clouds and\\nin node classification of protein functions across biological protein-protein\\ninteraction (PPI) graphs. We believe that the insights in this work will open a\\nlot of avenues for future research on GCNs and transfer to further tasks not\\nexplored in this work. The source code for this work is available for Pytorch\\nand Tensorflow at this https URL and\\nthis https URL respectively.\\n\\n    ', '\\nAbstract:  It is challenging for current one-step retrieve-and-read question answering\\n(QA) systems to answer questions like \"Which novel by the author of \\'Armada\\'\\nwill be adapted as a feature film by Steven Spielberg?\" because the question\\nseldom contains retrievable clues about the missing entity (here, the author).\\nAnswering such a question requires multi-hop reasoning where one must gather\\ninformation about the missing entity (or facts) to proceed with further\\nreasoning. We present GoldEn (Gold Entity) Retriever, which iterates between\\nreading context and retrieving more supporting documents to answer open-domain\\nmulti-hop questions. Instead of using opaque and computationally expensive\\nneural retrieval models, GoldEn Retriever generates natural language search\\nqueries given the question and available context, and leverages off-the-shelf\\ninformation retrieval systems to query for missing entities. This allows GoldEn\\nRetriever to scale up efficiently for open-domain multi-hop reasoning while\\nmaintaining interpretability. We evaluate GoldEn Retriever on the recently\\nproposed open-domain multi-hop QA dataset, HotpotQA, and demonstrate that it\\noutperforms the best previously published model despite not using pretrained\\nlanguage models such as BERT.\\n\\n    ', '\\nAbstract:  Nodes performing different functions in a network have different roles, and\\nthese roles can be gleaned from the structure of the network. Learning latent\\nrepresentations for the roles of nodes helps to understand the network and to\\ntransfer knowledge across networks. However, most existing structural embedding\\napproaches suffer from high computation and space cost or rely on heuristic\\nfeature engineering. Here we propose RiWalk, a flexible paradigm for learning\\nstructural node representations. It decouples the structural embedding problem\\ninto a role identification procedure and a network embedding procedure. Through\\nrole identification, rooted kernels with structural dependencies kept are built\\nto better integrate network embedding methods. To demonstrate the effectiveness\\nof RiWalk, we develop two different role identification methods named RiWalk-SP\\nand RiWalk-WL respectively and employ random walk based network embedding\\nmethods. Experiments on within-network classification tasks show that our\\nproposed algorithms achieve comparable performance with other baselines while\\nbeing an order of magnitude more efficient. Besides, we also conduct\\nacross-network role classification tasks. The results show potential of\\nstructural embeddings in transfer learning. RiWalk is also scalable, making it\\ncapable of capturing structural roles in massive networks.\\n\\n    ', \"\\nAbstract:  Developing a differentially private deep learning algorithm is challenging,\\ndue to the difficulty in analyzing the sensitivity of objective functions that\\nare typically used to train deep neural networks. Many existing methods resort\\nto the stochastic gradient descent algorithm and apply a pre-defined\\nsensitivity to the gradients for privatizing weights. However, their slow\\nconvergence typically yields a high cumulative privacy loss. Here, we take a\\ndifferent route by employing the method of auxiliary coordinates, which allows\\nus to independently update the weights per layer by optimizing a per-layer\\nobjective function. This objective function can be well approximated by a\\nlow-order Taylor's expansion, in which sensitivity analysis becomes tractable.\\nWe perturb the coefficients of the expansion for privacy, which we optimize\\nusing more advanced optimization routines than SGD for faster convergence. We\\nempirically show that our algorithm provides a decent trained model quality\\nunder a modest privacy budget.\\n\\n    \", '\\nAbstract:  Application of discrete-time survival methods for continuous-time survival\\nprediction is considered. For this purpose, a scheme for discretization of\\ncontinuous-time data is proposed by considering the quantiles of the estimated\\nevent-time distribution, and, for smaller data sets, it is found to be\\npreferable over the commonly used equidistant scheme. Furthermore, two\\ninterpolation schemes for continuous-time survival estimates are explored, both\\nof which are shown to yield improved performance compared to the discrete-time\\nestimates. The survival methods considered are based on the likelihood for\\nright-censored survival data, and parameterize either the probability mass\\nfunction (PMF) or the discrete-time hazard rate, both with neural networks.\\nThrough simulations and study of real-world data, the hazard rate\\nparametrization is found to perform slightly better than the parametrization of\\nthe PMF. Inspired by these investigations, a continuous-time method is proposed\\nby assuming that the continuous-time hazard rate is piecewise constant. The\\nmethod, named PC-Hazard, is found to be highly competitive with the\\naforementioned methods in addition to other methods for survival prediction\\nfound in the literature.\\n\\n    ', '\\nAbstract:  Semantic image synthesis aims at generating photorealistic images from\\nsemantic layouts. Previous approaches with conditional generative adversarial\\nnetworks (GAN) show state-of-the-art performance on this task, which either\\nfeed the semantic label maps as inputs to the generator, or use them to\\nmodulate the activations in normalization layers via affine transformations. We\\nargue that convolutional kernels in the generator should be aware of the\\ndistinct semantic labels at different locations when generating images. In\\norder to better exploit the semantic layout for the image generator, we propose\\nto predict convolutional kernels conditioned on the semantic label map to\\ngenerate the intermediate feature maps from the noise maps and eventually\\ngenerate the images. Moreover, we propose a feature pyramid semantics-embedding\\ndiscriminator, which is more effective in enhancing fine details and semantic\\nalignments between the generated images and the input semantic layouts than\\nprevious multi-scale discriminators. We achieve state-of-the-art results on\\nboth quantitative metrics and subjective evaluation on various semantic\\nsegmentation datasets, demonstrating the effectiveness of our approach.\\n\\n    ', '\\nAbstract:  Neural Machine Translation (NMT) models generally perform translation using a\\nfixed-size lexical vocabulary, which is an important bottleneck on their\\ngeneralization capability and overall translation quality. The standard\\napproach to overcome this limitation is to segment words into subword units,\\ntypically using some external tools with arbitrary heuristics, resulting in\\nvocabulary units not optimized for the translation task. Recent studies have\\nshown that the same approach can be extended to perform NMT directly at the\\nlevel of characters, which can deliver translation accuracy on-par with\\nsubword-based models, on the other hand, this requires relatively deeper\\nnetworks. In this paper, we propose a more computationally-efficient solution\\nfor character-level NMT which implements a hierarchical decoding architecture\\nwhere translations are subsequently generated at the level of words and\\ncharacters. We evaluate different methods for open-vocabulary NMT in the\\nmachine translation task from English into five languages with distinct\\nmorphological typology, and show that the hierarchical decoding model can reach\\nhigher translation accuracy than the subword-level NMT model using\\nsignificantly fewer parameters, while demonstrating better capacity in learning\\nlonger-distance contextual and grammatical dependencies than the standard\\ncharacter-level NMT model.\\n\\n    ', '\\nAbstract:  With the demand for machine learning increasing, so does the demand for tools\\nwhich make it easier to use. Automated machine learning (AutoML) tools have\\nbeen developed to address this need, such as the Tree-Based Pipeline\\nOptimization Tool (TPOT) which uses genetic programming to build optimal\\npipelines. We introduce Layered TPOT, a modification to TPOT which aims to\\ncreate pipelines equally good as the original, but in significantly less time.\\nThis approach evaluates candidate pipelines on increasingly large subsets of\\nthe data according to their fitness, using a modified evolutionary algorithm to\\nallow for separate competition between pipelines trained on different sample\\nsizes. Empirical evaluation shows that, on sufficiently large datasets, Layered\\nTPOT indeed finds better models faster.\\n\\n    ', '\\nAbstract:  As the field of data science continues to grow, there will be an\\never-increasing demand for tools that make machine learning accessible to\\nnon-experts. In this paper, we introduce the concept of tree-based pipeline\\noptimization for automating one of the most tedious parts of machine\\nlearning---pipeline design. We implement an open source Tree-based Pipeline\\nOptimization Tool (TPOT) in Python and demonstrate its effectiveness on a\\nseries of simulated and real-world benchmark data sets. In particular, we show\\nthat TPOT can design machine learning pipelines that provide a significant\\nimprovement over a basic machine learning analysis while requiring little to no\\ninput nor prior knowledge from the user. We also address the tendency for TPOT\\nto design overly complex pipelines by integrating Pareto optimization, which\\nproduces compact pipelines without sacrificing classification accuracy. As\\nsuch, this work represents an important step toward fully automating machine\\nlearning pipeline design.\\n\\n    ', '\\nAbstract:  Over the past decade, data science and machine learning has grown from a\\nmysterious art form to a staple tool across a variety of fields in academia,\\nbusiness, and government. In this paper, we introduce the concept of tree-based\\npipeline optimization for automating one of the most tedious parts of machine\\nlearning---pipeline design. We implement a Tree-based Pipeline Optimization\\nTool (TPOT) and demonstrate its effectiveness on a series of simulated and\\nreal-world genetic data sets. In particular, we show that TPOT can build\\nmachine learning pipelines that achieve competitive classification accuracy and\\ndiscover novel pipeline operators---such as synthetic feature\\nconstructors---that significantly improve classification accuracy on these data\\nsets. We also highlight the current challenges to pipeline optimization, such\\nas the tendency to produce pipelines that overfit the data, and suggest future\\nresearch paths to overcome these challenges. As such, this work represents an\\nearly step toward fully automating machine learning pipeline design.\\n\\n    ', '\\nAbstract:  Neural architecture search (NAS) has been proposed to automatically tune deep\\nneural networks, but existing search algorithms, e.g., NASNet, PNAS, usually\\nsuffer from expensive computational cost. Network morphism, which keeps the\\nfunctionality of a neural network while changing its neural architecture, could\\nbe helpful for NAS by enabling more efficient training during the search. In\\nthis paper, we propose a novel framework enabling Bayesian optimization to\\nguide the network morphism for efficient neural architecture search. The\\nframework develops a neural network kernel and a tree-structured acquisition\\nfunction optimization algorithm to efficiently explores the search space.\\nIntensive experiments on real-world benchmark datasets have been done to\\ndemonstrate the superior performance of the developed framework over the\\nstate-of-the-art methods. Moreover, we build an open-source AutoML system based\\non our method, namely Auto-Keras. The system runs in parallel on CPU and GPU,\\nwith an adaptive search strategy for different GPU memory limits.\\n\\n    ', '\\nAbstract:  DeepMind Lab is a first-person 3D game platform designed for research and\\ndevelopment of general artificial intelligence and machine learning systems.\\nDeepMind Lab can be used to study how autonomous artificial agents may learn\\ncomplex tasks in large, partially observed, and visually diverse worlds.\\nDeepMind Lab has a simple and flexible API enabling creative task-designs and\\nnovel AI-designs to be explored and quickly iterated upon. It is powered by a\\nfast and widely recognised game engine, and tailored for effective use by the\\nresearch community.\\n\\n    ', '\\nAbstract:  Analogical reasoning is effective in capturing linguistic regularities. This\\npaper proposes an analogical reasoning task on Chinese. After delving into\\nChinese lexical knowledge, we sketch 68 implicit morphological relations and 28\\nexplicit semantic relations. A big and balanced dataset CA8 is then built for\\nthis task, including 17813 questions. Furthermore, we systematically explore\\nthe influences of vector representations, context features, and corpora on\\nanalogical reasoning. With the experiments, CA8 is proved to be a reliable\\nbenchmark for evaluating Chinese word embeddings.\\n\\n    ', '\\nAbstract:  Generative Adversarial Networks (GANs) are powerful generative models, but\\nsuffer from training instability. The recently proposed Wasserstein GAN (WGAN)\\nmakes progress toward stable training of GANs, but sometimes can still generate\\nonly low-quality samples or fail to converge. We find that these problems are\\noften due to the use of weight clipping in WGAN to enforce a Lipschitz\\nconstraint on the critic, which can lead to undesired behavior. We propose an\\nalternative to clipping weights: penalize the norm of gradient of the critic\\nwith respect to its input. Our proposed method performs better than standard\\nWGAN and enables stable training of a wide variety of GAN architectures with\\nalmost no hyperparameter tuning, including 101-layer ResNets and language\\nmodels over discrete data. We also achieve high quality generations on CIFAR-10\\nand LSUN bedrooms.\\n\\n    ', '\\nAbstract:  We extend Generative Adversarial Networks (GANs) to the semi-supervised\\ncontext by forcing the discriminator network to output class labels. We train a\\ngenerative model G and a discriminator D on a dataset with inputs belonging to\\none of N classes. At training time, D is made to predict which of N+1 classes\\nthe input belongs to, where an extra class is added to correspond to the\\noutputs of G. We show that this method can be used to create a more\\ndata-efficient classifier and that it allows for generating higher quality\\nsamples than a regular GAN.\\n\\n    ', '\\nAbstract:  Collecting well-annotated image datasets to train modern machine learning\\nalgorithms is prohibitively expensive for many tasks. One appealing alternative\\nis rendering synthetic data where ground-truth annotations are generated\\nautomatically. Unfortunately, models trained purely on rendered images often\\nfail to generalize to real images. To address this shortcoming, prior work\\nintroduced unsupervised domain adaptation algorithms that attempt to map\\nrepresentations between the two domains or learn to extract features that are\\ndomain-invariant. In this work, we present a new approach that learns, in an\\nunsupervised manner, a transformation in the pixel space from one domain to the\\nother. Our generative adversarial network (GAN)-based method adapts\\nsource-domain images to appear as if drawn from the target domain. Our approach\\nnot only produces plausible samples, but also outperforms the state-of-the-art\\non a number of unsupervised domain adaptation scenarios by large margins.\\nFinally, we demonstrate that the adaptation process generalizes to object\\nclasses unseen during training.\\n\\n    ', '\\nAbstract:  Conditional Generative Adversarial Networks (GANs) for cross-domain\\nimage-to-image translation have made much progress recently. Depending on the\\ntask complexity, thousands to millions of labeled image pairs are needed to\\ntrain a conditional GAN. However, human labeling is expensive, even\\nimpractical, and large quantities of data may not always be available. Inspired\\nby dual learning from natural language translation, we develop a novel dual-GAN\\nmechanism, which enables image translators to be trained from two sets of\\nunlabeled images from two domains. In our architecture, the primal GAN learns\\nto translate images from domain U to those in domain V, while the dual GAN\\nlearns to invert the task. The closed loop made by the primal and dual tasks\\nallows images from either domain to be translated and then reconstructed. Hence\\na loss function that accounts for the reconstruction error of images can be\\nused to train the translators. Experiments on multiple image translation tasks\\nwith unlabeled data show considerable performance gain of DualGAN over a single\\nGAN. For some tasks, DualGAN can even achieve comparable or slightly better\\nresults than conditional GAN trained on fully labeled data.\\n\\n    ', '\\nAbstract:  We present Adaptive Instance Selection network architecture for\\nclass-agnostic instance segmentation. Given an input image and a point $(x,\\ny)$, it generates a mask for the object located at $(x, y)$. The network adapts\\nto the input point with a help of AdaIN layers, thus producing different masks\\nfor different objects on the same image. AdaptIS generates pixel-accurate\\nobject masks, therefore it accurately segments objects of complex shape or\\nseverely occluded ones. AdaptIS can be easily combined with standard semantic\\nsegmentation pipeline to perform panoptic segmentation. To illustrate the idea,\\nwe perform experiments on a challenging toy problem with difficult occlusions.\\nThen we extensively evaluate the method on panoptic segmentation benchmarks. We\\nobtain state-of-the-art results on Cityscapes and Mapillary even without\\npretraining on COCO, and show competitive results on a challenging COCO\\ndataset. The source code of the method and the trained models are available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  We provide an open-source C++ library for real-time metric-semantic\\nvisual-inertial Simultaneous Localization And Mapping (SLAM). The library goes\\nbeyond existing visual and visual-inertial SLAM libraries (e.g., ORB-SLAM,\\nVINS- Mono, OKVIS, ROVIO) by enabling mesh reconstruction and semantic labeling\\nin 3D. Kimera is designed with modularity in mind and has four key components:\\na visual-inertial odometry (VIO) module for fast and accurate state estimation,\\na robust pose graph optimizer for global trajectory estimation, a lightweight\\n3D mesher module for fast mesh reconstruction, and a dense 3D metric-semantic\\nreconstruction module. The modules can be run in isolation or in combination,\\nhence Kimera can easily fall back to a state-of-the-art VIO or a full SLAM\\nsystem. Kimera runs in real-time on a CPU and produces a 3D metric-semantic\\nmesh from semantically labeled images, which can be obtained by modern deep\\nlearning methods. We hope that the flexibility, computational efficiency,\\nrobustness, and accuracy afforded by Kimera will build a solid basis for future\\nmetric-semantic SLAM and perception research, and will allow researchers across\\nmultiple areas (e.g., VIO, SLAM, 3D reconstruction, segmentation) to benchmark\\nand prototype their own efforts without having to start from scratch.\\n\\n    ', \"\\nAbstract:  Recent studies have demonstrated the efficiency of generative pretraining for\\nEnglish natural language understanding. In this work, we extend this approach\\nto multiple languages and show the effectiveness of cross-lingual pretraining.\\nWe propose two methods to learn cross-lingual language models (XLMs): one\\nunsupervised that only relies on monolingual data, and one supervised that\\nleverages parallel data with a new cross-lingual language model objective. We\\nobtain state-of-the-art results on cross-lingual classification, unsupervised\\nand supervised machine translation. On XNLI, our approach pushes the state of\\nthe art by an absolute gain of 4.9% accuracy. On unsupervised machine\\ntranslation, we obtain 34.3 BLEU on WMT'16 German-English, improving the\\nprevious state of the art by more than 9 BLEU. On supervised machine\\ntranslation, we obtain a new state of the art of 38.5 BLEU on WMT'16\\nRomanian-English, outperforming the previous best approach by more than 4 BLEU.\\nOur code and pretrained models will be made publicly available.\\n\\n    \", '\\nAbstract:  Convolutional Neural Networks (CNNs) achieve impressive performance in a wide\\nvariety of fields. Their success benefited from a massive boost when very deep\\nCNN models were able to be reliably trained. Despite their merits, CNNs fail to\\nproperly address problems with non-Euclidean data. To overcome this challenge,\\nGraph Convolutional Networks (GCNs) build graphs to represent non-Euclidean\\ndata, borrow concepts from CNNs, and apply them in training. GCNs show\\npromising results, but they are usually limited to very shallow models due to\\nthe vanishing gradient problem. As a result, most state-of-the-art GCN models\\nare no deeper than 3 or 4 layers. In this work, we present new ways to\\nsuccessfully train very deep GCNs. We do this by borrowing concepts from CNNs,\\nspecifically residual/dense connections and dilated convolutions, and adapting\\nthem to GCN architectures. Extensive experiments show the positive effect of\\nthese deep GCN frameworks. Finally, we use these new concepts to build a very\\ndeep 56-layer GCN, and show how it significantly boosts performance (+3.7% mIoU\\nover state-of-the-art) in the task of point cloud semantic segmentation. We\\nbelieve that the community can greatly benefit from this work, as it opens up\\nmany opportunities for advancing GCN-based research.\\n\\n    ', '\\nAbstract:  The concept of non-linearity in a Neural Network is introduced by an\\nactivation function which serves an integral role in the training and\\nperformance evaluation of the network. Over the years of theoretical research,\\nmany activation functions have been proposed, however, only a few are widely\\nused in mostly all applications which include ReLU (Rectified Linear Unit),\\nTanH (Tan Hyperbolic), Sigmoid, Leaky ReLU and Swish. In this work, a novel\\nneural activation function called as Mish is proposed. The experiments show\\nthat Mish tends to work better than both ReLU and Swish along with other\\nstandard activation functions in many deep networks across challenging\\ndatasets. For instance, in Squeeze Excite Net- 18 for CIFAR 100 classification,\\nthe network with Mish had an increase in Top-1 test accuracy by 0.494% and\\n1.671% as compared to the same network with Swish and ReLU respectively. The\\nsimilarity to Swish along with providing a boost in performance and its\\nsimplicity in implementation makes it easier for researchers and developers to\\nuse Mish in their Neural Network Models.\\n\\n    ', '\\nAbstract:  Generative adversarial networks (GANs) are capable of producing high quality\\nsamples, but they suffer from numerous issues such as instability and mode\\ncollapse during training. To combat this, we propose to model the generator and\\ndiscriminator as agents acting under local information, uncertainty, and\\nawareness of their opponent. By doing so we achieve stable convergence, even\\nwhen the underlying game has no Nash equilibria. We call this mechanism\\nimplicit competitive regularization (ICR) and show that it is present in the\\nrecently proposed competitive gradient descent (CGD). When comparing CGD to\\nAdam using a variety of loss functions and regularizers on CIFAR10, CGD shows a\\nmuch more consistent performance, which we attribute to ICR. In our\\nexperiments, we achieve the highest inception score when using the WGAN loss\\n(without gradient penalty or weight clipping) together with CGD. This can be\\ninterpreted as minimizing a form of integral probability metric based on ICR.\\n\\n    ', '\\nAbstract:  In this work we aim to solve a large collection of tasks using a single\\nreinforcement learning agent with a single set of parameters. A key challenge\\nis to handle the increased amount of data and extended training time. We have\\ndeveloped a new distributed agent IMPALA (Importance Weighted Actor-Learner\\nArchitecture) that not only uses resources more efficiently in single-machine\\ntraining but also scales to thousands of machines without sacrificing data\\nefficiency or resource utilisation. We achieve stable learning at high\\nthroughput by combining decoupled acting and learning with a novel off-policy\\ncorrection method called V-trace. We demonstrate the effectiveness of IMPALA\\nfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the\\nDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available\\nAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our\\nresults show that IMPALA is able to achieve better performance than previous\\nagents with less data, and crucially exhibits positive transfer between tasks\\nas a result of its multi-task approach.\\n\\n    ', '\\nAbstract:  This paper presents a new Unified pre-trained Language Model (UniLM) that can\\nbe fine-tuned for both natural language understanding and generation tasks. The\\nmodel is pre-trained using three types of language modeling tasks:\\nunidirectional, bidirectional, and sequence-to-sequence prediction. The unified\\nmodeling is achieved by employing a shared Transformer network and utilizing\\nspecific self-attention masks to control what context the prediction conditions\\non. UniLM compares favorably with BERT on the GLUE benchmark, and the SQuAD 2.0\\nand CoQA question answering tasks. Moreover, UniLM achieves new\\nstate-of-the-art results on five natural language generation datasets,\\nincluding improving the CNN/DailyMail abstractive summarization ROUGE-L to\\n40.51 (2.04 absolute improvement), the Gigaword abstractive summarization\\nROUGE-L to 35.75 (0.86 absolute improvement), the CoQA generative question\\nanswering F1 score to 82.5 (37.1 absolute improvement), the SQuAD question\\ngeneration BLEU-4 to 22.12 (3.75 absolute improvement), and the DSTC7\\ndocument-grounded dialog response generation NIST-4 to 2.67 (human performance\\nis 2.65). The code and pre-trained models are available at\\nthis https URL.\\n\\n    ', \"\\nAbstract:  Recent advances in image-to-image translation have led to some ways to\\ngenerate multiple domain images through a single network. However, there is\\nstill a limit in creating an image of a target domain without a dataset on it.\\nWe propose a method that expands the concept of `multi-domain' from data to the\\nloss area and learns the combined characteristics of each domain to dynamically\\ninfer translations of images in mixed domains. First, we introduce\\nSym-parameter and its learning method for variously mixed losses while\\nsynchronizing them with input conditions. Then, we propose Sym-parameterized\\nGenerative Network (SGN) which is empirically confirmed of learning mixed\\ncharacteristics of various data and losses, and translating images to any\\nmixed-domain without ground truths, such as 30% Van Gogh and 20% Monet and 40%\\nsnowy.\\n\\n    \", '\\nAbstract:  Automatically learned quality assessment for images has recently become a hot\\ntopic due to its usefulness in a wide variety of applications such as\\nevaluating image capture pipelines, storage techniques and sharing media.\\nDespite the subjective nature of this problem, most existing methods only\\npredict the mean opinion score provided by datasets such as AVA [1] and TID2013\\n[2]. Our approach differs from others in that we predict the distribution of\\nhuman opinion scores using a convolutional neural network. Our architecture\\nalso has the advantage of being significantly simpler than other methods with\\ncomparable performance. Our proposed approach relies on the success (and\\nretraining) of proven, state-of-the-art deep object recognition networks. Our\\nresulting network can be used to not only score images reliably and with high\\ncorrelation to human perception, but also to assist with adaptation and\\noptimization of photo editing/enhancement algorithms in a photographic\\npipeline. All this is done without need for a \"golden\" reference image,\\nconsequently allowing for single-image, semantic- and perceptually-aware,\\nno-reference quality assessment.\\n\\n    ', '\\nAbstract:  Bidirectional Encoder Representations from Transformers (BERT) represents the\\nlatest incarnation of pretrained language models which have recently advanced a\\nwide range of natural language processing tasks. In this paper, we showcase how\\nBERT can be usefully applied in text summarization and propose a general\\nframework for both extractive and abstractive models. We introduce a novel\\ndocument-level encoder based on BERT which is able to express the semantics of\\na document and obtain representations for its sentences. Our extractive model\\nis built on top of this encoder by stacking several inter-sentence Transformer\\nlayers. For abstractive summarization, we propose a new fine-tuning schedule\\nwhich adopts different optimizers for the encoder and the decoder as a means of\\nalleviating the mismatch between the two (the former is pretrained while the\\nlatter is not). We also demonstrate that a two-staged fine-tuning approach can\\nfurther boost the quality of the generated summaries. Experiments on three\\ndatasets show that our model achieves state-of-the-art results across the board\\nin both extractive and abstractive settings. Our code is available at\\nthis https URL\\n', '\\nAbstract:  Channel attention has recently demonstrated to offer great potential in\\nimproving the performance of deep convolutional neural networks (CNNs).\\nHowever, most existing methods dedicate to developing more sophisticated\\nattention modules to achieve better performance, inevitably increasing the\\ncomputational burden. To overcome the paradox of performance and complexity\\ntrade-off, this paper makes an attempt to investigate an extremely lightweight\\nattention module for boosting the performance of deep CNNs. In particular, we\\npropose an Efficient Channel Attention (ECA) module, which only involves $k (k\\n< 9)$ parameters but brings clear performance gain. By revisiting the channel\\nattention module in SENet, we empirically show avoiding dimensionality\\nreduction and appropriate cross-channel interaction are important to learn\\neffective channel attention. Therefore, we propose a local cross-channel\\ninteraction strategy without dimension reduction, which can be efficiently\\nimplemented by a fast 1D convolution. Furthermore, we develop a function of\\nchannel dimension to adaptively determine kernel size of 1D convolution, which\\nstands for coverage of local cross-channel interaction. Our ECA module can be\\nflexibly incorporated into existing CNN architectures, and the resulting CNNs\\nare named by ECA-Net. We extensively evaluate the proposed ECA-Net on image\\nclassification, object detection and instance segmentation with backbones of\\nResNets and MobileNetV2. The experimental results show our ECA-Net is more\\nefficient while performing favorably against its counterparts. The source code\\nand models can be available at this https URL.\\n\\n    ', '\\nAbstract:  This work presents Kornia -- an open source computer vision library which\\nconsists of a set of differentiable routines and modules to solve generic\\ncomputer vision problems. The package uses PyTorch as its main backend both for\\nefficiency and to take advantage of the reverse-mode auto-differentiation to\\ndefine and compute the gradient of complex functions. Inspired by OpenCV,\\nKornia is composed of a set of modules containing operators that can be\\ninserted inside neural networks to train models to perform image\\ntransformations, camera calibration, epipolar geometry, and low level image\\nprocessing techniques, such as filtering and edge detection that operate\\ndirectly on high dimensional tensor representations. Examples of classical\\nvision problems implemented using our framework are provided including a\\nbenchmark comparing to existing vision libraries.\\n\\n    ', '\\nAbstract:  Filter pruning is one of the most effective ways to accelerate and compress\\nconvolutional neural networks (CNNs). In this work, we propose a global filter\\npruning algorithm called Gate Decorator, which transforms a vanilla CNN module\\nby multiplying its output by the channel-wise scaling factors, i.e. gate. When\\nthe scaling factor is set to zero, it is equivalent to removing the\\ncorresponding filter. We use Taylor expansion to estimate the change in the\\nloss function caused by setting the scaling factor to zero and use the\\nestimation for the global filter importance ranking. Then we prune the network\\nby removing those unimportant filters. After pruning, we merge all the scaling\\nfactors into its original module, so no special operations or structures are\\nintroduced. Moreover, we propose an iterative pruning framework called\\nTick-Tock to improve pruning accuracy. The extensive experiments demonstrate\\nthe effectiveness of our approaches. For example, we achieve the\\nstate-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without\\nnoticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with\\n40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy.\\nVarious datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet\\nILSVRC-12 and PASCAL VOC 2011. Code is available at\\nthis http URL\\n', '\\nAbstract:  Neural architecture search (NAS) aims to automate the search procedure of\\narchitecture instead of manual design. Even if recent NAS approaches finish the\\nsearch within days, lengthy training is still required for a specific\\narchitecture candidate to get the parameters for its accurate evaluation.\\nRecently one-shot NAS methods are proposed to largely squeeze the tedious\\ntraining process by sharing parameters across candidates. In this way, the\\nparameters for each candidate can be directly extracted from the shared\\nparameters instead of training them from scratch. However, they have no sense\\nof which candidate will perform better until evaluation so that the candidates\\nto evaluate are randomly sampled and the top-1 candidate is considered the\\nbest. In this paper, we propose a Self-Evaluated Template Network (SETN) to\\nimprove the quality of the architecture candidates for evaluation so that it is\\nmore likely to cover competitive candidates. SETN consists of two components:\\n(1) an evaluator, which learns to indicate the probability of each individual\\narchitecture being likely to have a lower validation loss. The candidates for\\nevaluation can thus be selectively sampled according to this evaluator. (2) a\\ntemplate network, which shares parameters among all candidates to amortize the\\ntraining cost of generated candidates. In experiments, the architecture found\\nby SETN achieves state-of-the-art performance on CIFAR and ImageNet benchmarks\\nwithin comparable computation costs. Code is publicly available on GitHub:\\nthis https URL.\\n\\n    ', '\\nAbstract:  Conventional neural architecture search (NAS) approaches are based on\\nreinforcement learning or evolutionary strategy, which take more than 3000 GPU\\nhours to find a good model on CIFAR-10. We propose an efficient NAS approach\\nlearning to search by gradient descent. Our approach represents the search\\nspace as a directed acyclic graph (DAG). This DAG contains billions of\\nsub-graphs, each of which indicates a kind of neural architecture. To avoid\\ntraversing all the possibilities of the sub-graphs, we develop a differentiable\\nsampler over the DAG. This sampler is learnable and optimized by the validation\\nloss after training the sampled architecture. In this way, our approach can be\\ntrained in an end-to-end fashion by gradient descent, named Gradient-based\\nsearch using Differentiable Architecture Sampler (GDAS). In experiments, we can\\nfinish one searching procedure in four GPU hours on CIFAR-10, and the\\ndiscovered model obtains a test error of 2.82\\\\% with only 2.5M parameters,\\nwhich is on par with the state-of-the-art. Code is publicly available on\\nGitHub: this https URL.\\n\\n    ', '\\nAbstract:  Network pruning reduces the computation costs of an over-parameterized\\nnetwork without performance damage. Prevailing pruning algorithms pre-define\\nthe width and depth of the pruned networks, and then transfer parameters from\\nthe unpruned network to pruned networks. To break the structure limitation of\\nthe pruned networks, we propose to apply neural architecture search to search\\ndirectly for a network with flexible channel and layer sizes. The number of the\\nchannels/layers is learned by minimizing the loss of the pruned networks. The\\nfeature map of the pruned network is an aggregation of K feature map fragments\\n(generated by K networks of different sizes), which are sampled based on the\\nprobability distribution.The loss can be back-propagated not only to the\\nnetwork weights, but also to the parameterized distribution to explicitly tune\\nthe size of the channels/layers. Specifically, we apply channel-wise\\ninterpolation to keep the feature map with different channel sizes aligned in\\nthe aggregation procedure. The maximum probability for the size in each\\ndistribution serves as the width and depth of the pruned network, whose\\nparameters are learned by knowledge transfer, e.g., knowledge distillation,\\nfrom the original networks. Experiments on CIFAR-10, CIFAR-100 and ImageNet\\ndemonstrate the effectiveness of our new perspective of network pruning\\ncompared to traditional network pruning algorithms. Various searching and\\nknowledge transfer approaches are conducted to show the effectiveness of the\\ntwo components. Code is at: this https URL.\\n\\n    ', '\\nAbstract:  In this paper, we introduce an anchor-box free and single shot instance\\nsegmentation method, which is conceptually simple, fully convolutional and can\\nbe used as a mask prediction module for instance segmentation, by easily\\nembedding it into most off-the-shelf detection methods. Our method, termed\\nPolarMask, formulates the instance segmentation problem as instance center\\nclassification and dense distance regression in a polar coordinate. Moreover,\\nwe propose two effective approaches to deal with sampling high-quality center\\nexamples and optimization for dense distance regression, respectively, which\\ncan significantly improve the performance and simplify the training process.\\nWithout any bells and whistles, PolarMask achieves 32.9% in mask mAP with\\nsingle-model and single-scale training/testing on challenging COCO dataset. For\\nthe first time, we demonstrate a much simpler and flexible instance\\nsegmentation framework achieving competitive accuracy. We hope that the\\nproposed PolarMask framework can serve as a fundamental and strong baseline for\\nsingle shot instance segmentation tasks. Code is available at:\\nthis http URL.\\n\\n    ', '\\nAbstract:  Recent advances in neural architecture search (NAS) demand tremendous\\ncomputational resources, which makes it difficult to reproduce experiments and\\nimposes a barrier-to-entry to researchers without access to large-scale\\ncomputation. We aim to ameliorate these problems by introducing NAS-Bench-101,\\nthe first public architecture dataset for NAS research. To build NAS-Bench-101,\\nwe carefully constructed a compact, yet expressive, search space, exploiting\\ngraph isomorphisms to identify 423k unique convolutional architectures. We\\ntrained and evaluated all of these architectures multiple times on CIFAR-10 and\\ncompiled the results into a large dataset of over 5 million trained models.\\nThis allows researchers to evaluate the quality of a diverse range of models in\\nmilliseconds by querying the pre-computed dataset. We demonstrate its utility\\nby analyzing the dataset as a whole and by benchmarking a range of architecture\\noptimization algorithms.\\n\\n    ', '\\nAbstract:  Face detection, as a fundamental technology for various applications, is\\nalways deployed on edge devices which have limited memory storage and low\\ncomputing power. This paper introduces a Light and Fast Face Detector (LFFD)\\nfor edge devices. The proposed method is anchor-free and belongs to the\\none-stage category. Specifically, we rethink the importance of receptive field\\n(RF) and effective receptive field (ERF) in the background of face detection.\\nEssentially, the RFs of neurons in a certain layer are distributed regularly in\\nthe input image and theses RFs are natural \"anchors\". Combining RF \"anchors\"\\nand appropriate RF strides, the proposed method can detect a large range of\\ncontinuous face scales with 100% coverage in theory. The insightful\\nunderstanding of relations between ERF and face scales motivates an efficient\\nbackbone for one-stage detection. The backbone is characterized by eight\\ndetection branches and common layers, resulting in efficient computation.\\nComprehensive and extensive experiments on popular benchmarks: WIDER FACE and\\nFDDB are conducted. A new evaluation schema is proposed for\\napplication-oriented scenarios. Under the new schema, the proposed method can\\nachieve superior accuracy (WIDER FACE Val/Test -- Easy: 0.910/0.896, Medium:\\n0.881/0.865, Hard: 0.780/0.770; FDDB -- discontinuous: 0.973, continuous:\\n0.724). Multiple hardware platforms are introduced to evaluate the running\\nefficiency. The proposed method can obtain fast inference speed (NVIDIA TITAN\\nXp: 131.45 FPS at 640x480; NVIDIA TX2: 136.99 PFS at 160x120; Raspberry Pi 3\\nModel B+: 8.44 FPS at 160x120) with model size of 9 MB.\\n\\n    ', '\\nAbstract:  The superior performance of Deformable Convolutional Networks arises from its\\nability to adapt to the geometric variations of objects. Through an examination\\nof its adaptive behavior, we observe that while the spatial support for its\\nneural features conforms more closely than regular ConvNets to object\\nstructure, this support may nevertheless extend well beyond the region of\\ninterest, causing features to be influenced by irrelevant image content. To\\naddress this problem, we present a reformulation of Deformable ConvNets that\\nimproves its ability to focus on pertinent image regions, through increased\\nmodeling power and stronger training. The modeling power is enhanced through a\\nmore comprehensive integration of deformable convolution within the network,\\nand by introducing a modulation mechanism that expands the scope of deformation\\nmodeling. To effectively harness this enriched modeling capability, we guide\\nnetwork training via a proposed feature mimicking scheme that helps the network\\nto learn features that reflect the object focus and classification power of\\nR-CNN features. With the proposed contributions, this new version of Deformable\\nConvNets yields significant performance gains over the original model and\\nproduces leading results on the COCO benchmark for object detection and\\ninstance segmentation.\\n\\n    ', '\\nAbstract:  Letting a deep network be aware of the quality of its own predictions is an\\ninteresting yet important problem. In the task of instance segmentation, the\\nconfidence of instance classification is used as mask quality score in most\\ninstance segmentation frameworks. However, the mask quality, quantified as the\\nIoU between the instance mask and its ground truth, is usually not well\\ncorrelated with classification score. In this paper, we study this problem and\\npropose Mask Scoring R-CNN which contains a network block to learn the quality\\nof the predicted instance masks. The proposed network block takes the instance\\nfeature and the corresponding predicted mask together to regress the mask IoU.\\nThe mask scoring strategy calibrates the misalignment between mask quality and\\nmask score, and improves instance segmentation performance by prioritizing more\\naccurate mask predictions during COCO AP evaluation. By extensive evaluations\\non the COCO dataset, Mask Scoring R-CNN brings consistent and noticeable gain\\nwith different models, and outperforms the state-of-the-art Mask R-CNN. We hope\\nour simple and effective approach will provide a new direction for improving\\ninstance segmentation. The source code of our method is available at\\n\\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  Attention mechanisms have become a popular component in deep neural networks,\\nyet there has been little examination of how different influencing factors and\\nmethods for computing attention from these factors affect performance. Toward a\\nbetter general understanding of attention mechanisms, we present an empirical\\nstudy that ablates various spatial attention elements within a generalized\\nattention formulation, encompassing the dominant Transformer attention as well\\nas the prevalent deformable convolution and dynamic convolution modules.\\nConducted on a variety of applications, the study yields significant findings\\nabout spatial attention in deep networks, some of which run counter to\\nconventional understanding. For example, we find that the query and key content\\ncomparison in Transformer attention is negligible for self-attention, but vital\\nfor encoder-decoder attention. A proper combination of deformable convolution\\nwith key content only saliency achieves the best accuracy-efficiency tradeoff\\nin self-attention. Our results suggest that there exists much room for\\nimprovement in the design of attention mechanisms.\\n\\n    ', '\\nAbstract:  In object detection, an intersection over union (IoU) threshold is required\\nto define positives and negatives. An object detector, trained with low IoU\\nthreshold, e.g. 0.5, usually produces noisy detections. However, detection\\nperformance tends to degrade with increasing the IoU thresholds. Two main\\nfactors are responsible for this: 1) overfitting during training, due to\\nexponentially vanishing positive samples, and 2) inference-time mismatch\\nbetween the IoUs for which the detector is optimal and those of the input\\nhypotheses. A multi-stage object detection architecture, the Cascade R-CNN, is\\nproposed to address these problems. It consists of a sequence of detectors\\ntrained with increasing IoU thresholds, to be sequentially more selective\\nagainst close false positives. The detectors are trained stage by stage,\\nleveraging the observation that the output of a detector is a good distribution\\nfor training the next higher quality detector. The resampling of progressively\\nimproved hypotheses guarantees that all detectors have a positive set of\\nexamples of equivalent size, reducing the overfitting problem. The same cascade\\nprocedure is applied at inference, enabling a closer match between the\\nhypotheses and the detector quality of each stage. A simple implementation of\\nthe Cascade R-CNN is shown to surpass all single-model object detectors on the\\nchallenging COCO dataset. Experiments also show that the Cascade R-CNN is\\nwidely applicable across detector architectures, achieving consistent gains\\nindependently of the baseline detector strength. The code will be made\\navailable at this https URL.\\n\\n    ', '\\nAbstract:  The Non-Local Network (NLNet) presents a pioneering approach for capturing\\nlong-range dependencies, via aggregating query-specific global context to each\\nquery position. However, through a rigorous empirical analysis, we have found\\nthat the global contexts modeled by non-local network are almost the same for\\ndifferent query positions within an image. In this paper, we take advantage of\\nthis finding to create a simplified network based on a query-independent\\nformulation, which maintains the accuracy of NLNet but with significantly less\\ncomputation. We further observe that this simplified design shares similar\\nstructure with Squeeze-Excitation Network (SENet). Hence we unify them into a\\nthree-step general framework for global context modeling. Within the general\\nframework, we design a better instantiation, called the global context (GC)\\nblock, which is lightweight and can effectively model the global context. The\\nlightweight property allows us to apply it for multiple layers in a backbone\\nnetwork to construct a global context network (GCNet), which generally\\noutperforms both simplified NLNet and SENet on major benchmarks for various\\nrecognition tasks. The code and configurations are released at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Despite the great success of two-stage detectors, single-stage detector is\\nstill a more elegant and efficient way, yet suffers from the two well-known\\ndisharmonies during training, i.e. the huge difference in quantity between\\npositive and negative examples as well as between easy and hard examples. In\\nthis work, we first point out that the essential effect of the two disharmonies\\ncan be summarized in term of the gradient. Further, we propose a novel gradient\\nharmonizing mechanism (GHM) to be a hedging for the disharmonies. The\\nphilosophy behind GHM can be easily embedded into both classification loss\\nfunction like cross-entropy (CE) and regression loss function like smooth-$L_1$\\n($SL_1$) loss. To this end, two novel loss functions called GHM-C and GHM-R are\\ndesigned to balancing the gradient flow for anchor classification and bounding\\nbox refinement, respectively. Ablation study on MS COCO demonstrates that\\nwithout laborious hyper-parameter tuning, both GHM-C and GHM-R can bring\\nsubstantial improvement for single-stage detector. Without any whistles and\\nbells, our model achieves 41.6 mAP on COCO test-dev set which surpasses the\\nstate-of-the-art method, Focal Loss (FL) + $SL_1$, by 0.8.\\n\\n    ', '\\nAbstract:  Grid R-CNN is a well-performed objection detection framework. It transforms\\nthe traditional box offset regression problem into a grid point estimation\\nproblem. With the guidance of the grid points, it can obtain high-quality\\nlocalization results. However, the speed of Grid R-CNN is not so satisfactory.\\nIn this technical report we present Grid R-CNN Plus, a better and faster\\nversion of Grid R-CNN. We have made several updates that significantly speed up\\nthe framework and simultaneously improve the accuracy. On COCO dataset, the\\nRes50-FPN based Grid R-CNN Plus detector achieves an mAP of 40.4%,\\noutperforming the baseline on the same model by 3.0 points with similar\\ninference time. Code is available at this https URL .\\n\\n    ', '\\nAbstract:  This paper proposes a novel object detection framework named Grid R-CNN,\\nwhich adopts a grid guided localization mechanism for accurate object\\ndetection. Different from the traditional regression based methods, the Grid\\nR-CNN captures the spatial information explicitly and enjoys the position\\nsensitive property of fully convolutional architecture. Instead of using only\\ntwo independent points, we design a multi-point supervision formulation to\\nencode more clues in order to reduce the impact of inaccurate prediction of\\nspecific points. To take the full advantage of the correlation of points in a\\ngrid, we propose a two-stage information fusion strategy to fuse feature maps\\nof neighbor grid points. The grid guided localization approach is easy to be\\nextended to different state-of-the-art detection frameworks. Grid R-CNN leads\\nto high quality object localization, and experiments demonstrate that it\\nachieves a 4.1% AP gain at IoU=0.8 and a 10.0% AP gain at IoU=0.9 on COCO\\nbenchmark compared to Faster R-CNN with Res50 backbone and FPN architecture.\\n\\n    ', '\\nAbstract:  Compared with model architectures, the training process, which is also\\ncrucial to the success of detectors, has received relatively less attention in\\nobject detection. In this work, we carefully revisit the standard training\\npractice of detectors, and find that the detection performance is often limited\\nby the imbalance during the training process, which generally consists in three\\nlevels - sample level, feature level, and objective level. To mitigate the\\nadverse effects caused thereby, we propose Libra R-CNN, a simple but effective\\nframework towards balanced learning for object detection. It integrates three\\nnovel components: IoU-balanced sampling, balanced feature pyramid, and balanced\\nL1 loss, respectively for reducing the imbalance at sample, feature, and\\nobjective level. Benefitted from the overall balanced design, Libra R-CNN\\nsignificantly improves the detection performance. Without bells and whistles,\\nit achieves 2.5 points and 2.0 points higher Average Precision (AP) than FPN\\nFaster R-CNN and RetinaNet respectively on MSCOCO.\\n\\n    ', '\\nAbstract:  Region anchors are the cornerstone of modern object detection techniques.\\nState-of-the-art detectors mostly rely on a dense anchoring scheme, where\\nanchors are sampled uniformly over the spatial domain with a predefined set of\\nscales and aspect ratios. In this paper, we revisit this foundational stage.\\nOur study shows that it can be done much more effectively and efficiently.\\nSpecifically, we present an alternative scheme, named Guided Anchoring, which\\nleverages semantic features to guide the anchoring. The proposed method jointly\\npredicts the locations where the center of objects of interest are likely to\\nexist as well as the scales and aspect ratios at different locations. On top of\\npredicted anchor shapes, we mitigate the feature inconsistency with a feature\\nadaption module. We also study the use of high-quality proposals to improve\\ndetection performance. The anchoring scheme can be seamlessly integrated into\\nproposal methods and detectors. With Guided Anchoring, we achieve 9.1% higher\\nrecall on MS COCO with 90% fewer anchors than the RPN baseline. We also adopt\\nGuided Anchoring in Fast R-CNN, Faster R-CNN and RetinaNet, respectively\\nimproving the detection mAP by 2.2%, 2.7% and 1.2%. Code will be available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Automatic synthesis of realistic images from text would be interesting and\\nuseful, but current AI systems are still far from this goal. However, in recent\\nyears generic and powerful recurrent neural network architectures have been\\ndeveloped to learn discriminative text feature representations. Meanwhile, deep\\nconvolutional generative adversarial networks (GANs) have begun to generate\\nhighly compelling images of specific categories, such as faces, album covers,\\nand room interiors. In this work, we develop a novel deep architecture and GAN\\nformulation to effectively bridge these advances in text and image model- ing,\\ntranslating visual concepts from characters to pixels. We demonstrate the\\ncapability of our model to generate plausible images of birds and flowers from\\ndetailed text descriptions.\\n\\n    ', '\\nAbstract:  Machine learning algorithms are often vulnerable to adversarial examples that\\nhave imperceptible alterations from the original counterparts but can fool the\\nstate-of-the-art models. It is helpful to evaluate or even improve the\\nrobustness of these models by exposing the maliciously crafted adversarial\\nexamples. In this paper, we present TextFooler, a simple but strong baseline to\\ngenerate natural adversarial text. By applying it to two fundamental natural\\nlanguage tasks, text classification and textual entailment, we successfully\\nattacked three target models, including the powerful pre-trained BERT, and the\\nwidely used convolutional and recurrent neural networks. We demonstrate the\\nadvantages of this framework in three ways: (1) effective---it outperforms\\nstate-of-the-art attacks in terms of success rate and perturbation rate, (2)\\nutility-preserving---it preserves semantic content and grammaticality, and\\nremains correctly classified by humans, and (3) efficient---it generates\\nadversarial text with computational complexity linear to the text length.\\n\\n    ', '\\nAbstract:  Although various techniques have been proposed to generate adversarial\\nsamples for white-box attacks on text, little attention has been paid to\\nblack-box attacks, which are more realistic scenarios. In this paper, we\\npresent a novel algorithm, DeepWordBug, to effectively generate small text\\nperturbations in a black-box setting that forces a deep-learning classifier to\\nmisclassify a text input. We employ novel scoring strategies to identify the\\ncritical tokens that, if modified, cause the classifier to make an incorrect\\nprediction. Simple character-level transformations are applied to the\\nhighest-ranked tokens in order to minimize the edit distance of the\\nperturbation, yet change the original classification. We evaluated DeepWordBug\\non eight real-world text datasets, including text classification, sentiment\\nanalysis, and spam detection. We compare the result of DeepWordBug with two\\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\\nresults indicate that DeepWordBug reduces the prediction accuracy of current\\nstate-of-the-art deep-learning models, including a decrease of 68\\\\% on average\\nfor a Word-LSTM model and 48\\\\% on average for a Char-CNN model.\\n\\n    ', \"\\nAbstract:  Deep Learning-based Text Understanding (DLTU) is the backbone technique\\nbehind various applications, including question answering, machine translation,\\nand text classification. Despite its tremendous popularity, the security\\nvulnerabilities of DLTU are still largely unknown, which is highly concerning\\ngiven its increasing use in security-sensitive applications such as sentiment\\nanalysis and toxic content detection. In this paper, we show that DLTU is\\ninherently vulnerable to adversarial text attacks, in which maliciously crafted\\ntexts trigger target DLTU systems and services to misbehave. Specifically, we\\npresent TextBugger, a general attack framework for generating adversarial\\ntexts. In contrast to prior works, TextBugger differs in significant ways: (i)\\neffective -- it outperforms state-of-the-art attacks in terms of attack success\\nrate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\\\% of\\nthe adversarial text correctly recognized by human readers; and (iii) efficient\\n-- it generates adversarial text with computational complexity sub-linear to\\nthe text length. We empirically evaluate TextBugger on a set of real-world DLTU\\nsystems and services used for sentiment analysis and toxic content detection,\\ndemonstrating its effectiveness, evasiveness, and efficiency. For instance,\\nTextBugger achieves 100\\\\% success rate on the IMDB dataset based on Amazon AWS\\nComprehend within 4.61 seconds and preserves 97\\\\% semantic similarity. We\\nfurther discuss possible defense mechanisms to mitigate such attack and the\\nadversary's potential countermeasures, which leads to promising directions for\\nfurther research.\\n\\n    \", '\\nAbstract:  Machine learning models are powerful but fallible. Generating adversarial\\nexamples - inputs deliberately crafted to cause model misclassification or\\nother errors - can yield important insight into model assumptions and\\nvulnerabilities. Despite significant recent work on adversarial example\\ngeneration targeting image classifiers, relatively little work exists exploring\\nadversarial example generation for text classifiers; additionally, many\\nexisting adversarial example generation algorithms require full access to\\ntarget model parameters, rendering them impractical for many real-world\\nattacks. In this work, we introduce DANCin SEQ2SEQ, a GAN-inspired algorithm\\nfor adversarial text example generation targeting largely black-box text\\nclassifiers. We recast adversarial text example generation as a reinforcement\\nlearning problem, and demonstrate that our algorithm offers preliminary but\\npromising steps towards generating semantically meaningful adversarial text\\nexamples in a real-world attack scenario.\\n\\n    ', \"\\nAbstract:  CleverHans is a software library that provides standardized reference\\nimplementations of adversarial example construction techniques and adversarial\\ntraining. The library may be used to develop more robust machine learning\\nmodels and to provide standardized benchmarks of models' performance in the\\nadversarial setting. Benchmarks constructed without a standardized\\nimplementation of adversarial example construction are not comparable to each\\nother, because a good result may indicate a robust model or it may merely\\nindicate a weak implementation of the adversarial example construction\\nprocedure.\\nThis technical report is structured as follows. Section 1 provides an\\noverview of adversarial examples in machine learning and of the CleverHans\\nsoftware. Section 2 presents the core functionalities of the library: namely\\nthe attacks based on adversarial examples and defenses to improve the\\nrobustness of machine learning models to these attacks. Section 3 describes how\\nto report benchmark results using the library. Section 4 describes the\\nversioning system.\\n\\n    \", '\\nAbstract:  Deep learning takes advantage of large datasets and computationally efficient\\ntraining algorithms to outperform other approaches at various machine learning\\ntasks. However, imperfections in the training phase of deep neural networks\\nmake them vulnerable to adversarial samples: inputs crafted by adversaries with\\nthe intent of causing deep neural networks to misclassify. In this work, we\\nformalize the space of adversaries against deep neural networks (DNNs) and\\nintroduce a novel class of algorithms to craft adversarial samples based on a\\nprecise understanding of the mapping between inputs and outputs of DNNs. In an\\napplication to computer vision, we show that our algorithms can reliably\\nproduce samples correctly classified by human subjects but misclassified in\\nspecific targets by a DNN with a 97% adversarial success rate while only\\nmodifying on average 4.02% of the input features per sample. We then evaluate\\nthe vulnerability of different sample classes to adversarial perturbations by\\ndefining a hardness measure. Finally, we describe preliminary work outlining\\ndefenses against adversarial samples by defining a predictive measure of\\ndistance between a benign input and a target classification.\\n\\n    ', '\\nAbstract:  Adversarial attacks to image classification systems present challenges to\\nconvolutional networks and opportunities for understanding them. This study\\nsuggests that adversarial perturbations on images lead to noise in the features\\nconstructed by these networks. Motivated by this observation, we develop new\\nnetwork architectures that increase adversarial robustness by performing\\nfeature denoising. Specifically, our networks contain blocks that denoise the\\nfeatures using non-local means or other filters; the entire networks are\\ntrained end-to-end. When combined with adversarial training, our feature\\ndenoising networks substantially improve the state-of-the-art in adversarial\\nrobustness in both white-box and black-box attack settings. On ImageNet, under\\n10-iteration PGD white-box attacks where prior art has 27.9% accuracy, our\\nmethod achieves 55.7%; even under extreme 2000-iteration PGD white-box attacks,\\nour method secures 42.6% accuracy. Our method was ranked first in Competition\\non Adversarial Attacks and Defenses (CAAD) 2018 --- it achieved 50.6%\\nclassification accuracy on a secret, ImageNet-like test dataset against 48\\nunknown attackers, surpassing the runner-up approach by ~10%. Code is available\\nat this https URL.\\n\\n    ', '\\nAbstract:  This paper investigates strategies that defend against adversarial-example\\nattacks on image-classification systems by transforming the inputs before\\nfeeding them to the system. Specifically, we study applying image\\ntransformations such as bit-depth reduction, JPEG compression, total variance\\nminimization, and image quilting before feeding the image to a convolutional\\nnetwork classifier. Our experiments on ImageNet show that total variance\\nminimization and image quilting are very effective defenses in practice, in\\nparticular, when the network is trained on transformed images. The strength of\\nthose defenses lies in their non-differentiable nature and their inherent\\nrandomness, which makes it difficult for an adversary to circumvent the\\ndefenses. Our best defense eliminates 60% of strong gray-box and 90% of strong\\nblack-box attacks by a variety of major attack methods\\n\\n    ', '\\nAbstract:  advertorch is a toolbox for adversarial robustness research. It contains\\nvarious implementations for attacks, defenses and robust training methods.\\nadvertorch is built on PyTorch (Paszke et al., 2017), and leverages the\\nadvantages of the dynamic computational graph to provide concise and efficient\\nreference implementations. The code is licensed under the LGPL license and is\\nopen sourced at this https URL .\\n\\n    ', '\\nAbstract:  Recent work has demonstrated that deep neural networks are vulnerable to\\nadversarial examples---inputs that are almost indistinguishable from natural\\ndata and yet classified incorrectly by the network. In fact, some of the latest\\nfindings suggest that the existence of adversarial attacks may be an inherent\\nweakness of deep learning models. To address this problem, we study the\\nadversarial robustness of neural networks through the lens of robust\\noptimization. This approach provides us with a broad and unifying view on much\\nof the prior work on this topic. Its principled nature also enables us to\\nidentify methods for both training and attacking neural networks that are\\nreliable and, in a certain sense, universal. In particular, they specify a\\nconcrete security guarantee that would protect against any adversary. These\\nmethods let us train networks with significantly improved resistance to a wide\\nrange of adversarial attacks. They also suggest the notion of security against\\na first-order adversary as a natural and broad security guarantee. We believe\\nthat robustness against such well-defined classes of adversaries is an\\nimportant stepping stone towards fully resistant deep learning models. Code and\\npre-trained models are available at this https URL\\nand this https URL.\\n\\n    ', \"\\nAbstract:  In this paper we establish rigorous benchmarks for image classifier\\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\\ncorruption robustness topic, while showing which classifiers are preferable in\\nsafety-critical applications. Then we propose a new dataset called ImageNet-P\\nwhich enables researchers to benchmark a classifier's robustness to common\\nperturbations. Unlike recent robustness research, this benchmark evaluates\\nperformance on common corruptions and perturbations not worst-case adversarial\\nperturbations. We find that there are negligible changes in relative corruption\\nrobustness from AlexNet classifiers to ResNet classifiers. Afterward we\\ndiscover ways to enhance corruption and perturbation robustness. We even find\\nthat a bypassed adversarial defense provides substantial common perturbation\\nrobustness. Together our benchmarks may aid future work toward networks that\\nrobustly generalize.\\n\\n    \", '\\nAbstract:  Correctly evaluating defenses against adversarial examples has proven to be\\nextremely difficult. Despite the significant amount of recent work attempting\\nto design defenses that withstand adaptive attacks, few have succeeded; most\\npapers that propose defenses are quickly shown to be incorrect.\\nWe believe a large contributing factor is the difficulty of performing\\nsecurity evaluations. In this paper, we discuss the methodological foundations,\\nreview commonly accepted best practices, and suggest new methods for evaluating\\ndefenses to adversarial examples. We hope that both researchers developing\\ndefenses as well as readers and reviewers who wish to understand the\\ncompleteness of an evaluation consider our advice in order to avoid common\\npitfalls.\\n\\n    ', '\\nAbstract:  We present a training system, which can provably defend significantly larger\\nneural networks than previously possible, including ResNet-34 and DenseNet-100.\\nOur approach is based on differentiable abstract interpretation and introduces\\ntwo novel concepts: (i) abstract layers for fine-tuning the precision and\\nscalability of the abstraction, (ii) a flexible domain specific language (DSL)\\nfor describing training objectives that combine abstract and concrete losses\\nwith arbitrary specifications. Our training method is implemented in the DiffAI\\nsystem.\\n\\n    ', \"\\nAbstract:  Neural networks are vulnerable to adversarial examples, which poses a threat\\nto their application in security sensitive systems. We propose high-level\\nrepresentation guided denoiser (HGD) as a defense for image classification.\\nStandard denoiser suffers from the error amplification effect, in which small\\nresidual adversarial noise is progressively amplified and leads to wrong\\nclassifications. HGD overcomes this problem by using a loss function defined as\\nthe difference between the target model's outputs activated by the clean image\\nand denoised image. Compared with ensemble adversarial training which is the\\nstate-of-the-art defending method on large images, HGD has three advantages.\\nFirst, with HGD as a defense, the target model is more robust to either\\nwhite-box or black-box adversarial attacks. Second, HGD can be trained on a\\nsmall subset of the images and generalizes well to other images and unseen\\nclasses. Third, HGD can be transferred to defend models other than the one\\nguiding it. In NIPS competition on defense against adversarial attacks, our HGD\\nsolution won the first place and outperformed other models by a large margin.\\n\\n    \", '\\nAbstract:  Neural architectures are the foundation for improving performance of deep\\nneural networks (DNNs). This paper presents deep compositional grammatical\\narchitectures which harness the best of two worlds: grammar models and DNNs.\\nThe proposed architectures integrate compositionality and reconfigurability of\\nthe former and the capability of learning rich features of the latter in a\\nprincipled way. We utilize AND-OR Grammar (AOG) as network generator in this\\npaper and call the resulting networks AOGNets. An AOGNet consists of a number\\nof stages each of which is composed of a number of AOG building blocks. An AOG\\nbuilding block splits its input feature map into N groups along feature\\nchannels and then treat it as a sentence of N words. It then jointly realizes a\\nphrase structure grammar and a dependency grammar in bottom-up parsing the\\n\"sentence\" for better feature exploration and reuse. It provides a unified\\nframework for the best practices developed in state-of-the-art DNNs. In\\nexperiments, AOGNet is tested in the CIFAR-10, CIFAR-100 and ImageNet-1K\\nclassification benchmark and the MS-COCO object detection and segmentation\\nbenchmark. In CIFAR-10, CIFAR-100 and ImageNet-1K, AOGNet obtains better\\nperformance than ResNet and most of its variants, ResNeXt and its attention\\nbased variants such as SENet, DenseNet and DualPathNet. AOGNet also obtains the\\nbest model interpretability score using network dissection. AOGNet further\\nshows better potential in adversarial defense. In MS-COCO, AOGNet obtains\\nbetter performance than the ResNet and ResNeXt backbones in Mask R-CNN.\\n\\n    ', '\\nAbstract:  Recent works have shown the effectiveness of randomized smoothing as a\\nscalable technique for building neural network-based classifiers that are\\nprovably robust to $\\\\ell_2$-norm adversarial perturbations. In this paper, we\\nemploy adversarial training to improve the performance of randomized smoothing.\\nWe design an adapted attack for smoothed classifiers, and we show how this\\nattack can be used in an adversarial training setting to boost the provable\\nrobustness of smoothed classifiers. We demonstrate through extensive\\nexperimentation that our method consistently outperforms all existing provably\\n$\\\\ell_2$-robust classifiers by a significant margin on ImageNet and CIFAR-10,\\nestablishing the state-of-the-art for provable $\\\\ell_2$-defenses. Moreover, we\\nfind that pre-training and semi-supervised learning boost adversarially trained\\nsmoothed classifiers even further. Our code and trained models are available at\\nthis http URL .\\n\\n    ', '\\nAbstract:  We identify a trade-off between robustness and accuracy that serves as a\\nguiding principle in the design of defenses against adversarial examples.\\nAlthough this problem has been widely studied empirically, much remains unknown\\nconcerning the theory underlying this trade-off. In this work, we decompose the\\nprediction error for adversarial examples (robust error) as the sum of the\\nnatural (classification) error and boundary error, and provide a differentiable\\nupper bound using the theory of classification-calibrated loss, which is shown\\nto be the tightest possible upper bound uniform over all probability\\ndistributions and measurable predictors. Inspired by our theoretical analysis,\\nwe also design a new defense method, TRADES, to trade adversarial robustness\\noff against accuracy. Our proposed algorithm performs well experimentally in\\nreal-world datasets. The methodology is the foundation of our entry to the\\nNeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of\\n~2,000 submissions, surpassing the runner-up approach by $11.41\\\\%$ in terms of\\nmean $\\\\ell_2$ perturbation distance.\\n\\n    ', \"\\nAbstract:  Deep learning achieves state-of-the-art results in many tasks in computer\\nvision and natural language processing. However, recent works have shown that\\ndeep networks can be vulnerable to adversarial perturbations, which raised a\\nserious robustness issue of deep networks. Adversarial training, typically\\nformulated as a robust optimization problem, is an effective way of improving\\nthe robustness of deep networks. A major drawback of existing adversarial\\ntraining algorithms is the computational overhead of the generation of\\nadversarial examples, typically far greater than that of the network training.\\nThis leads to the unbearable overall computational cost of adversarial\\ntraining. In this paper, we show that adversarial training can be cast as a\\ndiscrete time differential game. Through analyzing the Pontryagin's Maximal\\nPrinciple (PMP) of the problem, we observe that the adversary update is only\\ncoupled with the parameters of the first layer of the network. This inspires us\\nto restrict most of the forward and back propagation within the first layer of\\nthe network during adversary updates. This effectively reduces the total number\\nof full forward and backward propagation to only one for each group of\\nadversary updates. Therefore, we refer to this algorithm YOPO (You Only\\nPropagate Once). Numerical experiments demonstrate that YOPO can achieve\\ncomparable defense accuracy with approximately 1/5 ~ 1/4 GPU time of the\\nprojected gradient descent (PGD) algorithm. Our codes are available at\\nhttps://https://github.com/a1600012888/YOPO-You-Only-Propagate-Once.\\n\\n    \", '\\nAbstract:  Adversarial training, in which a network is trained on adversarial examples,\\nis one of the few defenses against adversarial attacks that withstands strong\\nattacks. Unfortunately, the high cost of generating strong adversarial examples\\nmakes standard adversarial training impractical on large-scale problems like\\nImageNet. We present an algorithm that eliminates the overhead cost of\\ngenerating adversarial examples by recycling the gradient information computed\\nwhen updating model parameters. Our \"free\" adversarial training algorithm\\nachieves state-of-the-art robustness on CIFAR-10 and CIFAR-100 datasets at\\nnegligible additional cost compared to natural training, and can be 7 to 30\\ntimes faster than other strong adversarial training methods. Using a single\\nworkstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model\\nfor the large-scale ImageNet classification task that maintains 40% accuracy\\nagainst PGD attacks.\\n\\n    ', 'It is pdf', '\\nAbstract:  Recent studies have shown that attackers can force deep learning models to\\nmisclassify so-called \"adversarial examples\": maliciously generated images\\nformed by making imperceptible modifications to pixel values. With growing\\ninterest in deep learning for security applications, it is important for\\nsecurity experts and users of machine learning to recognize how learning\\nsystems may be attacked. Due to the complex nature of deep learning, it is\\nchallenging to understand how deep models can be fooled by adversarial\\nexamples. Thus, we present a web-based visualization tool,\\nAdversarial-Playground, to demonstrate the efficacy of common adversarial\\nmethods against a convolutional neural network (CNN) system.\\nAdversarial-Playground is educational, modular and interactive. (1) It enables\\nnon-experts to compare examples visually and to understand why an adversarial\\nexample can fool a CNN-based image classifier. (2) It can help security experts\\nexplore more vulnerability of deep learning as a software module. (3) Building\\nan interactive visualization is challenging in this domain due to the large\\nfeature space of image classification (generating adversarial examples is slow\\nin general and visualizing images are costly). Through multiple novel design\\nchoices, our tool can provide fast and accurate responses to user requests.\\nEmpirically, we find that our client-server division strategy reduced the\\nresponse time by an average of 1.5 seconds per sample. Our other innovation, a\\nfaster variant of JSMA evasion algorithm, empirically performed twice as fast\\nas JSMA and yet maintains a comparable evasion rate.\\nProject source code and data from our experiments available at:\\nthis https URL\\n', '\\nAbstract:  We show how to turn any classifier that classifies well under Gaussian noise\\ninto a new classifier that is certifiably robust to adversarial perturbations\\nunder the $\\\\ell_2$ norm. This \"randomized smoothing\" technique has been\\nproposed recently in the literature, but existing guarantees are loose. We\\nprove a tight robustness guarantee in $\\\\ell_2$ norm for smoothing with Gaussian\\nnoise. We use randomized smoothing to obtain an ImageNet classifier with e.g. a\\ncertified top-1 accuracy of 49% under adversarial perturbations with $\\\\ell_2$\\nnorm less than 0.5 (=127/255). No certified defense has been shown feasible on\\nImageNet except for smoothing. On smaller-scale datasets where competing\\napproaches to certified $\\\\ell_2$ robustness are viable, smoothing delivers\\nhigher certified accuracies. Our strong empirical results suggest that\\nrandomized smoothing is a promising direction for future research into\\nadversarially robust classification. Code and models are available at\\nthis http URL.\\n\\n    ', '\\nAbstract:  In this paper we establish rigorous benchmarks for image classifier\\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\\ncorruption robustness topic, while showing which classifiers are preferable in\\nsafety-critical applications. Unlike recent robustness research, this benchmark\\nevaluates performance on commonplace corruptions not worst-case adversarial\\ncorruptions. We find that there are negligible changes in relative corruption\\nrobustness from AlexNet to ResNet classifiers, and we discover ways to enhance\\ncorruption robustness. Then we propose a new dataset called Icons-50 which\\nopens research on a new kind of robustness, surface variation robustness. With\\nthis dataset we evaluate the frailty of classifiers on new styles of known\\nobjects and unexpected instances of known classes. We also demonstrate two\\nmethods that improve surface variation robustness. Together our benchmarks may\\naid future work toward networks that learn fundamental class structure and also\\nrobustly generalize.\\n\\n    ', '\\nAbstract:  Deep neural networks (DNNs) are one of the most prominent technologies of our\\ntime, as they achieve state-of-the-art performance in many machine learning\\ntasks, including but not limited to image classification, text mining, and\\nspeech processing. However, recent research on DNNs has indicated\\never-increasing concern on the robustness to adversarial examples, especially\\nfor security-critical tasks such as traffic sign identification for autonomous\\ndriving. Studies have unveiled the vulnerability of a well-trained DNN by\\ndemonstrating the ability of generating barely noticeable (to both human and\\nmachines) adversarial images that lead to misclassification. Furthermore,\\nresearchers have shown that these adversarial images are highly transferable by\\nsimply training and attacking a substitute model built upon the target model,\\nknown as a black-box attack to DNNs.\\nSimilar to the setting of training substitute models, in this paper we\\npropose an effective black-box attack that also only has access to the input\\n(images) and the output (confidence scores) of a targeted DNN. However,\\ndifferent from leveraging attack transferability from substitute models, we\\npropose zeroth order optimization (ZOO) based attacks to directly estimate the\\ngradients of the targeted DNN for generating adversarial examples. We use\\nzeroth order stochastic coordinate descent along with dimension reduction,\\nhierarchical attack and importance sampling techniques to efficiently attack\\nblack-box models. By exploiting zeroth order optimization, improved attacks to\\nthe targeted DNN can be accomplished, sparing the need for training substitute\\nmodels and avoiding the loss in attack transferability. Experimental results on\\nMNIST, CIFAR10 and ImageNet show that the proposed ZOO attack is as effective\\nas the state-of-the-art white-box attack and significantly outperforms existing\\nblack-box attacks via substitute models.\\n\\n    ', '\\nAbstract:  Convolutional neural networks have demonstrated high accuracy on various\\ntasks in recent years. However, they are extremely vulnerable to adversarial\\nexamples. For example, imperceptible perturbations added to clean images can\\ncause convolutional neural networks to fail. In this paper, we propose to\\nutilize randomization at inference time to mitigate adversarial effects.\\nSpecifically, we use two randomization operations: random resizing, which\\nresizes the input images to a random size, and random padding, which pads zeros\\naround the input images in a random manner. Extensive experiments demonstrate\\nthat the proposed randomization method is very effective at defending against\\nboth single-step and iterative attacks. Our method provides the following\\nadvantages: 1) no additional training or fine-tuning, 2) very few additional\\ncomputations, 3) compatible with other adversarial defense methods. By\\ncombining the proposed randomization method with an adversarially trained\\nmodel, it achieves a normalized score of 0.924 (ranked No.2 among 107 defense\\nteams) in the NIPS 2017 adversarial examples defense challenge, which is far\\nbetter than using adversarial training alone with a normalized score of 0.773\\n(ranked No.56). The code is public available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  While neural networks have achieved high accuracy on standard image\\nclassification benchmarks, their accuracy drops to nearly zero in the presence\\nof small adversarial perturbations to test inputs. Defenses based on\\nregularization and adversarial training have been proposed, but often followed\\nby new, stronger attacks that defeat these defenses. Can we somehow end this\\narms race? In this work, we study this problem for neural networks with one\\nhidden layer. We first propose a method based on a semidefinite relaxation that\\noutputs a certificate that for a given network and test input, no attack can\\nforce the error to exceed a certain value. Second, as this certificate is\\ndifferentiable, we jointly optimize it with the network parameters, providing\\nan adaptive regularizer that encourages robustness against all attacks. On\\nMNIST, our approach produces a network and a certificate that no attack that\\nperturbs each pixel by at most \\\\epsilon = 0.1 can cause more than 35% test\\nerror.\\n\\n    ', \"\\nAbstract:  Deep Neural Networks (DNNs) have recently been shown to be vulnerable against\\nadversarial examples, which are carefully crafted instances that can mislead\\nDNNs to make errors during prediction. To better understand such attacks, a\\ncharacterization is needed of the properties of regions (the so-called\\n'adversarial subspaces') in which adversarial examples lie. We tackle this\\nchallenge by characterizing the dimensional properties of adversarial regions,\\nvia the use of Local Intrinsic Dimensionality (LID). LID assesses the\\nspace-filling capability of the region surrounding a reference example, based\\non the distance distribution of the example to its neighbors. We first provide\\nexplanations about how adversarial perturbation can affect the LID\\ncharacteristic of adversarial regions, and then show empirically that LID\\ncharacteristics can facilitate the distinction of adversarial examples\\ngenerated using state-of-the-art attacks. As a proof-of-concept, we show that a\\npotential application of LID is to distinguish adversarial examples, and the\\npreliminary results show that it can outperform several state-of-the-art\\ndetection measures by large margins for five attack strategies considered in\\nthis paper across three benchmark datasets. Our analysis of the LID\\ncharacteristic for adversarial regions not only motivates new directions of\\neffective adversarial defense, but also opens up more challenges for developing\\nnew attacks to better understand the vulnerabilities of DNNs.\\n\\n    \", '\\nAbstract:  A rapidly growing area of work has studied the existence of adversarial\\nexamples, datapoints which have been perturbed to fool a classifier, but the\\nvast majority of these works have focused primarily on threat models defined by\\n$\\\\ell_p$ norm-bounded perturbations. In this paper, we propose a new threat\\nmodel for adversarial attacks based on the Wasserstein distance. In the image\\nclassification setting, such distances measure the cost of moving pixel mass,\\nwhich naturally cover \"standard\" image manipulations such as scaling, rotation,\\ntranslation, and distortion (and can potentially be applied to other settings\\nas well). To generate Wasserstein adversarial examples, we develop a procedure\\nfor projecting onto the Wasserstein ball, based upon a modified version of the\\nSinkhorn iteration. The resulting algorithm can successfully attack image\\nclassification models, bringing traditional CIFAR10 models down to 3% accuracy\\nwithin a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1\\npixel), and we demonstrate that PGD-based adversarial training can improve this\\nadversarial accuracy to 76%. In total, this work opens up a new direction of\\nstudy in adversarial robustness, more formally considering convex metrics that\\naccurately capture the invariances that we typically believe should exist in\\nclassifiers. Code for all experiments in the paper is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Considerable work on adversarial defense has studied robustness to a fixed,\\nknown family of adversarial distortions, most frequently L_p-bounded\\ndistortions. In reality, the specific form of attack will rarely be known and\\nadversaries are free to employ distortions outside of any fixed set. The\\npresent work advocates measuring robustness against this much broader range of\\nunforeseen attacks---attacks whose precise form is not known when designing a\\ndefense.\\nWe propose a methodology for evaluating a defense against a diverse range of\\ndistortion types together with a summary metric UAR that measures the\\nUnforeseen Attack Robustness against a distortion. We construct novel JPEG,\\nFog, Gabor, and Snow adversarial attacks to simulate unforeseen adversaries and\\nperform a careful study of adversarial robustness against these and existing\\ndistortion types. We find that evaluation against existing L_p attacks yields\\nhighly correlated information that may not generalize to other attacks and\\nidentify a set of 4 attacks that yields more diverse information. We further\\nfind that adversarial training against either one or multiple distortions,\\nincluding our novel ones, does not confer robustness to unforeseen distortions.\\nThese results underscore the need to study robustness against unforeseen\\ndistortions and provide a starting point for doing so.\\n\\n    ', '\\nAbstract:  Convolutional Neural Networks have achieved significant success across\\nmultiple computer vision tasks. However, they are vulnerable to carefully\\ncrafted, human-imperceptible adversarial noise patterns which constrain their\\ndeployment in critical security-sensitive systems. This paper proposes a\\ncomputationally efficient image enhancement approach that provides a strong\\ndefense mechanism to effectively mitigate the effect of such adversarial\\nperturbations. We show that deep image restoration networks learn mapping\\nfunctions that can bring off-the-manifold adversarial samples onto the natural\\nimage manifold, thus restoring classification towards correct classes. A\\ndistinguishing feature of our approach is that, in addition to providing\\nrobustness against attacks, it simultaneously enhances image quality and\\nretains models performance on clean images. Furthermore, the proposed method\\ndoes not modify the classifier or requires a separate mechanism to detect\\nadversarial images. The effectiveness of the scheme has been demonstrated\\nthrough extensive experiments, where it has proven a strong defense in gray-box\\nsettings. The proposed scheme is simple and has the following advantages: (1)\\nit does not require any model training or parameter optimization, (2) it\\ncomplements other existing defense mechanisms, (3) it is agnostic to the\\nattacked model and attack type and (4) it provides superior performance across\\nall popular attack algorithms. Our codes are publicly available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Deep neural networks have achieved impressive experimental results in image\\nclassification, but can surprisingly be unstable with respect to adversarial\\nperturbations, that is, minimal changes to the input image that cause the\\nnetwork to misclassify it. With potential applications including perception\\nmodules and end-to-end controllers for self-driving cars, this raises concerns\\nabout their safety. We develop a novel automated verification framework for\\nfeed-forward multi-layer neural networks based on Satisfiability Modulo Theory\\n(SMT). We focus on safety of image classification decisions with respect to\\nimage manipulations, such as scratches or changes to camera angle or lighting\\nconditions that would result in the same class being assigned by a human, and\\ndefine safety for an individual decision in terms of invariance of the\\nclassification within a small neighbourhood of the original image. We enable\\nexhaustive search of the region by employing discretisation, and propagate the\\nanalysis layer by layer. Our method works directly with the network code and,\\nin contrast to existing methods, can guarantee that adversarial examples, if\\nthey exist, are found for the given region and family of manipulations. If\\nfound, adversarial examples can be shown to human testers and/or used to\\nfine-tune the network. We implement the techniques using Z3 and evaluate them\\non state-of-the-art networks, including regularised and deep learning networks.\\nWe also compare against existing techniques to search for adversarial examples\\nand estimate network robustness.\\n\\n    ', '\\nAbstract:  An intriguing property of deep neural networks is the existence of\\nadversarial examples, which can transfer among different architectures. These\\ntransferable adversarial examples may severely hinder deep neural network-based\\napplications. Previous works mostly study the transferability using small scale\\ndatasets. In this work, we are the first to conduct an extensive study of the\\ntransferability over large models and a large scale dataset, and we are also\\nthe first to study the transferability of targeted adversarial examples with\\ntheir target labels. We study both non-targeted and targeted adversarial\\nexamples, and show that while transferable non-targeted adversarial examples\\nare easy to find, targeted adversarial examples generated using existing\\napproaches almost never transfer with their target labels. Therefore, we\\npropose novel ensemble-based approaches to generating transferable adversarial\\nexamples. Using such approaches, we observe a large proportion of targeted\\nadversarial examples that are able to transfer with their target labels for the\\nfirst time. We also present some geometric studies to help understanding the\\ntransferable adversarial examples. Finally, we show that the adversarial\\nexamples generated using ensemble-based approaches can successfully attack\\nthis http URL, which is a black-box image classification system.\\n\\n    ', '\\nAbstract:  Adversarial robustness has emerged as an important topic in deep learning as\\ncarefully crafted attack samples can significantly disturb the performance of a\\nmodel. Many recent methods have proposed to improve adversarial robustness by\\nutilizing adversarial training or model distillation, which adds additional\\nprocedures to model training. In this paper, we propose a new training paradigm\\ncalled Guided Complement Entropy (GCE) that is capable of achieving\\n\"adversarial defense for free,\" which involves no additional procedures in the\\nprocess of improving adversarial robustness. In addition to maximizing model\\nprobabilities on the ground-truth class like cross-entropy, we neutralize its\\nprobabilities on the incorrect classes along with a \"guided\" term to balance\\nbetween these two terms. We show in the experiments that our method achieves\\nbetter model robustness with even better performance compared to the commonly\\nused cross-entropy training objective. We also show that our method can be used\\northogonal to adversarial training across well-known methods with noticeable\\nrobustness gain. To the best of our knowledge, our approach is the first one\\nthat improves model robustness without compromising performance.\\n\\n    ', '\\nAbstract:  Although adversarial examples and model robustness have been extensively\\nstudied in the context of linear models and neural networks, research on this\\nissue in tree-based models and how to make tree-based models robust against\\nadversarial examples is still limited. In this paper, we show that tree based\\nmodels are also vulnerable to adversarial examples and develop a novel\\nalgorithm to learn robust trees. At its core, our method aims to optimize the\\nperformance under the worst-case perturbation of input features, which leads to\\na max-min saddle point problem. Incorporating this saddle point objective into\\nthe decision tree building procedure is non-trivial due to the discrete nature\\nof trees --- a naive approach to finding the best split according to this\\nsaddle point objective will take exponential time. To make our approach\\npractical and scalable, we propose efficient tree building algorithms by\\napproximating the inner minimizer in this saddle point problem, and present\\nefficient implementations for classical information gain based trees as well as\\nstate-of-the-art tree boosting models such as XGBoost. Experimental results on\\nreal world datasets demonstrate that the proposed algorithms can substantially\\nimprove the robustness of tree-based models against adversarial examples.\\n\\n    ', '\\nAbstract:  Neural networks are increasingly deployed in real-world safety-critical\\ndomains such as autonomous driving, aircraft collision avoidance, and malware\\ndetection. However, these networks have been shown to often mispredict on\\ninputs with minor adversarial or even accidental perturbations. Consequences of\\nsuch errors can be disastrous and even potentially fatal as shown by the recent\\nTesla autopilot crash. Thus, there is an urgent need for formal analysis\\nsystems that can rigorously check neural networks for violations of different\\nsafety properties such as robustness against adversarial perturbations within a\\ncertain $L$-norm of a given image. An effective safety analysis system for a\\nneural network must be able to either ensure that a safety property is\\nsatisfied by the network or find a counterexample, i.e., an input for which the\\nnetwork will violate the property. Unfortunately, most existing techniques for\\nperforming such analysis struggle to scale beyond very small networks and the\\nones that can scale to larger networks suffer from high false positives and\\ncannot produce concrete counterexamples in case of a property violation. In\\nthis paper, we present a new efficient approach for rigorously checking\\ndifferent safety properties of neural networks that significantly outperforms\\nexisting approaches by multiple orders of magnitude. Our approach can check\\ndifferent safety properties and find concrete counterexamples for networks that\\nare 10$\\\\times$ larger than the ones supported by existing analysis techniques.\\nWe believe that our approach to estimating tight output bounds of a network for\\na given input range can also help improve the explainability of neural networks\\nand guide the training process of more robust neural networks.\\n\\n    ', '\\nAbstract:  Deep neural networks are vulnerable to adversarial attacks, which can fool\\nthem by adding minuscule perturbations to the input images. The robustness of\\nexisting defenses suffers greatly under white-box attack settings, where an\\nadversary has full knowledge about the network and can iterate several times to\\nfind strong perturbations. We observe that the main reason for the existence of\\nsuch perturbations is the close proximity of different class samples in the\\nlearned feature space. This allows model decisions to be totally changed by\\nadding an imperceptible perturbation in the inputs. To counter this, we propose\\nto class-wise disentangle the intermediate feature representations of deep\\nnetworks. Specifically, we force the features for each class to lie inside a\\nconvex polytope that is maximally separated from the polytopes of other\\nclasses. In this manner, the network is forced to learn distinct and distant\\ndecision regions for each class. We observe that this simple constraint on the\\nfeatures greatly enhances the robustness of learned models, even against the\\nstrongest white-box attacks, without degrading the classification performance\\non clean images. We report extensive evaluations in both black-box and\\nwhite-box attack scenarios and show significant gains in comparison to\\nstate-of-the art defenses.\\n\\n    ', '\\nAbstract:  In this work we revisit gradient regularization for adversarial robustness\\nwith some new ingredients. First, we derive new per-image theoretical\\nrobustness bounds based on local gradient information. These bounds strongly\\nmotivate input gradient regularization. Second, we implement a scaleable\\nversion of input gradient regularization which avoids double backpropagation:\\nadversarially robust ImageNet models are trained in 33 hours on four consumer\\ngrade GPUs. Finally, we show experimentally and through theoretical\\ncertification that input gradient regularization is competitive with\\nadversarial training. Moreover we demonstrate that gradient regularization does\\nnot lead to gradient obfuscation or gradient masking.\\n\\n    ', '\\nAbstract:  Adversarial examples have received a great deal of recent attention because\\nof their potential to uncover security flaws in machine learning systems.\\nHowever, most prior work on adversarial examples has been on parametric\\nclassifiers, for which generic attack and defense methods are known;\\nnon-parametric methods have been only considered on an ad-hoc or\\nclassifier-specific basis. In this work, we take a holistic look at adversarial\\nexamples for non-parametric methods. We first provide a general region-based\\nattack that applies to a wide range of classifiers, including nearest\\nneighbors, decision trees, and random forests. Motivated by the close\\nconnection between non-parametric methods and the Bayes Optimal classifier, we\\nnext exhibit a robust analogue to the Bayes Optimal, and we use it to motivate\\na novel and generic defense that we call adversarial pruning. We empirically\\nshow that the region-based attack and adversarial pruning defense are either\\nbetter than or competitive with existing attacks and defenses for\\nnon-parametric methods, while being considerably more generally applicable.\\n\\n    ', '\\nAbstract:  Recent works show that deep neural networks trained on image classification\\ndataset bias towards textures. Those models are easily fooled by applying small\\nhigh-frequency perturbations to clean images. In this paper, we learn robust\\nimage classification models by removing high-frequency components.\\nSpecifically, we develop a differentiable high-frequency suppression module\\nbased on discrete Fourier transform (DFT). Combining with adversarial training,\\nwe won the 5th place in the IJCAI-2019 Alibaba Adversarial AI Challenge. Our\\ncode is available online.\\n\\n    ', \"\\nAbstract:  The arms race between attacks and defenses for machine learning models has\\ncome to a forefront in recent years, in both the security community and the\\nprivacy community. However, one big limitation of previous research is that the\\nsecurity domain and the privacy domain have typically been considered\\nseparately. It is thus unclear whether the defense methods in one domain will\\nhave any unexpected impact on the other domain.\\nIn this paper, we take a step towards resolving this limitation by combining\\nthe two domains. In particular, we measure the success of membership inference\\nattacks against six state-of-the-art defense methods that mitigate the risk of\\nadversarial examples (i.e., evasion attacks). Membership inference attacks\\ndetermine whether or not an individual data record has been part of a model's\\ntraining set. The accuracy of such attacks reflects the information leakage of\\ntraining algorithms about individual members of the training set. Adversarial\\ndefense methods against adversarial examples influence the model's decision\\nboundaries such that model predictions remain unchanged for a small area around\\neach input. However, this objective is optimized on training data. Thus,\\nindividual data records in the training set have a significant influence on\\nrobust models. This makes the models more vulnerable to inference attacks.\\nTo perform the membership inference attacks, we leverage the existing\\ninference methods that exploit model predictions. We also propose two new\\ninference methods that exploit structural properties of robust models on\\nadversarially perturbed data. Our experimental evaluation demonstrates that\\ncompared with the natural training (undefended) approach, adversarial defense\\nmethods can indeed increase the target model's risk against membership\\ninference attacks.\\n\\n    \", '\\nAbstract:  Despite the improved accuracy of deep neural networks, the discovery of\\nadversarial examples has raised serious safety concerns. In this paper, we\\nstudy two variants of pointwise robustness, the maximum safe radius problem,\\nwhich for a given input sample computes the minimum distance to an adversarial\\nexample, and the feature robustness problem, which aims to quantify the\\nrobustness of individual features to adversarial perturbations. We demonstrate\\nthat, under the assumption of Lipschitz continuity, both problems can be\\napproximated using finite optimisation by discretising the input space, and the\\napproximation has provable guarantees, i.e., the error is bounded. We then show\\nthat the resulting optimisation problems can be reduced to the solution of\\ntwo-player turn-based games, where the first player selects features and the\\nsecond perturbs the image within the feature. While the second player aims to\\nminimise the distance to an adversarial example, depending on the optimisation\\nobjective the first player can be cooperative or competitive. We employ an\\nanytime approach to solve the games, in the sense of approximating the value of\\na game by monotonically improving its upper and lower bounds. The Monte Carlo\\ntree search algorithm is applied to compute upper bounds for both games, and\\nthe Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used\\nto compute lower bounds for the maximum safety radius and feature robustness\\ngames. When working on the upper bound of the maximum safe radius problem, our\\ntool demonstrates competitive performance against existing adversarial example\\ncrafting algorithms. Furthermore, we show how our framework can be deployed to\\nevaluate pointwise robustness of neural networks in safety-critical\\napplications such as traffic sign recognition in self-driving cars.\\n\\n    ', '\\nAbstract:  Empirical adversarial risk minimization (EARM) is a widely used mathematical\\nframework to robustly train deep neural nets (DNNs) that are resistant to\\nadversarial attacks. However, both natural and robust accuracies, in\\nclassifying clean and adversarial images, respectively, of the trained robust\\nmodels are far from satisfactory. In this work, we unify the theory of optimal\\ncontrol of transport equations with the practice of training and testing of\\nResNets. Based on this unified viewpoint, we propose a simple yet effective\\nResNets ensemble algorithm to boost the accuracy of the robustly trained model\\non both clean and adversarial images. The proposed algorithm consists of two\\ncomponents: First, we modify the base ResNets by injecting a variance specified\\nGaussian noise to the output of each residual mapping. Second, we average over\\nthe production of multiple jointly trained modified ResNets to get the final\\nprediction. These two steps give an approximation to the Feynman-Kac formula\\nfor representing the solution of a transport equation with viscosity, or a\\nconvection-diffusion equation. For the CIFAR10 benchmark, this simple algorithm\\nleads to a robust model with a natural accuracy of {\\\\bf 85.62}\\\\% on clean\\nimages and a robust accuracy of ${\\\\bf 57.94 \\\\%}$ under the 20 iterations of the\\nIFGSM attack, which outperforms the current state-of-the-art in defending\\nagainst IFGSM attack on the CIFAR10. Both natural and robust accuracies of the\\nproposed ResNets ensemble can be improved dynamically as the building block\\nResNet advances. The code is available at:\\n\\\\url{this https URL}.\\n\\n    ', '\\nAbstract:  Deep neural networks are known to be vulnerable to adversarial attacks. This\\nexposes them to potential exploits in security-sensitive applications and\\nhighlights their lack of robustness. This paper uses a variational auto-encoder\\n(VAE) to defend against adversarial attacks for image classification tasks.\\nThis VAE defense has a few nice properties: (1) it is quite flexible and its\\nuse of randomness makes it harder to attack; (2) it can learn disentangled\\nrepresentations that prevent blurry reconstruction; and (3) a patch-wise VAE\\ndefense strategy is used that does not require retraining for different size\\nimages. For moderate to severe attacks, this system outperforms or closely\\nmatches the performance of JPEG compression, with the best quality parameter.\\nIt also has more flexibility and potential for improvement via training.\\n\\n    ', '\\nAbstract:  We present a modern scalable reinforcement learning agent called SEED\\n(Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we\\nshow that it is not only possible to train on millions of frames per second but\\nalso to lower the cost of experiments compared to current methods. We achieve\\nthis with a simple architecture that features centralized inference and an\\noptimized communication layer. SEED adopts two state of the art distributed\\nalgorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is\\nevaluated on Atari-57, DeepMind Lab and Google Research Football. We improve\\nthe state of the art on Football and are able to reach state of the art on\\nAtari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to\\n80% cost reduction for running experiments is achieved. The implementation\\nalong with experiments is open-sourced so that results can be reproduced and\\nnovel ideas tried out.\\n\\n    ', '\\nAbstract:  We present a simple yet effective end-to-end trainable deep network with\\ngeometry-inspired convolutional operators for detecting vanishing points in\\nimages. Traditional convolutional neural networks rely on aggregating edge\\nfeatures and do not have mechanisms to directly exploit the geometric\\nproperties of vanishing points as the intersections of parallel lines. In this\\nwork, we identify a canonical conic space in which the neural network can\\neffectively compute the global geometric information of vanishing points\\nlocally, and we propose a novel operator named conic convolution that can be\\nimplemented as regular convolutions in this space. This new operator explicitly\\nenforces feature extractions and aggregations along the structural lines and\\nyet has the same number of parameters as the regular 2D convolution. Our\\nextensive experiments on both synthetic and real-world datasets show that the\\nproposed operator significantly improves the performance of vanishing point\\ndetection over traditional methods. The code and dataset have been made\\npublicly available at this https URL.\\n\\n    ', '\\nAbstract:  Recent studies proved that deep learning approaches achieve remarkable\\nresults on face detection task. On the other hand, the advances gave rise to a\\nnew problem associated with the security of the deep convolutional neural\\nnetwork models unveiling potential risks of DCNNs based applications. Even\\nminor input changes in the digital domain can result in the network being\\nfooled. It was shown then that some deep learning-based face detectors are\\nprone to adversarial attacks not only in a digital domain but also in the real\\nworld. In the paper, we investigate the security of the well-known cascade CNN\\nface detection system - MTCNN and introduce an easily reproducible and a robust\\nway to attack it. We propose different face attributes printed on an ordinary\\nwhite and black printer and attached either to the medical face mask or to the\\nface directly. Our approach is capable of breaking the MTCNN detector in a\\nreal-world scenario.\\n\\n    ', '\\nAbstract:  Pedestrian detection relying on deep convolution neural networks has made\\nsignificant progress. Though promising results have been achieved on standard\\npedestrians, the performance on heavily occluded pedestrians remains far from\\nsatisfactory. The main culprits are intra-class occlusions involving other\\npedestrians and inter-class occlusions caused by other objects, such as cars\\nand bicycles. These result in a multitude of occlusion patterns. We propose an\\napproach for occluded pedestrian detection with the following contributions.\\nFirst, we introduce a novel mask-guided attention network that fits naturally\\ninto popular pedestrian detection pipelines. Our attention network emphasizes\\non visible pedestrian regions while suppressing the occluded ones by modulating\\nfull body features. Second, we empirically demonstrate that coarse-level\\nsegmentation annotations provide reasonable approximation to their dense\\npixel-wise counterparts. Experiments are performed on CityPersons and Caltech\\ndatasets. Our approach sets a new state-of-the-art on both datasets. Our\\napproach obtains an absolute gain of 9.5% in log-average miss rate, compared to\\nthe best reported results on the heavily occluded (HO) pedestrian set of\\nCityPersons test set. Further, on the HO pedestrian set of Caltech dataset, our\\nmethod achieves an absolute gain of 5.0% in log-average miss rate, compared to\\nthe best reported results. Code and models are available at:\\nthis https URL.\\n\\n    ', \"\\nAbstract:  We propose a new, two-stage approach to the vertebrae centroid detection and\\nlocalization problem. The first stage detects where the vertebrae appear in the\\nscan using 3D samples, the second identifies the specific vertebrae within that\\nregion-of-interest using 2D slices. Our solution utilizes new techniques to\\nimprove the accuracy of the algorithm such as a revised approach to dense\\nlabelling from sparse centroid annotations and usage of large anisotropic\\nkernels in the base level of a U-net architecture to maximize the receptive\\nfield. Our method improves the state-of-the-art's mean localization accuracy by\\n0.87mm on a publicly available spine CT benchmark.\\n\\n    \", '\\nAbstract:  We compare the model-free reinforcement learning with the model-based\\napproaches through the lens of the expressive power of neural networks for\\npolicies, $Q$-functions, and dynamics. We show, theoretically and empirically,\\nthat even for one-dimensional continuous state space, there are many MDPs whose\\noptimal $Q$-functions and policies are much more complex than the dynamics. We\\nhypothesize many real-world MDPs also have a similar property. For these MDPs,\\nmodel-based planning is a favorable algorithm, because the resulting policies\\ncan approximate the optimal policy significantly better than a neural network\\nparameterization can, and model-free or model-based policy optimization rely on\\npolicy parameterization. Motivated by the theory, we apply a simple multi-step\\nmodel-based bootstrapping planner (BOOTS) to bootstrap a weak $Q$-function into\\na stronger policy. Empirical results show that applying BOOTS on top of\\nmodel-based or model-free policy optimization algorithms at the test time\\nimproves the performance on MuJoCo benchmark tasks.\\n\\n    ', '\\nAbstract:  Due to the inherent uncertainty of data, the problem of predicting partial\\nranking from pairwise comparison data with ties has attracted increasing\\ninterest in recent years. However, in real-world scenarios, different\\nindividuals often hold distinct preferences. It might be misleading to merely\\nlook at a global partial ranking while ignoring personal diversity. In this\\npaper, instead of learning a global ranking which is agreed with the consensus,\\nwe pursue the tie-aware partial ranking from an individualized perspective.\\nParticularly, we formulate a unified framework which not only can be used for\\nindividualized partial ranking prediction, but also be helpful for abnormal\\nuser selection. This is realized by a variable splitting-based algorithm called\\n\\\\ilbi. Specifically, our algorithm generates a sequence of estimations with a\\nregularization path, where both the hyperparameters and model parameters are\\nupdated. At each step of the path, the parameters can be decomposed into three\\northogonal parts, namely, abnormal signals, personalized signals and random\\nnoise. The abnormal signals can serve the purpose of abnormal user selection,\\nwhile the abnormal signals and personalized signals together are mainly\\nresponsible for individual partial ranking prediction. Extensive experiments on\\nsimulated and real-world datasets demonstrate that our new approach\\nsignificantly outperforms state-of-the-art alternatives. The code is now\\navailiable at this https URL.\\n\\n    ', '\\nAbstract:  Transfer learning makes use of data or knowledge in one problem to help solve\\na different, yet related, problem. It is particularly useful in brain-computer\\ninterfaces (BCIs), for coping with variations among different subjects and/or\\ntasks. This paper considers offline unsupervised cross-subject\\nelectroencephalogram (EEG) classification, i.e., we have labeled EEG trials\\nfrom one or more source subjects, but only unlabeled EEG trials from the target\\nsubject. We propose a novel manifold embedded knowledge transfer (MEKT)\\napproach, which first aligns the covariance matrices of the EEG trials in the\\nRiemannian manifold, extracts features in the tangent space, and then performs\\ndomain adaptation by minimizing the joint probability distribution shift\\nbetween the source and the target domains, while preserving their geometric\\nstructures. MEKT can cope with one or multiple source domains, and can be\\ncomputed efficiently. We also propose a domain transferability estimation (DTE)\\napproach to identify the most beneficial source domains, in case there are a\\nlarge number of source domains. Experiments on four EEG datasets from two\\ndifferent BCI paradigms demonstrated that MEKT outperformed several\\nstate-of-the-art transfer learning approaches, and DTE can reduce more than\\nhalf of the computational cost when the number of source subjects is large,\\nwith little sacrifice of classification accuracy.\\n\\n    ', '\\nAbstract:  Ancient history relies on disciplines such as epigraphy, the study of ancient\\ninscribed texts, for evidence of the recorded past. However, these texts,\\n\"inscriptions\", are often damaged over the centuries, and illegible parts of\\nthe text must be restored by specialists, known as epigraphists. This work\\npresents Pythia, the first ancient text restoration model that recovers missing\\ncharacters from a damaged text input using deep neural networks. Its\\narchitecture is carefully designed to handle long-term context information, and\\ndeal efficiently with missing or corrupted character and word representations.\\nTo train it, we wrote a non-trivial pipeline to convert PHI, the largest\\ndigital corpus of ancient Greek inscriptions, to machine actionable text, which\\nwe call PHI-ML. On PHI-ML, Pythia\\'s predictions achieve a 30.1% character error\\nrate, compared to the 57.3% of human epigraphists. Moreover, in 73.5% of cases\\nthe ground-truth sequence was among the Top-20 hypotheses of Pythia, which\\neffectively demonstrates the impact of this assistive method on the field of\\ndigital epigraphy, and sets the state-of-the-art in ancient text restoration.\\n\\n    ', '\\nAbstract:  It is very challenging to work with low-resource languages due to the\\ninadequate availability of data. Using a dictionary to map independently\\ntrained word embeddings into a shared vector space has proved to be very useful\\nin learning bilingual embeddings in the past. Here we have tried to map\\nindividual embeddings of words in English and their corresponding translated\\nwords in low-resource languages like Estonian, Slovenian, Slovakian, and\\nHungarian. We have used a supervised learning approach. We report accuracy\\nscores through various retrieval strategies which show that it is possible to\\napproach challenging tasks in Natural Language Processing like machine\\ntranslation for such languages, provided that we have at least some amount of\\nproper bilingual data. We also conclude that we can follow an unsupervised\\nlearning path on monolingual text data as that is more suitable for\\nlow-resource languages.\\n\\n    ', '\\nAbstract:  In low-resource settings, the performance of supervised labeling models can\\nbe improved with automatically annotated or distantly supervised data, which is\\ncheap to create but often noisy. Previous works have shown that significant\\nimprovements can be reached by injecting information about the confusion\\nbetween clean and noisy labels in this additional training data into the\\nclassifier training. However, for noise estimation, these approaches either do\\nnot take the input features (in our case word embeddings) into account, or they\\nneed to learn the noise modeling from scratch which can be difficult in a\\nlow-resource setting. We propose to cluster the training data using the input\\nfeatures and then compute different confusion matrices for each cluster. To the\\nbest of our knowledge, our approach is the first to leverage feature-dependent\\nnoise modeling with pre-initialized confusion matrices. We evaluate on\\nlow-resource named entity recognition settings in several languages, showing\\nthat our methods improve upon other confusion-matrix based methods by up to 9%.\\n\\n    ', \"\\nAbstract:  Currently, there is a limited understanding of how data privacy concerns vary\\nacross the world. The Cambridge Analytica scandal triggered a wide-ranging\\ndiscussion on social media about user data collection and use practices. We\\nconducted an inter-language study of this online conversation to compare how\\npeople speaking different languages react to data privacy breaches. We\\ncollected tweets about the scandal written in Spanish and English between April\\nand July 2018. We used the Meaning Extraction Method in both datasets to\\nidentify their main topics. They reveal a similar emphasis on Zuckerberg's\\nhearing in the US Congress and the scandal's impact on political issues.\\nHowever, our analysis also shows that while English speakers tend to attribute\\nresponsibilities to companies, Spanish speakers are more likely to connect them\\nto people. These findings show the potential of inter-language comparisons of\\nsocial media data to deepen the understanding of cultural differences in data\\nprivacy perspectives.\\n\\n    \", '\\nAbstract:  Large-scale and multidimensional spatiotemporal data sets are becoming\\nubiquitous in many real-world applications such as monitoring urban traffic and\\nair quality. Making predictions on these time series has become a critical\\nchallenge due to not only the large-scale and high-dimensional nature but also\\nthe considerable amount of missing data. In this paper, we propose a Bayesian\\ntemporal factorization (BTF) framework for modeling multidimensional time\\nseries---in particular spatiotemporal data---in the presence of missing values.\\nBy integrating low-rank matrix/tensor factorization and vector autoregressive\\n(VAR) process into a single probabilistic graphical model, this framework can\\ncharacterize both global and local consistencies in large-scale time series\\ndata. The graphical model allows us to effectively perform probabilistic\\npredictions and produce uncertainty estimates without imputing those missing\\nvalues. We develop efficient Gibbs sampling algorithms for model inference and\\ntest the proposed BTF framework on several real-world spatiotemporal data sets\\nfor both missing data imputation and short-term/long-term rolling prediction\\ntasks. The numerical experiments demonstrate the superiority of the proposed\\nBTF approaches over many state-of-the-art techniques.\\n\\n    ', '\\nAbstract:  We introduce a recent symplectic integration scheme derived for solving\\nphysically motivated systems with non-separable Hamiltonians. We show its\\nrelevance to Riemannian manifold Hamiltonian Monte Carlo (RMHMC) and provide an\\nalternative to the currently used generalised leapfrog symplectic integrator,\\nwhich relies on solving multiple fixed point iterations to convergence. Via\\nthis approach, we are able to reduce the number of higher-order derivative\\ncalculations per leapfrog step. We explore the implications of this integrator\\nand demonstrate its efficacy in reducing the computational burden of RMHMC. Our\\ncode is provided in a new open-source Python package, hamiltorch.\\n\\n    ', \"\\nAbstract:  We evaluate three simple, normalization-centric changes to improve\\nTransformer training. First, we show that pre-norm residual connections\\n(PreNorm) and smaller initializations enable warmup-free, validation-based\\ntraining with large learning rates. Second, we propose $\\\\ell_2$ normalization\\nwith a single scale parameter (ScaleNorm) for faster training and better\\nperformance. Finally, we reaffirm the effectiveness of normalizing word\\nembeddings to a fixed length (FixNorm). On five low-resource translation pairs\\nfrom TED Talks-based corpora, these changes always converge, giving an average\\n+1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on\\nIWSLT'15 English-Vietnamese. We observe sharper performance curves, more\\nconsistent gradient norms, and a linear relationship between activation scaling\\nand decoder depth. Surprisingly, in the high-resource setting (WMT'14\\nEnglish-German), ScaleNorm and FixNorm remain competitive but PreNorm degrades\\nperformance.\\n\\n    \", '\\nAbstract:  We study a security threat to batch reinforcement learning and control where\\nthe attacker aims to poison the learned policy. The victim is a reinforcement\\nlearner / controller which first estimates the dynamics and the rewards from a\\nbatch data set, and then solves for the optimal policy with respect to the\\nestimates. The attacker can modify the data set slightly before learning\\nhappens, and wants to force the learner into learning a target policy chosen by\\nthe attacker. We present a unified framework for solving batch policy poisoning\\nattacks, and instantiate the attack on two standard victims: tabular certainty\\nequivalence learner in reinforcement learning and linear quadratic regulator in\\ncontrol. We show that both instantiation result in a convex optimization\\nproblem on which global optimality is guaranteed, and provide analysis on\\nattack feasibility and attack cost. Experiments show the effectiveness of\\npolicy poisoning attacks.\\n\\n    ', \"\\nAbstract:  While we would like agents that can coordinate with humans, current\\nalgorithms such as self-play and population-based training create agents that\\ncan coordinate with themselves. Agents that assume their partner to be optimal\\nor similar to them can converge to coordination protocols that fail to\\nunderstand and be understood by humans. To demonstrate this, we introduce a\\nsimple environment that requires challenging coordination, based on the popular\\ngame Overcooked, and learn a simple model that mimics human play. We evaluate\\nthe performance of agents trained via self-play and population-based training.\\nThese agents perform very well when paired with themselves, but when paired\\nwith our human model, they are significantly worse than agents designed to play\\nwith the human model. An experiment with a planning algorithm yields the same\\nconclusion, though only when the human-aware planner is given the exact human\\nmodel that it is playing with. A user study with real humans shows this pattern\\nas well, though less strongly. Qualitatively, we find that the gains come from\\nhaving the agent adapt to the human's gameplay. Given this result, we suggest\\nseveral approaches for designing agents that learn about humans in order to\\nbetter coordinate with them. Code is available at\\nthis https URL.\\n\\n    \", '\\nAbstract:  We present an image translation approach to generate augmented data for\\nmitigating data imbalances in a dataset of histopathology images of colorectal\\npolyps, adenomatous tumors that can lead to colorectal cancer if left\\nuntreated. By applying cycle-consistent generative adversarial networks\\n(CycleGANs) to a source domain of normal colonic mucosa images, we generate\\nsynthetic colorectal polyp images that belong to diagnostically less common\\npolyp classes. Generated images maintain the general structure of their source\\nimage but exhibit adenomatous features that can be enhanced with our proposed\\nfiltration module, called Path-Rank-Filter. We evaluate the quality of\\ngenerated images through Turing tests with four gastrointestinal pathologists,\\nfinding that at least two of the four pathologists could not identify generated\\nimages at a statistically significant level. Finally, we demonstrate that using\\nCycleGAN-generated images to augment training data improves the AUC of a\\nconvolutional neural network for detecting sessile serrated adenomas by over\\n10%, suggesting that our approach might warrant further research for other\\nhistopathology image classification tasks.\\n\\n    ', '\\nAbstract:  Unsupervised domain adaptation aims to generalize the hypothesis trained in a\\nsource domain to an unlabeled target domain. One popular approach to this\\nproblem is to learn domain-invariant embeddings for both domains. In this work,\\nwe study, theoretically and empirically, the effect of the embedding complexity\\non generalization to the target domain. In particular, this complexity affects\\nan upper bound on the target risk; this is reflected in experiments, too. Next,\\nwe specify our theoretical framework to multilayer neural networks. As a\\nresult, we develop a strategy that mitigates sensitivity to the embedding\\ncomplexity, and empirically achieves performance on par with or better than the\\nbest layer-dependent complexity tradeoff.\\n\\n    ', '\\nAbstract:  Diagnosing different retinal diseases from Spectral Domain Optical Coherence\\nTomography (SD-OCT) images is a challenging task. Different automated\\napproaches such as image processing, machine learning and deep learning\\nalgorithms have been used for early detection and diagnosis of retinal\\ndiseases. Unfortunately, these are prone to error and computational\\ninefficiency, which requires further intervention from human experts. In this\\npaper, we propose a novel convolution neural network architecture to\\nsuccessfully distinguish between different degeneration of retinal layers and\\ntheir underlying causes. The proposed novel architecture outperforms other\\nclassification models while addressing the issue of gradient explosion. Our\\napproach reaches near perfect accuracy of 99.8% and 100% for two separately\\navailable Retinal SD-OCT data-set respectively. Additionally, our architecture\\npredicts retinal diseases in real time while outperforming human\\ndiagnosticians.\\n\\n    ', '\\nAbstract:  Recent works on domain adaptation exploit adversarial training to obtain\\ndomain-invariant feature representations from the joint learning of feature\\nextractor and domain discriminator networks. However, domain adversarial\\nmethods render suboptimal performances since they attempt to match the\\ndistributions among the domains without considering the task at hand. We\\npropose Drop to Adapt (DTA), which leverages adversarial dropout to learn\\nstrongly discriminative features by enforcing the cluster assumption.\\nAccordingly, we design objective functions to support robust domain adaptation.\\nWe demonstrate efficacy of the proposed method on various experiments and\\nachieve consistent improvements in both image classification and semantic\\nsegmentation tasks. Our source code is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  As evolutionary algorithms (EAs) are general-purpose optimization algorithms,\\nrecent theoretical studies have tried to analyze their performance for solving\\ngeneral problem classes, with the goal of providing a general theoretical\\nexplanation of the behavior of EAs. Particularly, a simple multi-objective EA,\\ni.e., GSEMO, has been shown to be able to achieve good polynomial-time\\napproximation guarantees for submodular optimization, where the objective\\nfunction is only required to satisfy some properties but without explicit\\nformulation. Submodular optimization has wide applications in diverse areas,\\nand previous studies have considered the cases where the objective functions\\nare monotone submodular, monotone non-submodular, or non-monotone submodular.\\nTo complement this line of research, this paper studies the problem class of\\nmaximizing monotone approximately submodular minus modular functions (i.e.,\\n$f=g-c$) with a size constraint, where $g$ is a non-negative monotone\\napproximately submodular function and $c$ is a non-negative modular function,\\nresulting in the objective function $f$ being non-monotone non-submodular. We\\nprove that the GSEMO can achieve the best-known polynomial-time approximation\\nguarantee. Empirical studies on the applications of Bayesian experimental\\ndesign and directed vertex cover show the excellent performance of the GSEMO.\\n\\n    ', '\\nAbstract:  A great deal of historical corpora suffer from errors introduced by the OCR\\n(optical character recognition) methods used in the digitization process.\\nCorrecting these errors manually is a time-consuming process and a great part\\nof the automatic approaches have been relying on rules or supervised machine\\nlearning. We present a fully automatic unsupervised way of extracting parallel\\ndata for training a character-based sequence-to-sequence NMT (neural machine\\ntranslation) model to conduct OCR error correction.\\n\\n    ', '\\nAbstract:  Humans tackle new problems by making inferences that go far beyond the\\ninformation available, reusing what they have previously learned, and weighing\\ndifferent alternatives in the face of uncertainty. Incorporating these\\nabilities in an artificial system is a major objective in machine learning.\\nTowards this goal, we introduce a Bayesian method based on Gaussian Processes\\n(GPs) that can learn efficiently from a limited amount of data and generalize\\nacross new tasks and domains. We frame few-shot learning as a model selection\\nproblem by learning a deep kernel across tasks, and then using this kernel as a\\ncovariance function in a GP prior for Bayesian inference. This probabilistic\\ntreatment allows for cross-domain flexibility, and uncertainty quantification.\\nWe provide substantial experimental evidence, showing that the proposed method\\nis better than several state-of-the-art algorithms in few-shot regression and\\ncross-domain classification.\\n\\n    ', '\\nAbstract:  We consider the problem of constructing a reduced-rank regression model whose\\ncoefficient parameter is represented as a singular value decomposition with\\nsparse singular vectors. The traditional estimation procedure for the\\ncoefficient parameter often fails when the true rank of the parameter is high.\\nTo overcome this issue, we develop an estimation algorithm with rank and\\nvariable selection via sparse regularization and manifold optimization, which\\nenables us to obtain an accurate estimation of the coefficient parameter even\\nif the true rank of the coefficient parameter is high. Using sparse\\nregularization, we can also select an optimal value of the rank. We conduct\\nMonte Carlo experiments and real data analysis to illustrate the effectiveness\\nof our proposed method.\\n\\n    ', '\\nAbstract:  We present the first dataset targeted at end-to-end NLG in Czech in the\\nrestaurant domain, along with several strong baseline models using the\\nsequence-to-sequence approach. While non-English NLG is under-explored in\\ngeneral, Czech, as a morphologically rich language, makes the task even harder:\\nSince Czech requires inflecting named entities, delexicalization or copy\\nmechanisms do not work out-of-the-box and lexicalizing the generated outputs is\\nnon-trivial.\\nIn our experiments, we present two different approaches to this this problem:\\n(1) using a neural language model to select the correct inflected form while\\nlexicalizing, (2) a two-step generation setup: our sequence-to-sequence model\\ngenerates an interleaved sequence of lemmas and morphological tags, which are\\nthen inflected by a morphological generator.\\n\\n    ', \"\\nAbstract:  The evolution of social media users' behavior over time complicates\\nuser-level comparison tasks such as verification, classification, clustering,\\nand ranking. As a result, naïve approaches may fail to generalize to new\\nusers or even to future observations of previously known users. In this paper,\\nwe propose a novel procedure to learn a mapping from short episodes of user\\nactivity on social media to a vector space in which the distance between points\\ncaptures the similarity of the corresponding users' invariant features. We fit\\nthe model by optimizing a surrogate metric learning objective over a large\\ncorpus of unlabeled social media content. Once learned, the mapping may be\\napplied to users not seen at training time and enables efficient comparisons of\\nusers in the resulting vector space. We present a comprehensive evaluation to\\nvalidate the benefits of the proposed approach using data from Reddit, Twitter,\\nand Wikipedia.\\n\\n    \", '\\nAbstract:  Recurrent neural networks (RNNs) are known to be difficult to train due to\\nthe gradient vanishing and exploding problems and thus difficult to learn\\nlong-term patterns. Long short-term memory (LSTM) was developed to address\\nthese problems, but the use of hyperbolic tangent and the sigmoid activation\\nfunctions results in gradient decay over layers. Consequently, construction of\\nan efficiently trainable deep RNN is challenging. Moreover, training of LSTM is\\nvery compute-intensive as the recurrent connection using matrix product is\\nconducted at every time step. To address these problems, this paper proposes a\\nnew type of RNNs with the recurrent connection formulated as Hadamard product,\\nreferred to as independently recurrent neural network (IndRNN), where neurons\\nin the same layer are independent of each other and connected across layers.\\nThe gradient vanishing and exploding problems are solved in IndRNN by simply\\nregulating the recurrent weights, and thus long-term dependencies can be\\nlearned. Moreover, an IndRNN can work with non-saturated activation functions\\nsuch as ReLU and be still trained robustly. Different deeper IndRNN\\narchitectures, including the basic stacked IndRNN, residual IndRNN and densely\\nconnected IndRNN, have been investigated, all of which can be much deeper than\\nthe existing RNNs. Furthermore, IndRNN reduces the computation at each time\\nstep and can be over 10 times faster than the LSTM. The code is made publicly\\navailable at this https URL. Experimental\\nresults have shown that the proposed IndRNN is able to process very long\\nsequences (over 5000 time steps), can be used to construct very deep networks\\n(the 21 layers residual IndRNN and deep densely connected IndRNN used in the\\nexperiment for example). Better performances have been achieved on various\\ntasks with IndRNNs compared with the traditional RNN and LSTM.\\n\\n    ', '\\nAbstract:  Ground-based whole sky cameras are extensively used for localized monitoring\\nof clouds nowadays. They capture hemispherical images of the sky at regular\\nintervals using a fisheye lens. In this paper, we propose a framework for\\nestimating solar irradiance from pictures taken by those imagers. Unlike\\npyranometers, such sky images contain information about cloud coverage and can\\nbe used to derive cloud movement. An accurate estimation of solar irradiance\\nusing solely those images is thus a first step towards short-term forecasting\\nof solar energy generation based on cloud movement. We derive and validate our\\nmodel using pyranometers co-located with our whole sky imagers. We achieve a\\nbetter performance in estimating solar irradiance and in particular its\\nshort-term variations as compared to other related methods using ground-based\\nobservations.\\n\\n    ', \"\\nAbstract:  Social media have become a rich source of data, particularly in health\\nresearch. Yet, the use of such data raises significant ethical questions about\\nthe need for the informed consent of those being studied. Consent mechanisms,\\nif even obtained, are typically broad and inflexible, or place a significant\\nburden on the participant. Machine learning algorithms show much promise for\\nfacilitating a 'middle ground' approach: using trained models to predict and\\nautomate granular consent decisions. Such techniques, however, raise a myriad\\nof follow-on ethical and technical considerations. In this paper, we present an\\nexploratory user study (n = 67) in which we find that we can predict the\\nappropriate flow of health-related social media data with reasonable accuracy,\\nwhile minimising undesired data leaks. We then attempt to deconstruct the\\nfindings of this study, identifying and discussing a number of real-world\\nimplications if such a technique were put into practice.\\n\\n    \", '\\nAbstract:  To improve the discriminative and generalization ability of lightweight\\nnetwork for face recognition, we propose an efficient variable group\\nconvolutional network called VarGFaceNet. Variable group convolution is\\nintroduced by VarGNet to solve the conflict between small computational cost\\nand the unbalance of computational intensity inside a block. We employ variable\\ngroup convolution to design our network which can support large scale face\\nidentification while reduce computational cost and parameters. Specifically, we\\nuse a head setting to reserve essential information at the start of the network\\nand propose a particular embedding setting to reduce parameters of\\nfully-connected layer for embedding. To enhance interpretation ability, we\\nemploy an equivalence of angular distillation loss to guide our lightweight\\nnetwork and we apply recursive knowledge distillation to relieve the\\ndiscrepancy between the teacher model and the student model. The champion of\\ndeepglint-light track of LFR (2019) challenge demonstrates the effectiveness of\\nour model and approach. Implementation of VarGFaceNet will be released at\\nthis https URL soon.\\n\\n    ', '\\nAbstract:  Biomedical challenges have become the de facto standard for benchmarking\\nbiomedical image analysis algorithms. While the number of challenges is\\nsteadily increasing, surprisingly little effort has been invested in ensuring\\nhigh quality design, execution and reporting for these international\\ncompetitions. Specifically, results analysis and visualization in the event of\\nuncertainties have been given almost no attention in the literature. Given\\nthese shortcomings, the contribution of this paper is two-fold: (1) We present\\na set of methods to comprehensively analyze and visualize the results of\\nsingle-task and multi-task challenges and apply them to a number of simulated\\nand real-life challenges to demonstrate their specific strengths and\\nweaknesses; (2) We release the open-source framework challengeR as part of this\\nwork to enable fast and wide adoption of the methodology proposed in this\\npaper. Our approach offers an intuitive way to gain important insights into the\\nrelative and absolute performance of algorithms, which cannot be revealed by\\ncommonly applied visualization techniques. This is demonstrated by the\\nexperiments performed within this work. Our framework could thus become an\\nimportant tool for analyzing and visualizing challenge results in the field of\\nbiomedical image analysis and beyond.\\n\\n    ', '\\nAbstract:  Recognizing emotions in conversations is a challenging task due to the\\npresence of contextual dependencies governed by self- and inter-personal\\ninfluences. Recent approaches have focused on modeling these dependencies\\nprimarily via supervised learning. However, purely supervised strategies demand\\nlarge amounts of annotated data, which is lacking in most of the available\\ncorpora in this task. To tackle this challenge, we look at transfer learning\\napproaches as a viable alternative. Given the large amount of available\\nconversational data, we investigate whether generative conversational models\\ncan be leveraged to transfer affective knowledge for the target task of\\ndetecting emotions in context. We propose an approach where we first train a\\nneural dialogue model and then perform parameter transfer to initiate our\\ntarget model. Apart from the traditional pre-trained sentence encoders, we also\\nincorporate parameter transfer from the recurrent components that model\\ninter-sentence context across the whole conversation. Based on this idea, we\\nperform several experiments across multiple datasets and find improvement in\\nperformance and robustness against limited training data. Our models also\\nachieve better validation performances in significantly fewer epochs. Overall,\\nwe infer that knowledge acquired from dialogue generators can indeed help\\nrecognize emotions in conversations.\\n\\n    ', '\\nAbstract:  Recent advances in NLP with language models such as BERT, GPT-2, XLNet or\\nXLM, have allowed surpassing human performance on Reading Comprehension tasks\\non large-scale datasets (e.g. SQuAD), and this opens up many perspectives for\\nConversational AI. However, task-specific datasets are mostly in English which\\nmakes it difficult to acknowledge progress in foreign languages. Fortunately,\\nstate-of-the-art models are now being pre-trained on multiple languages (e.g.\\nBERT was released in a multilingual version managing a hundred languages) and\\nare exhibiting ability for zero-shot transfer from English to others languages\\non XNLI. In this paper, we run experiments that show that multilingual BERT,\\ntrained to solve the complex Question Answering task defined in the English\\nSQuAD dataset, is able to achieve the same task in Japanese and French. It even\\noutperforms the best published results of a baseline which explicitly combines\\nan English model for Reading Comprehension and a Machine Translation Model for\\ntransfer. We run further tests on crafted cross-lingual QA datasets (context in\\none language and question in another) to provide intuition on the mechanisms\\nthat allow BERT to transfer the task from one language to another. Finally, we\\nintroduce our application Kate. Kate is a conversational agent dedicated to HR\\nsupport for employees that exploits multilingual models to accurately answer to\\nquestions, in several languages, directly from information web pages.\\n\\n    ', '\\nAbstract:  Contrastive unsupervised representation learning (CURL) is the\\nstate-of-the-art technique to learn representations (as a set of features) from\\nunlabelled data. While CURL has collected several empirical successes recently,\\ntheoretical understanding of its performance was still missing. In a recent\\nwork, Arora et al. (2019) provide the first generalisation bounds for CURL,\\nrelying on a Rademacher complexity. We extend their framework to the flexible\\nPAC-Bayes setting, allowing to deal with the non-iid setting. We present\\nPAC-Bayesian generalisation bounds for CURL, which are then used to derive a\\nnew representation learning algorithm. Numerical experiments on real-life\\ndatasets illustrate that our algorithm achieves competitive accuracy, and\\nyields generalisation bounds with non-vacuous values.\\n\\n    ', '\\nAbstract:  Methods tackling multi-object tracking need to estimate the number of targets\\nin the sensing area as well as to estimate their continuous state. While the\\nmajority of existing methods focus on data association, precise state (3D pose)\\nestimation is often only coarsely estimated by approximating targets with\\ncentroids or (3D) bounding boxes. However, in automotive scenarios, motion\\nperception of surrounding agents is critical and inaccuracies in the vehicle\\nclose-range can have catastrophic consequences. In this work, we focus on\\nprecise 3D track state estimation and propose a learning-based approach for\\nobject-centric relative motion estimation of partially observed objects.\\nInstead of approximating targets with their centroids, our approach is capable\\nof utilizing noisy 3D point segments of objects to estimate their motion. To\\nthat end, we propose a simple, yet effective and efficient network, \\\\method,\\nthat learns to align point clouds. Our evaluation on two different datasets\\ndemonstrates that our method outperforms computationally expensive, global 3D\\nregistration methods while being significantly more efficient. We make our\\ndata, code, and models available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  In this paper we propose a semi-supervised variational autoencoder for\\nclassification of overall survival groups from tumor segmentation masks. The\\nmodel can use the output of any tumor segmentation algorithm, removing all\\nassumptions on the scanning platform and the specific type of pulse sequences\\nused, thereby increasing its generalization properties. Due to its\\nsemi-supervised nature, the method can learn to classify survival time by using\\na relatively small number of labeled subjects. We validate our model on the\\npublicly available dataset from the Multimodal Brain Tumor Segmentation\\nChallenge (BraTS) 2019.\\n\\n    ', '\\nAbstract:  Visual navigation tasks in real world environments often require both\\nself-motion and place recognition feedback. While deep reinforcement learning\\nhas shown success in solving these perception and decision-making problems in\\nan end-to-end manner, these algorithms require large amounts of experience to\\nlearn navigation policies from high-dimensional inputs, which is generally\\nimpractical for real robots due to sample complexity. In this paper, we address\\nthese problems with two main contributions. We first leverage place recognition\\nand deep learning techniques combined with goal destination feedback to\\ngenerate compact, bimodal images representations that can then be used to\\neffectively learn control policies at kilometer scale from a small amount of\\nexperience. Second, we present an interactive and realistic framework, called\\nCityLearn, that enables for the first time the training of navigation\\nalgorithms across city-sized, real-world environments with extreme\\nenvironmental changes. CityLearn features over 10 benchmark real-world datasets\\noften used in place recognition research with more than 100 recorded traversals\\nand across 60 cities around the world. We evaluate our approach in two\\nCityLearn environments where our navigation policy is trained using a single\\ntraversal. Results show our method can be over 2 orders of magnitude faster\\nthan when using raw images and can also generalize across extreme visual\\nchanges including day to night and summer to winter transitions.\\n\\n    ', \"\\nAbstract:  Deep learning is attracting significant interest in the neuroimaging\\ncommunity as a means to diagnose psychiatric and neurological disorders from\\nstructural magnetic resonance images. However, there is a tendency amongst\\nresearchers to adopt architectures optimized for traditional computer vision\\ntasks, rather than design networks customized for neuroimaging data. We address\\nthis by introducing NEURO-DRAM, a 3D recurrent visual attention model tailored\\nfor neuroimaging classification with the flexibility to incorporate non-imaging\\ninformation. The model comprises an agent which, trained by reinforcement\\nlearning, learns to navigate through volumetric images, selectively attending\\nto the most informative regions for a given task. When applied to Alzheimer's\\ndisease prediction, NEURODRAM achieves state-of-the-art classification accuracy\\non an out-of-sample dataset, significantly outperforming a baseline\\nconvolutional neural network. When further applied to the task of predicting\\nwhich patients with mild cognitive impairment will be diagnosed with\\nAlzheimer's disease within two years, the model achieves state-of-the-art\\naccuracy with no additional training. Encouragingly, the agent learns, without\\nexplicit instruction, a search policy in agreement with standardized\\nradiological hallmarks of Alzheimer's disease, suggesting a route to automated\\nbiomarker discovery for more poorly understood disorders.\\n\\n    \", '\\nAbstract:  We propose two novel variants of Gromov-Wasserstein (GW) between probability\\nmeasures in different probability spaces based on projecting these measures\\ninto the tree metric spaces. Our first proposed discrepancy, named\\n\\\\emph{flow-based tree Gromov-Wasserstein}, hinges upon the tree metric from\\nnode to root in each tree to define the structure representation of probability\\nmeasures on trees. The flow-based tree GW shares similar structures with\\nunivariate Wasserstein distance while keeping sufficient spatial information of\\nthe original projected probability measures. In order to further explore the\\nstructure of tree, we proposed another version of flow-based tree GW, which we\\nrefer to as \\\\emph{depth-based tree Gromov-Wasserstein}. That discrepancy\\nconsiders the alignment of probability measures hierarchically along each depth\\nlevel of the tree structures. Finally, we demonstrate via extensive simulation\\nstudies on large-scale real data sets the relative advantage of the proposed\\ndiscrepancies.\\n\\n    ', '\\nAbstract:  We present a new task of query auto-completion for estimating instance\\nprobabilities. We complete a user query prefix conditioned upon an image. Given\\nthe complete query, we fine tune a BERT embedding for estimating probabilities\\nof a broad set of instances. The resulting instance probabilities are used for\\nselection while being agnostic to the segmentation or attention mechanism. Our\\nresults demonstrate that auto-completion using both language and vision\\nperforms better than using only language, and that fine tuning a BERT embedding\\nallows to efficiently rank instances in the image. In the spirit of\\nreproducible research we make our data, models, and code available.\\n\\n    ', '\\nAbstract:  We present a recurrent neural network based system for automatic quality\\nestimation of natural language generation (NLG) outputs, which jointly learns\\nto assign numerical ratings to individual outputs and to provide pairwise\\nrankings of two different outputs. The latter is trained using pairwise hinge\\nloss over scores from two copies of the rating network.\\nWe use learning to rank and synthetic data to improve the quality of ratings\\nassigned by our system: we synthesise training pairs of distorted system\\noutputs and train the system to rank the less distorted one higher. This leads\\nto a 12% increase in correlation with human ratings over the previous\\nbenchmark. We also establish the state of the art on the dataset of relative\\nrankings from the E2E NLG Challenge (Dušek et al., 2019), where synthetic\\ndata lead to a 4% accuracy increase over the base model.\\n\\n    ', '\\nAbstract:  Deep learning based image Super-Resolution (SR) has shown rapid development\\ndue to its ability of big data digestion. Generally, deeper and wider networks\\ncan extract richer feature maps and generate SR images with remarkable quality.\\nHowever, the more complex network we have, the more time consumption is\\nrequired for practical applications. It is important to have a simplified\\nnetwork for efficient image SR. In this paper, we propose an Attention based\\nBack Projection Network (ABPN) for image super-resolution. Similar to some\\nrecent works, we believe that the back projection mechanism can be further\\ndeveloped for SR. Enhanced back projection blocks are suggested to iteratively\\nupdate low- and high-resolution feature residues. Inspired by recent studies on\\nattention models, we propose a Spatial Attention Block (SAB) to learn the\\ncross-correlation across features at different layers. Based on the assumption\\nthat a good SR image should be close to the original LR image after\\ndown-sampling. We propose a Refined Back Projection Block (RBPB) for final\\nreconstruction. Extensive experiments on some public and AIM2019 Image\\nSuper-Resolution Challenge datasets show that the proposed ABPN can provide\\nstate-of-the-art or even better performance in both quantitative and\\nqualitative measurements.\\n\\n    ', '\\nAbstract:  Computer vision has undergone a dramatic revolution in performance, driven in\\nlarge part through deep features trained on large-scale supervised datasets.\\nHowever, much of these improvements have focused on static image analysis;\\nvideo understanding has seen rather modest improvements. Even though new\\ndatasets and spatiotemporal models have been proposed, simple frame-by-frame\\nclassification methods often still remain competitive. We posit that current\\nvideo datasets are plagued with implicit biases over scene and object structure\\nthat can dwarf variations in temporal structure. In this work, we build a video\\ndataset with fully observable and controllable object and scene bias, and which\\ntruly requires spatiotemporal understanding in order to be solved. Our dataset,\\nnamed CATER, is rendered synthetically using a library of standard 3D objects,\\nand tests the ability to recognize compositions of object movements that\\nrequire long-term reasoning. In addition to being a challenging dataset, CATER\\nalso provides a plethora of diagnostic tools to analyze modern spatiotemporal\\nvideo architectures by being completely observable and controllable. Using\\nCATER, we provide insights into some of the most recent state of the art deep\\nvideo architectures.\\n\\n    ', '\\nAbstract:  Referring expressions are natural language descriptions that identify a\\nparticular object within a scene and are widely used in our daily\\nconversations. In this work, we focus on segmenting the object in an image\\nspecified by a referring expression. To this end, we propose an end-to-end\\ntrainable comprehension network that consists of the language and visual\\nencoders to extract feature representations from both domains. We introduce the\\nspatial-aware dynamic filters to transfer knowledge from text to image, and\\neffectively capture the spatial information of the specified object. To better\\ncommunicate between the language and visual modules, we employ a caption\\ngeneration network that takes features shared across both domains as input, and\\nimproves both representations via a consistency that enforces the generated\\nsentence to be similar to the given referring expression. We evaluate the\\nproposed framework on two referring expression datasets and show that our\\nmethod performs favorably against the state-of-the-art algorithms.\\n\\n    ', '\\nAbstract:  Learning multilingual representations of text has proven a successful method\\nfor many cross-lingual transfer learning tasks. There are two main paradigms\\nfor learning such representations: (1) alignment, which maps different\\nindependently trained monolingual representations into a shared space, and (2)\\njoint training, which directly learns unified multilingual representations\\nusing monolingual and cross-lingual objectives jointly. In this paper, we first\\nconduct direct comparisons of representations learned using both of these\\nmethods across diverse cross-lingual tasks. Our empirical results reveal a set\\nof pros and cons for both methods, and show that the relative performance of\\nalignment versus joint training is task-dependent. Stemming from this analysis,\\nwe propose a simple and novel framework that combines these two previously\\nmutually-exclusive approaches. Extensive experiments on various tasks\\ndemonstrate that our proposed framework alleviates limitations of both\\napproaches, and outperforms existing methods on the MUSE bilingual lexicon\\ninduction (BLI) benchmark. We further show that our proposed framework can\\ngeneralize to contextualized representations and achieves state-of-the-art\\nresults on the CoNLL cross-lingual NER benchmark.\\n\\n    ', '\\nAbstract:  We introduce a theoretical framework for performing statistical\\ntasks---including, but not limited to, averaging and principal component\\nanalysis---on the space of (possibly asymmetric) matrices with arbitrary\\nentries and sizes. This is carried out under the lens of the Gromov-Wasserstein\\n(GW) distance, and our methods translate the Riemannian framework of GW\\ndistances developed by Sturm into practical, implementable tools for network\\ndata analysis. Our methods are illustrated on datasets of asymmetric stochastic\\nblockmodel networks and planar shapes viewed as metric spaces. On the\\ntheoretical front, we supplement the work of Sturm by producing additional\\nresults on the tangent structure of this \"space of spaces\", as well as on the\\ngradient flow of the Fréchet functional on this space.\\n\\n    ', \"\\nAbstract:  Robots can learn the right reward function by querying a human expert.\\nExisting approaches attempt to choose questions where the robot is most\\nuncertain about the human's response; however, they do not consider how easy it\\nwill be for the human to answer! In this paper we explore an information gain\\nformulation for optimally selecting questions that naturally account for the\\nhuman's ability to answer. Our approach identifies questions that optimize the\\ntrade-off between robot and human uncertainty, and determines when these\\nquestions become redundant or costly. Simulations and a user study show our\\nmethod not only produces easy questions, but also ultimately results in faster\\nreward learning.\\n\\n    \", '\\nAbstract:  An agent who interacts with a wide population of other agents needs to be\\naware that there may be variations in their understanding of the world.\\nFurthermore, the machinery which they use to perceive may be inherently\\ndifferent, as is the case between humans and machines. In this work, we present\\nboth an image reference game between a speaker and a population of listeners\\nwhere reasoning about the concepts other agents can comprehend is necessary and\\na model formulation with this capability. We focus on reasoning about the\\nconceptual understanding of others, as well as adapting to novel gameplay\\npartners and dealing with differences in perceptual machinery. Our experiments\\non three benchmark image/attribute datasets suggest that our learner indeed\\nencodes information directly pertaining to the understanding of other agents,\\nand that leveraging this information is crucial for maximizing gameplay\\nperformance.\\n\\n    ', \"\\nAbstract:  Autonomous robots have the potential to serve as versatile caregivers that\\nimprove quality of life for millions of people worldwide. Yet, conducting\\nresearch in this area presents numerous challenges, including the risks of\\nphysical interaction between people and robots. Physics simulations have been\\nused to optimize and train robots for physical assistance, but have typically\\nfocused on a single task. In this paper, we present Assistive Gym, an open\\nsource physics simulation framework for assistive robots that models multiple\\ntasks. It includes six simulated environments in which a robotic manipulator\\ncan attempt to assist a person with activities of daily living (ADLs): itch\\nscratching, drinking, feeding, body manipulation, dressing, and bathing.\\nAssistive Gym models a person's physical capabilities and preferences for\\nassistance, which are used to provide a reward function. We present baseline\\npolicies trained using reinforcement learning for four different commercial\\nrobots in the six environments. We demonstrate that modeling human motion\\nresults in better assistance and we compare the performance of different\\nrobots. Overall, we show that Assistive Gym is a promising tool for assistive\\nrobotics research.\\n\\n    \", '\\nAbstract:  Recent approaches for predicting layouts from 360 panoramas produce excellent\\nresults. These approaches build on a common framework consisting of three\\nsteps: a pre-processing step based on edge-based alignment, prediction of\\nlayout elements, and a post-processing step by fitting a 3D layout to the\\nlayout elements. Until now, it has been difficult to compare the methods due to\\nmultiple different design decisions, such as the encoding network (e.g. SegNet\\nor ResNet), type of elements predicted (e.g. corners, wall/floor boundaries, or\\nsemantic segmentation), or method of fitting the 3D layout. To address this\\nchallenge, we summarize and describe the common framework, the variants, and\\nthe impact of the design decisions. For a complete evaluation, we also propose\\nextended annotations for the Matterport3D dataset, and introduce two\\ndepth-based evaluation metrics.\\n\\n    ', \"\\nAbstract:  Anticipating the intentions of vulnerable road users (VRUs) such as\\npedestrians and cyclists is critical for performing safe and comfortable\\ndriving maneuvers. This is the case for human driving and, thus, should be\\ntaken into account by systems providing any level of driving assistance, from\\nadvanced driver assistant systems (ADAS) to fully autonomous vehicles (AVs). In\\nthis paper, we show how the latest advances on monocular vision-based human\\npose estimation, i.e. those relying on deep Convolutional Neural Networks\\n(CNNs), enable to recognize the intentions of such VRUs. In the case of\\ncyclists, we assume that they follow traffic rules to indicate future maneuvers\\nwith arm signals. In the case of pedestrians, no indications can be assumed.\\nInstead, we hypothesize that the walking pattern of a pedestrian allows to\\ndetermine if he/she has the intention of crossing the road in the path of the\\nego-vehicle, so that the ego-vehicle must maneuver accordingly (e.g. slowing\\ndown or stopping). In this paper, we show how the same methodology can be used\\nfor recognizing pedestrians and cyclists' intentions. For pedestrians, we\\nperform experiments on the JAAD dataset. For cyclists, we did not found an\\nanalogous dataset, thus, we created our own one by acquiring and annotating\\nvideos which we share with the research community. Overall, the proposed\\npipeline provides new state-of-the-art results on the intention recognition of\\nVRUs.\\n\\n    \", '\\nAbstract:  Effective network congestion control strategies are key to keeping the\\nInternet (or any large computer network) operational. Network congestion\\ncontrol has been dominated by hand-crafted heuristics for decades. Recently,\\nReinforcementLearning (RL) has emerged as an alternative to automatically\\noptimize such control strategies. Research so far has primarily considered RL\\ninterfaces which block the sender while an agent considers its next action.\\nThis is largely an artifact of building on top of frameworks designed for RL in\\ngames (e.g. OpenAI Gym). However, this does not translate to real-world\\nnetworking environments, where a network sender waiting on a policy without\\nsending data is costly for throughput. We instead propose to formulate\\ncongestion control with an asynchronous RL agent that handles delayed actions.\\nWe present MVFST-RL, a scalable framework for congestion control in the QUIC\\ntransport protocol that leverages state-of-the-art in asynchronous RL training\\nwith off-policy correction. We analyze modeling improvements to mitigate the\\ndeviation from Markovian dynamics, and evaluate our method on emulated networks\\nfrom the Pantheon benchmark platform. The source code is publicly available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  We present multi-point optimization: an optimization technique that allows to\\ntrain several models simultaneously without the need to keep the parameters of\\neach one individually. The proposed method is used for a thorough empirical\\nanalysis of the loss landscape of neural networks. By extensive experiments on\\nFashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface is\\nsurprisingly diverse and intricate in terms of landscape patterns it contains,\\nand 2) adding batch normalization makes it more smooth. Source code to\\nreproduce all the reported results is available on GitHub:\\nthis https URL.\\n\\n    ', '\\nAbstract:  Accurate localization of proteins from fluorescence microscopy images is a\\nchallenging task due to the inter-class similarities and intra-class\\ndisparities introducing grave concerns in addressing multi-class classification\\nproblems. Conventional machine learning-based image prediction relies heavily\\non pre-processing such as normalization and segmentation followed by\\nhand-crafted feature extraction before classification to identify useful and\\ninformative as well as application specific features.We propose an end-to-end\\nProtein Localization Convolutional Neural Network (PLCNN) that classifies\\nprotein localization images more accurately and reliably. PLCNN directly\\nprocesses raw imagery without involving any pre-processing steps and produces\\noutputs without any customization or parameter adjustment for a particular\\ndataset. The output of our approach is computed from probabilities produced by\\nthe network. Experimental analysis is performed on five publicly available\\nbenchmark datasets. PLCNN consistently outperformed the existing\\nstate-of-the-art approaches from machine learning and deep architectures.\\n\\n    ', '\\nAbstract:  By design, discriminatively trained neural network classifiers produce\\nreliable predictions only for in-distribution samples. For their real-world\\ndeployments, detecting out-of-distribution (OOD) samples is essential. Assuming\\nOOD to be outside the closed boundary of in-distribution, typical neural\\nclassifiers do not contain the knowledge of this boundary for OOD detection\\nduring inference. There have been recent approaches to instill this knowledge\\nin classifiers by explicitly training the classifier with OOD samples close to\\nthe in-distribution boundary. However, these generated samples fail to cover\\nthe entire in-distribution boundary effectively, thereby resulting in a\\nsub-optimal OOD detector. In this paper, we analyze the feasibility of such\\napproaches by investigating the complexity of producing such \"effective\" OOD\\nsamples. We also propose a novel algorithm to generate such samples using a\\nmanifold learning network (e.g., variational autoencoder) and then train an n+1\\nclassifier for OOD detection, where the $n+1^{th}$ class represents the OOD\\nsamples. We compare our approach against several recent classifier-based OOD\\ndetectors on MNIST and Fashion-MNIST datasets. Overall the proposed approach\\nconsistently performs better than the others.\\n\\n    ', '\\nAbstract:  The multilingual BERT model is trained on 104 languages and meant to serve as\\na universal language model and tool for encoding sentences. We explore how well\\nthe model performs on several languages across several tasks: a diagnostic\\nclassification probing the embeddings for a particular syntactic property, a\\ncloze task testing the language modelling ability to fill in gaps in a\\nsentence, and a natural language generation task testing for the ability to\\nproduce coherent text fitting a given context. We find that the currently\\navailable multilingual BERT model is clearly inferior to the monolingual\\ncounterparts, and cannot in many cases serve as a substitute for a well-trained\\nmonolingual model. We find that the English and German models perform well at\\ngeneration, whereas the multilingual model is lacking, in particular, for\\nNordic languages.\\n\\n    ', '\\nAbstract:  Generative adversarial networks (GANs) are a powerful approach to\\nunsupervised learning. They have achieved state-of-the-art performance in the\\nimage domain. However, GANs are limited in two ways. They often learn\\ndistributions with low support---a phenomenon known as mode collapse---and they\\ndo not guarantee the existence of a probability density, which makes evaluating\\ngeneralization using predictive log-likelihood impossible. In this paper, we\\ndevelop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs\\nadd noise to the output of a density network and optimize an\\nentropy-regularized adversarial loss. The added noise renders tractable\\napproximations of the predictive log-likelihood and stabilizes the training\\nprocedure. The entropy regularizer encourages PresGANs to capture all the modes\\nof the data distribution. Fitting PresGANs involves computing the intractable\\ngradients of the entropy regularization term; PresGANs sidestep this\\nintractability using unbiased stochastic estimates. We evaluate PresGANs on\\nseveral datasets and found they mitigate mode collapse and generate samples\\nwith high perceptual quality. We further found that PresGANs reduce the gap in\\nperformance in terms of predictive log-likelihood between traditional GANs and\\nvariational autoencoders (VAEs).\\n\\n    ', '\\nAbstract:  We present a domain adaptation (DA) system that can be used in multi-source\\nand semi-supervised settings. Using the proposed method we achieved 2nd place\\non multi-source track and 3rd place on semi-supervised track of the VisDA 2019\\nchallenge (this http URL). The source code of the method is\\navailable at this https URL.\\n\\n    ', '\\nAbstract:  To accelerate DNNs inference, low-rank approximation has been widely adopted\\nbecause of its solid theoretical rationale and efficient implementations.\\nSeveral previous works attempted to directly approximate a pre-trained model by\\nlow-rank decomposition; however, small approximation errors in parameters can\\nripple over a large prediction loss. Apparently, it is not optimal to separate\\nlow-rank approximation from training. Unlike previous works, this paper\\nintegrates low rank approximation and regularization into the training process.\\nWe propose Trained Rank Pruning (TRP), which alternates between low rank\\napproximation and training. TRP maintains the capacity of the original network\\nwhile imposing low-rank constraints during training. A nuclear regularization\\noptimized by stochastic sub-gradient descent is utilized to further promote low\\nrank in TRP. Networks trained with TRP has a low-rank structure in nature, and\\nis approximated with negligible performance loss, thus eliminating fine-tuning\\nafter low rank approximation. The proposed method is comprehensively evaluated\\non CIFAR-10 and ImageNet, outperforming previous compression counterparts using\\nlow rank approximation. Our code is available at:\\nthis https URL.\\n\\n    ', \"\\nAbstract:  Interpretability methods often measure the contribution of an input feature\\nto an image classifier's decisions by heuristically removing it via e.g.\\nblurring, adding noise, or graying out, which often produce unrealistic,\\nout-of-samples. Instead, we propose to integrate a generative inpainter into\\nthree representative attribution methods to remove an input feature. Compared\\nto the original counterparts, our methods (1) generate more plausible\\ncounterfactual samples under the true data generating process; (2) are more\\nrobust to hyperparameter settings; and (3) localize objects more accurately.\\nOur findings were consistent across both ImageNet and Places365 datasets and\\ntwo different pairs of classifiers and inpainters.\\n\\n    \", \"\\nAbstract:  With the ubiquity of sensors in the IoT era, statistical observations are\\nbecoming increasingly available in the form of massive (multivariate)\\ntime-series. Formulated as unsupervised anomaly detection tasks, an abundance\\nof applications like aviation safety management, the health monitoring of\\ncomplex infrastructures or fraud detection can now rely on such functional\\ndata, acquired and stored with an ever finer granularity. The concept of\\nstatistical depth, which reflects centrality of an arbitrary observation w.r.t.\\na statistical population may play a crucial role in this regard, anomalies\\ncorresponding to observations with 'small' depth. Supported by sound\\ntheoretical and computational developments in the recent decades, it has proven\\nto be extremely useful, in particular in functional spaces. However, most\\napproaches documented in the literature consist in evaluating independently the\\ncentrality of each point forming the time series and consequently exhibit a\\ncertain insensitivity to possible shape changes. In this paper, we propose a\\nnovel notion of functional depth based on the area of the convex hull of\\nsampled curves, capturing gradual departures from centrality, even beyond the\\nenvelope of the data, in a natural fashion. We discuss practical relevance of\\ncommonly imposed axioms on functional depths and investigate which of them are\\nsatisfied by the notion of depth we promote here. Estimation and computational\\nissues are also addressed and various numerical experiments provide empirical\\nevidence of the relevance of the approach proposed.\\n\\n    \", '\\nAbstract:  Criminal and victim identification based on crime scene images is an\\nimportant part of forensic investigation. Criminals usually avoid\\nidentification by covering their faces and tattoos in the evidence images,\\nwhich are taken in uncontrolled environments. Existing identification methods,\\nwhich make use of biometric traits, such as vein, skin mark, height, skin\\ncolor, weight, race, etc., are considered for solving this problem. The soft\\nbiometric traits, including skin color, gender, height, weight and race,\\nprovide useful information but not distinctive enough. Veins and skin marks are\\nlimited to high resolution images and some body sites may neither have enough\\nskin marks nor clear veins. Terrorists and rioters tend to expose their wrists\\nin a gesture of triumph, greeting or salute, while paedophiles usually show\\nthem when touching victims. However, wrists were neglected by the biometric\\ncommunity for forensic applications. In this paper, a wrist identification\\nalgorithm, which includes skin segmentation, key point localization, image to\\ntemplate alignment, large feature set extraction, and classification, is\\nproposed. The proposed algorithm is evaluated on NTU-Wrist-Image-Database-v1,\\nwhich consists of 3945 images from 731 different wrists, including 205 pairs of\\nwrist images collected from the Internet, taken under uneven illuminations with\\ndifferent poses and resolutions. The experimental results show that wrist is a\\nuseful clue for criminal and victim identification. Keywords: biometrics,\\ncriminal and victim identification, forensics, wrist.\\n\\n    ', '\\nAbstract:  Although there is an unprecedented effort to provide adequate responses in\\nterms of laws and policies to hate content on social media platforms, dealing\\nwith hatred online is still a tough problem. Tackling hate speech in the\\nstandard way of content deletion or user suspension may be charged with\\ncensorship and overblocking. One alternate strategy, that has received little\\nattention so far by the research community, is to actually oppose hate content\\nwith counter-narratives (i.e. informed textual responses). In this paper, we\\ndescribe the creation of the first large-scale, multilingual, expert-based\\ndataset of hate speech/counter-narrative pairs. This dataset has been built\\nwith the effort of more than 100 operators from three different NGOs that\\napplied their training and expertise to the task. Together with the collected\\ndata we also provide additional annotations about expert demographics, hate and\\nresponse type, and data augmentation through translation and paraphrasing.\\nFinally, we provide initial experiments to assess the quality of our data.\\n\\n    ', '\\nAbstract:  Irrespective of the fact that Machine learning has produced groundbreaking\\nresults, it demands an enormous amount of data in order to perform so. Even\\nthough data production has been in its all-time high, almost all the data is\\nunlabelled, hence making them unsuitable for training the algorithms. This\\npaper proposes a novel method of extracting the features using Dynamic Mode\\nDecomposition (DMD). The experiment is performed using data samples from\\nImagenet. The learning is done using SVM-linear, SVM-RBF, Random Kitchen Sink\\napproach (RKS). The results have shown that DMD features with RKS give\\ncompeting results.\\n\\n    ', '\\nAbstract:  Presence of bias and confounding effects is inarguably one of the most\\ncritical challenges in machine learning applications that has alluded to\\npivotal debates in the recent years. Such challenges range from spurious\\nassociations of confounding variables in medical studies to the bias of race in\\ngender or face recognition systems. One solution is to enhance datasets and\\norganize them such that they do not reflect biases, which is a cumbersome and\\nintensive task. The alternative is to make use of available data and build\\nmodels considering these biases. Traditional statistical methods apply\\nstraightforward techniques such as residualization or stratification to\\nprecomputed features to account for confounding variables. However, these\\ntechniques are generally not suitable for end-to-end deep learning methods. In\\nthis paper, we propose a method based on the adversarial training strategy to\\nlearn discriminative features unbiased and invariant to the confounder(s). This\\nis enabled by incorporating a new adversarial loss function that encourages a\\nvanished correlation between the bias and learned features. We apply our method\\nto synthetic data, medical images, and a gender classification (Gender Shades\\nPilot Parliaments Benchmark) dataset. Our results show that the learned\\nfeatures by our method not only result in superior prediction performance but\\nalso are uncorrelated with the bias or confounder variables. The code is\\navailable at this http URL.\\n\\n    ', '\\nAbstract:  The major challenge of learning from multi-label data has arisen from the\\noverwhelming size of label space which makes this problem NP-hard. This problem\\ncan be alleviated by gradually involving easy to hard tags into the learning\\nprocess. Besides, the utilization of a diversity maintenance approach avoids\\noverfitting on a subset of easy labels. In this paper, we propose a self-paced\\nmulti-label learning with diversity (SPMLD) which aims to cover diverse labels\\nwith respect to its learning pace. In addition, the proposed framework is\\napplied to an efficient correlation-based multi-label method. The non-convex\\nobjective function is optimized by an extension of the block coordinate descent\\nalgorithm. Empirical evaluations on real-world datasets with different\\ndimensions of features and labels imply the effectiveness of the proposed\\npredictive model.\\n\\n    ', '\\nAbstract:  We introduce the Mutual Information Machine (MIM), an autoencoder model for\\nlearning joint distributions over observations and latent states. The model\\nformulation reflects two key design principles: 1) symmetry, to encourage the\\nencoder and decoder to learn consistent factorizations of the same underlying\\ndistribution; and 2) mutual information, to encourage the learning of useful\\nrepresentations for downstream tasks. The objective comprises the\\nJensen-Shannon divergence between the encoding and decoding joint\\ndistributions, plus a mutual information term. We show that this objective can\\nbe bounded by a tractable cross-entropy loss between the true model and a\\nparameterized approximation, and relate this to maximum likelihood estimation\\nand variational autoencoders. Experiments show that MIM is capable of learning\\na latent representation with high mutual information, and good unsupervised\\nclustering, while providing data log likelihood comparable to VAE (with a\\nsufficiently expressive architecture).\\n\\n    ', '\\nAbstract:  Sample-efficient exploration is crucial not only for discovering rewarding\\nexperiences but also for adapting to environment changes in a task-agnostic\\nfashion. A principled treatment of the problem of optimal input synthesis for\\nsystem identification is provided within the framework of sequential Bayesian\\nexperimental design. In this paper, we present an effective\\ntrajectory-optimization-based approximate solution of this otherwise\\nintractable problem that models optimal exploration in an unknown Markov\\ndecision process (MDP). By interleaving episodic exploration with Bayesian\\nnonlinear system identification, our algorithm takes advantage of the inductive\\nbias to explore in a directed manner, without assuming prior knowledge of the\\nMDP. Empirical evaluations indicate a clear advantage of the proposed algorithm\\nin terms of the rate of convergence and the final model fidelity when compared\\nto intrinsic-motivation-based algorithms employing exploration bonuses such as\\nprediction error and information gain. Moreover, our method maintains a\\ncomputational advantage over a recent model-based active exploration (MAX)\\nalgorithm, by focusing on the information gain along trajectories instead of\\nseeking a global exploration policy. A reference implementation of our\\nalgorithm and the conducted experiments is publicly available.\\n\\n    ', '\\nAbstract:  Previous works \\\\citep{donahue2018adversarial, engel2019gansynth} have found\\nthat generating coherent raw audio waveforms with GANs is challenging. In this\\npaper, we show that it is possible to train GANs reliably to generate high\\nquality coherent waveforms by introducing a set of architectural changes and\\nsimple training techniques. Subjective evaluation metric (Mean Opinion Score,\\nor MOS) shows the effectiveness of the proposed approach for high quality\\nmel-spectrogram inversion. To establish the generality of the proposed\\ntechniques, we show qualitative results of our model in speech synthesis, music\\ndomain translation and unconditional music synthesis. We evaluate the various\\ncomponents of the model through ablation studies and suggest a set of\\nguidelines to design general purpose discriminators and generators for\\nconditional sequence synthesis tasks. Our model is non-autoregressive, fully\\nconvolutional, with significantly fewer parameters than competing models and\\ngeneralizes to unseen speakers for mel-spectrogram inversion. Our pytorch\\nimplementation runs at more than 100x faster than realtime on GTX 1080Ti GPU\\nand more than 2x faster than real-time on CPU, without any hardware specific\\noptimization tricks. Blog post with samples and accompanying code coming soon.\\n\\n    ', '\\nAbstract:  Learning useful representations is a key ingredient to the success of modern\\nmachine learning. Currently, representation learning mostly relies on embedding\\ndata into Euclidean space. However, recent work has shown that data in some\\ndomains is better modeled by non-euclidean metric spaces, and inappropriate\\ngeometry can result in inferior performance. In this paper, we aim to eliminate\\nthe inductive bias imposed by the embedding space geometry. Namely, we propose\\nto map data into more general non-vector metric spaces: a weighted graph with a\\nshortest path distance. By design, such graphs can model arbitrary geometry\\nwith a proper configuration of edges and weights. Our main contribution is\\nPRODIGE: a method that learns a weighted graph representation of data\\nend-to-end by gradient descent. Greater generality and fewer model assumptions\\nmake PRODIGE more powerful than existing embedding-based approaches. We confirm\\nthe superiority of our method via extensive experiments on a wide range of\\ntasks, including classification, compression, and collaborative filtering.\\n\\n    ', '\\nAbstract:  We present a visual imitation learning framework that enables learning of\\nrobot action policies solely based on expert samples without any robot trials.\\nRobot exploration and on-policy trials in a real-world environment could often\\nbe expensive/dangerous. We present a new approach to address this problem by\\nlearning a future scene prediction model solely on a collection of expert\\ntrajectories consisting of unlabeled example videos and actions, and by\\nenabling generalized action cloning using future image similarity. The robot\\nlearns to visually predict the consequences of taking an action, and obtains\\nthe policy by evaluating how similar the predicted future image is to an expert\\nimage. We develop a stochastic action-conditioned convolutional autoencoder,\\nand present how we take advantage of future images for robot learning. We\\nconduct experiments in simulated and real-life environments using a ground\\nmobility robot with and without obstacles, and compare our models to multiple\\nbaseline methods.\\n\\n    ', '\\nAbstract:  While it is widely known that neural networks are universal approximators of\\ncontinuous functions, a less known and perhaps more powerful result is that a\\nneural network with a single hidden layer can approximate accurately any\\nnonlinear continuous operator \\\\cite{chen1995universal}. This universal\\napproximation theorem is suggestive of the potential application of neural\\nnetworks in learning nonlinear operators from data. However, the theorem\\nguarantees only a small approximation error for a sufficient large network, and\\ndoes not consider the important optimization and generalization errors. To\\nrealize this theorem in practice, we propose deep operator networks (DeepONets)\\nto learn operators accurately and efficiently from a relatively small dataset.\\nA DeepONet consists of two sub-networks, one for encoding the input function at\\na fixed number of sensors $x_i, i=1,\\\\dots,m$ (branch net), and another for\\nencoding the locations for the output functions (trunk net). We perform\\nsystematic simulations for identifying two types of operators, i.e., dynamic\\nsystems and partial differential equations, and demonstrate that DeepONet\\nsignificantly reduces the generalization error compared to the fully-connected\\nnetworks. We also derive theoretically the dependence of the approximation\\nerror in terms of the number of sensors (where the input function is defined)\\nas well as the input function type, and we verify the theorem with\\ncomputational results. More importantly, we observe high-order error\\nconvergence in our computational tests, namely polynomial rates (from half\\norder to fourth order) and even exponential convergence with respect to the\\ntraining dataset size.\\n\\n    ', '\\nAbstract:  Deep neural networks are susceptible to adversarial manipulations in the\\ninput domain. The extent of vulnerability has been explored intensively in\\ncases of $\\\\ell_p$-bounded and $\\\\ell_p$-minimal adversarial perturbations.\\nHowever, the vulnerability of DNNs to adversarial perturbations with specific\\nstatistical properties or frequency-domain characteristics has not been\\nsufficiently explored. In this paper, we study the smoothness of perturbations\\nand propose SmoothFool, a general and computationally efficient framework for\\ncomputing smooth adversarial perturbations. Through extensive experiments, we\\nvalidate the efficacy of the proposed method for both the white-box and\\nblack-box attack scenarios. In particular, we demonstrate that: (i) there exist\\nextremely smooth adversarial perturbations for well-established and widely used\\nnetwork architectures, (ii) smoothness significantly enhances the robustness of\\nperturbations against state-of-the-art defense mechanisms, (iii) smoothness\\nimproves the transferability of adversarial perturbations across both data\\npoints and network architectures, and (iv) class categories exhibit a variable\\nrange of susceptibility to smooth perturbations. Our results suggest that\\nsmooth APs can play a significant role in exploring the vulnerability extent of\\nDNNs to adversarial examples.\\n\\n    ', '\\nAbstract:  Painting captions are often dry and simplistic which motivates us to describe\\na painting creatively in the style of Shakespearean prose. This is a difficult\\nproblem, since there does not exist a large supervised dataset from paintings\\nto Shakespearean prose. Our solution is to use an intermediate English poem\\ndescription of the painting and then apply language style transfer which\\nresults in Shakespearean prose describing the painting. We rate our results by\\nhuman evaluation on a Likert scale, and evaluate the quality of language style\\ntransfer using BLEU score as a function of prose length. We demonstrate the\\napplicability and limitations of our approach by generating Shakespearean prose\\nfor famous paintings. We make our models and code publicly available.\\n\\n    ', '\\nAbstract:  Understanding human visual attention and saliency is an integral part of\\nvision research. In this context, there is an ever-present need for fresh and\\ndiverse benchmark datasets, particularly for insight into special use cases\\nlike crowded scenes. We contribute to this end by: (1) reviewing the dynamics\\nbehind saliency and crowds. (2) using eye tracking to create a dynamic human\\neye fixation dataset over a new set of crowd videos gathered from the Internet.\\nThe videos are annotated into three distinct density levels. (3) Finally, we\\nevaluate state-of-the-art saliency models on our dataset to identify possible\\nimprovements for the design and creation of a more robust saliency model.\\n\\n    ', '\\nAbstract:  Failures are challenging for learning to control physical systems since they\\nrisk damage, time-consuming resets, and often provide little gradient\\ninformation. Adding safety constraints to exploration typically requires a lot\\nof prior knowledge and domain expertise. We present a safety measure which\\nimplicitly captures how the system dynamics relate to a set of failure states.\\nNot only can this measure be used as a safety function, but also to directly\\ncompute the set of safe state-action pairs. Further, we show a model-free\\napproach to learn this measure by active sampling using Gaussian processes.\\nWhile safety can only be guaranteed after learning the safety measure, we show\\nthat failures can already be greatly reduced by using the estimated measure\\nduring learning.\\n\\n    ', '\\nAbstract:  PyODDS is an end-to end Python system for outlier detection with database\\nsupport. PyODDS provides outlier detection algorithms which meet the demands\\nfor users in different fields, w/wo data science or machine learning\\nbackground. PyODDS gives the ability to execute machine learning algorithms\\nin-database without moving data out of the database server or over the network.\\nIt also provides access to a wide range of outlier detection algorithms,\\nincluding statistical analysis and more recent deep learning based approaches.\\nPyODDS is released under the MIT open-source license, and currently available\\nat (this https URL) with official documentations at\\n(this https URL).\\n\\n    ', \"\\nAbstract:  We cast the problem of image denoising as a domain translation problem\\nbetween high and low noise domains. By modifying the cycleGAN model, we are\\nable to learn a mapping between these domains on unpaired retinal optical\\ncoherence tomography images. In quantitative measurements and a qualitative\\nevaluation by ophthalmologists, we show how this approach outperforms other\\nestablished methods. The results indicate that the network differentiates\\nsubtle changes in the level of noise in the image. Further investigation of the\\nmodel's feature maps reveals that it has learned to distinguish retinal layers\\nand other distinct regions of the images.\\n\\n    \", '\\nAbstract:  Generating point clouds, e.g., molecular structures, in arbitrary rotations,\\ntranslations, and enumerations remains a challenging task. Meanwhile, neural\\nnetworks utilizing symmetry invariant layers have been shown to be able to\\noptimize their training objective in a data-efficient way. In this spirit, we\\npresent an architecture which allows to produce valid Euclidean distance\\nmatrices, which by construction are already invariant under rotation and\\ntranslation of the described object. Motivated by the goal to generate\\nmolecular structures in Cartesian space, we use this architecture to construct\\na Wasserstein GAN utilizing a permutation invariant critic network. This makes\\nit possible to generate molecular structures in a one-shot fashion by producing\\nEuclidean distance matrices which have a three-dimensional embedding.\\n\\n    ', '\\nAbstract:  A defining characteristic of intelligent systems is the ability to make\\naction decisions based on the anticipated outcomes. Video prediction systems\\nhave been demonstrated as a solution for predicting how the future will unfold\\nvisually, and thus, many models have been proposed that are capable of\\npredicting future frames based on a history of observed frames~(and sometimes\\nrobot actions). However, a comprehensive method for determining the fitness of\\ndifferent video prediction models at guiding the selection of actions is yet to\\nbe developed. Current metrics assess video prediction models based on human\\nperception of frame quality. In contrast, we argue that if these systems are to\\nbe used to guide action, necessarily, the actions the robot performs should be\\nencoded in the predicted frames. In this paper, we are proposing a new metric\\nto compare different video prediction models based on this argument. More\\nspecifically, we propose an action inference system and quantitatively rank\\ndifferent models based on how well we can infer the robot actions from the\\npredicted frames. Our extensive experiments show that models with high\\nperceptual scores can perform poorly in the proposed action inference tests and\\nthus, may not be suitable options to be used in robot planning systems.\\n\\n    ', \"\\nAbstract:  The homogeneous transformation between a LiDAR and monocular camera is\\nrequired for sensor fusion tasks, such as SLAM. While determining such a\\ntransformation is not considered glamorous in any sense of the word, it is\\nnonetheless crucial for many modern autonomous systems. Indeed, an error of a\\nfew degrees in rotation or a few percent in translation can lead to 20 cm\\ntranslation errors at a distance of 5 m when overlaying a LiDAR image on a\\ncamera image. The biggest impediments to determining the transformation\\naccurately are the relative sparsity of LiDAR point clouds and systematic\\nerrors in their distance measurements. This paper proposes (1) the use of\\ntargets of known dimension and geometry to ameliorate target pose estimation in\\nface of the quantization and systematic errors inherent in a LiDAR image of a\\ntarget, and (2) a fitting method for the LiDAR to monocular camera\\ntransformation that fundamentally assumes the camera image data is the most\\naccurate information in one's possession.\\n\\n    \", '\\nAbstract:  The ability to generate natural language explanations conditioned on the\\nvisual perception is a crucial step towards autonomous agents which can explain\\nthemselves and communicate with humans. While the research efforts in image and\\nvideo captioning are giving promising results, this is often done at the\\nexpense of the computational requirements of the approaches, limiting their\\napplicability to real contexts. In this paper, we propose a fully-attentive\\ncaptioning algorithm which can provide state of the art performances on\\nlanguage generation while restricting its computational demands. Our model is\\ninspired by the Transformer model and employs only two Transformer layers in\\nthe encoding and decoding stages. Further, it incorporates a novel memory-aware\\nencoding of image regions. Experiments demonstrate that our approach is state\\nof the art in terms of caption quality while featuring reduced computational\\ndemands. Further, to evaluate its applicability on autonomous agents, we\\nconduct experiments on simulated scenes taken from the perspective of domestic\\nrobots.\\n\\n    ', \"\\nAbstract:  From social networks to protein complexes to disease genomes to visual data,\\nhypergraphs are everywhere. However, the scope of research studying deep\\nlearning on hypergraphs is still quite sparse and nascent, as there has not yet\\nexisted an effective, unified framework for using hyperedge and vertex\\nembeddings jointly in the hypergraph context, despite a large body of prior\\nwork that has shown the utility of deep learning over graphs and sets. Building\\nupon these recent advances, we propose \\\\textit{Deep Hyperedges} (DHE), a\\nmodular framework that jointly uses contextual and permutation-invariant vertex\\nmembership properties of hyperedges in hypergraphs to perform classification\\nand regression in transductive and inductive learning settings. In our\\nexperiments, we use a novel random walk procedure and show that our model\\nachieves and, in most cases, surpasses state-of-the-art performance on\\nbenchmark datasets. Additionally, we study our framework's performance on a\\nvariety of diverse, non-standard hypergraph datasets and propose several\\navenues of future work to further enhance DHE.\\n\\n    \", '\\nAbstract:  For many linear and nonlinear systems that arise from the discretization of\\npartial differential equations the construction of an efficient multigrid\\nsolver is a challenging task. Here we present a novel approach for the\\noptimization of geometric multigrid methods that is based on evolutionary\\ncomputation, a generic program optimization technique inspired by the principle\\nof natural evolution. A multigrid solver is represented as a tree of\\nmathematical expressions which we generate based on a tailored grammar. The\\nquality of each solver is evaluated in terms of convergence and compute\\nperformance using automated local Fourier analysis (LFA) and roofline\\nperformance modeling, respectively. Based on these objectives a multi-objective\\noptimization is performed using strongly typed genetic programming with a\\nnon-dominated sorting based selection. To evaluate the model-based prediction\\nand to target concrete applications, scalable implementations of an evolved\\nsolver can be automatically generated with the ExaStencils framework. We\\ndemonstrate our approach by constructing multigrid solvers for the steady-state\\nheat equation with constant and variable coefficients that consistently perform\\nbetter than common V- and W-cycles.\\n\\n    ', '\\nAbstract:  The last decades have witnessed the breakthrough of autonomous vehicles\\n(AVs), and the perception capabilities of AVs have been dramatically improved.\\nVarious sensors installed on AVs, including, but are not limited to, LiDAR,\\nradar, camera and stereovision, will be collecting massive data and perceiving\\nthe surrounding traffic states continuously. In fact, a fleet of AVs can serve\\nas floating (or probe) sensors, which can be utilized to infer traffic\\ninformation while cruising around the roadway networks. In contrast,\\nconventional traffic sensing methods rely on fixed traffic sensors such as loop\\ndetectors, cameras and microwave vehicle detectors. Due to the high cost of\\nconventional traffic sensors, traffic state data are usually obtained in a\\nlow-frequency and sparse manner. In view of this, this paper leverages rich\\ndata collected through AVs to propose the high-resolution traffic sensing\\nframework. The proposed framework estimates the fundamental traffic state\\nvariables, namely, flow, density and speed in high spatio-temporal resolution,\\nand it is developed under different levels of AV perception capabilities and\\nlow AV market penetration rate. The Next Generation Simulation (NGSIM) data is\\nadopted to examine the accuracy and robustness of the proposed framework.\\nExperimental results show that the proposed estimation framework achieves high\\naccuracy even with low AV market penetration rate. Sensitivity analysis\\nregarding AV penetration rate, sensor configuration, and perception accuracy\\nwill also be studied. This study will help policymakers and private sectors\\n(e.g Uber, Waymo) to understand the values of AVs, especially the values of\\nmassive data collected by AVs, in traffic operation and management.\\n\\n    ', \"\\nAbstract:  Recent developments in Named Entity Recognition (NER) have resulted in better\\nand better models. However, is there a glass ceiling? Do we know which types of\\nerrors are still hard or even impossible to correct? In this paper, we present\\na detailed analysis of the types of errors in state-of-the-art machine learning\\n(ML) methods. Our study reveals the weak and strong points of the Stanford,\\nCMU, FLAIR, ELMO and BERT models, as well as their shared limitations. We also\\nintroduce new techniques for improving annotation, for training processes and\\nfor checking a model's quality and stability. Presented results are based on\\nthe CoNLL 2003 data set for the English language. A new enriched semantic\\nannotation of errors for this data set and new diagnostic data sets are\\nattached in the supplementary materials.\\n\\n    \", '\\nAbstract:  When humans observe a physical system, they can easily locate objects,\\nunderstand their interactions, and anticipate future behavior, even in settings\\nwith complicated and previously unseen interactions. For computers, however,\\nlearning such models from videos in an unsupervised fashion is an unsolved\\nresearch problem. In this paper, we present STOVE, a novel state-space model\\nfor videos, which explicitly reasons about objects and their positions,\\nvelocities, and interactions. It is constructed by combining an image model and\\na dynamics model in compositional manner and improves on previous work by\\nreusing the dynamics model for inference, accelerating and regularizing\\ntraining. STOVE predicts videos with convincing physical behavior over hundreds\\nof timesteps, outperforms previous unsupervised models, and even approaches the\\nperformance of supervised baselines. We further demonstrate the strength of our\\nmodel as a simulator for sample efficient model-based control in a task with\\nheavily interacting objects.\\n\\n    ', '\\nAbstract:  While translating between East Asian languages, many works have discovered\\nclear advantages of using characters as the translation unit. Unfortunately,\\ntraditional recurrent neural machine translation systems hinder the practical\\nusage of those character-based systems due to their architectural limitations.\\nThey are unfavorable in handling extremely long sequences as well as highly\\nrestricted in parallelizing the computations. In this paper, we demonstrate\\nthat the new transformer architecture can perform character-based translation\\nbetter than the recurrent one. We conduct experiments on a low-resource\\nlanguage pair: Japanese-Vietnamese. Our models considerably outperform the\\nstate-of-the-art systems which employ word-based recurrent architectures.\\n\\n    ', \"\\nAbstract:  In fighting against fake news, many fact-checking systems comprised of\\nhuman-based fact-checking sites (e.g., this http URL and this http URL) and\\nautomatic detection systems have been developed in recent years. However,\\nonline users still keep sharing fake news even when it has been debunked. It\\nmeans that early fake news detection may be insufficient and we need another\\ncomplementary approach to mitigate the spread of misinformation. In this paper,\\nwe introduce a novel application of text generation for combating fake news. In\\nparticular, we (1) leverage online users named \\\\emph{fact-checkers}, who cite\\nfact-checking sites as credible evidences to fact-check information in public\\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\\n(3) propose and build a deep learning framework to generate responses with\\nfact-checking intention to increase the fact-checkers' engagement in\\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\\nrefute misinformation and use formal language (e.g. few swear words and\\nInternet slangs). Our framework successfully generates relevant responses, and\\noutperforms competing models by achieving up to 30\\\\% improvements. Our\\nqualitative study also confirms that the superiority of our generated responses\\ncompared with responses generated from the existing models.\\n\\n    \", \"\\nAbstract:  Efforts are underway to study ways via which the power of deep neural\\nnetworks can be extended to non-standard data types such as structured data\\n(e.g., graphs) or manifold-valued data (e.g., unit vectors or special\\nmatrices). Often, sizable empirical improvements are possible when the geometry\\nof such data spaces are incorporated into the design of the model,\\narchitecture, and the algorithms. Motivated by neuroimaging applications, we\\nstudy formulations where the data are {\\\\em sequential manifold-valued\\nmeasurements}. This case is common in brain imaging, where the samples\\ncorrespond to symmetric positive definite matrices or orientation distribution\\nfunctions. Instead of a recurrent model which poses computational/technical\\nissues, and inspired by recent results showing the viability of dilated\\nconvolutional models for sequence prediction, we develop a dilated\\nconvolutional neural network architecture for this task. On the technical side,\\nwe show how the modules needed in our network can be derived while explicitly\\ntaking the Riemannian manifold structure into account. We show how the\\noperations needed can leverage known results for calculating the weighted\\nFréchet Mean (wFM). Finally, we present scientific results for group\\ndifference analysis in Alzheimer's disease (AD) where the groups are derived\\nusing AD pathology load: here the model finds several brain fiber bundles that\\nare related to AD even when the subjects are all still cognitively healthy.\\n\\n    \", '\\nAbstract:  Word embeddings have become a staple of several natural language processing\\ntasks, yet much remains to be understood about their properties. In this work,\\nwe analyze word embeddings in terms of their principal components and arrive at\\na number of novel and counterintuitive observations. In particular, we\\ncharacterize the utility of variance explained by the principal components as a\\nproxy for downstream performance. Furthermore, through syntactic probing of the\\nprincipal embedding space, we show that the syntactic information captured by a\\nprincipal component does not correlate with the amount of variance it explains.\\nConsequently, we investigate the limitations of variance based embedding\\npost-processing and demonstrate that such post-processing is counter-productive\\nin sentence classification and machine translation tasks. Finally, we offer a\\nfew precautionary guidelines on applying variance based embedding\\npost-processing and explain why non-isotropic geometry might be integral to\\nword embedding performance.\\n\\n    ', '\\nAbstract:  3D skeleton-based action recognition and motion prediction are two essential\\nproblems of human activity understanding. In many previous works: 1) they\\nstudied two tasks separately, neglecting internal correlations; 2) they did not\\ncapture sufficient relations inside the body. To address these issues, we\\npropose a symbiotic model to handle two tasks jointly; and we propose two\\nscales of graphs to explicitly capture relations among body-joints and\\nbody-parts. Together, we propose symbiotic graph neural networks, which contain\\na backbone, an action-recognition head, and a motion-prediction head. Two heads\\nare trained jointly and enhance each other. For the backbone, we propose\\nmulti-branch multi-scale graph convolution networks to extract spatial and\\ntemporal features. The multi-scale graph convolution networks are based on\\njoint-scale and part-scale graphs. The joint-scale graphs contain actional\\ngraphs, capturing action-based relations, and structural graphs, capturing\\nphysical constraints. The part-scale graphs integrate body-joints to form\\nspecific parts, representing high-level relations. Moreover, dual bone-based\\ngraphs and networks are proposed to learn complementary features. We conduct\\nextensive experiments for skeleton-based action recognition and motion\\nprediction with four datasets, NTU-RGB+D, Kinetics, Human3.6M, and CMU Mocap.\\nExperiments show that our symbiotic graph neural networks achieve better\\nperformances on both tasks compared to the state-of-the-art methods.\\n\\n    ', '\\nAbstract:  Training deep neural networks on large scientific data is a challenging task\\nthat requires enormous compute power, especially if no pre-trained models exist\\nto initialize the process. We present a novel tournament method to train\\ntraditional as well as generative adversarial networks built on LBANN, a\\nscalable deep learning framework optimized for HPC systems. LBANN combines\\nmultiple levels of parallelism and exploits some of the worlds largest\\nsupercomputers. We demonstrate our framework by creating a complex predictive\\nmodel based on multi-variate data from high-energy-density physics containing\\nhundreds of millions of images and hundreds of millions of scalar values\\nderived from tens of millions of simulations of inertial confinement fusion.\\nOur approach combines an HPC workflow and extends LBANN with optimized data\\ningestion and the new tournament-style training algorithm to produce a scalable\\nneural network architecture using a CORAL-class supercomputer. Experimental\\nresults show that 64 trainers (1024 GPUs) achieve a speedup of 70.2 over a\\nsingle trainer (16 GPUs) baseline, and an effective 109% parallel efficiency.\\n\\n    ', '\\nAbstract:  Dimensionality reduction plays an important role in computer vision problems\\nsince it reduces computational cost and is often capable of yielding more\\ndiscriminative data representation. In this context, Partial Least Squares\\n(PLS) has presented notable results in tasks such as image classification and\\nneural network optimization. However, PLS is infeasible on large datasets\\n(e.g., ImageNet) because it requires all the data to be in memory in advance,\\nwhich is often impractical due to hardware limitations. Additionally, this\\nrequirement prevents us from employing PLS on streaming applications where the\\ndata are being continuously generated. Motivated by this, we propose a novel\\nincremental PLS, named Covariance-free Incremental Partial Least Squares\\n(CIPLS), which learns a low-dimensional representation of the data using a\\nsingle sample at a time. In contrast to other state-of-the-art approaches,\\ninstead of adopting a partially-discriminative or SGD-based model, we extend\\nNonlinear Iterative Partial Least Squares (NIPALS) - the standard algorithm\\nused to compute PLS - for incremental processing. Among the advantages of this\\napproach are the preservation of discriminative information across all\\ncomponents, the possibility of employing its score matrices for feature\\nselection, and its computational efficiency. We validate CIPLS on face\\nverification and image classification tasks, where it outperforms several other\\nincremental dimensionality reduction methods. In the context of feature\\nselection, CIPLS achieves comparable results when compared to state-of-the-art\\ntechniques.\\n\\n    ', \"\\nAbstract:  We introduce MAgent, a platform to support research and development of\\nmany-agent reinforcement learning. Unlike previous research platforms on single\\nor multi-agent reinforcement learning, MAgent focuses on supporting the tasks\\nand the applications that require hundreds to millions of agents. Within the\\ninteractions among a population of agents, it enables not only the study of\\nlearning algorithms for agents' optimal polices, but more importantly, the\\nobservation and understanding of individual agent's behaviors and social\\nphenomena emerging from the AI society, including communication languages,\\nleaderships, altruism. MAgent is highly scalable and can host up to one million\\nagents on a single GPU server. MAgent also provides flexible configurations for\\nAI researchers to design their customized environments and agents. In this\\ndemo, we present three environments designed on MAgent and show emerged\\ncollective intelligence by learning from scratch.\\n\\n    \", '\\nAbstract:  We explore deep reinforcement learning methods for multi-agent domains. We\\nbegin by analyzing the difficulty of traditional algorithms in the multi-agent\\ncase: Q-learning is challenged by an inherent non-stationarity of the\\nenvironment, while policy gradient suffers from a variance that increases as\\nthe number of agents grows. We then present an adaptation of actor-critic\\nmethods that considers action policies of other agents and is able to\\nsuccessfully learn policies that require complex multi-agent coordination.\\nAdditionally, we introduce a training regimen utilizing an ensemble of policies\\nfor each agent that leads to more robust multi-agent policies. We show the\\nstrength of our approach compared to existing methods in cooperative as well as\\ncompetitive scenarios, where agent populations are able to discover various\\nphysical and informational coordination strategies.\\n\\n    ', '\\nAbstract:  We consider the problem of multiple agents sensing and acting in environments\\nwith the goal of maximising their shared utility. In these environments, agents\\nmust learn communication protocols in order to share information that is needed\\nto solve the tasks. By embracing deep neural networks, we are able to\\ndemonstrate end-to-end learning of protocols in complex environments inspired\\nby communication riddles and multi-agent computer vision problems with partial\\nobservability. We propose two approaches for learning in these domains:\\nReinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning\\n(DIAL). The former uses deep Q-learning, while the latter exploits the fact\\nthat, during learning, agents can backpropagate error derivatives through\\n(noisy) communication channels. Hence, this approach uses centralised learning\\nbut decentralised execution. Our experiments introduce new environments for\\nstudying the learning of communication protocols and present a set of\\nengineering innovations that are essential for success in these domains.\\n\\n    ', '\\nAbstract:  In the last few years, deep multi-agent reinforcement learning (RL) has\\nbecome a highly active area of research. A particularly challenging class of\\nproblems in this area is partially observable, cooperative, multi-agent\\nlearning, in which teams of agents must learn to coordinate their behaviour\\nwhile conditioning only on their private observations. This is an attractive\\nresearch area since such problems are relevant to a large number of real-world\\nsystems and are also more amenable to evaluation than general-sum problems.\\nStandardised environments such as the ALE and MuJoCo have allowed single-agent\\nRL to move beyond toy domains, such as grid worlds. However, there is no\\ncomparable benchmark for cooperative multi-agent RL. As a result, most papers\\nin this field use one-off toy problems, making it difficult to measure real\\nprogress. In this paper, we propose the StarCraft Multi-Agent Challenge (SMAC)\\nas a benchmark problem to fill this gap. SMAC is based on the popular real-time\\nstrategy game StarCraft II and focuses on micromanagement challenges where each\\nunit is controlled by an independent agent that must act based on local\\nobservations. We offer a diverse set of challenge maps and recommendations for\\nbest practices in benchmarking and evaluations. We also open-source a deep\\nmulti-agent RL learning framework including state-of-the-art algorithms. We\\nbelieve that SMAC can provide a standard benchmark environment for years to\\ncome. Videos of our best agents for several SMAC scenarios are available at:\\nthis https URL.\\n\\n    ', '\\nAbstract:  In many real-world settings, a team of agents must coordinate their behaviour\\nwhile acting in a decentralised way. At the same time, it is often possible to\\ntrain the agents in a centralised fashion in a simulated or laboratory setting,\\nwhere global state information is available and communication constraints are\\nlifted. Learning joint action-values conditioned on extra state information is\\nan attractive way to exploit centralised learning, but the best strategy for\\nthen extracting decentralised policies is unclear. Our solution is QMIX, a\\nnovel value-based method that can train decentralised policies in a centralised\\nend-to-end fashion. QMIX employs a network that estimates joint action-values\\nas a complex non-linear combination of per-agent values that condition only on\\nlocal observations. We structurally enforce that the joint-action value is\\nmonotonic in the per-agent values, which allows tractable maximisation of the\\njoint action-value in off-policy learning, and guarantees consistency between\\nthe centralised and decentralised policies. We evaluate QMIX on a challenging\\nset of StarCraft II micromanagement tasks, and show that QMIX significantly\\noutperforms existing value-based multi-agent reinforcement learning methods.\\n\\n    ', \"\\nAbstract:  RLCard is an open-source toolkit for reinforcement learning research in card\\ngames. It supports various card environments with easy-to-use interfaces,\\nincluding Blackjack, Leduc Hold'em, Texas Hold'em, UNO, Dou Dizhu and Mahjong.\\nThe goal of RLCard is to bridge reinforcement learning and imperfect\\ninformation games, and push forward the research of reinforcement learning in\\ndomains with multiple agents, large state and action space, and sparse reward.\\nIn this paper, we provide an overview of the key components in RLCard, a\\ndiscussion of the design principles, a brief introduction of the interfaces,\\nand comprehensive evaluations of the environments. The codes and documents are\\navailable at this https URL\\n\", '\\nAbstract:  Learning in multi-agent scenarios is a fruitful research direction, but\\ncurrent approaches still show scalability problems in multiple games with\\ngeneral reward settings and different opponent types. The Multi-Agent\\nReinforcement Learning in MalmÖ (MARLÖ) competition is a new challenge that\\nproposes research in this domain using multiple 3D games. The goal of this\\ncontest is to foster research in general agents that can learn across different\\ngames and opponent types, proposing a challenge as a milestone in the direction\\nof Artificial General Intelligence.\\n\\n    ', \"\\nAbstract:  Traffic signal control is an emerging application scenario for reinforcement\\nlearning. Besides being as an important problem that affects people's daily\\nlife in commuting, traffic signal control poses its unique challenges for\\nreinforcement learning in terms of adapting to dynamic traffic environment and\\ncoordinating thousands of agents including vehicles and pedestrians. A key\\nfactor in the success of modern reinforcement learning relies on a good\\nsimulator to generate a large number of data samples for learning. The most\\ncommonly used open-source traffic simulator SUMO is, however, not scalable to\\nlarge road network and large traffic flow, which hinders the study of\\nreinforcement learning on traffic scenarios. This motivates us to create a new\\ntraffic simulator CityFlow with fundamentally optimized data structures and\\nefficient algorithms. CityFlow can support flexible definitions for road\\nnetwork and traffic flow based on synthetic and real-world data. It also\\nprovides user-friendly interface for reinforcement learning. Most importantly,\\nCityFlow is more than twenty times faster than SUMO and is capable of\\nsupporting city-wide traffic simulation with an interactive render for\\nmonitoring. Besides traffic signal control, CityFlow could serve as the base\\nfor other transportation studies and can create new possibilities to test\\nmachine learning methods in the intelligent transportation domain.\\n\\n    \", '\\nAbstract:  Cooperation is critical in multi-agent reinforcement learning (MARL). In the\\ncontext of traffic signal control, good cooperation among the traffic signal\\nagents enables the vehicles to move through intersections more smoothly.\\nConventional transportation approaches implement cooperation by pre-calculating\\nthe offsets between two intersections. Such pre-calculated offsets are not\\nsuitable for dynamic traffic environments. To incorporate cooperation in\\nreinforcement learning (RL), two typical approaches are proposed to take the\\ninfluence of other agents into consideration: (1) learning the communications\\n(i.e., the representation of influences between agents) and (2) learning joint\\nactions for agents. While joint modeling of actions has shown a preferred trend\\nin recent studies, an in-depth study of improving the learning of\\ncommunications between agents has not been systematically studied in the\\ncontext of traffic signal control. To learn the communications between agents,\\nin this paper, we propose to use graph attentional network to facilitate\\ncooperation. Specifically, for a target intersection in a network, our proposed\\nmodel, CoLight, cannot only incorporate the influences of neighboring\\nintersections but learn to differentiate their impacts to the target\\nintersection. To the best of our knowledge, we are the first to use graph\\nattentional network in the setting of reinforcement learning for traffic signal\\ncontrol. In experiments, we demonstrate that by learning the communication, the\\nproposed model can achieve surprisingly good performance, whereas the existing\\napproaches based on joint action modeling fail to learn well.\\n\\n    ', \"\\nAbstract:  We propose a unified mechanism for achieving coordination and communication\\nin Multi-Agent Reinforcement Learning (MARL), through rewarding agents for\\nhaving causal influence over other agents' actions. Causal influence is\\nassessed using counterfactual reasoning. At each timestep, an agent simulates\\nalternate actions that it could have taken, and computes their effect on the\\nbehavior of other agents. Actions that lead to bigger changes in other agents'\\nbehavior are considered influential and are rewarded. We show that this is\\nequivalent to rewarding agents for having high mutual information between their\\nactions. Empirical results demonstrate that influence leads to enhanced\\ncoordination and communication in challenging social dilemma environments,\\ndramatically increasing the learning curves of the deep RL agents, and leading\\nto more meaningful learned communication protocols. The influence rewards for\\nall agents can be computed in a decentralized way by enabling agents to learn a\\nmodel of other agents using deep neural networks. In contrast, key previous\\nworks on emergent communication in the MARL setting were unable to learn\\ndiverse policies in a decentralized manner and had to resort to centralized\\ntraining. Consequently, the influence reward opens up a window of new\\nopportunities for research in this area.\\n\\n    \", '\\nAbstract:  Groups of humans are often able to find ways to cooperate with one another in\\ncomplex, temporally extended social dilemmas. Models based on behavioral\\neconomics are only able to explain this phenomenon for unrealistic stateless\\nmatrix games. Recently, multi-agent reinforcement learning has been applied to\\ngeneralize social dilemma problems to temporally and spatially extended Markov\\ngames. However, this has not yet generated an agent that learns to cooperate in\\nsocial dilemmas as humans do. A key insight is that many, but not all, human\\nindividuals have inequity averse social preferences. This promotes a particular\\nresolution of the matrix game social dilemma wherein inequity-averse\\nindividuals are personally pro-social and punish defectors. Here we extend this\\nidea to Markov games and show that it promotes cooperation in several types of\\nsequential social dilemma, via a profitable interaction with policy\\nlearnability. In particular, we find that inequity aversion improves temporal\\ncredit assignment for the important class of intertemporal social dilemmas.\\nThese results help explain how large-scale cooperation may emerge and persist.\\n\\n    ', \"\\nAbstract:  Matrix games like Prisoner's Dilemma have guided research on social dilemmas\\nfor decades. However, they necessarily treat the choice to cooperate or defect\\nas an atomic action. In real-world social dilemmas these choices are temporally\\nextended. Cooperativeness is a property that applies to policies, not\\nelementary actions. We introduce sequential social dilemmas that share the\\nmixed incentive structure of matrix game social dilemmas but also require\\nagents to learn policies that implement their strategic intentions. We analyze\\nthe dynamics of policies learned by multiple self-interested independent\\nlearning agents, each using its own deep Q-network, on two Markov games we\\nintroduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We\\ncharacterize how learned behavior in each domain changes as a function of\\nenvironmental factors including resource abundance. Our experiments show how\\nconflict can emerge from competition over shared resources and shed light on\\nhow the sequential nature of real world social dilemmas affects cooperation.\\n\\n    \", \"\\nAbstract:  Existing multi-agent reinforcement learning methods are limited typically to\\na small number of agents. When the agent number increases largely, the learning\\nbecomes intractable due to the curse of the dimensionality and the exponential\\ngrowth of agent interactions. In this paper, we present Mean Field\\nReinforcement Learning where the interactions within the population of agents\\nare approximated by those between a single agent and the average effect from\\nthe overall population or neighboring agents; the interplay between the two\\nentities is mutually reinforced: the learning of the individual agent's optimal\\npolicy depends on the dynamics of the population, while the dynamics of the\\npopulation change according to the collective patterns of the individual\\npolicies. We develop practical mean field Q-learning and mean field\\nActor-Critic algorithms and analyze the convergence of the solution to Nash\\nequilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\\njustify the learning effectiveness of our mean field approaches. In addition,\\nwe report the first result to solve the Ising model via model-free\\nreinforcement learning methods.\\n\\n    \", '\\nAbstract:  Reinforcement learning in multi-agent scenarios is important for real-world\\napplications but presents challenges beyond those seen in single-agent\\nsettings. We present an actor-critic algorithm that trains decentralized\\npolicies in multi-agent settings, using centrally computed critics that share\\nan attention mechanism which selects relevant information for each agent at\\nevery timestep. This attention mechanism enables more effective and scalable\\nlearning in complex multi-agent environments, when compared to recent\\napproaches. Our approach is applicable not only to cooperative settings with\\nshared rewards, but also individualized reward settings, including adversarial\\nsettings, as well as settings that do not provide global states, and it makes\\nno assumptions about the action spaces of the agents. As such, it is flexible\\nenough to be applied to most multi-agent learning problems.\\n\\n    ', \"\\nAbstract:  Multi-agent settings are quickly gathering importance in machine learning.\\nThis includes a plethora of recent work on deep multi-agent reinforcement\\nlearning, but also can be extended to hierarchical RL, generative adversarial\\nnetworks and decentralised optimisation. In all these settings the presence of\\nmultiple learning agents renders the training problem non-stationary and often\\nleads to unstable training or undesired final results. We present Learning with\\nOpponent-Learning Awareness (LOLA), a method in which each agent shapes the\\nanticipated learning of the other agents in the environment. The LOLA learning\\nrule includes a term that accounts for the impact of one agent's policy on the\\nanticipated parameter update of the other agents. Results show that the\\nencounter of two LOLA agents leads to the emergence of tit-for-tat and\\ntherefore cooperation in the iterated prisoners' dilemma, while independent\\nlearning does not. In this domain, LOLA also receives higher payouts compared\\nto a naive learner, and is robust against exploitation by higher order\\ngradient-based methods. Applied to repeated matching pennies, LOLA agents\\nconverge to the Nash equilibrium. In a round robin tournament we show that LOLA\\nagents successfully shape the learning of a range of multi-agent learning\\nalgorithms from literature, resulting in the highest average returns on the\\nIPD. We also show that the LOLA update rule can be efficiently calculated using\\nan extension of the policy gradient estimator, making the method suitable for\\nmodel-free RL. The method thus scales to large parameter and input spaces and\\nnonlinear function approximators. We apply LOLA to a grid world task with an\\nembedded social dilemma using recurrent policies and opponent modelling. By\\nexplicitly considering the learning of the other agent, LOLA agents learn to\\ncooperate out of self-interest. The code is at this http URL.\\n\\n    \", '\\nAbstract:  Large-scale online ride-sharing platforms have substantially transformed our\\nlives by reallocating transportation resources to alleviate traffic congestion\\nand promote transportation efficiency. An efficient fleet management strategy\\nnot only can significantly improve the utilization of transportation resources\\nbut also increase the revenue and customer satisfaction. It is a challenging\\ntask to design an effective fleet management strategy that can adapt to an\\nenvironment involving complex dynamics between demand and supply. Existing\\nstudies usually work on a simplified problem setting that can hardly capture\\nthe complicated stochastic demand-supply variations in high-dimensional space.\\nIn this paper we propose to tackle the large-scale fleet management problem\\nusing reinforcement learning, and propose a contextual multi-agent\\nreinforcement learning framework including two concrete algorithms, namely\\ncontextual deep Q-learning and contextual multi-agent actor-critic, to achieve\\nexplicit coordination among a large number of agents adaptive to different\\ncontexts. We show significant improvements of the proposed framework over\\nstate-of-the-art approaches through extensive empirical studies.\\n\\n    ', '\\nAbstract:  While multi-agent interactions can be naturally modeled as a graph, the\\nenvironment has traditionally been considered as a black box. We propose to\\ncreate a shared agent-entity graph, where agents and environmental entities\\nform vertices, and edges exist between the vertices which can communicate with\\neach other. Agents learn to cooperate by exchanging messages along the edges of\\nthis graph. Our proposed multi-agent reinforcement learning framework is\\ninvariant to the number of agents or entities present in the system as well as\\npermutation invariance, both of which are desirable properties for any\\nmulti-agent system representation. We present state-of-the-art results on\\ncoverage, formation and line control tasks for multi-agent teams in a fully\\ndecentralized framework and further show that the learned policies quickly\\ntransfer to scenarios with different team sizes along with strong zero-shot\\ngeneralization performance. This is an important step towards developing\\nmulti-agent teams which can be realistically deployed in the real world without\\nassuming complete prior knowledge or instantaneous communication at unbounded\\ndistances.\\n\\n    ', \"\\nAbstract:  Most of the prior work on multi-agent reinforcement learning (MARL) achieves\\noptimal collaboration by directly controlling the agents to maximize a common\\nreward. In this paper, we aim to address this from a different angle. In\\nparticular, we consider scenarios where there are self-interested agents (i.e.,\\nworker agents) which have their own minds (preferences, intentions, skills,\\netc.) and can not be dictated to perform tasks they do not wish to do. For\\nachieving optimal coordination among these agents, we train a super agent\\n(i.e., the manager) to manage them by first inferring their minds based on both\\ncurrent and past observations and then initiating contracts to assign suitable\\ntasks to workers and promise to reward them with corresponding bonuses so that\\nthey will agree to work together. The objective of the manager is maximizing\\nthe overall productivity as well as minimizing payments made to the workers for\\nad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\\nManagement Reinforcement Learning (M^3RL), which consists of agent modeling and\\npolicy learning. We have evaluated our approach in two environments, Resource\\nCollection and Crafting, to simulate multi-agent management problems with\\nvarious task settings and multiple designs for the worker agents. The\\nexperimental results have validated the effectiveness of our approach in\\nmodeling worker agents' minds online, and in achieving optimal ad-hoc teaming\\nwith good generalization and fast adaptation.\\n\\n    \", '\\nAbstract:  We propose a novel hierarchical agent architecture for multi-agent\\nreinforcement learning with concealed information. The hierarchy is grounded in\\nthe concealed information about other players, which resolves \"the chicken or\\nthe egg\" nature of option discovery. We factorise the value function over a\\nlatent representation of the concealed information and then re-use this latent\\nspace to factorise the policy into options. Low-level policies (options) are\\ntrained to respond to particular states of other agents grouped by the latent\\nrepresentation, while the top level (meta-policy) learns to infer the latent\\nrepresentation from its own observation thereby to select the right option.\\nThis grounding facilitates credit assignment across the levels of hierarchy. We\\nshow that this helps generalisation---performance against a held-out set of\\npre-trained competitors, while training in self- or population-play---and\\nresolution of social dilemmas in self-play.\\n\\n    ', \"\\nAbstract:  We consider the multi-agent reinforcement learning setting with imperfect\\ninformation in which each agent is trying to maximize its own utility. The\\nreward function depends on the hidden state (or goal) of both agents, so the\\nagents must infer the other players' hidden goals from their observed behavior\\nin order to solve the tasks. We propose a new approach for learning in these\\ndomains: Self Other-Modeling (SOM), in which an agent uses its own policy to\\npredict the other agent's actions and update its belief of their hidden state\\nin an online manner. We evaluate this approach on three different tasks and\\nshow that the agents are able to learn better policies using their estimate of\\nthe other players' hidden states, in both cooperative and adversarial settings.\\n\\n    \", '\\nAbstract:  We consider the problem of \\\\emph{fully decentralized} multi-agent\\nreinforcement learning (MARL), where the agents are located at the nodes of a\\ntime-varying communication network. Specifically, we assume that the reward\\nfunctions of the agents might correspond to different tasks, and are only known\\nto the corresponding agent. Moreover, each agent makes individual decisions\\nbased on both the information observed locally and the messages received from\\nits neighbors over the network. Within this setting, the collective goal of the\\nagents is to maximize the globally averaged return over the network through\\nexchanging information with their neighbors. To this end, we propose two\\ndecentralized actor-critic algorithms with function approximation, which are\\napplicable to large-scale MARL problems where both the number of states and the\\nnumber of agents are massively large. Under the decentralized structure, the\\nactor step is performed individually by each agent with no need to infer the\\npolicies of others. For the critic step, we propose a consensus update via\\ncommunication over the network. Our algorithms are fully incremental and can be\\nimplemented in an online fashion. Convergence analyses of the algorithms are\\nprovided when the value functions are approximated within the class of linear\\nfunctions. Extensive simulation results with both linear and nonlinear function\\napproximations are presented to validate the proposed algorithms. Our work\\nappears to be the first study of fully decentralized MARL algorithms for\\nnetworked agents with function approximation, with provable convergence\\nguarantees.\\n\\n    ', \"\\nAbstract:  Many real-world problems, such as network packet routing and urban traffic\\ncontrol, are naturally modeled as multi-agent reinforcement learning (RL)\\nproblems. However, existing multi-agent RL methods typically scale poorly in\\nthe problem size. Therefore, a key challenge is to translate the success of\\ndeep learning on single-agent RL to the multi-agent setting. A major stumbling\\nblock is that independent Q-learning, the most popular multi-agent RL method,\\nintroduces nonstationarity that makes it incompatible with the experience\\nreplay memory on which deep Q-learning relies. This paper proposes two methods\\nthat address this problem: 1) using a multi-agent variant of importance\\nsampling to naturally decay obsolete data and 2) conditioning each agent's\\nvalue function on a fingerprint that disambiguates the age of the data sampled\\nfrom the replay memory. Results on a challenging decentralised variant of\\nStarCraft unit micromanagement confirm that these methods enable the successful\\ncombination of experience replay with multi-agent RL.\\n\\n    \", \"\\nAbstract:  Many real-world reinforcement learning tasks require multiple agents to make\\nsequential decisions under the agents' interaction, where well-coordinated\\nactions among the agents are crucial to achieve the target goal better at these\\ntasks. One way to accelerate the coordination effect is to enable multiple\\nagents to communicate with each other in a distributed manner and behave as a\\ngroup. In this paper, we study a practical scenario when (i) the communication\\nbandwidth is limited and (ii) the agents share the communication medium so that\\nonly a restricted number of agents are able to simultaneously use the medium,\\nas in the state-of-the-art wireless networking standards. This calls for a\\ncertain form of communication scheduling. In that regard, we propose a\\nmulti-agent deep reinforcement learning framework, called SchedNet, in which\\nagents learn how to schedule themselves, how to encode the messages, and how to\\nselect actions based on received messages. SchedNet is capable of deciding\\nwhich agents should be entitled to broadcasting their (encoded) messages, by\\nlearning the importance of each agent's partially observed information. We\\nevaluate SchedNet against multiple baselines under two different applications,\\nnamely, cooperative communication and navigation, and predator-prey. Our\\nexperiments show a non-negligible performance gap between SchedNet and other\\nmechanisms such as the ones without communication and with vanilla scheduling\\nmethods, e.g., round robin, ranging from 32% to 43%.\\n\\n    \", '\\nAbstract:  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\\nan inference problem by introducing a binary random variable o, which stands\\nfor the \"optimality\". In this paper, we redefine the binary random variable o\\nin multi-agent setting and formalize multi-agent reinforcement learning (MARL)\\nas probabilistic inference. We derive a variational lower bound of the\\nlikelihood of achieving the optimality and name it as Regularized Opponent\\nModel with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\\nperspective on opponent modeling and show how it can improve the performance of\\ntraining agents theoretically and empirically in cooperative games. To optimize\\nROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\\nconvergence. We extend the exact algorithm to complex environments by proposing\\nan approximate version, ROMMEO-AC. We evaluate these two algorithms on the\\nchallenging iterated matrix game and differential game respectively and show\\nthat they can outperform strong MARL baselines.\\n\\n    ', \"\\nAbstract:  We explore value-based solutions for multi-agent reinforcement learning\\n(MARL) tasks in the centralized training with decentralized execution (CTDE)\\nregime popularized recently. However, VDN and QMIX are representative examples\\nthat use the idea of factorization of the joint action-value function into\\nindividual ones for decentralized execution. VDN and QMIX address only a\\nfraction of factorizable MARL tasks due to their structural constraint in\\nfactorization such as additivity and monotonicity. In this paper, we propose a\\nnew factorization method for MARL, QTRAN, which is free from such structural\\nconstraints and takes on a new approach to transforming the original joint\\naction-value function into an easily factorizable one, with the same optimal\\nactions. QTRAN guarantees more general factorization than VDN or QMIX, thus\\ncovering a much wider class of MARL tasks than does previous methods. Our\\nexperiments for the tasks of multi-domain Gaussian-squeeze and modified\\npredator-prey demonstrate QTRAN's superior performance with especially larger\\nmargins in games whose payoffs penalize non-cooperative behavior more\\naggressively.\\n\\n    \", '\\nAbstract:  In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\\nlearners must overcome a number of pathologies to learn optimal joint policies.\\nAddressing one pathology often leaves approaches vulnerable towards others. For\\ninstance, hysteretic Q-learning addresses miscoordination while leaving agents\\nvulnerable towards misleading stochastic rewards. Other methods, such as\\nleniency, have proven more robust when dealing with multiple pathologies\\nsimultaneously. However, leniency has predominately been studied within the\\ncontext of strategic form games (bimatrix games) and fully observable Markov\\ngames consisting of a small number of probabilistic state transitions. This\\nraises the question of whether these findings scale to more complex domains.\\nFor this purpose we implement a temporally extend version of the Climb Game,\\nwithin which agents must overcome multiple pathologies simultaneously,\\nincluding relative overgeneralisation, stochasticity, the alter-exploration and\\nmoving target problems, while learning from a large observation space. We find\\nthat existing lenient and hysteretic approaches fail to consistently learn near\\noptimal joint-policies in this environment. To address these pathologies we\\nintroduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\\nwhich discards episodes yielding cumulative rewards outside the range of\\nexpanding intervals. NUI-DDQN consistently gravitates towards optimal\\njoint-policies in our environment, overcoming the outlined pathologies.\\n\\n    ', '\\nAbstract:  Much of the success of single agent deep reinforcement learning (DRL) in\\nrecent years can be attributed to the use of experience replay memories (ERM),\\nwhich allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\\nstored state transitions. However, care is required when using ERMs for\\nmulti-agent deep reinforcement learning (MA-DRL), as stored transitions can\\nbecome outdated because agents update their policies in parallel [11]. In this\\nwork we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\\ndecaying temperature values that control the amount of leniency applied towards\\nnegative policy updates that are sampled from the ERM. This introduces optimism\\nin the value-function update, and has been shown to facilitate cooperation in\\ntabular fully-cooperative multi-agent reinforcement learning problems. We\\nevaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\\n(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\\nthat uses average reward learning near terminal states. Evaluations take place\\nin extended variations of the Coordinated Multi-Agent Object Transportation\\nProblem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\\nrewards. We find that LDQN agents are more likely to converge to the optimal\\npolicy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\\nagents.\\n\\n    ', \"\\nAbstract:  Cooperative game is a critical research area in multi-agent reinforcement\\nlearning (MARL). Global reward game is a subclass of cooperative games, where\\nall agents aim to maximize cumulative global rewards. Credit assignment is an\\nimportant problem studied in the global reward game. Most of works stand by the\\nview of non-cooperative-game theoretical framework with the shared reward\\napproach, i.e., each agent being assigned a shared global reward directly.\\nThis, however, may give each agent an inaccurate feedback on its contribution\\nto the group. In this paper, we introduce a cooperative-game theoretical\\nframework and extend it to the infinite-horizon case. We show that our proposed\\nframework is a superset of the global reward game. Based on this framework, we\\npropose a local reward approach called Shapley Q-value that can distribute the\\ncumulative global rewards fairly, reflecting each agent's own contribution in\\ncontrast to the shared reward approach. Moreover, we derive an MARL algorithm\\ncalled Shapley Q-value policy gradient (SQPG), using Shapley Q-value as\\ncritics. We evaluate SQPG on Cooperative Navigation, Prey-and-Predator and\\nTraffic Junction, compared with MADDPG, COMA, Independent A2C and Independent\\nDDPG. In the experiments, SQPG shows the better performance than the baselines.\\nIn addition, we also plot the Shapley Q-value and validate the property of\\nfairly distributing the global rewards.\\n\\n    \", '\\nAbstract:  The detection of anatomical landmarks is a vital step for medical image\\nanalysis and applications for diagnosis, interpretation and guidance. Manual\\nannotation of landmarks is a tedious process that requires domain-specific\\nexpertise and introduces inter-observer variability. This paper proposes a new\\ndetection approach for multiple landmarks based on multi-agent reinforcement\\nlearning. Our hypothesis is that the position of all anatomical landmarks is\\ninterdependent and non-random within the human anatomy, thus finding one\\nlandmark can help to deduce the location of others. Using a Deep Q-Network\\n(DQN) architecture we construct an environment and agent with implicit\\ninter-communication such that we can accommodate K agents acting and learning\\nsimultaneously, while they attempt to detect K different landmarks. During\\ntraining the agents collaborate by sharing their accumulated knowledge for a\\ncollective gain. We compare our approach with state-of-the-art architectures\\nand achieve significantly better accuracy by reducing the detection error by\\n50%, while requiring fewer computational resources and time to train compared\\nto the naive approach of training K agents separately.\\n\\n    ', '\\nAbstract:  State-of-the-art meta reinforcement learning algorithms typically assume the\\nsetting of a single agent interacting with its environment in a sequential\\nmanner. A negative side-effect of this sequential execution paradigm is that,\\nas the environment becomes more and more challenging, and thus requiring more\\ninteraction episodes for the meta-learner, it needs the agent to reason over\\nlonger and longer time-scales. To combat the difficulty of long time-scale\\ncredit assignment, we propose an alternative parallel framework, which we name\\n\"Concurrent Meta-Reinforcement Learning\" (CMRL), that transforms the temporal\\ncredit assignment problem into a multi-agent reinforcement learning one. In\\nthis multi-agent setting, a set of parallel agents are executed in the same\\nenvironment and each of these \"rollout\" agents are given the means to\\ncommunicate with each other. The goal of the communication is to coordinate, in\\na collaborative manner, the most efficient exploration of the shared task the\\nagents are currently assigned. This coordination therefore represents the\\nmeta-learning aspect of the framework, as each agent can be assigned or assign\\nitself a particular section of the current task\\'s state space. This framework\\nis in contrast to standard RL methods that assume that each parallel rollout\\noccurs independently, which can potentially waste computation if many of the\\nrollouts end up sampling the same part of the state space. Furthermore, the\\nparallel setting enables us to define several reward sharing functions and\\nauxiliary losses that are non-trivial to apply in the sequential setting. We\\ndemonstrate the effectiveness of our proposed CMRL at improving over sequential\\nmethods in a variety of challenging tasks.\\n\\n    ', '\\nAbstract:  A standard belief on emerging collective behavior is that it emerges from\\nsimple individual rules. Most of the mathematical research on such collective\\nbehavior starts from imperative individual rules, like always go to the center.\\nBut how could an (optimal) individual rule emerge during a short period within\\nthe group lifetime, especially if communication is not available. We argue that\\nsuch rules can actually emerge in a group in a short span of time via\\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\\npunishments. We consider the gathering problem: several agents (social animals,\\nswarming robots...) must gather around a same position, which is not determined\\nin advance. They must do so without communication on their planned decision,\\njust by looking at the position of other agents. We present the first\\nexperimental evidence that a gathering behavior can be learned without\\ncommunication in a partially observable environment. The learned behavior has\\nthe same properties as a self-stabilizing distributed algorithm, as processes\\ncan gather from any initial state (and thus tolerate any transient failure).\\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\\\%\\nof agents without significant impact on the behavior.\\n\\n    ', '\\nAbstract:  Reinforcement Learning (RL) is a learning paradigm concerned with learning to\\ncontrol a system so as to maximize an objective over the long term. This\\napproach to learning has received immense interest in recent times and success\\nmanifests itself in the form of human-level performance on games like\\n\\\\textit{Go}. While RL is emerging as a practical component in real-life\\nsystems, most successes have been in Single Agent domains. This report will\\ninstead specifically focus on challenges that are unique to Multi-Agent Systems\\ninteracting in mixed cooperative and competitive environments. The report\\nconcludes with advances in the paradigm of training Multi-Agent Systems called\\n\\\\textit{Decentralized Actor, Centralized Critic}, based on an extension of MDPs\\ncalled \\\\textit{Decentralized Partially Observable MDP}s, which has seen a\\nrenewed interest lately.\\n\\n    ', \"\\nAbstract:  Here we explore a new algorithmic framework for multi-agent reinforcement\\nlearning, called Malthusian reinforcement learning, which extends self-play to\\ninclude fitness-linked population size dynamics that drive ongoing innovation.\\nIn Malthusian RL, increases in a subpopulation's average return drive\\nsubsequent increases in its size, just as Thomas Malthus argued in 1798 was the\\nrelationship between preindustrial income levels and population growth.\\nMalthusian reinforcement learning harnesses the competitive pressures arising\\nfrom growing and shrinking population size to drive agents to explore regions\\nof state and policy spaces that they could not otherwise reach. Furthermore, in\\nenvironments where there are potential gains from specialization and division\\nof labor, we show that Malthusian reinforcement learning is better positioned\\nto take advantage of such synergies than algorithms based on self-play.\\n\\n    \", '\\nAbstract:  This paper presents an upgraded, real world application oriented version of\\ngym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement\\nLearning (RL) toolkit, which complies with OpenAI Gym. The content discusses\\nthe new ROS 2 based software architecture and summarizes the results obtained\\nusing Proximal Policy Optimization (PPO). Ultimately, the output of this work\\npresents a benchmarking system for robotics that allows different techniques\\nand algorithms to be compared using the same virtual conditions. We have\\nevaluated environments with different levels of complexity of the Modular\\nArticulated Robotic Arm (MARA), reaching accuracies in the millimeter scale.\\nThe converged results show the feasibility and usefulness of the gym-gazebo 2\\ntoolkit, its potential and applicability in industrial use cases, using modular\\nrobots.\\n\\n    ', '\\nAbstract:  The ability to act in multiple environments and transfer previous knowledge\\nto new situations can be considered a critical aspect of any intelligent agent.\\nTowards this goal, we define a novel method of multitask and transfer learning\\nthat enables an autonomous agent to learn how to behave in multiple tasks\\nsimultaneously, and then generalize its knowledge to new domains. This method,\\ntermed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model\\ncompression techniques to train a single policy network that learns how to act\\nin a set of distinct tasks by using the guidance of several expert teachers. We\\nthen show that the representations learnt by the deep policy network are\\ncapable of generalizing to new tasks with no prior expert guidance, speeding up\\nlearning in novel environments. Although our method can in general be applied\\nto a wide range of problems, we use Atari games as a testing environment to\\ndemonstrate these methods.\\n\\n    ', '\\nAbstract:  The purpose of this technical report is two-fold. First of all, it introduces\\na suite of challenging continuous control tasks (integrated with OpenAI Gym)\\nbased on currently existing robotics hardware. The tasks include pushing,\\nsliding and pick & place with a Fetch robotic arm as well as in-hand object\\nmanipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards\\nand follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent\\nis told what to do using an additional input.\\nThe second part of the paper presents a set of concrete research ideas for\\nimproving RL algorithms, most of which are related to Multi-Goal RL and\\nHindsight Experience Replay.\\n\\n    ', '\\nAbstract:  Intrinsically motivated spontaneous exploration is a key enabler of\\nautonomous lifelong learning in human children. It allows them to discover and\\nacquire large repertoires of skills through self-generation, self-selection,\\nself-ordering and self-experimentation of learning goals. We present the\\nunsupervised multi-goal reinforcement learning formal framework as well as an\\nalgorithmic approach called intrinsically motivated goal exploration processes\\n(IMGEP) to enable similar properties of autonomous learning in machines. The\\nIMGEP algorithmic architecture relies on several principles: 1) self-generation\\nof goals as parameterized reinforcement learning problems; 2) selection of\\ngoals based on intrinsic rewards; 3) exploration with parameterized\\ntime-bounded policies and fast incremental goal-parameterized policy search; 4)\\nsystematic reuse of information acquired when targeting a goal for improving\\nother goals. We present a particularly efficient form of IMGEP that uses a\\nmodular representation of goal spaces as well as intrinsic rewards based on\\nlearning progress. We show how IMGEPs automatically generate a learning\\ncurriculum within an experimental setup where a real humanoid robot can explore\\nmultiple spaces of goals with several hundred continuous dimensions. While no\\nparticular target goal is provided to the system beforehand, this curriculum\\nallows the discovery of skills of increasing complexity, that act as stepping\\nstone for learning more complex skills (like nested tool use). We show that\\nlearning several spaces of diverse problems can be more efficient for learning\\ncomplex skills than only trying to directly learn these complex skills. We\\nillustrate the computational efficiency of IMGEPs as these robotic experiments\\nuse a simple memory-based low-level policy representations and search\\nalgorithm, enabling the whole system to learn online and incrementally on a\\nRaspberry Pi 3.\\n\\n    ', '\\nAbstract:  In Multi-Goal Reinforcement Learning, an agent learns to achieve multiple\\ngoals with a goal-conditioned policy. During learning, the agent first collects\\nthe trajectories into a replay buffer, and later these trajectories are\\nselected randomly for replay. However, the achieved goals in the replay buffer\\nare often biased towards the behavior policies. From a Bayesian perspective,\\nwhen there is no prior knowledge about the target goal distribution, the agent\\nshould learn uniformly from diverse achieved goals. Therefore, we first propose\\na novel multi-goal RL objective based on weighted entropy. This objective\\nencourages the agent to maximize the expected return, as well as to achieve\\nmore diverse goals. Secondly, we developed a maximum entropy-based\\nprioritization framework to optimize the proposed objective. For evaluation of\\nthis framework, we combine it with Deep Deterministic Policy Gradient, both\\nwith or without Hindsight Experience Replay. On a set of multi-goal robotic\\ntasks of OpenAI Gym, we compare our method with other baselines and show\\npromising improvements in both performance and sample-efficiency.\\n\\n    ', '\\nAbstract:  This paper introduces SC2LE (StarCraft II Learning Environment), a\\nreinforcement learning environment based on the StarCraft II game. This domain\\nposes a new grand challenge for reinforcement learning, representing a more\\ndifficult class of problems than considered in most prior work. It is a\\nmulti-agent problem with multiple players interacting; there is imperfect\\ninformation due to a partially observed map; it has a large action space\\ninvolving the selection and control of hundreds of units; it has a large state\\nspace that must be observed solely from raw input feature planes; and it has\\ndelayed credit assignment requiring long-term strategies over thousands of\\nsteps. We describe the observation, action, and reward specification for the\\nStarCraft II domain and provide an open source Python-based interface for\\ncommunicating with the game engine. In addition to the main game maps, we\\nprovide a suite of mini-games focusing on different elements of StarCraft II\\ngameplay. For the main game maps, we also provide an accompanying dataset of\\ngame replay data from human expert players. We give initial baseline results\\nfor neural networks trained from this data to predict game outcomes and player\\nactions. Finally, we present initial baseline results for canonical deep\\nreinforcement learning agents applied to the StarCraft II domain. On the\\nmini-games, these agents learn to achieve a level of play that is comparable to\\na novice player. However, when trained on the main game, these agents are\\nunable to make significant progress. Thus, SC2LE offers a new and challenging\\nenvironment for exploring deep reinforcement learning algorithms and\\narchitectures.\\n\\n    ', '\\nAbstract:  In this paper, we propose ELF, an Extensive, Lightweight and Flexible\\nplatform for fundamental reinforcement learning research. Using ELF, we\\nimplement a highly customizable real-time strategy (RTS) engine with three game\\nenvironments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a\\nminiature version of StarCraft, captures key game dynamics and runs at 40K\\nframe-per-second (FPS) per core on a Macbook Pro notebook. When coupled with\\nmodern reinforcement learning methods, the system can train a full-game bot\\nagainst built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition,\\nour platform is flexible in terms of environment-agent communication\\ntopologies, choices of RL methods, changes in game parameters, and can host\\nexisting C/C++-based game environments like Arcade Learning Environment. Using\\nELF, we thoroughly explore training parameters and show that a network with\\nLeaky ReLU and Batch Normalization coupled with long-horizon training and\\nprogressive curriculum beats the rule-based built-in AI more than $70\\\\%$ of the\\ntime in the full game of Mini-RTS. Strong performance is also achieved on the\\nother two games. In game replays, we show our agents learn interesting\\nstrategies. ELF, along with its RL platform, is open-sourced at\\nthis https URL.\\n\\n    ', '\\nAbstract:  We present TorchCraft, a library that enables deep learning research on\\nReal-Time Strategy (RTS) games such as StarCraft: Brood War, by making it\\neasier to control these games from a machine learning framework, here Torch.\\nThis white paper argues for using RTS games as a benchmark for AI research, and\\ndescribes the design and components of TorchCraft.\\n\\n    ', '\\nAbstract:  We release a dataset of 65646 StarCraft replays that contains 1535 million\\nframes and 496 million player actions. We provide full game state data along\\nwith the original replays that can be viewed in StarCraft. The game state data\\nwas recorded every 3 frames which ensures suitability for a wide variety of\\nmachine learning tasks such as strategy classification, inverse reinforcement\\nlearning, imitation learning, forward modeling, partial information extraction,\\nand others. We use TorchCraft to extract and store the data, which standardizes\\nthe data format for both reading from replays and reading directly from the\\ngame. Furthermore, the data can be used on different operating systems and\\nplatforms. The dataset contains valid, non-corrupted replays only and its\\nquality and diversity was ensured by a number of heuristics. We illustrate the\\ndiversity of the data with various statistics and provide examples of tasks\\nthat benefit from the dataset. We make the dataset available at\\nthis https URL . En Taro Adun!\\n\\n    ', \"\\nAbstract:  This paper advocates the exploration of the full state of recorded real-time\\nstrategy (RTS) games, by human or robotic players, to discover how to reason\\nabout tactics and strategy. We present a dataset of StarCraft games\\nencompassing the most of the games' state (not only player's orders). We\\nexplain one of the possible usages of this dataset by clustering armies on\\ntheir compositions. This reduction of armies compositions to mixtures of\\nGaussian allow for strategic reasoning at the level of the components. We\\nevaluated this clustering method by predicting the outcomes of battles based on\\narmies compositions' mixtures components\\n\\n    \", '\\nAbstract:  We present a dockerized version of a real-time strategy game StarCraft: Brood\\nWar, commonly used as a domain for AI research, with a pre-installed collection\\nof AI developement tools supporting all the major types of StarCraft bots. This\\nprovides a convenient way to deploy StarCraft AIs on numerous hosts at once and\\nacross multiple platforms despite limited OS support of StarCraft. In this\\ntechnical report, we describe the design of our Docker images and present a few\\nuse cases.\\n\\n    ', \"\\nAbstract:  Macro-management is an important problem in StarCraft, which has been studied\\nfor a long time. Various datasets together with assorted methods have been\\nproposed in the last few years. But these datasets have some defects for\\nboosting the academic and industrial research: 1) There're neither standard\\npreprocessing, parsing and feature extraction procedures nor predefined\\ntraining, validation and test set in some datasets. 2) Some datasets are only\\nspecified for certain tasks in macro-management. 3) Some datasets are either\\ntoo small or don't have enough labeled data for modern machine learning\\nalgorithms such as deep neural networks. So most previous methods are trained\\nwith various features, evaluated on different test sets from the same or\\ndifferent datasets, making it difficult to be compared directly. To boost the\\nresearch of macro-management in StarCraft, we release a new dataset MSC based\\non the platform SC2LE. MSC consists of well-designed feature vectors,\\npre-defined high-level actions and final result of each match. We also split\\nMSC into training, validation and test set for the convenience of evaluation\\nand comparison. Besides the dataset, we propose a baseline model and present\\ninitial baseline results for global state evaluation and build order\\nprediction, which are two of the key tasks in macro-management. Various\\ndownstream tasks and analyses of the dataset are also described for the sake of\\nresearch on macro-management in StarCraft II. Homepage:\\nthis https URL.\\n\\n    \", '\\nAbstract:  Learning when to communicate and doing that effectively is essential in\\nmulti-agent tasks. Recent works show that continuous communication allows\\nefficient training with back-propagation in multi-agent scenarios, but have\\nbeen restricted to fully-cooperative tasks. In this paper, we present\\nIndividualized Controlled Continuous Communication Model (IC3Net) which has\\nbetter training efficiency than simple continuous communication model, and can\\nbe applied to semi-cooperative and competitive settings along with the\\ncooperative settings. IC3Net controls continuous communication with a gating\\nmechanism and uses individualized rewards foreach agent to gain better\\nperformance and scalability while fixing credit assignment issues. Using\\nvariety of tasks including StarCraft BroodWars explore and combat scenarios, we\\nshow that our network yields improved performance and convergence rates than\\nthe baselines as the scale increases. Our results convey that IC3Net agents\\nlearn when to communicate based on the scenario and profitability.\\n\\n    ', '\\nAbstract:  Starcraft II (SC2) is widely considered as the most challenging Real Time\\nStrategy (RTS) game. The underlying challenges include a large observation\\nspace, a huge (continuous and infinite) action space, partial observations,\\nsimultaneous move for all players, and long horizon delayed rewards for local\\ndecisions. To push the frontier of AI research, Deepmind and Blizzard jointly\\ndeveloped the StarCraft II Learning Environment (SC2LE) as a testbench of\\ncomplex decision making systems. SC2LE provides a few mini games such as\\nMoveToBeacon, CollectMineralShards, and DefeatRoaches, where some AI agents\\nhave achieved the performance level of human professional players. However, for\\nfull games, the current AI agents are still far from achieving human\\nprofessional level performance. To bridge this gap, we present two full game AI\\nagents in this paper - the AI agent TStarBot1 is based on deep reinforcement\\nlearning over a flat action structure, and the AI agent TStarBot2 is based on\\nhard-coded rules over a hierarchical action structure. Both TStarBot1 and\\nTStarBot2 are able to defeat the built-in AI agents from level 1 to level 10 in\\na full game (1v1 Zerg-vs-Zerg game on the AbyssalReef map), noting that level\\n8, level 9, and level 10 are cheating agents with unfair advantages such as\\nfull vision on the whole map and resource harvest boosting. To the best of our\\nknowledge, this is the first public work to investigate AI agents that can\\ndefeat the built-in AI in the StarCraft II full game.\\n\\n    ', '\\nAbstract:  StarCraft (SC) is one of the most popular and successful Real Time Strategy\\n(RTS) games. In recent years, SC is also widely accepted as a challenging\\ntestbed for AI research because of its enormous state space, partially observed\\ninformation, multi-agent collaboration, and so on. With the help of annual\\nAIIDE and CIG competitions, a growing number of SC bots are proposed and\\ncontinuously improved. However, a large gap remains between the top-level bot\\nand the professional human player. One vital reason is that current SC bots\\nmainly rely on predefined rules to select macro actions during their games.\\nThese rules are not scalable and efficient enough to cope with the enormous yet\\npartially observed state space in the game. In this paper, we propose a deep\\nreinforcement learning (DRL) framework to improve the selection of macro\\nactions. Our framework is based on the combination of the Ape-X DQN and the\\nLong-Short-Term-Memory (LSTM). We use this framework to build our bot, named as\\nLastOrder. Our evaluation, based on training against all bots from the AIIDE\\n2017 StarCraft AI competition set, shows that LastOrder achieves an 83% winning\\nrate, outperforming 26 bots in total 28 entrants.\\n\\n    ', '\\nAbstract:  StarCraft provides an extremely challenging platform for reinforcement\\nlearning due to its huge state-space and game length. The previous fastest\\nmethod requires days to train a full-length game policy in a single commercial\\nmachine. Introduction of background knowledge can accelerate the training of\\nreinforcement learning. But how to effectively introduce background knowledge\\nis still an open question. In this paper, we incorporate the background\\nknowledge to reinforcement learning in the form of a thought-game. With the\\nthought-game, the policy is firstly trained in the thought-game fastly and is\\nthen transferred to the real game using mapping functions for the second phase\\ntraining. In our experiments, the trained agent can achieve a 100\\\\% win-rate on\\nthe map \\\\textit{Simple64} against the most difficult non-cheating built-in bot\\n(level-7), and the training is 100 times faster than the previous ones under\\nthe same computational resource. To test the generalization performance of the\\nagent, a Golden level of StarCraft~II Ladder human player has competed with the\\nagent. With restricted strategy, the agent wins the human player by 4 out of 5\\ngames. We also apply thought-game idea to another game which is \"StarCraft:\\nBrood War\", the predecessor of StarCraft II. The thought-game approach might\\nshed some light for further studies of efficient reinforcement learning.\\n\\n    ', '\\nAbstract:  We formulate the problem of defogging as state estimation and future state\\nprediction from previous, partial observations in the context of real-time\\nstrategy games. We propose to employ encoder-decoder neural networks for this\\ntask, and introduce proxy tasks and baselines for evaluation to assess their\\nability of capturing basic game rules and high-level dynamics. By combining\\nconvolutional neural networks and recurrent networks, we exploit spatial and\\nsequential correlations and train well-performing models on a large dataset of\\nhuman games of StarCraft: Brood War. Finally, we demonstrate the relevance of\\nour models to downstream tasks by applying them for enemy unit prediction in a\\nstate-of-the-art, rule-based StarCraft bot. We observe improvements in win\\nrates against several strong community bots.\\n\\n    ', '\\nAbstract:  Real-Time Strategy (RTS) games have recently become a popular testbed for\\nartificial intelligence research. They represent a complex adversarial domain\\nproviding a number of interesting AI challenges. There exists a wide variety of\\nresearch-supporting software tools, libraries and frameworks for one RTS game\\nin particular -- StarCraft: Brood War. These tools are designed to address\\nvarious specific sub-problems, such as resource allocation or opponent\\nmodelling so that researchers can focus exclusively on the tasks relevant to\\nthem. We present one such tool -- a library called StarAlgo that produces plans\\nfor the coordinated movement of squads (groups of combat units) within the game\\nworld. StarAlgo library can solve the squad movement planning problem using one\\nof two algorithms: Monte Carlo Tree Search Considering Durations (MCTSCD) and a\\nslightly modified version of Negamax. We evaluate both the algorithms, compare\\nthem, and demonstrate their usage. The library is implemented as a static C++\\nlibrary that can be easily plugged into most StarCraft AI bots.\\n\\n    ', '\\nAbstract:  In January 2019, DeepMind revealed AlphaStar to the world-the first\\nartificial intelligence (AI) system to beat a professional player at the game\\nof StarCraft II-representing a milestone in the progress of AI. AlphaStar draws\\non many areas of AI research, including deep learning, reinforcement learning,\\ngame theory, and evolutionary computation (EC). In this paper we analyze\\nAlphaStar primarily through the lens of EC, presenting a new look at the system\\nand relating it to many concepts in the field. We highlight some of its most\\ninteresting aspects-the use of Lamarckian evolution, competitive co-evolution,\\nand quality diversity. In doing so, we hope to provide a bridge between the\\nwider EC community and one of the most significant AI systems developed in\\nrecent times.\\n\\n    ', '\\nAbstract:  We introduce Act2Vec, a general framework for learning context-based action\\nrepresentation for Reinforcement Learning. Representing actions in a vector\\nspace help reinforcement learning algorithms achieve better performance by\\ngrouping similar actions and utilizing relations between different actions. We\\nshow how prior knowledge of an environment can be extracted from demonstrations\\nand injected into action vector representations that encode natural compatible\\nbehavior. We then use these for augmenting state representations as well as\\nimproving function approximation of Q-values. We visualize and test action\\nembeddings in three domains including a drawing task, a high dimensional\\nnavigation task, and the large action space domain of StarCraft II.\\n\\n    ', '\\nAbstract:  We introduce an approach for deep reinforcement learning (RL) that improves\\nupon the efficiency, generalization capacity, and interpretability of\\nconventional approaches through structured perception and relational reasoning.\\nIt uses self-attention to iteratively reason about the relations between\\nentities in a scene and to guide a model-free policy. Our results show that in\\na novel navigation and planning task called Box-World, our agent finds\\ninterpretable solutions that improve upon baselines in terms of sample\\ncomplexity, ability to generalize to more complex scenes than experienced\\nduring training, and overall performance. In the StarCraft II Learning\\nEnvironment, our agent achieves state-of-the-art performance on six mini-games\\n-- surpassing human grandmaster performance on four. By considering\\narchitectural inductive biases, our work opens new directions for overcoming\\nimportant, but stubborn, challenges in deep RL.\\n\\n    ', \"\\nAbstract:  Cooperative multi-agent systems can be naturally used to model many real\\nworld problems, such as network packet routing and the coordination of\\nautonomous vehicles. There is a great need for new reinforcement learning\\nmethods that can efficiently learn decentralised policies for such systems. To\\nthis end, we propose a new multi-agent actor-critic method called\\ncounterfactual multi-agent (COMA) policy gradients. COMA uses a centralised\\ncritic to estimate the Q-function and decentralised actors to optimise the\\nagents' policies. In addition, to address the challenges of multi-agent credit\\nassignment, it uses a counterfactual baseline that marginalises out a single\\nagent's action, while keeping the other agents' actions fixed. COMA also uses a\\ncritic representation that allows the counterfactual baseline to be computed\\nefficiently in a single forward pass. We evaluate COMA in the testbed of\\nStarCraft unit micromanagement, using a decentralised variant with significant\\npartial observability. COMA significantly improves average performance over\\nother multi-agent actor-critic methods in this setting, and the best performing\\nagents are competitive with state-of-the-art centralised controllers that get\\naccess to the full state.\\n\\n    \", \"\\nAbstract:  This paper introduces MazeBase: an environment for simple 2D games, designed\\nas a sandbox for machine learning approaches to reasoning and planning. Within\\nit, we create 10 simple games embodying a range of algorithmic tasks (e.g.\\nif-then statements or set negation). A variety of neural models (fully\\nconnected, convolutional network, memory network) are deployed via\\nreinforcement learning on these games, with and without a procedurally\\ngenerated curriculum. Despite the tasks' simplicity, the performance of the\\nmodels is far from optimal, suggesting directions for future development. We\\nalso demonstrate the versatility of MazeBase by using it to emulate small\\ncombat scenarios from StarCraft. Models trained on the MazeBase version can be\\ndirectly applied to StarCraft, where they consistently beat the in-game AI.\\n\\n    \", '\\nAbstract:  Computing expected predictions has many interesting applications in areas\\nsuch as fairness, handling missing values, and data analysis. Unfortunately,\\ncomputing expectations of a discriminative model with respect to a probability\\ndistribution defined by an arbitrary generative model has been proven to be\\nhard in general. In fact, the task is intractable even for simple models such\\nas logistic regression and a naive Bayes distribution. In this paper, we\\nidentify a pair of generative and discriminative models that enables tractable\\ncomputation of expectations of the latter with respect to the former, as well\\nas moments of any order, in case of regression. Specifically, we consider\\nexpressive probabilistic circuits with certain structural constraints that\\nsupport tractable probabilistic inference. Moreover, we exploit the tractable\\ncomputation of high-order moments to derive an algorithm to approximate the\\nexpectations, for classification scenarios in which exact computations are\\nintractable. We evaluate the effectiveness of our exact and approximate\\nalgorithms in handling missing data during prediction time where they prove to\\nbe competitive to standard imputation techniques on a variety of datasets.\\nFinally, we illustrate how expected prediction framework can be used to reason\\nabout the behaviour of discriminative models.\\n\\n    ', \"\\nAbstract:  Sentiment classification is an important process in understanding people's\\nperception towards a product, service, or topic. Many natural language\\nprocessing models have been proposed to solve the sentiment classification\\nproblem. However, most of them have focused on binary sentiment classification.\\nIn this paper, we use a promising deep learning model called BERT to solve the\\nfine-grained sentiment classification task. Experiments show that our model\\noutperforms other popular models for this task without sophisticated\\narchitecture. We also demonstrate the effectiveness of transfer learning in\\nnatural language processing in the process.\\n\\n    \", '\\nAbstract:  We propose a new variational model for nonlinear image fusion. Our approach\\nincorporates the osmosis model proposed in Vogel et al. (2013) and Weickert et\\nal. (2013) as an energy term in a variational model. The osmosis energy is\\nknown to realize visually plausible image data fusion. As a consequence, our\\nmethod is invariant to multiplicative brightness changes. On the practical\\nside, it requires minimal supervision and parameter tuning and can encode prior\\ninformation on the structure of the images to be fused. We develop a\\nprimal-dual algorithm for solving this new image fusion model and we apply the\\nresulting minimisation scheme to multi-modal image fusion for face fusion,\\ncolour transfer and some cultural heritage conservation challenges. Visual\\ncomparison to state-of-the-art proves the quality and flexibility of our\\nmethod.\\n\\n    ', '\\nAbstract:  The Neural Arithmetic Logic Unit (NALU) is a neural network layer that can\\nlearn exact arithmetic operations between the elements of a hidden state. The\\ngoal of NALU is to learn perfect extrapolation, which requires learning the\\nexact underlying logic of an unknown arithmetic problem. Evaluating the\\nperformance of the NALU is non-trivial as one arithmetic problem might have\\nmany solutions. As a consequence, single-instance MSE has been used to evaluate\\nand compare performance between models. However, it can be hard to interpret\\nwhat magnitude of MSE represents a correct solution and models sensitivity to\\ninitialization. We propose using a success-criterion to measure if and when a\\nmodel converges. Using a success-criterion we can summarize success-rate over\\nmany initialization seeds and calculate confidence intervals. We contribute a\\ngeneralized version of the previous arithmetic benchmark to measure models\\nsensitivity under different conditions. This is, to our knowledge, the first\\nextensive evaluation with respect to convergence of the NALU and its sub-units.\\nUsing a success-criterion to summarize 4800 experiments we find that\\nconsistently learning arithmetic extrapolation is challenging, in particular\\nfor multiplication.\\n\\n    ', '\\nAbstract:  Several computational models have been developed to detect and analyze\\ndialect variation in recent years. Most of these models assume a predefined set\\nof geographical regions over which they detect and analyze dialectal variation.\\nHowever, dialect variation occurs at multiple levels of geographic resolution\\nranging from cities within a state, states within a country, and between\\ncountries across continents. In this work, we propose a model that enables\\ndetection of dialectal variation at multiple levels of geographic resolution\\nobviating the need for a-priori definition of the resolution level. Our method\\nDialectGram, learns dialect-sensitive word embeddings while being agnostic of\\nthe geographic resolution. Specifically it only requires one-time training and\\nenables analysis of dialectal variation at a chosen resolution post-hoc -- a\\nsignificant departure from prior models which need to be re-trained whenever\\nthe pre-defined set of regions changes. Furthermore, DialectGram explicitly\\nmodels senses thus enabling one to estimate the proportion of each sense usage\\nin any given region. Finally, we quantitatively evaluate our model against\\nother baselines on a new evaluation dataset DialectSim (in English) and show\\nthat DialectGram can effectively model linguistic variation.\\n\\n    ', '\\nAbstract:  News articles such as sports game reports are often thought to closely follow\\nthe underlying game statistics, but in practice they contain a notable amount\\nof background knowledge, interpretation, insight into the game, and quotes that\\nare not present in the official statistics. This poses a challenge for\\nautomated data-to-text news generation with real-world news corpora as training\\ndata. We report on the development of a corpus of Finnish ice hockey news,\\nedited to be suitable for training of end-to-end news generation methods, as\\nwell as demonstrate generation of text, which was judged by journalists to be\\nrelatively close to a viable product. The new dataset and system source code\\nare available for research purposes at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Face is one of the most important things for communication with the world\\naround us. It also forms our identity and expressions. Estimating the face\\nstructure is a fundamental task in computer vision with applications in\\ndifferent areas such as face recognition and medical surgeries. Recently, deep\\nlearning techniques achieved significant results for 3D face reconstruction\\nfrom flat images. The main challenge of such techniques is a vital need for\\nlarge 3D face datasets. Usually, this challenge is handled by synthetic face\\ngeneration. However, synthetic datasets suffer from the existence of\\nnon-possible faces. Here, we propose a face manifold learning method for\\nsynthetic diverse face dataset generation. First, the face structure is divided\\ninto the shape and expression groups. Then, a fully convolutional autoencoder\\nnetwork is exploited to deal with the non-possible faces, and, simultaneously,\\npreserving the dataset diversity. Simulation results show that the proposed\\nmethod is capable of denoising highly corrupted faces. The diversity of the\\ngenerated dataset is evaluated qualitatively and quantitatively and compared to\\nthe existing methods. Experiments show that our manifold learning method\\noutperforms the state of the art methods significantly.\\n\\n    ', '\\nAbstract:  Generating visualizations and interpretations from high-dimensional data is a\\ncommon problem in many fields. Two key approaches for tackling this problem are\\nclustering and representation learning. There are very performant deep\\nclustering models on the one hand and interpretable representation learning\\ntechniques, often relying on latent topological structures such as\\nself-organizing maps, on the other hand. However, current methods do not yet\\nsuccessfully combine these two approaches. We present a new deep architecture\\nfor probabilistic clustering, VarPSOM, and its extension to time series data,\\nVarTPSOM. We show that they achieve superior clustering performance compared to\\ncurrent deep clustering methods on static MNIST/Fashion-MNIST data as well as\\nmedical time series, while inducing an interpretable representation. Moreover,\\non the medical time series, VarTPSOM successfully predicts future trajectories\\nin the original data space.\\n\\n    ', '\\nAbstract:  Empirical scoring functions based on either molecular force fields or\\ncheminformatics descriptors are widely used, in conjunction with molecular\\ndocking, during the early stages of drug discovery to predict potency and\\nbinding affinity of a drug-like molecule to a given target. These models\\nrequire expert-level knowledge of physical chemistry and biology to be encoded\\nas hand-tuned parameters or features rather than allowing the underlying model\\nto select features in a data-driven procedure. Here, we develop a general\\n3-dimensional spatial convolution operation for learning atomic-level chemical\\ninteractions directly from atomic coordinates and demonstrate its application\\nto structure-based bioactivity prediction. The atomic convolutional neural\\nnetwork is trained to predict the experimentally determined binding affinity of\\na protein-ligand complex by direct calculation of the energy associated with\\nthe complex, protein, and ligand given the crystal structure of the binding\\npose. Non-covalent interactions present in the complex that are absent in the\\nprotein-ligand sub-structures are identified and the model learns the\\ninteraction strength associated with these features. We test our model by\\npredicting the binding free energy of a subset of protein-ligand complexes\\nfound in the PDBBind dataset and compare with state-of-the-art cheminformatics\\nand machine learning-based approaches. We find that all methods achieve\\nexperimental accuracy and that atomic convolutional networks either outperform\\nor perform competitively with the cheminformatics based methods. Unlike all\\nprevious protein-ligand prediction systems, atomic convolutional networks are\\nend-to-end and fully-differentiable. They represent a new data-driven,\\nphysics-based deep learning model paradigm that offers a strong foundation for\\nfuture improvements in structure-based bioactivity prediction.\\n\\n    ', '\\nAbstract:  Deep Learning has revolutionized vision via convolutional neural networks\\n(CNNs) and natural language processing via recurrent neural networks (RNNs).\\nHowever, success stories of Deep Learning with standard feed-forward neural\\nnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,\\ntherefore cannot exploit many levels of abstract representations. We introduce\\nself-normalizing neural networks (SNNs) to enable high-level abstract\\nrepresentations. While batch normalization requires explicit normalization,\\nneuron activations of SNNs automatically converge towards zero mean and unit\\nvariance. The activation function of SNNs are \"scaled exponential linear units\"\\n(SELUs), which induce self-normalizing properties. Using the Banach fixed-point\\ntheorem, we prove that activations close to zero mean and unit variance that\\nare propagated through many network layers will converge towards zero mean and\\nunit variance -- even under the presence of noise and perturbations. This\\nconvergence property of SNNs allows to (1) train deep networks with many\\nlayers, (2) employ strong regularization, and (3) to make learning highly\\nrobust. Furthermore, for activations not close to unit variance, we prove an\\nupper and lower bound on the variance, thus, vanishing and exploding gradients\\nare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning\\nrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with\\nstandard FNNs and other machine learning methods such as random forests and\\nsupport vector machines. SNNs significantly outperformed all competing FNN\\nmethods at 121 UCI tasks, outperformed all competing methods at the Tox21\\ndataset, and set a new record at an astronomy data set. The winning SNN\\narchitectures are often very deep. Implementations are available at:\\nthis http URL.\\n\\n    ', '\\nAbstract:  Supervised learning on molecules has incredible potential to be useful in\\nchemistry, drug discovery, and materials science. Luckily, several promising\\nand closely related neural network models invariant to molecular symmetries\\nhave already been described in the literature. These models learn a message\\npassing algorithm and aggregation procedure to compute a function of their\\nentire input graph. At this point, the next step is to find a particularly\\neffective variant of this general approach and apply it to chemical prediction\\nbenchmarks until we either solve them or reach the limits of the approach. In\\nthis paper, we reformulate existing models into a single common framework we\\ncall Message Passing Neural Networks (MPNNs) and explore additional novel\\nvariations within this framework. Using MPNNs we demonstrate state of the art\\nresults on an important molecular property prediction benchmark; these results\\nare strong enough that we believe future work should focus on datasets with\\nlarger molecules or more accurate ground truth labels.\\n\\n    ', '\\nAbstract:  Graph-structured data appears frequently in domains including chemistry,\\nnatural language semantics, social networks, and knowledge bases. In this work,\\nwe study feature learning techniques for graph-structured inputs. Our starting\\npoint is previous work on Graph Neural Networks (Scarselli et al., 2009), which\\nwe modify to use gated recurrent units and modern optimization techniques and\\nthen extend to output sequences. The result is a flexible and broadly useful\\nclass of neural network models that has favorable inductive biases relative to\\npurely sequence-based models (e.g., LSTMs) when the problem is\\ngraph-structured. We demonstrate the capabilities on some simple AI (bAbI) and\\ngraph algorithm learning tasks. We then show it achieves state-of-the-art\\nperformance on a problem from program verification, in which subgraphs need to\\nbe matched to abstract data structures.\\n\\n    ', '\\nAbstract:  Multi-task learning (MTL) has led to successes in many applications of\\nmachine learning, from natural language processing and speech recognition to\\ncomputer vision and drug discovery. This article aims to give a general\\noverview of MTL, particularly in deep neural networks. It introduces the two\\nmost common methods for MTL in Deep Learning, gives an overview of the\\nliterature, and discusses recent advances. In particular, it seeks to help ML\\npractitioners apply MTL by shedding light on how MTL works and providing\\nguidelines for choosing appropriate auxiliary tasks.\\n\\n    ', '\\nAbstract:  We introduce a convolutional neural network that operates directly on graphs.\\nThese networks allow end-to-end learning of prediction pipelines whose inputs\\nare graphs of arbitrary size and shape. The architecture we present generalizes\\nstandard molecular feature extraction methods based on circular fingerprints.\\nWe show that these data-driven features are more interpretable, and have better\\npredictive performance on a variety of tasks.\\n\\n    ', '\\nAbstract:  Deep generative models such as generative adversarial networks, variational\\nautoencoders, and autoregressive models are rapidly growing in popularity for\\nthe discovery of new molecules and materials. In this work, we introduce\\nMOlecular SEtS (MOSES), a benchmarking platform to support research on machine\\nlearning for drug discovery. MOSES implements several popular molecular\\ngeneration models and includes a set of metrics that evaluate the diversity and\\nquality of generated molecules. MOSES is meant to standardize the research on\\nmolecular generation and facilitate the sharing and comparison of new models.\\nAdditionally, we provide a large-scale comparison of existing state of the art\\nmodels and elaborate on current challenges for generative models that might\\nprove fertile ground for new research. Our platform and source code are freely\\navailable at this https URL.\\n\\n    ', '\\nAbstract:  We seek to automate the design of molecules based on specific chemical\\nproperties. In computational terms, this task involves continuous embedding and\\ngeneration of molecular graphs. Our primary contribution is the direct\\nrealization of molecular graphs, a task previously approached by generating\\nlinear SMILES strings instead of graphs. Our junction tree variational\\nautoencoder generates molecular graphs in two phases, by first generating a\\ntree-structured scaffold over chemical substructures, and then combining them\\ninto a molecule with a graph message passing network. This approach allows us\\nto incrementally expand molecules while maintaining chemical validity at every\\nstep. We evaluate our model on multiple tasks ranging from molecular generation\\nto optimization. Across these tasks, our model outperforms previous\\nstate-of-the-art baselines by a significant margin.\\n\\n    ', '\\nAbstract:  Generating molecules with desired chemical properties is important for drug\\ndiscovery. The use of generative neural networks is promising for this task.\\nHowever, from visual inspection, it often appears that generated samples lack\\ndiversity. In this paper, we quantify this internal chemical diversity, and we\\nraise the following challenge: can a nontrivial AI model reproduce natural\\nchemical diversity for desired molecules? To illustrate this question, we\\nconsider two generative models: a Reinforcement Learning model and the recently\\nintroduced ORGAN. Both fail at this challenge. We hope this challenge will\\nstimulate research in this direction.\\n\\n    ', '\\nAbstract:  Docking is an important tool in computational drug discovery that aims to\\npredict the binding pose of a ligand to a target protein through a combination\\nof pose scoring and optimization. A scoring function that is differentiable\\nwith respect to atom positions can be used for both scoring and gradient-based\\noptimization of poses for docking. Using a differentiable grid-based atomic\\nrepresentation as input, we demonstrate that a scoring function learned by\\ntraining a convolutional neural network (CNN) to identify binding poses can\\nalso be applied to pose optimization. We also show that an iteratively-trained\\nCNN that includes poses optimized by the first CNN in its training set performs\\neven better at optimizing randomly initialized poses than either the first CNN\\nscoring function or AutoDock Vina.\\n\\n    ', '\\nAbstract:  Computational approaches to drug discovery can reduce the time and cost\\nassociated with experimental assays and enable the screening of novel\\nchemotypes. Structure-based drug design methods rely on scoring functions to\\nrank and predict binding affinities and poses. The ever-expanding amount of\\nprotein-ligand binding and structural data enables the use of deep machine\\nlearning techniques for protein-ligand scoring.\\nWe describe convolutional neural network (CNN) scoring functions that take as\\ninput a comprehensive 3D representation of a protein-ligand interaction. A CNN\\nscoring function automatically learns the key features of protein-ligand\\ninteractions that correlate with binding. We train and optimize our CNN scoring\\nfunctions to discriminate between correct and incorrect binding poses and known\\nbinders and non-binders. We find that our CNN scoring function outperforms the\\nAutoDock Vina scoring function when ranking poses both for pose prediction and\\nvirtual screening.\\n\\n    ', '\\nAbstract:  We develop a Bayesian \"sum-of-trees\" model where each tree is constrained by\\na regularization prior to be a weak learner, and fitting and inference are\\naccomplished via an iterative Bayesian backfitting MCMC algorithm that\\ngenerates samples from a posterior. Effectively, BART is a nonparametric\\nBayesian regression approach which uses dimensionally adaptive random basis\\nelements. Motivated by ensemble methods in general, and boosting algorithms in\\nparticular, BART is defined by a statistical model: a prior and a likelihood.\\nThis approach enables full posterior inference including point and interval\\nestimates of the unknown regression function as well as the marginal effects of\\npotential predictors. By keeping track of predictor inclusion frequencies, BART\\ncan also be used for model-free variable selection. BART\\'s many features are\\nillustrated with a bake-off against competing methods on 42 different data\\nsets, with a simulation experiment and on a drug discovery classification\\nproblem.\\n\\n    ', '\\nAbstract:  The identification of novel drug-target (DT) interactions is a substantial\\npart of the drug discovery process. Most of the computational methods that have\\nbeen proposed to predict DT interactions have focused on binary classification,\\nwhere the goal is to determine whether a DT pair interacts or not. However,\\nprotein-ligand interactions assume a continuum of binding strength values, also\\ncalled binding affinity and predicting this value still remains a challenge.\\nThe increase in the affinity data available in DT knowledge-bases allows the\\nuse of advanced learning techniques such as deep learning architectures in the\\nprediction of binding affinities. In this study, we propose a deep-learning\\nbased model that uses only sequence information of both targets and drugs to\\npredict DT interaction binding affinities. The few studies that focus on DT\\nbinding affinity prediction use either 3D structures of protein-ligand\\ncomplexes or 2D features of compounds. One novel approach used in this work is\\nthe modeling of protein sequences and compound 1D representations with\\nconvolutional neural networks (CNNs). The results show that the proposed deep\\nlearning based model that uses the 1D representations of targets and drugs is\\nan effective approach for drug target binding affinity prediction. The model in\\nwhich high-level representations of a drug and a target are constructed via\\nCNNs achieved the best Concordance Index (CI) performance in one of our larger\\nbenchmark data sets, outperforming the KronRLS algorithm and SimBoost, a\\nstate-of-the-art method for DT binding affinity prediction.\\n\\n    ', '\\nAbstract:  Predicating macroscopic influences of drugs on human body, like efficacy and\\ntoxicity, is a central problem of small-molecule based drug discovery.\\nMolecules can be represented as an undirected graph, and we can utilize graph\\nconvolution networks to predication molecular properties. However, graph\\nconvolutional networks and other graph neural networks all focus on learning\\nnode-level representation rather than graph-level representation. Previous\\nworks simply sum all feature vectors for all nodes in the graph to obtain the\\ngraph feature vector for drug predication. In this paper, we introduce a dummy\\nsuper node that is connected with all nodes in the graph by a directed edge as\\nthe representation of the graph and modify the graph operation to help the\\ndummy super node learn graph-level feature. Thus, we can handle graph-level\\nclassification and regression in the same way as node-level classification and\\nregression. In addition, we apply focal loss to address class imbalance in drug\\ndatasets. The experiments on MoleculeNet show that our method can effectively\\nimprove the performance of molecular properties predication.\\n\\n    ', '\\nAbstract:  In de novo drug design, computational strategies are used to generate novel\\nmolecules with good affinity to the desired biological target. In this work, we\\nshow that recurrent neural networks can be trained as generative models for\\nmolecular structures, similar to statistical language models in natural\\nlanguage processing. We demonstrate that the properties of the generated\\nmolecules correlate very well with the properties of the molecules used to\\ntrain the model. In order to enrich libraries with molecules active towards a\\ngiven biological target, we propose to fine-tune the model with small sets of\\nmolecules, which are known to be active against that target.\\nAgainst Staphylococcus aureus, the model reproduced 14% of 6051 hold-out test\\nmolecules that medicinal chemists designed, whereas against Plasmodium\\nfalciparum (Malaria) it reproduced 28% of 1240 test molecules. When coupled\\nwith a scoring function, our model can perform the complete de novo drug design\\ncycle to generate large sets of novel molecules for drug discovery.\\n\\n    ', '\\nAbstract:  Adversarial training provides a means of regularizing supervised learning\\nalgorithms while virtual adversarial training is able to extend supervised\\nlearning algorithms to the semi-supervised setting. However, both methods\\nrequire making small perturbations to numerous entries of the input vector,\\nwhich is inappropriate for sparse high-dimensional inputs such as one-hot word\\nrepresentations. We extend adversarial and virtual adversarial training to the\\ntext domain by applying perturbations to the word embeddings in a recurrent\\nneural network rather than to the original input itself. The proposed method\\nachieves state of the art results on multiple benchmark semi-supervised and\\npurely supervised tasks. We provide visualizations and analysis showing that\\nthe learned word embeddings have improved in quality and that while training,\\nthe model is less prone to overfitting.\\n\\n    ', '\\nAbstract:  Named entity recognition is a challenging task that has traditionally\\nrequired large amounts of knowledge in the form of feature engineering and\\nlexicons to achieve high performance. In this paper, we present a novel neural\\nnetwork architecture that automatically detects word- and character-level\\nfeatures using a hybrid bidirectional LSTM and CNN architecture, eliminating\\nthe need for most feature engineering. We also propose a novel method of\\nencoding partial lexicon matches in neural networks and compare it to existing\\napproaches. Extensive evaluation shows that, given only tokenized text and\\npublicly available word embeddings, our system is competitive on the CoNLL-2003\\ndataset and surpasses the previously reported state of the art performance on\\nthe OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed\\nfrom publicly-available sources, we establish new state of the art performance\\nwith an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing\\nsystems that employ heavy feature engineering, proprietary lexicons, and rich\\nentity linking information.\\n\\n    ', '\\nAbstract:  We present StarSpace, a general-purpose neural embedding model that can solve\\na wide variety of problems: labeling tasks such as text classification, ranking\\ntasks such as information retrieval/web search, collaborative filtering-based\\nor content-based recommendation, embedding of multi-relational graphs, and\\nlearning word, sentence or document level embeddings. In each case the model\\nworks by embedding those entities comprised of discrete features and comparing\\nthem against each other -- learning similarities dependent on the task.\\nEmpirical results on a number of tasks show that StarSpace is highly\\ncompetitive with existing methods, whilst also being generally applicable to\\nnew cases where those methods are not.\\n\\n    ', '\\nAbstract:  Word embeddings are a popular approach to unsupervised learning of word\\nrelationships that are widely used in natural language processing. In this\\narticle, we present a new set of embeddings for medical concepts learned using\\nan extremely large collection of multimodal medical data. Leaning on recent\\ntheoretical insights, we demonstrate how an insurance claims database of 60\\nmillion members, a collection of 20 million clinical notes, and 1.7 million\\nfull text biomedical journal articles can be combined to embed concepts into a\\ncommon space, resulting in the largest ever set of embeddings for 108,477\\nmedical concepts. To evaluate our approach, we present a new benchmark\\nmethodology based on statistical power specifically designed to test embeddings\\nof medical concepts. Our approach, called cui2vec, attains state-of-the-art\\nperformance relative to previous methods in most instances. Finally, we provide\\na downloadable set of pre-trained embeddings for other researchers to use, as\\nwell as an online tool for interactive exploration of the cui2vec embeddings\\n\\n    ', \"\\nAbstract:  Named Entity Recognition (NER) is one of the most common tasks of the natural\\nlanguage processing. The purpose of NER is to find and classify tokens in text\\ndocuments into predefined categories called tags, such as person names,\\nquantity expressions, percentage expressions, names of locations,\\norganizations, as well as expression of time, currency and others. Although\\nthere is a number of approaches have been proposed for this task in Russian\\nlanguage, it still has a substantial potential for the better solutions. In\\nthis work, we studied several deep neural network models starting from vanilla\\nBi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with\\nConditional Random Fields (CRF) as well as highway networks and finally adding\\nexternal word embeddings. All models were evaluated across three datasets:\\nGareev's dataset, Person-1000, FactRuEval-2016. We found that extension of\\nBi-LSTM model with CRF significantly increased the quality of predictions.\\nEncoding input tokens with external word embeddings reduced training time and\\nallowed to achieve state of the art for the Russian NER task.\\n\\n    \", '\\nAbstract:  Distributed dense word vectors have been shown to be effective at capturing\\ntoken-level semantic and syntactic regularities in language, while topic models\\ncan form interpretable representations over documents. In this work, we\\ndescribe lda2vec, a model that learns dense word vectors jointly with\\nDirichlet-distributed latent document-level mixtures of topic vectors. In\\ncontrast to continuous dense document representations, this formulation\\nproduces sparse, interpretable document mixtures through a non-negative simplex\\nconstraint. Our method is simple to incorporate into existing automatic\\ndifferentiation frameworks and allows for unsupervised document representations\\ngeared for use by scientists while simultaneously learning word vectors and the\\nlinear relationships between them.\\n\\n    ', '\\nAbstract:  We consider the task of aligning two sets of points in high dimension, which\\nhas many applications in natural language processing and computer vision. As an\\nexample, it was recently shown that it is possible to infer a bilingual\\nlexicon, without supervised data, by aligning word embeddings trained on\\nmonolingual data. These recent advances are based on adversarial training to\\nlearn the mapping between the two embeddings. In this paper, we propose to use\\nan alternative formulation, based on the joint estimation of an orthogonal\\nmatrix and a permutation matrix. While this problem is not convex, we propose\\nto initialize our optimization algorithm by using a convex relaxation,\\ntraditionally considered for the graph isomorphism problem. We propose a\\nstochastic algorithm to minimize our cost function on large scale problems.\\nFinally, we evaluate our method on the problem of unsupervised word\\ntranslation, by aligning word embeddings trained on monolingual data. On this\\ntask, our method obtains state of the art results, while requiring less\\ncomputational resources than competing approaches.\\n\\n    ', '\\nAbstract:  State-of-the-art methods for learning cross-lingual word embeddings have\\nrelied on bilingual dictionaries or parallel corpora. Recent studies showed\\nthat the need for parallel data supervision can be alleviated with\\ncharacter-level information. While these methods showed encouraging results,\\nthey are not on par with their supervised counterparts and are limited to pairs\\nof languages sharing a common alphabet. In this work, we show that we can build\\na bilingual dictionary between two languages without using any parallel\\ncorpora, by aligning monolingual word embedding spaces in an unsupervised way.\\nWithout using any character information, our model even outperforms existing\\nsupervised methods on cross-lingual tasks for some language pairs. Our\\nexperiments demonstrate that our method works very well also for distant\\nlanguage pairs, like English-Russian or English-Chinese. We finally describe\\nexperiments on the English-Esperanto low-resource language pair, on which there\\nonly exists a limited amount of parallel data, to show the potential impact of\\nour method in fully unsupervised machine translation. Our code, embeddings and\\ndictionaries are publicly available.\\n\\n    ', '\\nAbstract:  Many modern NLP systems rely on word embeddings, previously trained in an\\nunsupervised manner on large corpora, as base features. Efforts to obtain\\nembeddings for larger chunks of text, such as sentences, have however not been\\nso successful. Several attempts at learning unsupervised representations of\\nsentences have not reached satisfactory enough performance to be widely\\nadopted. In this paper, we show how universal sentence representations trained\\nusing the supervised data of the Stanford Natural Language Inference datasets\\ncan consistently outperform unsupervised methods like SkipThought vectors on a\\nwide range of transfer tasks. Much like how computer vision uses ImageNet to\\nobtain features, which can then be transferred to other tasks, our work tends\\nto indicate the suitability of natural language inference for transfer learning\\nto other NLP tasks. Our encoder is publicly available.\\n\\n    ', '\\nAbstract:  Despite the fast developmental pace of new sentence embedding methods, it is\\nstill challenging to find comprehensive evaluations of these different\\ntechniques. In the past years, we saw significant improvements in the field of\\nsentence embeddings and especially towards the development of universal\\nsentence encoders that could provide inductive transfer to a wide variety of\\ndownstream tasks. In this work, we perform a comprehensive evaluation of recent\\nmethods using a wide variety of downstream and linguistic feature probing\\ntasks. We show that a simple approach using bag-of-words with a recently\\nintroduced language model for deep context-dependent word embeddings proved to\\nyield better results in many tasks when compared to sentence encoders trained\\non entailment datasets. We also show, however, that we are still far away from\\na universal encoder that can perform consistently across several downstream\\ntasks.\\n\\n    ', '\\nAbstract:  Probabilistic atlas priors have been commonly used to derive adaptive and\\nrobust brain MRI segmentation algorithms. Widely-used neuroimage analysis\\npipelines rely heavily on these techniques, which are often computationally\\nexpensive. In contrast, there has been a recent surge of approaches that\\nleverage deep learning to implement segmentation tools that are computationally\\nefficient at test time. However, most of these strategies rely on learning from\\nmanually annotated images. These supervised deep learning methods are therefore\\nsensitive to the intensity profiles in the training dataset. To develop a deep\\nlearning-based segmentation model for a new image dataset (e.g., of different\\ncontrast), one usually needs to create a new labeled training dataset, which\\ncan be prohibitively expensive, or rely on suboptimal ad hoc adaptation or\\naugmentation approaches. In this paper, we propose an alternative strategy that\\ncombines a conventional probabilistic atlas-based segmentation with deep\\nlearning, enabling one to train a segmentation model for new MRI scans without\\nthe need for any manually segmented images. Our experiments include thousands\\nof brain MRI scans and demonstrate that the proposed method achieves good\\naccuracy for a brain MRI segmentation task for different MRI contrasts,\\nrequiring only approximately 15 seconds at test time on a GPU. The code is\\nfreely available at this http URL.\\n\\n    ', '\\nAbstract:  We address the problem of segmenting 3D multi-modal medical images in\\nscenarios where very few labeled examples are available for training.\\nLeveraging the recent success of adversarial learning for semi-supervised\\nsegmentation, we propose a novel method based on Generative Adversarial\\nNetworks (GANs) to train a segmentation model with both labeled and unlabeled\\nimages. The proposed method prevents over-fitting by learning to discriminate\\nbetween true and fake patches obtained by a generator network. Our work extends\\ncurrent adversarial learning approaches, which focus on 2D single-modality\\nimages, to the more challenging context of 3D volumes of multiple modalities.\\nThe proposed method is evaluated on the problem of segmenting brain MRI from\\nthe iSEG-2017 and MRBrainS 2013 datasets. Significant performance improvement\\nis reported, compared to state-of-art segmentation networks trained in a\\nfully-supervised manner. In addition, our work presents a comprehensive\\nanalysis of different GAN architectures for semi-supervised segmentation,\\nshowing recent techniques like feature matching to yield a higher performance\\nthan conventional adversarial training approaches. Our code is publicly\\navailable at this https URL\\n', '\\nAbstract:  Recent analysis identified distinct genomic subtypes of lower-grade glioma\\ntumors which are associated with shape features. In this study, we propose a\\nfully automatic way to quantify tumor imaging characteristics using deep\\nlearning-based segmentation and test whether these characteristics are\\npredictive of tumor genomic subtypes. We used preoperative imaging and genomic\\ndata of 110 patients from 5 institutions with lower-grade gliomas from The\\nCancer Genome Atlas. Based on automatic deep learning segmentations, we\\nextracted three features which quantify two-dimensional and three-dimensional\\ncharacteristics of the tumors. Genomic data for the analyzed cohort of patients\\nconsisted of previously identified genomic clusters based on IDH mutation and\\n1p/19q co-deletion, DNA methylation, gene expression, DNA copy number, and\\nmicroRNA expression. To analyze the relationship between the imaging features\\nand genomic clusters, we conducted the Fisher exact test for 10 hypotheses for\\neach pair of imaging feature and genomic subtype. To account for multiple\\nhypothesis testing, we applied a Bonferroni correction. P-values lower than\\n0.005 were considered statistically significant. We found the strongest\\nassociation between RNASeq clusters and the bounding ellipsoid volume ratio\\n($p<0.0002$) and between RNASeq clusters and margin fluctuation ($p<0.005$). In\\naddition, we identified associations between bounding ellipsoid volume ratio\\nand all tested molecular subtypes ($p<0.02$) as well as between angular\\nstandard deviation and RNASeq cluster ($p<0.02$). In terms of automatic tumor\\nsegmentation that was used to generate the quantitative image characteristics,\\nour deep learning algorithm achieved a mean Dice coefficient of 82% which is\\ncomparable to human performance.\\n\\n    ', '\\nAbstract:  This study investigates a 3D and fully convolutional neural network (CNN) for\\nsubcortical brain structure segmentation in MRI. 3D CNN architectures have been\\ngenerally avoided due to their computational and memory requirements during\\ninference. We address the problem via small kernels, allowing deeper\\narchitectures. We further model both local and global context by embedding\\nintermediate-layer outputs in the final prediction, which encourages\\nconsistency between features extracted at different scales and embeds\\nfine-grained information directly in the segmentation process. Our model is\\nefficiently trained end-to-end on a graphics processing unit (GPU), in a single\\nstage, exploiting the dense inference capabilities of fully CNNs.\\nWe performed comprehensive experiments over two publicly available datasets.\\nFirst, we demonstrate a state-of-the-art performance on the ISBR dataset. Then,\\nwe report a {\\\\em large-scale} multi-site evaluation over 1112 unregistered\\nsubject datasets acquired from 17 different sites (ABIDE dataset), with ages\\nranging from 7 to 64 years, showing that our method is robust to various\\nacquisition protocols, demographics and clinical factors. Our method yielded\\nsegmentations that are highly consistent with a standard atlas-based approach,\\nwhile running in a fraction of the time needed by atlas-based methods and\\navoiding registration/normalization steps. This makes it convenient for massive\\nmulti-site neuroanatomical imaging studies. To the best of our knowledge, our\\nwork is the first to study subcortical structure segmentation on such\\nlarge-scale and heterogeneous data.\\n\\n    ', '\\nAbstract:  Recently, dense connections have attracted substantial attention in computer\\nvision because they facilitate gradient flow and implicit deep supervision\\nduring training. Particularly, DenseNet, which connects each layer to every\\nother layer in a feed-forward fashion, has shown impressive performances in\\nnatural image classification tasks. We propose HyperDenseNet, a 3D fully\\nconvolutional neural network that extends the definition of dense connectivity\\nto multi-modal segmentation problems. Each imaging modality has a path, and\\ndense connections occur not only between the pairs of layers within the same\\npath, but also between those across different paths. This contrasts with the\\nexisting multi-modal CNN approaches, in which modeling several modalities\\nrelies entirely on a single joint layer (or level of abstraction) for fusion,\\ntypically either at the input or at the output of the network. Therefore, the\\nproposed network has total freedom to learn more complex combinations between\\nthe modalities, within and in-between all the levels of abstraction, which\\nincreases significantly the learning representation. We report extensive\\nevaluations over two different and highly competitive multi-modal brain tissue\\nsegmentation challenges, iSEG 2017 and MRBrainS 2013, with the former focusing\\non 6-month infant data and the latter on adult images. HyperDenseNet yielded\\nsignificant improvements over many state-of-the-art segmentation networks,\\nranking at the top on both benchmarks. We further provide a comprehensive\\nexperimental analysis of features re-use, which confirms the importance of\\nhyper-dense connections in multi-modal representation learning. Our code is\\npublicly available at this https URL.\\n\\n    ', '\\nAbstract:  Inspired by recent successes of deep learning in computer vision, we propose\\na novel framework for encoding time series as different types of images,\\nnamely, Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov\\nTransition Fields (MTF). This enables the use of techniques from computer\\nvision for time series classification and imputation. We used Tiled\\nConvolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn\\nhigh-level features from the individual and compound GASF-GADF-MTF images. Our\\napproaches achieve highly competitive results when compared to nine of the\\ncurrent best time series classification approaches. Inspired by the bijection\\nproperty of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on\\nthe GASF images of four standard and one synthesized compound dataset. The\\nimputation MSE on test data is reduced by 12.18%-48.02% when compared to using\\nthe raw data. An analysis of the features and weights learned via tiled CNNs\\nand DAs explains why the approaches work.\\n\\n    ', '\\nAbstract:  Spatial studies of transcriptome provide biologists with gene expression maps\\nof heterogeneous and complex tissues. However, most experimental protocols for\\nspatial transcriptomics suffer from the need to select beforehand a small\\nfraction of genes to be quantified over the entire transcriptome. Standard\\nsingle-cell RNA sequencing (scRNA-seq) is more prevalent, easier to implement\\nand can in principle capture any gene but cannot recover the spatial location\\nof the cells. In this manuscript, we focus on the problem of imputation of\\nmissing genes in spatial transcriptomic data based on (unpaired) standard\\nscRNA-seq data from the same biological tissue. Building upon domain adaptation\\nwork, we propose gimVI, a deep generative model for the integration of spatial\\ntranscriptomic data and scRNA-seq data that can be used to impute missing\\ngenes. After describing our generative model and an inference procedure for it,\\nwe compare gimVI to alternative methods from computational biology or domain\\nadaptation on real datasets and outperform Seurat Anchors, Liger and CORAL to\\nimpute held-out genes.\\n\\n    ', '\\nAbstract:  This paper presents the input convex neural network architecture. These are\\nscalar-valued (potentially deep) neural networks with constraints on the\\nnetwork parameters such that the output of the network is a convex function of\\n(some of) the inputs. The networks allow for efficient inference via\\noptimization over some inputs to the network given others, and can be applied\\nto settings including structured prediction, data imputation, reinforcement\\nlearning, and others. In this paper we lay the basic groundwork for these\\nmodels, proposing methods for inference, optimization and learning, and analyze\\ntheir representational power. We show that many existing neural network\\narchitectures can be made input-convex with a minor modification, and develop\\nspecialized optimization algorithms tailored to this setting. Finally, we\\nhighlight the performance of the methods on multi-label prediction, image\\ncompletion, and reinforcement learning problems, where we show improvement over\\nthe existing state of the art in many cases.\\n\\n    ', '\\nAbstract:  As sound event classification moves towards larger datasets, issues of label\\nnoise become inevitable. Web sites can supply large volumes of user-contributed\\naudio and metadata, but inferring labels from this metadata introduces errors\\ndue to unreliable inputs, and limitations in the mapping. There is, however,\\nlittle research into the impact of these errors. To foster the investigation of\\nlabel noise in sound event classification we present FSDnoisy18k, a dataset\\ncontaining 42.5 hours of audio across 20 sound classes, including a small\\namount of manually-labeled data and a larger quantity of real-world noisy data.\\nWe characterize the label noise empirically, and provide a CNN baseline system.\\nExperiments suggest that training with large amounts of noisy data can\\noutperform training with smaller amounts of carefully-labeled data. We also\\nshow that noise-robust loss functions can be effective in improving performance\\nin presence of corrupted labels.\\n\\n    ', '\\nAbstract:  Sound event detection (SED) methods are tasked with labeling segments of\\naudio recordings by the presence of active sound sources. SED is typically\\nposed as a supervised machine learning problem, requiring strong annotations\\nfor the presence or absence of each sound source at every time instant within\\nthe recording. However, strong annotations of this type are both labor- and\\ncost-intensive for human annotators to produce, which limits the practical\\nscalability of SED methods.\\nIn this work, we treat SED as a multiple instance learning (MIL) problem,\\nwhere training labels are static over a short excerpt, indicating the presence\\nor absence of sound sources but not their temporal locality. The models,\\nhowever, must still produce temporally dynamic predictions, which must be\\naggregated (pooled) when comparing against static labels during training. To\\nfacilitate this aggregation, we develop a family of adaptive pooling\\noperators---referred to as auto-pool---which smoothly interpolate between\\ncommon pooling operators, such as min-, max-, or average-pooling, and\\nautomatically adapt to the characteristics of the sound sources in question. We\\nevaluate the proposed pooling operators on three datasets, and demonstrate that\\nin each case, the proposed methods outperform non-adaptive pooling operators\\nfor static prediction, and nearly match the performance of models trained with\\nstrong, dynamic annotations. The proposed method is evaluated in conjunction\\nwith convolutional neural networks, but can be readily applied to any\\ndifferentiable model for time-series label prediction.\\n\\n    ', '\\nAbstract:  Spatiotemporal forecasting has various applications in neuroscience, climate\\nand transportation domain. Traffic forecasting is one canonical example of such\\nlearning task. The task is challenging due to (1) complex spatial dependency on\\nroad networks, (2) non-linear temporal dynamics with changing road conditions\\nand (3) inherent difficulty of long-term forecasting. To address these\\nchallenges, we propose to model the traffic flow as a diffusion process on a\\ndirected graph and introduce Diffusion Convolutional Recurrent Neural Network\\n(DCRNN), a deep learning framework for traffic forecasting that incorporates\\nboth spatial and temporal dependency in the traffic flow. Specifically, DCRNN\\ncaptures the spatial dependency using bidirectional random walks on the graph,\\nand the temporal dependency using the encoder-decoder architecture with\\nscheduled sampling. We evaluate the framework on two real-world large scale\\nroad network traffic datasets and observe consistent improvement of 12% - 15%\\nover state-of-the-art baselines.\\n\\n    ', '\\nAbstract:  Accurate and real-time traffic forecasting plays an important role in the\\nIntelligent Traffic System and is of great significance for urban traffic\\nplanning, traffic management, and traffic control. However, traffic forecasting\\nhas always been considered an open scientific issue, owing to the constraints\\nof urban road network topological structure and the law of dynamic change with\\ntime, namely, spatial dependence and temporal dependence. To capture the\\nspatial and temporal dependence simultaneously, we propose a novel neural\\nnetwork-based traffic forecasting method, the temporal graph convolutional\\nnetwork (T-GCN) model, which is in combination with the graph convolutional\\nnetwork (GCN) and gated recurrent unit (GRU). Specifically, the GCN is used to\\nlearn complex topological structures to capture spatial dependence and the\\ngated recurrent unit is used to learn dynamic changes of traffic data to\\ncapture temporal dependence. Then, the T-GCN model is employed to traffic\\nforecasting based on the urban road network. Experiments demonstrate that our\\nT-GCN model can obtain the spatio-temporal correlation from traffic data and\\nthe predictions outperform state-of-art baselines on real-world traffic\\ndatasets. Our tensorflow implementation of the T-GCN is available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  Predicting traffic conditions from online route queries is a challenging task\\nas there are many complicated interactions over the roads and crowds involved.\\nIn this paper, we intend to improve traffic prediction by appropriate\\nintegration of three kinds of implicit but essential factors encoded in\\nauxiliary information. We do this within an encoder-decoder sequence learning\\nframework that integrates the following data: 1) offline geographical and\\nsocial attributes. For example, the geographical structure of roads or public\\nsocial events such as national celebrations; 2) road intersection information.\\nIn general, traffic congestion occurs at major junctions; 3) online crowd\\nqueries. For example, when many online queries issued for the same destination\\ndue to a public performance, the traffic around the destination will\\npotentially become heavier at this location after a while. Qualitative and\\nquantitative experiments on a real-world dataset from Baidu have demonstrated\\nthe effectiveness of our framework.\\n\\n    ', \"\\nAbstract:  Interpretability of deep neural networks is a recently emerging area of\\nmachine learning research targeting a better understanding of how models\\nperform feature selection and derive their classification decisions. In this\\npaper, two neural network architectures are trained on spectrogram and raw\\nwaveform data for audio classification tasks on a newly created audio dataset\\nand layer-wise relevance propagation (LRP), a previously proposed\\ninterpretability method, is applied to investigate the models' feature\\nselection and decision making. It is demonstrated that the networks are highly\\nreliant on feature marked as relevant by LRP through systematic manipulation of\\nthe input data. Our results show that by making deep audio classifiers\\ninterpretable, one can analyze and compare the properties and strategies of\\ndifferent models beyond classification accuracy, which potentially opens up new\\nways for model improvements.\\n\\n    \", '\\nAbstract:  Convolutional Neural Networks (CNNs) have proven very effective in image\\nclassification and show promise for audio. We use various CNN architectures to\\nclassify the soundtracks of a dataset of 70M training videos (5.24 million\\nhours) with 30,871 video-level labels. We examine fully connected Deep Neural\\nNetworks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We\\ninvestigate varying the size of both training set and label vocabulary, finding\\nthat analogs of the CNNs used in image classification do well on our audio\\nclassification task, and larger training and label sets help up to a point. A\\nmodel using embeddings from these classifiers does much better than raw\\nfeatures on the Audio Set [5] Acoustic Event Detection (AED) classification\\ntask.\\n\\n    ', '\\nAbstract:  Efficient audio synthesis is an inherently difficult machine learning task,\\nas human perception is sensitive to both global structure and fine-scale\\nwaveform coherence. Autoregressive models, such as WaveNet, model local\\nstructure at the expense of global latent structure and slow iterative\\nsampling, while Generative Adversarial Networks (GANs), have global latent\\nconditioning and efficient parallel sampling, but struggle to generate\\nlocally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact\\ngenerate high-fidelity and locally-coherent audio by modeling log magnitudes\\nand instantaneous frequencies with sufficient frequency resolution in the\\nspectral domain. Through extensive empirical investigations on the NSynth\\ndataset, we demonstrate that GANs are able to outperform strong WaveNet\\nbaselines on automated and human evaluation metrics, and efficiently generate\\naudio several orders of magnitude faster than their autoregressive\\ncounterparts.\\n\\n    ', '\\nAbstract:  Audio signals are sampled at high temporal resolutions, and learning to\\nsynthesize audio requires capturing structure across a range of timescales.\\nGenerative adversarial networks (GANs) have seen wide success at generating\\nimages that are both locally and globally coherent, but they have seen little\\napplication to audio generation. In this paper we introduce WaveGAN, a first\\nattempt at applying GANs to unsupervised synthesis of raw-waveform audio.\\nWaveGAN is capable of synthesizing one second slices of audio waveforms with\\nglobal coherence, suitable for sound effect generation. Our experiments\\ndemonstrate that, without labels, WaveGAN learns to produce intelligible words\\nwhen trained on a small-vocabulary speech dataset, and can also synthesize\\naudio from other domains such as drums, bird vocalizations, and piano. We\\ncompare WaveGAN to a method which applies GANs designed for image generation on\\nimage-like audio feature representations, finding both approaches to be\\npromising.\\n\\n    ', '\\nAbstract:  In this paper we propose a novel model for unconditional audio generation\\nbased on generating one audio sample at a time. We show that our model, which\\nprofits from combining memory-less modules, namely autoregressive multilayer\\nperceptrons, and stateful recurrent neural networks in a hierarchical structure\\nis able to capture underlying sources of variations in the temporal sequences\\nover very long time spans, on three datasets of different nature. Human\\nevaluation on the generated samples indicate that our model is preferred over\\ncompeting models. We also show how each component of the model contributes to\\nthe exhibited performance.\\n\\n    ', '\\nAbstract:  We introduce a new audio processing technique that increases the sampling\\nrate of signals such as speech or music using deep convolutional neural\\nnetworks. Our model is trained on pairs of low and high-quality audio examples;\\nat test-time, it predicts missing samples within a low-resolution signal in an\\ninterpolation process similar to image super-resolution. Our method is simple\\nand does not involve specialized audio processing techniques; in our\\nexperiments, it outperforms baselines on standard speech and music benchmarks\\nat upscaling ratios of 2x, 4x, and 6x. The method has practical applications in\\ntelephony, compression, and text-to-speech generation; it demonstrates the\\neffectiveness of feed-forward convolutional architectures on an audio\\ngeneration task.\\n\\n    ', '\\nAbstract:  Capturing high-level structure in audio waveforms is challenging because a\\nsingle second of audio spans tens of thousands of timesteps. While long-range\\ndependencies are difficult to model directly in the time domain, we show that\\nthey can be more tractably modelled in two-dimensional time-frequency\\nrepresentations such as spectrograms. By leveraging this representational\\nadvantage, in conjunction with a highly expressive probabilistic model and a\\nmultiscale generation procedure, we design a model capable of generating\\nhigh-fidelity audio samples which capture structure at timescales that\\ntime-domain models have yet to achieve. We apply our model to a variety of\\naudio generation tasks, including unconditional speech generation, music\\ngeneration, and text-to-speech synthesis---showing improvements over previous\\napproaches in both density estimates and human judgments.\\n\\n    ', '\\nAbstract:  End-to-end models for raw audio generation are a challenge, specially if they\\nhave to work with non-parallel data, which is a desirable setup in many\\nsituations. Voice conversion, in which a model has to impersonate a speaker in\\na recording, is one of those situations. In this paper, we propose Blow, a\\nsingle-scale normalizing flow using hypernetwork conditioning to perform\\nmany-to-many voice conversion between raw audio. Blow is trained end-to-end,\\nwith non-parallel data, on a frame-by-frame basis using a single speaker\\nidentifier. We show that Blow compares favorably to existing flow-based\\narchitectures and other competitive baselines, obtaining equal or better\\nperformance in both objective and subjective evaluations. We further assess the\\nimpact of its main components with an ablation study, and quantify a number of\\nproperties such as the necessary amount of training data or the preference for\\nsource or target speakers.\\n\\n    ', '\\nAbstract:  Generative models are successfully used for image synthesis in the recent\\nyears. But when it comes to other modalities like audio, text etc little\\nprogress has been made. Recent works focus on generating audio from a\\ngenerative model in an unsupervised setting. We explore the possibility of\\nusing generative models conditioned on class labels. Concatenation based\\nconditioning and conditional scaling were explored in this work with various\\nhyper-parameter tuning methods. In this paper we introduce Conditional WaveGANs\\n(cWaveGAN). Find our implementation at this https URL\\n', '\\nAbstract:  Dilated convolutions, also known as atrous convolutions, have been widely\\nexplored in deep convolutional neural networks (DCNNs) for various dense\\nprediction tasks. However, dilated convolutions suffer from the gridding\\nartifacts, which hampers the performance. In this work, we propose two simple\\nyet effective degridding methods by studying a decomposition of dilated\\nconvolutions. Unlike existing models, which explore solutions by focusing on a\\nblock of cascaded dilated convolutional layers, our methods address the\\ngridding artifacts by smoothing the dilated convolution itself. In addition, we\\npoint out that the two degridding approaches are intrinsically related and\\ndefine separable and shared (SS) operations, which generalize the proposed\\nmethods. We further explore SS operations in view of operations on graphs and\\npropose the SS output layer, which is able to smooth the entire DCNNs by only\\nreplacing the output layer. We evaluate our degridding methods and the SS\\noutput layer thoroughly, and visualize the smoothing effect through effective\\nreceptive field analysis. Results show that our methods degridding yield\\nconsistent improvements on the performance of dense prediction tasks, while\\nadding negligible amounts of extra training parameters. And the SS output layer\\nimproves the performance significantly and is very efficient in terms of number\\nof training parameters.\\n\\n    ', '\\nAbstract:  It has been shown recently that deep convolutional generative adversarial\\nnetworks (GANs) can learn to generate music in the form of piano-rolls, which\\nrepresent music by binary-valued time-pitch matrices. However, existing models\\ncan only generate real-valued piano-rolls and require further post-processing,\\nsuch as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final\\nbinary-valued results. In this paper, we study whether we can have a\\nconvolutional GAN model that directly creates binary-valued piano-rolls by\\nusing binary neurons. Specifically, we propose to append to the generator an\\nadditional refiner network, which uses binary neurons at the output layer. The\\nwhole network is trained in two stages. Firstly, the generator and the\\ndiscriminator are pretrained. Then, the refiner network is trained along with\\nthe discriminator to learn to binarize the real-valued piano-rolls the\\npretrained generator creates. Experimental results show that using binary\\nneurons instead of HT or BS indeed leads to better results in a number of\\nobjective measures. Moreover, deterministic binary neurons perform better than\\nstochastic ones in both objective measures and a subjective test. The source\\ncode, training data and audio examples of the generated results can be found at\\nthis https URL .\\n\\n    ', '\\nAbstract:  Generating music has a few notable differences from generating images and\\nvideos. First, music is an art of time, necessitating a temporal model. Second,\\nmusic is usually composed of multiple instruments/tracks with their own\\ntemporal dynamics, but collectively they unfold over time interdependently.\\nLastly, musical notes are often grouped into chords, arpeggios or melodies in\\npolyphonic music, and thereby introducing a chronological ordering of notes is\\nnot naturally suitable. In this paper, we propose three models for symbolic\\nmulti-track music generation under the framework of generative adversarial\\nnetworks (GANs). The three models, which differ in the underlying assumptions\\nand accordingly the network architectures, are referred to as the jamming\\nmodel, the composer model and the hybrid model. We trained the proposed models\\non a dataset of over one hundred thousand bars of rock music and applied them\\nto generate piano-rolls of five tracks: bass, drums, guitar, piano and strings.\\nA few intra-track and inter-track objective metrics are also proposed to\\nevaluate the generative results, in addition to a subjective user study. We\\nshow that our models can generate coherent music of four bars right from\\nscratch (i.e. without human inputs). We also extend our models to human-AI\\ncooperative music generation: given a specific track composed by human, we can\\ngenerate four additional tracks to accompany it. All code, the dataset and the\\nrendered audio samples are available at this https URL .\\n\\n    ', \"\\nAbstract:  Existing research on music generation focuses on composition, but often\\nignores the expressive performance characteristics required for plausible\\nrenditions of resultant pieces. In this paper, we introduce the Nintendo\\nEntertainment System Music Database (NES-MDB), a large corpus allowing for\\nseparate examination of the tasks of composition and performance. NES-MDB\\ncontains thousands of multi-instrumental songs composed for playback by the\\ncompositionally-constrained NES audio synthesizer. For each song, the dataset\\ncontains a musical score for four instrument voices as well as expressive\\nattributes for the dynamics and timbre of each voice. Unlike datasets comprised\\nof General MIDI files, NES-MDB includes all of the information needed to render\\nexact acoustic performances of the original compositions. Alongside the\\ndataset, we provide a tool that renders generated compositions as NES-style\\naudio by emulating the device's audio processor. Additionally, we establish\\nbaselines for the tasks of composition, which consists of learning the\\nsemantics of composing for the NES synthesizer, and performance, which involves\\nfinding a mapping between a composition and realistic expressive attributes.\\n\\n    \", '\\nAbstract:  Recent progress in deep learning for audio synthesis opens the way to models\\nthat directly produce the waveform, shifting away from the traditional paradigm\\nof relying on vocoders or MIDI synthesizers for speech or music generation.\\nDespite their successes, current state-of-the-art neural audio synthesizers\\nsuch as WaveNet and SampleRNN suffer from prohibitive training and inference\\ntimes because they are based on autoregressive models that generate audio\\nsamples one at a time at a rate of 16kHz. In this work, we study the more\\ncomputationally efficient alternative of generating the waveform frame-by-frame\\nwith large strides. We present SING, a lightweight neural audio synthesizer for\\nthe original task of generating musical notes given desired instrument, pitch\\nand velocity. Our model is trained end-to-end to generate notes from nearly\\n1000 instruments with a single decoder, thanks to a new loss function that\\nminimizes the distances between the log spectrograms of the generated and\\ntarget waveforms. On the generalization task of synthesizing notes for pairs of\\npitch and instrument not seen during training, SING produces audio with\\nsignificantly improved perceptual quality compared to a state-of-the-art\\nautoencoder based on WaveNet as measured by a Mean Opinion Score (MOS), and is\\nabout 32 times faster for training and 2, 500 times faster for inference.\\n\\n    ', '\\nAbstract:  Lidar based 3D object detection is inevitable for autonomous driving, because\\nit directly links to environmental understanding and therefore builds the base\\nfor prediction and motion planning. The capacity of inferencing highly sparse\\n3D data in real-time is an ill-posed problem for lots of other application\\nareas besides automated vehicles, e.g. augmented reality, personal robotics or\\nindustrial automation. We introduce Complex-YOLO, a state of the art real-time\\n3D object detection network on point clouds only. In this work, we describe a\\nnetwork that expands YOLOv2, a fast 2D standard object detector for RGB images,\\nby a specific complex regression strategy to estimate multi-class 3D boxes in\\nCartesian space. Thus, we propose a specific Euler-Region-Proposal Network\\n(E-RPN) to estimate the pose of the object by adding an imaginary and a real\\nfraction to the regression network. This ends up in a closed complex space and\\navoids singularities, which occur by single angle estimations. The E-RPN\\nsupports to generalize well during training. Our experiments on the KITTI\\nbenchmark suite show that we outperform current leading methods for 3D object\\ndetection specifically in terms of efficiency. We achieve state of the art\\nresults for cars, pedestrians and cyclists by being more than five times faster\\nthan the fastest competitor. Further, our model is capable of estimating all\\neight KITTI-classes, including Vans, Trucks or sitting pedestrians\\nsimultaneously with high accuracy.\\n\\n    ', \"\\nAbstract:  Robots that navigate among pedestrians use collision avoidance algorithms to\\nenable safe and efficient operation. Recent works present deep reinforcement\\nlearning as a framework to model the complex interactions and cooperation.\\nHowever, they are implemented using key assumptions about other agents'\\nbehavior that deviate from reality as the number of agents in the environment\\nincreases. This work extends our previous approach to develop an algorithm that\\nlearns collision avoidance among a variety of types of dynamic agents without\\nassuming they follow any particular behavior rules. This work also introduces a\\nstrategy using LSTM that enables the algorithm to use observations of an\\narbitrary number of other agents, instead of previous methods that have a fixed\\nobservation size. The proposed algorithm outperforms our previous approach in\\nsimulation as the number of agents increases, and the algorithm is demonstrated\\non a fully autonomous robotic vehicle traveling at human walking speed, without\\nthe use of a 3D Lidar.\\n\\n    \", '\\nAbstract:  Many problems in computer vision and robotics can be phrased as non-linear\\nleast squares optimization problems represented by factor graphs, for example,\\nsimultaneous localization and mapping (SLAM), structure from motion (SfM),\\nmotion planning, and control. We have developed an open-source C++/Python\\nframework miniSAM, for solving such factor graph based least squares problems.\\nCompared to most existing frameworks for least squares solvers, miniSAM has (1)\\nfull Python/NumPy API, which enables more agile development and easy binding\\nwith existing Python projects, and (2) a wide list of sparse linear solvers,\\nincluding CUDA enabled sparse linear solvers. Our benchmarking results shows\\nminiSAM offers comparable performances on various types of problems, with more\\nflexible and smoother development experience.\\n\\n    ', \"\\nAbstract:  Sampling-based Motion Planners (SMPs) have become increasingly popular as\\nthey provide collision-free path solutions regardless of obstacle geometry in a\\ngiven environment. However, their computational complexity increases\\nsignificantly with the dimensionality of the motion planning problem. Adaptive\\nsampling is one of the ways to speed up SMPs by sampling a particular region of\\na configuration space that is more likely to contain an optimal path solution.\\nAlthough there are a wide variety of algorithms for adaptive sampling, they\\nrely on hand-crafted heuristics; furthermore, their performance decreases\\nsignificantly in high-dimensional spaces. In this paper, we present a neural\\nnetwork-based adaptive sampler for motion planning called Deep Sampling-based\\nMotion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their\\noverall speed significantly while exhibiting efficient scalability to\\nhigher-dimensional problems. DeepSMP's neural architecture comprises of a\\nContractive AutoEncoder which encodes given workspaces directly from a raw\\npoint cloud data, and a Dropout-based stochastic deep feedforward neural\\nnetwork which takes the workspace encoding, start and goal configuration, and\\niteratively generates feasible samples for SMPs to compute end-to-end\\ncollision-free optimal paths. DeepSMP is not only consistently computationally\\nefficient in all tested environments but has also shown remarkable\\ngeneralization to completely unseen environments. We evaluate DeepSMP on\\nmultiple planning problems including planning of a point-mass robot,\\nrigid-body, 6-link robotic manipulator in various 2D and 3D environments. The\\nresults show that on average our method is at least 7 times faster in\\npoint-mass and rigid-body case and about 28 times faster in 6-link robot case\\nthan the existing state-of-the-art.\\n\\n    \", '\\nAbstract:  In the past, Acoustic Scene Classification systems have been based on hand\\ncrafting audio features that are input to a classifier. Nowadays, the common\\ntrend is to adopt data driven techniques, e.g., deep learning, where audio\\nrepresentations are learned from data. In this paper, we propose a system that\\nconsists of a simple fusion of two methods of the aforementioned types: a deep\\nlearning approach where log-scaled mel-spectrograms are input to a\\nconvolutional neural network, and a feature engineering approach, where a\\ncollection of hand-crafted features is input to a gradient boosting machine. We\\nfirst show that both methods provide complementary information to some extent.\\nThen, we use a simple late fusion strategy to combine both methods. We report\\nclassification accuracy of each method individually and the combined system on\\nthe TUT Acoustic Scenes 2017 dataset. The proposed fused system outperforms\\neach of the individual methods and attains a classification accuracy of 72.8%\\non the evaluation set, improving the baseline system by 11.8%.\\n\\n    ', '\\nAbstract:  What is a good visual representation for autonomous agents? We address this\\nquestion in the context of semantic visual navigation, which is the problem of\\na robot finding its way through a complex environment to a target object, e.g.\\ngo to the refrigerator. Instead of acquiring a metric semantic map of an\\nenvironment and using planning for navigation, our approach learns navigation\\npolicies on top of representations that capture spatial layout and semantic\\ncontextual cues. We propose to using high level semantic and contextual\\nfeatures including segmentation and detection masks obtained by off-the-shelf\\nstate-of-the-art vision as observations and use deep network to learn the\\nnavigation policy. This choice allows using additional data, from orthogonal\\nsources, to better train different parts of the model the representation\\nextraction is trained on large standard vision datasets while the navigation\\ncomponent leverages large synthetic environments for training. This combination\\nof real and synthetic is possible because equitable feature representations are\\navailable in both (e.g., segmentation and detection masks), which alleviates\\nthe need for domain adaptation. Both the representation and the navigation\\npolicy can be readily applied to real non-synthetic environments as\\ndemonstrated on the Active Vision Dataset [1]. Our approach gets successfully\\nto the target in 54% of the cases in unexplored environments, compared to 46%\\nfor non-learning based approach, and 28% for the learning-based baseline.\\n\\n    ', \"\\nAbstract:  The cost of large scale data collection and annotation often makes the\\napplication of machine learning algorithms to new tasks or datasets\\nprohibitively expensive. One approach circumventing this cost is training\\nmodels on synthetic data where annotations are provided automatically. Despite\\ntheir appeal, such models often fail to generalize from synthetic to real\\nimages, necessitating domain adaptation algorithms to manipulate these models\\nbefore they can be successfully applied. Existing approaches focus either on\\nmapping representations from one domain to the other, or on learning to extract\\nfeatures that are invariant to the domain from which they were extracted.\\nHowever, by focusing only on creating a mapping or shared representation\\nbetween the two domains, they ignore the individual characteristics of each\\ndomain. We suggest that explicitly modeling what is unique to each domain can\\nimprove a model's ability to extract domain-invariant features. Inspired by\\nwork on private-shared component analysis, we explicitly learn to extract image\\nrepresentations that are partitioned into two subspaces: one component which is\\nprivate to each domain and one which is shared across domains. Our model is\\ntrained not only to perform the task we care about in the source domain, but\\nalso to use the partitioned representation to reconstruct the images from both\\ndomains. Our novel architecture results in a model that outperforms the\\nstate-of-the-art on a range of unsupervised domain adaptation scenarios and\\nadditionally produces visualizations of the private and shared representations\\nenabling interpretation of the domain adaptation process.\\n\\n    \", '\\nAbstract:  In this paper, we propose a new loss function called generalized end-to-end\\n(GE2E) loss, which makes the training of speaker verification models more\\nefficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\\nTE2E, the GE2E loss function updates the network in a way that emphasizes\\nexamples that are difficult to verify at each step of the training process.\\nAdditionally, the GE2E loss does not require an initial stage of example\\nselection. With these properties, our model with the new loss function\\ndecreases speaker verification EER by more than 10%, while reducing the\\ntraining time by 60% at the same time. We also introduce the MultiReader\\ntechnique, which allows us to do domain adaptation - training a more accurate\\nmodel that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\\nwell as multiple dialects.\\n\\n    ', '\\nAbstract:  Pronounced as \"musician\", the musicnn library contains a set of pre-trained\\nmusically motivated convolutional neural networks for music audio tagging:\\nthis https URL. This repository also includes some\\npre-trained vgg-like baselines. These models can be used as out-of-the-box\\nmusic audio taggers, as music feature extractors, or as pre-trained models for\\ntransfer learning.\\nWe also provide the code to train the aforementioned models:\\nthis https URL. This framework also allows\\nimplementing novel models. For example, a musically motivated convolutional\\nneural network with an attention-based output layer (instead of the temporal\\npooling layer) can achieve state-of-the-art results for music audio tagging:\\n90.77 ROC-AUC / 38.61 PR-AUC on the MagnaTagATune dataset --- and 88.81 ROC-AUC\\n/ 31.51 PR-AUC on the Million Song Dataset.\\n\\n    ', '\\nAbstract:  This paper introduces Task 2 of the DCASE2019 Challenge, titled \"Audio\\ntagging with noisy labels and minimal supervision\". This task was hosted on the\\nKaggle platform as \"Freesound Audio Tagging 2019\". The task evaluates systems\\nfor multi-label audio tagging using a large set of noisy-labeled data, and a\\nmuch smaller set of manually-labeled data, under a large vocabulary setting of\\n80 everyday sound classes. In addition, the proposed dataset poses an acoustic\\nmismatch problem between the noisy train set and the test set due to the fact\\nthat they come from different web audio sources. This can correspond to a\\nrealistic scenario given by the difficulty in gathering large amounts of\\nmanually labeled data. We present the task setup, the FSDKaggle2019 dataset\\nprepared for this scientific evaluation, and a baseline system consisting of a\\nconvolutional neural network. All these resources are freely available.\\n\\n    ', '\\nAbstract:  Audio tagging aims to infer descriptive labels from audio clips. Audio\\ntagging is challenging due to the limited size of data and noisy labels. In\\nthis paper, we describe our solution for the DCASE 2018 Task 2 general audio\\ntagging challenge. The contributions of our solution include: We investigated a\\nvariety of convolutional neural network architectures to solve the audio\\ntagging task. Statistical features are applied to capture statistical patterns\\nof audio features to improve the classification performance. Ensemble learning\\nis applied to ensemble the outputs from the deep classifiers to utilize\\ncomplementary information. a sample re-weight strategy is employed for ensemble\\ntraining to address the noisy label problem. Our system achieves a mean average\\nprecision (mAP@3) of 0.958, outperforming the baseline system of 0.704. Our\\nsystem ranked the 1st and 4th out of 558 submissions in the public and private\\nleaderboard of DCASE 2018 Task 2 challenge. Our codes are available at\\nthis https URL.\\n\\n    ', '\\nAbstract:  This paper describes Task 2 of the DCASE 2018 Challenge, titled\\n\"General-purpose audio tagging of Freesound content with AudioSet labels\". This\\ntask was hosted on the Kaggle platform as \"Freesound General-Purpose Audio\\nTagging Challenge\". The goal of the task is to build an audio tagging system\\nthat can recognize the category of an audio clip from a subset of 41 diverse\\ncategories drawn from the AudioSet Ontology. We present the task, the dataset\\nprepared for the competition, and a baseline system.\\n\\n    ', '\\nAbstract:  Audio tagging aims to predict one or several labels in an audio clip. Many\\nprevious works use weakly labelled data (WLD) for audio tagging, where only\\npresence or absence of sound events is known, but the order of sound events is\\nunknown. To use the order information of sound events, we propose sequential\\nlabelled data (SLD), where both the presence or absence and the order\\ninformation of sound events are known. To utilize SLD in audio tagging, we\\npropose a Convolutional Recurrent Neural Network followed by a Connectionist\\nTemporal Classification (CRNN-CTC) objective function to map from an audio clip\\nspectrogram to SLD. Experiments show that CRNN-CTC obtains an Area Under Curve\\n(AUC) score of 0.986 in audio tagging, outperforming the baseline CRNN of 0.908\\nand 0.815 with Max Pooling and Average Pooling, respectively. In addition, we\\nshow CRNN-CTC has the ability to predict the order of sound events in an audio\\nclip.\\n\\n    ', '\\nAbstract:  Environmental audio tagging aims to predict only the presence or absence of\\ncertain acoustic events in the interested acoustic scene. In this paper we make\\ncontributions to audio tagging in two parts, respectively, acoustic modeling\\nand feature learning. We propose to use a shrinking deep neural network (DNN)\\nframework incorporating unsupervised feature learning to handle the multi-label\\nclassification task. For the acoustic modeling, a large set of contextual\\nframes of the chunk are fed into the DNN to perform a multi-label\\nclassification for the expected tags, considering that only chunk (or\\nutterance) level rather than frame-level labels are available. Dropout and\\nbackground noise aware training are also adopted to improve the generalization\\ncapability of the DNNs. For the unsupervised feature learning, we propose to\\nuse a symmetric or asymmetric deep de-noising auto-encoder (sDAE or aDAE) to\\ngenerate new data-driven features from the Mel-Filter Banks (MFBs) features.\\nThe new features, which are smoothed against background noise and more compact\\nwith contextual information, can further improve the performance of the DNN\\nbaseline. Compared with the standard Gaussian Mixture Model (GMM) baseline of\\nthe DCASE 2016 audio tagging challenge, our proposed method obtains a\\nsignificant equal error rate (EER) reduction from 0.21 to 0.13 on the\\ndevelopment set. The proposed aDAE system can get a relative 6.7% EER reduction\\ncompared with the strong DNN baseline on the development set. Finally, the\\nresults also show that our approach obtains the state-of-the-art performance\\nwith 0.15 EER on the evaluation set of the DCASE 2016 audio tagging task while\\nEER of the first prize of this challenge is 0.17.\\n\\n    ', '\\nAbstract:  The ability of deep convolutional neural networks (CNN) to learn\\ndiscriminative spectro-temporal patterns makes them well suited to\\nenvironmental sound classification. However, the relative scarcity of labeled\\ndata has impeded the exploitation of this family of high-capacity models. This\\nstudy has two primary contributions: first, we propose a deep convolutional\\nneural network architecture for environmental sound classification. Second, we\\npropose the use of audio data augmentation for overcoming the problem of data\\nscarcity and explore the influence of different augmentations on the\\nperformance of the proposed CNN architecture. Combined with data augmentation,\\nthe proposed model produces state-of-the-art results for environmental sound\\nclassification. We show that the improved performance stems from the\\ncombination of a deep, high-capacity model and an augmented training set: this\\ncombination outperforms both the proposed CNN without augmentation and a\\n\"shallow\" dictionary learning model with augmentation. Finally, we examine the\\ninfluence of each augmentation on the model\\'s classification accuracy for each\\nclass, and observe that the accuracy for each class is influenced differently\\nby each augmentation, suggesting that the performance of the model could be\\nimproved further by applying class-conditional data augmentation.\\n\\n    ', '\\nAbstract:  End-to-end neural network based approaches to audio modelling are generally\\noutperformed by models trained on high-level data representations. In this\\npaper we present preliminary work that shows the feasibility of training the\\nfirst layers of a deep convolutional neural network (CNN) model to learn the\\ncommonly-used log-scaled mel-spectrogram transformation. Secondly, we\\ndemonstrate that upon initializing the first layers of an end-to-end CNN\\nclassifier with the learned transformation, convergence and performance on the\\nESC-50 environmental sound classification dataset are similar to a CNN-based\\nmodel trained on the highly pre-processed log-scaled mel-spectrogram features.\\n\\n    ', \"\\nAbstract:  The ConditionaL Neural Network (CLNN) exploits the nature of the temporal\\nsequencing of the sound signal represented in a spectrogram, and its variant\\nthe Masked ConditionaL Neural Network (MCLNN) induces the network to learn in\\nfrequency bands by embedding a filterbank-like sparseness over the network's\\nlinks using a binary mask. Additionally, the masking automates the exploration\\nof different feature combinations concurrently analogous to handcrafting the\\noptimum combination of features for a recognition task. We have evaluated the\\nMCLNN performance using the Urbansound8k dataset of environmental sounds.\\nAdditionally, we present a collection of manually recorded sounds for rail and\\nroad traffic, YorNoise, to investigate the confusion rates among machine\\ngenerated sounds possessing low-frequency components. MCLNN has achieved\\ncompetitive results without augmentation and using 12% of the trainable\\nparameters utilized by an equivalent model based on state-of-the-art\\nConvolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k\\ndataset with YorNoise, where experiments have shown that common tonal\\nproperties affect the classification performance.\\n\\n    \", '\\nAbstract:  In this paper, we propose a framework for environmental sound classification\\nin a low-data context (less than 100 labeled examples per class). We show that\\nusing pre-trained image classification models along with the usage of data\\naugmentation techniques results in higher performance over alternative\\napproaches. We applied this system to the task of Urban Sound Tagging, part of\\nthe DCASE 2019. The objective was to label different sources of noise from raw\\naudio data. A modified form of MobileNetV2, a convolutional neural network\\n(CNN) model was trained to classify both coarse and fine tags jointly. The\\nproposed model uses log-scaled Mel-spectrogram as the representation format for\\nthe audio data. Mixup, Random erasing, scaling, and shifting are used as data\\naugmentation techniques. A second model that uses scaled labels was built to\\naccount for human errors in the annotations. The proposed model achieved the\\nfirst rank on the leaderboard with Micro-AUPRC values of 0.751 and 0.860 on\\nfine and coarse tags, respectively.\\n\\n    ', '\\nAbstract:  Stereo image pairs can be used to improve the performance of super-resolution\\n(SR) since additional information is provided from a second viewpoint. However,\\nit is challenging to incorporate this information for SR since disparities\\nbetween stereo images vary significantly. In this paper, we propose a\\nparallax-attention stereo superresolution network (PASSRnet) to integrate the\\ninformation from a stereo image pair for SR. Specifically, we introduce a\\nparallax-attention mechanism with a global receptive field along the epipolar\\nline to handle different stereo images with large disparity variations. We also\\npropose a new and the largest dataset for stereo image SR (namely, Flickr1024).\\nExtensive experiments demonstrate that the parallax-attention mechanism can\\ncapture correspondence between stereo images to improve SR performance with a\\nsmall computational and memory cost. Comparative results show that our PASSRnet\\nachieves the state-of-the-art performance on the Middlebury, KITTI 2012 and\\nKITTI 2015 datasets.\\n\\n    ', '\\nAbstract:  With the popularity of dual cameras in recently released smart phones, a\\ngrowing number of super-resolution (SR) methods have been proposed to enhance\\nthe resolution of stereo image pairs. However, the lack of high-quality stereo\\ndatasets has limited the research in this area. To facilitate the training and\\nevaluation of novel stereo SR algorithms, in this paper, we present a\\nlarge-scale stereo dataset named Flickr1024, which contains 1024 pairs of\\nhigh-quality images and covers diverse scenarios. We first introduce the data\\nacquisition and processing pipeline, and then compare several popular stereo\\ndatasets. Finally, we conduct crossdataset experiments to investigate the\\npotential benefits introduced by our dataset. Experimental results show that,\\nas compared to the KITTI and Middlebury datasets, our Flickr1024 dataset can\\nhelp to handle the over-fitting problem and significantly improves the\\nperformance of stereo SR methods. The Flickr1024 dataset is available online\\nat: this https URL.\\n\\n    ', '\\nAbstract:  We present a method for audio denoising that combines processing done in both\\nthe time domain and the time-frequency domain. Given a noisy audio clip, the\\nmethod trains a deep neural network to fit this signal. Since the fitting is\\nonly partly successful and is able to better capture the underlying clean\\nsignal than the noise, the output of the network helps to disentangle the clean\\naudio from the rest of the signal. The method is completely unsupervised and\\nonly trains on the specific audio clip that is being denoised. Our experiments\\ndemonstrate favorable performance in comparison to the literature methods, and\\nour code and audio samples are available at https: //github.com/mosheman5/DNP.\\nIndex Terms: Audio denoising; Unsupervised learning\\n\\n    ', '\\nAbstract:  Perceiving a scene most fully requires all the senses. Yet modeling how\\nobjects look and sound is challenging: most natural scenes and events contain\\nmultiple objects, and the audio track mixes all the sound sources together. We\\npropose to learn audio-visual object models from unlabeled video, then exploit\\nthe visual context to perform audio source separation in novel videos. Our\\napproach relies on a deep multi-instance multi-label learning framework to\\ndisentangle the audio frequency bases that map to individual visual objects,\\neven without observing/hearing those objects in isolation. We show how the\\nrecovered disentangled bases can be used to guide audio source separation to\\nobtain better-separated, object-level sounds. Our work is the first to learn\\naudio source separation from large-scale \"in the wild\" videos containing\\nmultiple audio sources per video. We obtain state-of-the-art results on\\nvisually-aided audio source separation and audio denoising. Our video results:\\nthis http URL\\n', '\\nAbstract:  Learning how objects sound from video is challenging, since they often\\nheavily overlap in a single audio channel. Current methods for visually-guided\\naudio source separation sidestep the issue by training with artificially mixed\\nvideo clips, but this puts unwieldy restrictions on training data collection\\nand may even prevent learning the properties of \"true\" mixed sounds. We\\nintroduce a co-separation training paradigm that permits learning object-level\\nsounds from unlabeled multi-source videos. Our novel training objective\\nrequires that the deep neural network\\'s separated audio for similar-looking\\nobjects be consistently identifiable, while simultaneously reproducing accurate\\nvideo-level audio tracks for each source training pair. Our approach\\ndisentangles sounds in realistic test videos, even in cases where an object was\\nnot observed individually during training. We obtain state-of-the-art results\\non visually-guided audio source separation and audio denoising for the MUSIC,\\nAudioSet, and AV-Bench datasets.\\n\\n    ', '\\nAbstract:  We explore frame-level audio feature learning for chord recognition using\\nartificial neural networks. We present the argument that chroma vectors\\npotentially hold enough information to model harmonic content of audio for\\nchord recognition, but that standard chroma extractors compute too noisy\\nfeatures. This leads us to propose a learned chroma feature extractor based on\\nartificial neural networks. It is trained to compute chroma features that\\nencode harmonic information important for chord recognition, while being robust\\nto irrelevant interferences. We achieve this by feeding the network an audio\\nspectrum with context instead of a single frame as input. This way, the network\\ncan learn to selectively compensate noise and resolve harmonic ambiguities.\\nWe compare the resulting features to hand-crafted ones by using a simple\\nlinear frame-wise classifier for chord recognition on various data sets. The\\nresults show that the learned feature extractor produces superior chroma\\nvectors for chord recognition.\\n\\n    ', '\\nAbstract:  Chord recognition is an important task since chords are highly abstract and\\ndescriptive features of music. For effective chord recognition, it is essential\\nto utilize relevant context in audio sequence. While various machine learning\\nmodels such as convolutional neural networks (CNNs) and recurrent neural\\nnetworks (RNNs) have been employed for the task, most of them have limitations\\nin capturing long-term dependency or require training of an additional model.\\nIn this work, we utilize a self-attention mechanism for chord recognition to\\nfocus on certain regions of chords. Training of the proposed bi-directional\\nTransformer for chord recognition (BTC) consists of a single phase while\\nshowing competitive performance. Through an attention map analysis, we have\\nvisualized how attention was performed. It turns out that the model was able to\\ndivide segments of chords by utilizing adaptive receptive field of the\\nattention mechanism. Furthermore, it was observed that the model was able to\\neffectively capture long-term dependencies, making use of essential information\\nregardless of distance.\\n\\n    ', \"\\nAbstract:  Every minute, hundreds of hours of video are uploaded to social media sites\\nand the Internet from around the world. This material creates a visual record\\nof the experiences of a significant percentage of humanity and can help\\nilluminate how we live in the present moment. When properly analyzed, this\\nvideo can also help analysts to reconstruct events of interest, including war\\ncrimes, human rights violations, and terrorist acts. Machine learning and\\ncomputer vision can play a crucial role in this process. In this technical\\nreport, we describe the Video Event Reconstruction and Analysis (VERA) system.\\nThis new tool brings together a variety of capabilities we have developed over\\nthe past few years (including video synchronization and geolocation to order\\nunstructured videos lacking metadata over time and space, and sound recognition\\nalgorithms) to enable the reconstruction and analysis of events captured on\\nvideo. Among other uses, VERA enables the localization of a shooter from just a\\nfew videos that include the sound of gunshots. To demonstrate the efficacy of\\nthis suite of tools, we present the results of estimating the shooter's\\nlocation of the Las Vegas Shooting in 2017 and show that VERA accurately\\npredicts the shooter's location using only the first few gunshots. We then\\npoint out future directions that can help improve the system and further reduce\\nunnecessary human labor in the process. All of the components of VERA run\\nthrough a web interface that enables human-in-the-loop verification to ensure\\naccurate estimations. All relevant source code, including the web interface and\\nmachine learning models, is freely available on Github. We hope that\\nresearchers and software developers will be inspired to improve and expand this\\nsystem moving forward to better meet the needs of human rights and public\\nsafety.\\n\\n    \", '\\nAbstract:  We present a novel learning-based approach to estimate the\\ndirection-of-arrival (DOA) of a sound source using a convolutional recurrent\\nneural network (CRNN) trained via regression on synthetic data and Cartesian\\nlabels. We also describe an improved method to generate synthetic data to train\\nthe neural network using state-of-the-art sound propagation algorithms that\\nmodel specular as well as diffuse reflections of sound. We compare our model\\nagainst three other CRNNs trained using different formulations of the same\\nproblem: classification on categorical labels, and regression on spherical\\ncoordinate labels. In practice, our model achieves up to 43% decrease in\\nangular error over prior methods. The use of diffuse reflection results in 34%\\nand 41% reduction in angular prediction errors on LOCATA and SOFA datasets,\\nrespectively, over prior methods based on image-source methods. Our method\\nresults in an additional 3% error reduction over prior schemes that use\\nclassification based networks, and we use 36% fewer network parameters.\\n\\n    ', '\\nAbstract:  We investigate supervised learning strategies that improve the training of\\nneural network audio classifiers on small annotated collections. In particular,\\nwe study whether (i) a naive regularization of the solution space, (ii)\\nprototypical networks, (iii) transfer learning, or (iv) their combination, can\\nfoster deep learning models to better leverage a small amount of training\\nexamples. To this end, we evaluate (i-iv) for the tasks of acoustic event\\nrecognition and acoustic scene classification, considering from 1 to 100\\nlabeled examples per class. Results indicate that transfer learning is a\\npowerful strategy in such scenarios, but prototypical networks show promising\\nresults when one does not count with external or validation data.\\n\\n    ', '\\nAbstract:  A general problem in acoustic scene classification task is the mismatched\\nconditions between training and testing data, which significantly reduces the\\nperformance of the developed methods on classification accuracy. As a\\ncountermeasure, we present the first method of unsupervised adversarial domain\\nadaptation for acoustic scene classification. We employ a model pre-trained on\\ndata from one set of conditions and by using data from other set of conditions,\\nwe adapt the model in order that its output cannot be used for classifying the\\nset of conditions that input data belong to. We use a freely available dataset\\nfrom the DCASE 2018 challenge Task 1, subtask B, that contains data from\\nmismatched recording devices. We consider the scenario where the annotations\\nare available for the data recorded from one device, but not for the rest. Our\\nresults show that with our model agnostic method we can achieve $\\\\sim 10\\\\%$\\nincrease at the accuracy on an unseen and unlabeled dataset, while keeping\\nalmost the same performance on the labeled dataset.\\n\\n    ', '\\nAbstract:  A challenging problem in deep learning-based machine listening field is the\\ndegradation of the performance when using data from unseen conditions. In this\\npaper we focus on the acoustic scene classification (ASC) task and propose an\\nadversarial deep learning method to allow adapting an acoustic scene\\nclassification system to deal with a new acoustic channel resulting from data\\ncaptured with a different recording device. We build upon the theoretical model\\nof H{\\\\Delta}H-distance and previous adversarial discriminative deep learning\\nmethod for ASC unsupervised domain adaptation, and we present an adversarial\\ntraining based method using the Wasserstein distance. We improve the\\nstate-of-the-art mean accuracy on the data from the unseen conditions from 32%\\nto 45%, using the TUT Acoustic Scenes dataset.\\n\\n    ', '\\nAbstract:  In this paper, we propose a new strategy for acoustic scene classification\\n(ASC) , namely recognizing acoustic scenes through identifying distinct sound\\nevents. This differs from existing strategies, which focus on characterizing\\nglobal acoustical distributions of audio or the temporal evolution of\\nshort-term audio features, without analysis down to the level of sound events.\\nTo identify distinct sound events for each scene, we formulate ASC in a\\nmulti-instance learning (MIL) framework, where each audio recording is mapped\\ninto a bag-of-instances representation. Here, instances can be seen as\\nhigh-level representations for sound events inside a scene. We also propose a\\nMIL neural networks model, which implicitly identifies distinct instances\\n(i.e., sound events). Furthermore, we propose two specially designed modules\\nthat model the multi-temporal scale and multi-modal natures of the sound events\\nrespectively. The experiments were conducted on the official development set of\\nthe DCASE2018 Task1 Subtask B, and our best-performing model improves over the\\nofficial baseline by 9.4% (68.3% vs 58.9%) in terms of classification accuracy.\\nThis study indicates that recognizing acoustic scenes by identifying distinct\\nsound events is effective and paves the way for future studies that combine\\nthis strategy with previous ones.\\n\\n    ', \"\\nAbstract:  Convolutional Neural Networks (CNNs) can learn effective features, though\\nhave been shown to suffer from a performance drop when the distribution of the\\ndata changes from training to test data. In this paper we analyze the internal\\nrepresentations of CNNs and observe that the representations of unseen data in\\neach class, spread more (with higher variance) in the embedding space of the\\nCNN compared to representations of the training data. More importantly, this\\ndifference is more extreme if the unseen data comes from a shifted\\ndistribution. Based on this observation, we objectively evaluate the degree of\\nrepresentation's variance in each class via eigenvalue decomposition on the\\nwithin-class covariance of the internal representations of CNNs and observe the\\nsame behaviour. This can be problematic as larger variances might lead to\\nmis-classification if the sample crosses the decision boundary of its class. We\\napply nearest neighbor classification on the representations and empirically\\nshow that the embeddings with the high variance actually have significantly\\nworse KNN classification performances, although this could not be foreseen from\\ntheir end-to-end classification results. To tackle this problem, we propose\\nDeep Within-Class Covariance Analysis (DWCCA), a deep neural network layer that\\nsignificantly reduces the within-class covariance of a DNN's representation,\\nimproving performance on unseen test data from a shifted distribution. We\\nempirically evaluate DWCCA on two datasets for Acoustic Scene Classification\\n(DCASE2016 and DCASE2017). We demonstrate that not only does DWCCA\\nsignificantly improve the network's internal representation, it also increases\\nthe end-to-end classification accuracy, especially when the test set exhibits a\\ndistribution shift. By adding DWCCA to a VGG network, we achieve around 6\\npercentage points improvement in the case of a distribution mismatch.\\n\\n    \", '\\nAbstract:  Recent work has shown that depth estimation from a stereo pair of images can\\nbe formulated as a supervised learning task to be resolved with convolutional\\nneural networks (CNNs). However, current architectures rely on patch-based\\nSiamese networks, lacking the means to exploit context information for finding\\ncorrespondence in illposed regions. To tackle this problem, we propose PSMNet,\\na pyramid stereo matching network consisting of two main modules: spatial\\npyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage\\nof the capacity of global context information by aggregating context in\\ndifferent scales and locations to form a cost volume. The 3D CNN learns to\\nregularize cost volume using stacked multiple hourglass networks in conjunction\\nwith intermediate supervision. The proposed approach was evaluated on several\\nbenchmark datasets. Our method ranked first in the KITTI 2012 and 2015\\nleaderboards before March 18, 2018. The codes of PSMNet are available at:\\nthis https URL.\\n\\n    ', '\\nAbstract:  Stereo matching algorithms usually consist of four steps, including matching\\ncost calculation, matching cost aggregation, disparity calculation, and\\ndisparity refinement. Existing CNN-based methods only adopt CNN to solve parts\\nof the four steps, or use different networks to deal with different steps,\\nmaking them difficult to obtain the overall optimal solution. In this paper, we\\npropose a network architecture to incorporate all steps of stereo matching. The\\nnetwork consists of three parts. The first part calculates the multi-scale\\nshared features. The second part performs matching cost calculation, matching\\ncost aggregation and disparity calculation to estimate the initial disparity\\nusing shared features. The initial disparity and the shared features are used\\nto calculate the feature constancy that measures correctness of the\\ncorrespondence between two input images. The initial disparity and the feature\\nconstancy are then fed to a sub-network to refine the initial disparity. The\\nproposed method has been evaluated on the Scene Flow and KITTI datasets. It\\nachieves the state-of-the-art performance on the KITTI 2012 and KITTI 2015\\nbenchmarks while maintaining a very fast running time.\\n\\n    ', '\\nAbstract:  We present a method for extracting depth information from a rectified image\\npair. Our approach focuses on the first stage of many stereo algorithms: the\\nmatching cost computation. We approach the problem by learning a similarity\\nmeasure on small image patches using a convolutional neural network. Training\\nis carried out in a supervised manner by constructing a binary classification\\ndata set with examples of similar and dissimilar pairs of patches. We examine\\ntwo network architectures for this task: one tuned for speed, the other for\\naccuracy. The output of the convolutional neural network is used to initialize\\nthe stereo matching cost. A series of post-processing steps follow: cross-based\\ncost aggregation, semiglobal matching, a left-right consistency check, subpixel\\nenhancement, a median filter, and a bilateral filter. We evaluate our method on\\nthe KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it\\noutperforms other approaches on all three data sets.\\n\\n    ', '\\nAbstract:  Depth prediction is one of the fundamental problems in computer vision. In\\nthis paper, we propose a simple yet effective convolutional spatial propagation\\nnetwork (CSPN) to learn the affinity matrix for various depth estimation tasks.\\nSpecifically, it is an efficient linear propagation model, in which the\\npropagation is performed with a manner of recurrent convolutional operation,\\nand the affinity among neighboring pixels is learned through a deep\\nconvolutional neural network (CNN). We can append this module to any output\\nfrom a state-of-the-art (SOTA) depth estimation networks to improve their\\nperformances. In practice, we further extend CSPN in two aspects: 1) take\\nsparse depth map as additional input, which is useful for the task of depth\\ncompletion; 2) similar to commonly used 3D convolution operation in CNNs, we\\npropose 3D CSPN to handle features with one additional dimension, which is\\neffective in the task of stereo matching using 3D cost volume. For the tasks of\\nsparse to dense, a.k.a depth completion. We experimented the proposed CPSN\\nconjunct algorithms over the popular NYU v2 and KITTI datasets, where we show\\nthat our proposed algorithms not only produce high quality (e.g., 30% more\\nreduction in depth error), but also run faster (e.g., 2 to 5x faster) than\\nprevious SOTA spatial propagation network. We also evaluated our stereo\\nmatching algorithm on the Scene Flow and KITTI Stereo datasets, and rank 1st on\\nboth the KITTI Stereo 2012 and 2015 benchmarks, which demonstrates the\\neffectiveness of the proposed module. The code of CSPN proposed in this work\\nwill be released at this https URL.\\n\\n    ', '\\nAbstract:  We present an accurate stereo matching method using local expansion moves\\nbased on graph cuts. This new move-making scheme is used to efficiently infer\\nper-pixel 3D plane labels on a pairwise Markov random field (MRF) that\\neffectively combines recently proposed slanted patch matching and curvature\\nregularization terms. The local expansion moves are presented as many\\nalpha-expansions defined for small grid regions. The local expansion moves\\nextend traditional expansion moves by two ways: localization and spatial\\npropagation. By localization, we use different candidate alpha-labels according\\nto the locations of local alpha-expansions. By spatial propagation, we design\\nour local alpha-expansions to propagate currently assigned labels for nearby\\nregions. With this localization and spatial propagation, our method can\\nefficiently infer MRF models with a continuous label space using randomized\\nsearch. Our method has several advantages over previous approaches that are\\nbased on fusion moves or belief propagation; it produces submodular moves\\nderiving a subproblem optimality; it helps find good, smooth, piecewise linear\\ndisparity maps; it is suitable for parallelization; it can use cost-volume\\nfiltering techniques for accelerating the matching cost computations. Even\\nusing a simple pairwise MRF, our method is shown to have best performance in\\nthe Middlebury stereo benchmark V2 and V3.\\n\\n    ', '\\nAbstract:  This paper presents StereoNet, the first end-to-end deep architecture for\\nreal-time stereo matching that runs at 60 fps on an NVidia Titan X, producing\\nhigh-quality, edge-preserved, quantization-free disparity maps. A key insight\\nof this paper is that the network achieves a sub-pixel matching precision than\\nis a magnitude higher than those of traditional stereo matching approaches.\\nThis allows us to achieve real-time performance by using a very low resolution\\ncost volume that encodes all the information needed to achieve high disparity\\nprecision. Spatial precision is achieved by employing a learned edge-aware\\nupsampling function. Our model uses a Siamese network to extract features from\\nthe left and right image. A first estimate of the disparity is computed in a\\nvery low resolution cost volume, then hierarchically the model re-introduces\\nhigh-frequency details through a learned upsampling function that uses compact\\npixel-to-pixel refinement networks. Leveraging color input as a guide, this\\nfunction is capable of producing high-quality edge-aware output. We achieve\\ncompelling results on multiple benchmarks, showing how the proposed method\\noffers extreme flexibility at an acceptable computational budget.\\n\\n    ', '\\nAbstract:  Human beings process stereoscopic correspondence across multiple scales.\\nHowever, this bio-inspiration is ignored by state-of-the-art cost aggregation\\nmethods for dense stereo correspondence. In this paper, a generic cross-scale\\ncost aggregation framework is proposed to allow multi-scale interaction in cost\\naggregation. We firstly reformulate cost aggregation from a unified\\noptimization perspective and show that different cost aggregation methods\\nessentially differ in the choices of similarity kernels. Then, an inter-scale\\nregularizer is introduced into optimization and solving this new optimization\\nproblem leads to the proposed framework. Since the regularization term is\\nindependent of the similarity kernel, various cost aggregation methods can be\\nintegrated into the proposed general framework. We show that the cross-scale\\nframework is important as it effectively and efficiently expands\\nstate-of-the-art cost aggregation methods and leads to significant\\nimprovements, when evaluated on Middlebury, KITTI and New Tsukuba datasets.\\n\\n    ', '\\nAbstract:  Stereo matching estimates the disparity between a rectified image pair, which\\nis of great importance to depth sensing, autonomous driving, and other related\\ntasks. Previous works built cost volumes with cross-correlation or\\nconcatenation of left and right features across all disparity levels, and then\\na 2D or 3D convolutional neural network is utilized to regress the disparity\\nmaps. In this paper, we propose to construct the cost volume by group-wise\\ncorrelation. The left features and the right features are divided into groups\\nalong the channel dimension, and correlation maps are computed among each group\\nto obtain multiple matching cost proposals, which are then packed into a cost\\nvolume. Group-wise correlation provides efficient representations for measuring\\nfeature similarities and will not lose too much information like full\\ncorrelation. It also preserves better performance when reducing parameters\\ncompared with previous methods. The 3D stacked hourglass network proposed in\\nprevious works is improved to boost the performance and decrease the inference\\ncomputational cost. Experiment results show that our method outperforms\\nprevious methods on Scene Flow, KITTI 2012, and KITTI 2015 datasets. The code\\nis available at this https URL\\n', '\\nAbstract:  In this paper we address issues with image retrieval benchmarking on standard\\nand popular Oxford 5k and Paris 6k datasets. In particular, annotation errors,\\nthe size of the dataset, and the level of challenge are addressed: new\\nannotation for both datasets is created with an extra attention to the\\nreliability of the ground truth. Three new protocols of varying difficulty are\\nintroduced. The protocols allow fair comparison between different methods,\\nincluding those using a dataset pre-processing stage. For each dataset, 15 new\\nchallenging queries are introduced. Finally, a new set of 1M hard,\\nsemi-automatically cleaned distractors is selected.\\nAn extensive comparison of the state-of-the-art methods is performed on the\\nnew benchmark. Different types of methods are evaluated, ranging from\\nlocal-feature-based to modern CNN based methods. The best results are achieved\\nby taking the best of the two worlds. Most importantly, image retrieval appears\\nfar from being solved.\\n\\n    ', '\\nAbstract:  We present MMDetection, an object detection toolbox that contains a rich set\\nof object detection and instance segmentation methods as well as related\\ncomponents and modules. The toolbox started from a codebase of MMDet team who\\nwon the detection track of COCO Challenge 2018. It gradually evolves into a\\nunified platform that covers many popular detection methods and contemporary\\nmodules. It not only includes training and inference codes, but also provides\\nweights for more than 200 network models. We believe this toolbox is by far the\\nmost complete detection toolbox. In this paper, we introduce the various\\nfeatures of this toolbox. In addition, we also conduct a benchmarking study on\\ndifferent methods, components, and their hyper-parameters. We wish that the\\ntoolbox and benchmark could serve the growing research community by providing a\\nflexible toolkit to reimplement existing methods and develop their own new\\ndetectors. Code and models are available at\\nthis https URL. The project is under active\\ndevelopment and we will keep this document updated.\\n\\n    ', '\\nAbstract:  We have recently seen the emergence of several publicly available Natural\\nLanguage Understanding (NLU) toolkits, which map user utterances to structured,\\nbut more abstract, Dialogue Act (DA) or Intent specifications, while making\\nthis process accessible to the lay developer. In this paper, we present the\\nfirst wide coverage evaluation and comparison of some of the most popular NLU\\nservices, on a large, multi-domain (21 domains) dataset of 25K user utterances\\nthat we have collected and annotated with Intent and Entity Type specifications\\nand which will be released as part of this submission. The results show that on\\nIntent classification Watson significantly outperforms the other platforms,\\nnamely, Dialogflow, LUIS and Rasa; though these also perform well.\\nInterestingly, on Entity Type recognition, Watson performs significantly worse\\ndue to its low Precision. Again, Dialogflow, LUIS and Rasa perform well on this\\ntask.\\n\\n    ', \"\\nAbstract:  AutoML serves as the bridge between varying levels of expertise when\\ndesigning machine learning systems and expedites the data science process. A\\nwide range of techniques is taken to address this, however there does not exist\\nan objective comparison of these techniques. We present a benchmark of current\\nopen source AutoML solutions using open source datasets. We test auto-sklearn,\\nTPOT, auto_ml, and H2O's AutoML solution against a compiled set of regression\\nand classification datasets sourced from OpenML and find that auto-sklearn\\nperforms the best across classification datasets and TPOT performs the best\\nacross regression datasets.\\n\\n    \", '\\nAbstract:  In this article we introduce the Arcade Learning Environment (ALE): both a\\nchallenge problem and a platform and methodology for evaluating the development\\nof general, domain-independent AI technology. ALE provides an interface to\\nhundreds of Atari 2600 game environments, each one different, interesting, and\\ndesigned to be a challenge for human players. ALE presents significant research\\nchallenges for reinforcement learning, model learning, model-based planning,\\nimitation learning, transfer learning, and intrinsic motivation. Most\\nimportantly, it provides a rigorous testbed for evaluating and comparing\\napproaches to these problems. We illustrate the promise of ALE by developing\\nand benchmarking domain-independent agents designed using well-established AI\\ntechniques for both reinforcement learning and planning. In doing so, we also\\npropose an evaluation methodology made possible by ALE, reporting empirical\\nresults on over 55 different games. All of the software, including the\\nbenchmark agents, is publicly available.\\n\\n    ', '\\nAbstract:  This paper describes ANN-Benchmarks, a tool for evaluating the performance of\\nin-memory approximate nearest neighbor algorithms. It provides a standard\\ninterface for measuring the performance and quality achieved by nearest\\nneighbor algorithms on different standard data sets. It supports several\\ndifferent ways of integrating $k$-NN algorithms, and its configuration system\\nautomatically tests a range of parameter settings for each algorithm.\\nAlgorithms are compared with respect to many different (approximate) quality\\nmeasures, and adding more is easy and fast; the included plotting front-ends\\ncan visualise these as images, $\\\\LaTeX$ plots, and websites with interactive\\nplots. ANN-Benchmarks aims to provide a constantly updated overview of the\\ncurrent state of the art of $k$-NN algorithms. In the short term, this overview\\nallows users to choose the correct $k$-NN algorithm and parameters for their\\nsimilarity search task; in the longer term, algorithm designers will be able to\\nuse this overview to test and refine automatic parameter tuning. The paper\\ngives an overview of the system, evaluates the results of the benchmark, and\\npoints out directions for future work. Interestingly, very different approaches\\nto $k$-NN search yield comparable quality-performance trade-offs. The system is\\navailable at this http URL .\\n\\n    ', '\\nAbstract:  We present PartNet: a consistent, large-scale dataset of 3D objects annotated\\nwith fine-grained, instance-level, and hierarchical 3D part information. Our\\ndataset consists of 573,585 part instances over 26,671 3D models covering 24\\nobject categories. This dataset enables and serves as a catalyst for many tasks\\nsuch as shape analysis, dynamic 3D scene modeling and simulation, affordance\\nanalysis, and others. Using our dataset, we establish three benchmarking tasks\\nfor evaluating 3D part recognition: fine-grained semantic segmentation,\\nhierarchical semantic segmentation, and instance segmentation. We benchmark\\nfour state-of-the-art 3D deep learning algorithms for fine-grained semantic\\nsegmentation and three baseline methods for hierarchical semantic segmentation.\\nWe also propose a novel method for part instance segmentation and demonstrate\\nits superior performance over existing methods.\\n\\n    ', '\\nAbstract:  We introduce EvalAI, an open source platform for evaluating and comparing\\nmachine learning (ML) and artificial intelligence algorithms (AI) at scale.\\nEvalAI is built to provide a scalable solution to the research community to\\nfulfill the critical need of evaluating machine learning models and agents\\nacting in an environment against annotations or with a human-in-the-loop. This\\nwill help researchers, students, and data scientists to create, collaborate,\\nand participate in AI challenges organized around the globe. By simplifying and\\nstandardizing the process of benchmarking these models, EvalAI seeks to lower\\nthe barrier to entry for participating in the global scientific effort to push\\nthe frontiers of machine learning and artificial intelligence, thereby\\nincreasing the rate of measurable progress in this domain.\\n\\n    ', '\\nAbstract:  Fairness is an increasingly important concern as machine learning models are\\nused to support decision making in high-stakes applications such as mortgage\\nlending, hiring, and prison sentencing. This paper introduces a new open source\\nPython toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released\\nunder an Apache v2.0 license {this https URL). The main\\nobjectives of this toolkit are to help facilitate the transition of fairness\\nresearch algorithms to use in an industrial setting and to provide a common\\nframework for fairness researchers to share and evaluate algorithms.\\nThe package includes a comprehensive set of fairness metrics for datasets and\\nmodels, explanations for these metrics, and algorithms to mitigate bias in\\ndatasets and models. It also includes an interactive Web experience\\n(this https URL) that provides a gentle introduction to the\\nconcepts and capabilities for line-of-business users, as well as extensive\\ndocumentation, usage guidance, and industry-specific tutorials to enable data\\nscientists and practitioners to incorporate the most appropriate tool for their\\nproblem into their work products. The architecture of the package has been\\nengineered to conform to a standard paradigm used in data science, thereby\\nfurther improving usability for practitioners. Such architectural design and\\nabstractions enable researchers and developers to extend the toolkit with their\\nnew algorithms and improvements, and to use it for performance benchmarking. A\\nbuilt-in testing infrastructure maintains code quality.\\n\\n    ', '\\nAbstract:  We introduce Texygen, a benchmarking platform to support research on\\nopen-domain text generation models. Texygen has not only implemented a majority\\nof text generation models, but also covered a set of metrics that evaluate the\\ndiversity, the quality and the consistency of the generated texts. The Texygen\\nplatform could help standardize the research on text generation and facilitate\\nthe sharing of fine-tuned open-source implementations among researchers for\\ntheir work. As a consequence, this would help in improving the reproductivity\\nand reliability of future research work in text generation.\\n\\n    ', '\\nAbstract:  Automatically describing an image with a sentence is a long-standing\\nchallenge in computer vision and natural language processing. Due to recent\\nprogress in object detection, attribute classification, action recognition,\\netc., there is renewed interest in this area. However, evaluating the quality\\nof descriptions has proven to be challenging. We propose a novel paradigm for\\nevaluating image descriptions that uses human consensus. This paradigm consists\\nof three main parts: a new triplet-based method of collecting human annotations\\nto measure consensus, a new automated metric (CIDEr) that captures consensus,\\nand two new datasets: PASCAL-50S and ABSTRACT-50S that contain 50 sentences\\ndescribing each image. Our simple metric captures human judgment of consensus\\nbetter than existing metrics across sentences generated by various sources. We\\nalso evaluate five state-of-the-art image description approaches using this new\\nprotocol and provide a benchmark for future comparisons. A version of CIDEr\\nnamed CIDEr-D is available as a part of MS COCO evaluation server to enable\\nsystematic evaluation and benchmarking.\\n\\n    ', \"\\nAbstract:  We present Habitat, a new platform for research in embodied artificial\\nintelligence (AI). Habitat enables training embodied agents (virtual robots) in\\nhighly efficient photorealistic 3D simulation, before transferring the learned\\nskills to reality.\\nSpecifically, Habitat consists of the following: 1. Habitat-Sim: a flexible,\\nhigh-performance 3D simulator with configurable agents, multiple sensors, and\\ngeneric 3D dataset handling (with built-in support for SUNCG, Matterport3D,\\nGibson datasets). Habitat-Sim is fast -- when rendering a scene from the\\nMatterport3D dataset, Habitat-Sim achieves several thousand frames per second\\n(fps) running single-threaded, and can reach over 10,000 fps multi-process on a\\nsingle GPU, which is orders of magnitude faster than the closest simulator. 2.\\nHabitat-API: a modular high-level library for end-to-end development of\\nembodied AI algorithms -- defining embodied AI tasks (e.g. navigation,\\ninstruction following, question answering), configuring and training embodied\\nagents (via imitation or reinforcement learning, or via classic SLAM), and\\nbenchmarking using standard metrics.\\nThese large-scale engineering contributions enable us to answer scientific\\nquestions requiring experiments that were till now impracticable or `merely'\\nimpractical. Specifically, in the context of point-goal navigation (1) we\\nrevisit the comparison between learning and SLAM approaches from two recent\\nworks and find evidence for the opposite conclusion -- that learning\\noutperforms SLAM, if scaled to total experience far surpassing that of previous\\ninvestigations, and (2) we conduct the first cross-dataset generalization\\nexperiments {train, test} x {Matterport3D, Gibson} for multiple sensors {blind,\\nRGB, RGBD, D} and find that only agents with depth (D) sensors generalize\\nacross datasets. We hope that our open-source platform and these findings will\\nadvance research in embodied AI.\\n\\n    \", '\\nAbstract:  Semantic segmentation benefits robotics related applications especially\\nautonomous driving. Most of the research on semantic segmentation is only on\\nincreasing the accuracy of segmentation models with little attention to\\ncomputationally efficient solutions. The few work conducted in this direction\\ndoes not provide principled methods to evaluate the different design choices\\nfor segmentation. In this paper, we address this gap by presenting a real-time\\nsemantic segmentation benchmarking framework with a decoupled design for\\nfeature extraction and decoding methods. The framework is comprised of\\ndifferent network architectures for feature extraction such as VGG16, Resnet18,\\nMobileNet, and ShuffleNet. It is also comprised of multiple meta-architectures\\nfor segmentation that define the decoding methodology. These include SkipNet,\\nUNet, and Dilation Frontend. Experimental results are presented on the\\nCityscapes dataset for urban scenes. The modular design allows novel\\narchitectures to emerge, that lead to 143x GFLOPs reduction in comparison to\\nSegNet. This benchmarking framework is publicly available at\\n\"this https URL\".\\n\\n    ', '\\nAbstract:  The selection, development, or comparison of machine learning methods in data\\nmining can be a difficult task based on the target problem and goals of a\\nparticular study. Numerous publicly available real-world and simulated\\nbenchmark datasets have emerged from different sources, but their organization\\nand adoption as standards have been inconsistent. As such, selecting and\\ncurating specific benchmarks remains an unnecessary burden on machine learning\\npractitioners and data scientists. The present study introduces an accessible,\\ncurated, and developing public benchmark resource to facilitate identification\\nof the strengths and weaknesses of different machine learning methodologies. We\\ncompare meta-features among the current set of benchmark datasets in this\\nresource to characterize the diversity of available data. Finally, we apply a\\nnumber of established machine learning methods to the entire benchmark suite\\nand analyze how datasets and algorithms cluster in terms of performance. This\\nwork is an important first step towards understanding the limitations of\\npopular benchmarking suites and developing a resource that connects existing\\nbenchmarking standards to more diverse and efficient standards in the future.\\n\\n    ', '\\nAbstract:  In mainstream computer vision and machine learning, public datasets such as\\nImageNet, COCO and KITTI have helped drive enormous improvements by enabling\\nresearchers to understand the strengths and limitations of different algorithms\\nvia performance comparison. However, this type of approach has had limited\\ntranslation to problems in robotic assisted surgery as this field has never\\nestablished the same level of common datasets and benchmarking methods. In 2015\\na sub-challenge was introduced at the EndoVis workshop where a set of robotic\\nimages were provided with automatically generated annotations from robot\\nforward kinematics. However, there were issues with this dataset due to the\\nlimited background variation, lack of complex motion and inaccuracies in the\\nannotation. In this work we present the results of the 2017 challenge on\\nrobotic instrument segmentation which involved 10 teams participating in\\nbinary, parts and type based segmentation of articulated da Vinci robotic\\ninstruments.\\n\\n    ', '\\nAbstract:  This paper proposes an end-to-end deep hashing framework with category mask\\nfor fast video retrieval. We train our network in a supervised way by fully\\nexploiting inter-class diversity and intra-class identity. Classification loss\\nis optimized to maximize inter-class diversity, while intra-pair is introduced\\nto learn representative intra-class identity. We investigate the binary bits\\ndistribution related to categories and find out that the effectiveness of\\nbinary bits is highly correlated with data categories, and some bits may\\ndegrade classification performance of some categories. We then design hash code\\ngeneration scheme with category mask to filter out bits with negative\\ncontribution. Experimental results demonstrate the proposed method outperforms\\nseveral state-of-the-arts under various evaluation metrics on public datasets.\\n\\n    ', '\\nAbstract:  We present TRANX, a transition-based neural semantic parser that maps natural\\nlanguage (NL) utterances into formal meaning representations (MRs). TRANX uses\\na transition system based on the abstract syntax description language for the\\ntarget MR, which gives it two major advantages: (1) it is highly accurate,\\nusing information from the syntax of the target MR to constrain the output\\nspace and model the information flow, and (2) it is highly generalizable, and\\ncan easily be applied to new types of MR by just writing a new abstract syntax\\ndescription corresponding to the allowable structures in the MR. Experiments on\\nfour different semantic parsing and code generation tasks show that our system\\nis generalizable, extensible, and effective, registering strong results\\ncompared to existing neural semantic parsers.\\n\\n    ', '\\nAbstract:  Semantic parsing is the task of transducing natural language (NL) utterances\\ninto formal meaning representations (MRs), commonly represented as tree\\nstructures. Annotating NL utterances with their corresponding MRs is expensive\\nand time-consuming, and thus the limited availability of labeled data often\\nbecomes the bottleneck of data-driven, supervised models. We introduce\\nStructVAE, a variational auto-encoding model for semisupervised semantic\\nparsing, which learns both from limited amounts of parallel data, and\\nreadily-available unlabeled NL utterances. StructVAE models latent MRs not\\nobserved in the unlabeled data as tree-structured latent variables. Experiments\\non semantic parsing on the ATIS domain and Python code generation show that\\nwith extra unlabeled data, StructVAE outperforms strong supervised models.\\n\\n    ', '\\nAbstract:  Many language generation tasks require the production of text conditioned on\\nboth structured and unstructured inputs. We present a novel neural network\\narchitecture which generates an output sequence conditioned on an arbitrary\\nnumber of input functions. Crucially, our approach allows both the choice of\\nconditioning context and the granularity of generation, for example characters\\nor tokens, to be marginalised, thus permitting scalable and effective training.\\nUsing this framework, we address the problem of generating programming code\\nfrom a mixed natural language and structured specification. We create two new\\ndata sets for this paradigm derived from the collectible trading card games\\nMagic the Gathering and Hearthstone. On these, and a third preexisting corpus,\\nwe demonstrate that marginalising multiple predictors allows our model to\\noutperform strong benchmarks.\\n\\n    ', '\\nAbstract:  Automated documentation of programming source code and automated code\\ngeneration from natural language are challenging tasks of both practical and\\nscientific interest. Progress in these areas has been limited by the low\\navailability of parallel corpora of code and natural language descriptions,\\nwhich tend to be small and constrained to specific domains.\\nIn this work we introduce a large and diverse parallel corpus of a hundred\\nthousands Python functions with their documentation strings (\"docstrings\")\\ngenerated by scraping open source repositories on GitHub. We describe baseline\\nresults for the code documentation and code generation tasks obtained by neural\\nmachine translation. We also experiment with data augmentation techniques to\\nfurther increase the amount of training data.\\nWe release our datasets and processing scripts in order to stimulate research\\nin these areas.\\n\\n    ', '\\nAbstract:  Research on question answering with knowledge base has recently seen an\\nincreasing use of deep architectures. In this extended abstract, we study the\\napplication of the neural machine translation paradigm for question parsing. We\\nemploy a sequence-to-sequence model to learn graph patterns in the SPARQL graph\\nquery language and their compositions. Instead of inducing the programs through\\nquestion-answer pairs, we expect a semi-supervised approach, where alignments\\nbetween questions and queries are built through templates. We argue that the\\ncoverage of language utterances can be expanded using late notable works in\\nnatural language generation.\\n\\n    ', '\\nAbstract:  Code generation maps a program description to executable source code in a\\nprogramming language. Existing approaches mainly rely on a recurrent neural\\nnetwork (RNN) as the decoder. However, we find that a program contains\\nsignificantly more tokens than a natural language sentence, and thus it may be\\ninappropriate for RNN to capture such a long sequence. In this paper, we\\npropose a grammar-based structural convolutional neural network (CNN) for code\\ngeneration. Our model generates a program by predicting the grammar rules of\\nthe programming language; we design several CNN modules, including the\\ntree-based convolution and pre-order convolution, whose information is further\\naggregated by dedicated attentive pooling layers. Experimental results on the\\nHearthStone benchmark dataset show that our CNN code generator significantly\\noutperforms the previous state-of-the-art method by 5 percentage points;\\nadditional experiments on several semantic parsing tasks demonstrate the\\nrobustness of our model. We also conduct in-depth ablation test to better\\nunderstand each component of our model.\\n\\n    ', '\\nAbstract:  Synthesizing SQL queries from natural language is a long-standing open\\nproblem and has been attracting considerable interest recently. Toward solving\\nthe problem, the de facto approach is to employ a sequence-to-sequence-style\\nmodel. Such an approach will necessarily require the SQL queries to be\\nserialized. Since the same SQL query may have multiple equivalent\\nserializations, training a sequence-to-sequence-style model is sensitive to the\\nchoice from one of them. This phenomenon is documented as the \"order-matters\"\\nproblem. Existing state-of-the-art approaches rely on reinforcement learning to\\nreward the decoder when it generates any of the equivalent serializations.\\nHowever, we observe that the improvement from reinforcement learning is\\nlimited.\\nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally\\nsolve this problem by avoiding the sequence-to-sequence structure when the\\norder does not matter. In particular, we employ a sketch-based approach where\\nthe sketch contains a dependency graph so that one prediction can be done by\\ntaking into consideration only the previous predictions that it depends on. In\\naddition, we propose a sequence-to-set model as well as the column attention\\nmechanism to synthesize the query based on the sketch. By combining all these\\nnovel techniques, we show that SQLNet can outperform the prior art by 9% to 13%\\non the WikiSQL task.\\n\\n    ', \"\\nAbstract:  A significant amount of the world's knowledge is stored in relational\\ndatabases. However, the ability for users to retrieve facts from a database is\\nlimited due to a lack of understanding of query languages such as SQL. We\\npropose Seq2SQL, a deep neural network for translating natural language\\nquestions to corresponding SQL queries. Our model leverages the structure of\\nSQL queries to significantly reduce the output space of generated queries.\\nMoreover, we use rewards from in-the-loop query execution over the database to\\nlearn a policy to generate unordered parts of the query, which we show are less\\nsuitable for optimization via cross entropy loss. In addition, we will publish\\nWikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL\\nqueries distributed across 24241 tables from Wikipedia. This dataset is\\nrequired to train our model and is an order of magnitude larger than comparable\\ndatasets. By applying policy-based reinforcement learning with a query\\nexecution environment to WikiSQL, our model Seq2SQL outperforms attentional\\nsequence to sequence models, improving execution accuracy from 35.9% to 59.4%\\nand logical form accuracy from 23.4% to 48.3%.\\n\\n    \", '\\nAbstract:  We present Spider, a large-scale, complex and cross-domain semantic parsing\\nand text-to-SQL dataset annotated by 11 college students. It consists of 10,181\\nquestions and 5,693 unique complex SQL queries on 200 databases with multiple\\ntables, covering 138 different domains. We define a new complex and\\ncross-domain semantic parsing and text-to-SQL task where different complex SQL\\nqueries and databases appear in train and test sets. In this way, the task\\nrequires the model to generalize well to both new SQL queries and new database\\nschemas. Spider is distinct from most of the previous semantic parsing tasks\\nbecause they all use a single database and the exact same programs in the train\\nset and the test set. We experiment with various state-of-the-art models and\\nthe best model achieves only 12.4% exact matching accuracy on a database split\\nsetting. This shows that Spider presents a strong challenge for future\\nresearch. Our dataset and task are publicly available at\\nthis https URL\\n', '\\nAbstract:  To be informative, an evaluation must measure how well systems generalize to\\nrealistic unseen data. We identify limitations of and propose improvements to\\ncurrent evaluations of text-to-SQL systems. First, we compare human-generated\\nand automatically generated questions, characterizing properties of queries\\nnecessary for real-world applications. To facilitate evaluation on multiple\\ndatasets, we release standardized and improved versions of seven existing\\ndatasets and one new text-to-SQL dataset. Second, we show that the current\\ndivision of data into training and test sets measures robustness to variations\\nin the way questions are asked, but only partially tests how well systems\\ngeneralize to new queries; therefore, we propose a complementary dataset split\\nfor evaluation of future work. Finally, we demonstrate how the common practice\\nof anonymizing variables during evaluation removes an important challenge of\\nthe task. Our observations highlight key difficulties, and our methodology\\nenables effective measurement of future development.\\n\\n    ', '\\nAbstract:  Most existing studies in text-to-SQL tasks do not require generating complex\\nSQL queries with multiple clauses or sub-queries, and generalizing to new,\\nunseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network\\nto address the complex and cross-domain text-to-SQL generation task.\\nSyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL\\ngeneration path history and table-aware column attention encoders. We evaluate\\nSyntaxSQLNet on the Spider text-to-SQL task, which contains databases with\\nmultiple tables and complex SQL queries with multiple SQL clauses and nested\\nqueries. We use a database split setting where databases in the test set are\\nunseen during training. Experimental results show that SyntaxSQLNet can handle\\na significantly greater number of complex SQL examples than prior work,\\noutperforming the previous state-of-the-art model by 7.3% in exact matching\\naccuracy. We also show that SyntaxSQLNet can further improve the performance by\\nan additional 7.5% using a cross-domain augmentation method, resulting in a\\n14.8% improvement in total. To our knowledge, we are the first to study this\\ncomplex and cross-domain text-to-SQL task.\\n\\n    ', \"\\nAbstract:  Interacting with relational databases through natural language helps users of\\nany background easily query and analyze a vast amount of data. This requires a\\nsystem that understands users' questions and converts them to SQL queries\\nautomatically. In this paper we present a novel approach, TypeSQL, which views\\nthis problem as a slot filling task. Additionally, TypeSQL utilizes type\\ninformation to better understand rare entities and numbers in natural language\\nquestions. We test this idea on the WikiSQL dataset and outperform the prior\\nstate-of-the-art by 5.5% in much less time. We also show that accessing the\\ncontent of databases can significantly improve the performance when users'\\nqueries are not well-formed. TypeSQL gets 82.6% accuracy, a 17.5% absolute\\nimprovement compared to the previous content-sensitive model.\\n\\n    \", '\\nAbstract:  We consider the problem of neural semantic parsing, which translates natural\\nlanguage questions into executable SQL queries. We introduce a new mechanism,\\nexecution guidance, to leverage the semantics of SQL. It detects and excludes\\nfaulty programs during the decoding procedure by conditioning on the execution\\nof partially generated program. The mechanism can be used with any\\nautoregressive generative model, which we demonstrate on four state-of-the-art\\nrecurrent or template-based semantic parsing models. We demonstrate that\\nexecution guidance universally improves model performance on various\\ntext-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\\nand GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\\nof 83.8% on WikiSQL.\\n\\n    ', '\\nAbstract:  The ability to generate natural language sequences from source code snippets\\nhas a variety of applications such as code summarization, documentation, and\\nretrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine\\ntranslation (NMT), have achieved state-of-the-art performance on these tasks by\\ntreating source code as a sequence of tokens. We present ${\\\\rm {\\\\scriptsize\\nCODE2SEQ}}$: an alternative approach that leverages the syntactic structure of\\nprogramming languages to better encode source code. Our model represents a code\\nsnippet as the set of compositional paths in its abstract syntax tree (AST) and\\nuses attention to select the relevant paths while decoding. We demonstrate the\\neffectiveness of our approach for two tasks, two programming languages, and\\nfour datasets of up to $16$M examples. Our model significantly outperforms\\nprevious models that were specifically designed for programming languages, as\\nwell as state-of-the-art NMT models. An interactive online demo of our model is\\navailable at this http URL. Our code, data and trained models are\\navailable at this http URL.\\n\\n    ', \"\\nAbstract:  Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are\\nwidely used because they are expressive and are easy to train. Our interest\\nlies in empirically evaluating the expressiveness and the learnability of LSTMs\\nin the sequence-to-sequence regime by training them to evaluate short computer\\nprograms, a domain that has traditionally been seen as too complex for neural\\nnetworks. We consider a simple class of programs that can be evaluated with a\\nsingle left-to-right pass using constant memory. Our main result is that LSTMs\\ncan learn to map the character-level representations of such programs to their\\ncorrect outputs. Notably, it was necessary to use curriculum learning, and\\nwhile conventional curriculum learning proved ineffective, we developed a new\\nvariant of curriculum learning that improved our networks' performance in all\\nexperimental conditions. The improved curriculum had a dramatic impact on an\\naddition problem, making it possible to train an LSTM to add two 9-digit\\nnumbers with 99% accuracy.\\n\\n    \", '\\nAbstract:  Neural machine translation models are used to automatically generate a\\ndocument from given source code since this can be regarded as a machine\\ntranslation task. Source code summarization is one of the components for\\nautomatic document generation, which generates a summary in natural language\\nfrom given source code. This suggests that techniques used in neural machine\\ntranslation, such as Long Short-Term Memory (LSTM), can be used for source code\\nsummarization. However, there is a considerable difference between source code\\nand natural language: Source code is essentially {\\\\em structured}, having loops\\nand conditional branching, etc. Therefore, there is some obstacle to apply\\nknown machine translation models to source code.\\nAbstract syntax trees (ASTs) capture these structural properties and play an\\nimportant role in recent machine learning studies on source code. Tree-LSTM is\\nproposed as a generalization of LSTMs for tree-structured data. However, there\\nis a critical issue when applying it to ASTs: It cannot handle a tree that\\ncontains nodes having an arbitrary number of children and their order\\nsimultaneously, which ASTs generally have such nodes. To address this issue, we\\npropose an extension of Tree-LSTM, which we call \\\\emph{Multi-way Tree-LSTM} and\\napply it for source code summarization. As a result of computational\\nexperiments, our proposal achieved better results when compared with several\\nstate-of-the-art techniques.\\n\\n    ', '\\nAbstract:  Semantic code search is the task of retrieving relevant code given a natural\\nlanguage query. While related to other information retrieval tasks, it requires\\nbridging the gap between the language used in code (often abbreviated and\\nhighly technical) and natural language more suitable to describe vague concepts\\nand ideas.\\nTo enable evaluation of progress on code search, we are releasing the\\nCodeSearchNet Corpus and are presenting the CodeSearchNet Challenge, which\\nconsists of 99 natural language queries with about 4k expert relevance\\nannotations of likely results from CodeSearchNet Corpus. The corpus contains\\nabout 6 million functions from open-source code spanning six programming\\nlanguages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet\\nCorpus also contains automatically generated query-like natural language for 2\\nmillion functions, obtained from mechanically scraping and preprocessing\\nassociated function documentation. In this article, we describe the methodology\\nused to obtain the corpus and expert labels, as well as a number of simple\\nbaseline solutions for the task.\\nWe hope that CodeSearchNet Challenge encourages researchers and practitioners\\nto study this interesting task further and will host a competition and\\nleaderboard to track the progress on the challenge. We are also keen on\\nextending CodeSearchNet Challenge to more queries and programming languages in\\nthe future.\\n\\n    ', '\\nAbstract:  We consider the task of program synthesis in the presence of a reward\\nfunction over the output of programs, where the goal is to find programs with\\nmaximal rewards. We employ an iterative optimization scheme, where we train an\\nRNN on a dataset of K best programs from a priority queue of the generated\\nprograms so far. Then, we synthesize new programs and add them to the priority\\nqueue by sampling from the RNN. We benchmark our algorithm, called priority\\nqueue training (or PQT), against genetic algorithm and reinforcement learning\\nbaselines on a simple but expressive Turing complete programming language\\ncalled BF. Our experimental results show that our simple PQT algorithm\\nsignificantly outperforms the baselines. By adding a program length penalty to\\nthe reward function, we are able to synthesize short, human readable programs.\\n\\n    ', '\\nAbstract:  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\\nway to leverage a memory buffer of promising trajectories to reduce the\\nvariance of policy gradient estimate. MAPO is applicable to deterministic\\nenvironments with discrete actions, such as structured prediction and\\ncombinatorial optimization tasks. We express the expected return objective as a\\nweighted sum of two terms: an expectation over the high-reward trajectories\\ninside the memory buffer, and a separate expectation over trajectories outside\\nthe buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\\nweight clipping to accelerate and stabilize training; (2) systematic\\nexploration to discover high-reward trajectories; (3) distributed sampling from\\ninside and outside of the memory buffer to scale up training. MAPO improves the\\nsample efficiency and robustness of policy gradient, especially on tasks with\\nsparse rewards. We evaluate MAPO on weakly supervised program synthesis from\\nnatural language (semantic parsing). On the WikiTableQuestions benchmark, we\\nimprove the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\\nWikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\\nsupervision, outperforming several strong baselines with full supervision. Our\\nsource code is available at\\nthis https URL\\n', \"\\nAbstract:  We develop a first line of attack for solving programming competition-style\\nproblems from input-output examples using deep learning. The approach is to\\ntrain a neural network to predict properties of the program that generated the\\noutputs from the inputs. We use the neural network's predictions to augment\\nsearch techniques from the programming languages community, including\\nenumerative search and an SMT-based solver. Empirically, we show that our\\napproach leads to an order of magnitude speedup over the strong non-augmented\\nbaselines and a Recurrent Neural Network approach, and that we are able to\\nsolve problems of difficulty comparable to the simplest problems on programming\\ncompetition websites.\\n\\n    \", '\\nAbstract:  Human activity recognition is typically addressed by detecting key concepts\\nlike global and local motion, features related to object classes present in the\\nscene, as well as features related to the global context. The next open\\nchallenges in activity recognition require a level of understanding that pushes\\nbeyond this and call for models with capabilities for fine distinction and\\ndetailed comprehension of interactions between actors and objects in a scene.\\nWe propose a model capable of learning to reason about semantically meaningful\\nspatiotemporal interactions in videos. The key to our approach is a choice of\\nperforming this reasoning at the object level through the integration of state\\nof the art object detection networks. This allows the model to learn detailed\\nspatial interactions that exist at a semantic, object-interaction relevant\\nlevel. We evaluate our method on three standard datasets (Twenty-BN\\nSomething-Something, VLOG and EPIC Kitchens) and achieve state of the art\\nresults on all of them. Finally, we show visualizations of the interactions\\nlearned by the model, which illustrate object classes and their interactions\\ncorresponding to different activity classes.\\n\\n    ', \"\\nAbstract:  Synthesizing programs using example input/outputs is a classic problem in\\nartificial intelligence. We present a method for solving Programming By Example\\n(PBE) problems by using a neural model to guide the search of a constraint\\nlogic programming system called miniKanren. Crucially, the neural model uses\\nminiKanren's internal representation as input; miniKanren represents a PBE\\nproblem as recursive constraints imposed by the provided examples. We explore\\nRecurrent Neural Network and Graph Neural Network models. We contribute a\\nmodified miniKanren, drivable by an external agent, available at\\nthis https URL. We show that our neural-guided approach\\nusing constraints can synthesize programs faster in many cases, and\\nimportantly, can generalize to larger problems.\\n\\n    \", \"\\nAbstract:  We consider the problem of generating automatic code given sample\\ninput-output pairs. We train a neural network to map from the current state and\\nthe outputs to the program's next statement. The neural network optimizes\\nmultiple tasks concurrently: the next operation out of a set of high level\\ncommands, the operands of the next statement, and which variables can be\\ndropped from memory. Using our method we are able to create programs that are\\nmore than twice as long as existing state-of-the-art solutions, while improving\\nthe success rate for comparable lengths, and cutting the run-time by two orders\\nof magnitude. Our code, including an implementation of various literature\\nbaselines, is publicly available at this https URL\\n\", '\\nAbstract:  Recent two-stream deep Convolutional Neural Networks (ConvNets) have made\\nsignificant progress in recognizing human actions in videos. Despite their\\nsuccess, methods extending the basic two-stream ConvNet have not systematically\\nexplored possible network architectures to further exploit spatiotemporal\\ndynamics within video sequences. Further, such networks often use different\\nbaseline two-stream networks. Therefore, the differences and the distinguishing\\nfactors between various methods using Recurrent Neural Networks (RNN) or\\nconvolutional networks on temporally-constructed feature vectors\\n(Temporal-ConvNet) are unclear. In this work, we first demonstrate a strong\\nbaseline two-stream ConvNet using ResNet-101. We use this baseline to\\nthoroughly examine the use of both RNNs and Temporal-ConvNets for extracting\\nspatiotemporal information. Building upon our experimental results, we then\\npropose and investigate two different networks to further integrate\\nspatiotemporal information: 1) temporal segment RNN and 2) Inception-style\\nTemporal-ConvNet. We demonstrate that using both RNNs (using LSTMs) and\\nTemporal-ConvNets on spatiotemporal feature matrices are able to exploit\\nspatiotemporal dynamics to improve the overall performance. However, each of\\nthese methods require proper care to achieve state-of-the-art performance; for\\nexample, LSTMs require pre-segmented data or else they cannot fully exploit\\ntemporal information. Our analysis identifies specific limitations for each\\nmethod that could form the basis of future work. Our experimental results on\\nUCF101 and HMDB51 datasets achieve state-of-the-art performances, 94.1% and\\n69.0%, respectively, without requiring extensive temporal augmentation.\\n\\n    ', '\\nAbstract:  Over the past decade, multivariate time series classification has received\\ngreat attention. We propose transforming the existing univariate time series\\nclassification models, the Long Short Term Memory Fully Convolutional Network\\n(LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series\\nclassification model by augmenting the fully convolutional block with a\\nsqueeze-and-excitation block to further improve accuracy. Our proposed models\\noutperform most state-of-the-art models while requiring minimum preprocessing.\\nThe proposed models work efficiently on various complex multivariate time\\nseries classification tasks such as activity recognition or action recognition.\\nFurthermore, the proposed models are highly efficient at test time and small\\nenough to deploy on memory constrained systems.\\n\\n    ', '\\nAbstract:  Research on depth-based human activity analysis achieved outstanding\\nperformance and demonstrated the effectiveness of 3D representation for action\\nrecognition. The existing depth-based and RGB+D-based action recognition\\nbenchmarks have a number of limitations, including the lack of large-scale\\ntraining samples, realistic number of distinct class categories, diversity in\\ncamera views, varied environmental conditions, and variety of human subjects.\\nIn this work, we introduce a large-scale dataset for RGB+D human action\\nrecognition, which is collected from 106 distinct subjects and contains more\\nthan 114 thousand video samples and 8 million frames. This dataset contains 120\\ndifferent action classes including daily, mutual, and health-related\\nactivities. We evaluate the performance of a series of existing 3D activity\\nanalysis methods on this dataset, and show the advantage of applying deep\\nlearning methods for 3D-based human action recognition. Furthermore, we\\ninvestigate a novel one-shot 3D activity recognition problem on our dataset,\\nand a simple yet effective Action-Part Semantic Relevance-aware (APSR)\\nframework is proposed for this task, which yields promising results for\\nrecognition of the novel action classes. We believe the introduction of this\\nlarge-scale dataset will enable the community to apply, adapt, and develop\\nvarious data-hungry learning techniques for depth-based and RGB+D-based human\\nactivity understanding. [The dataset is available at:\\nthis http URL]\\n\\n    ', '\\nAbstract:  Cross-correlator plays a significant role in many visual perception tasks,\\nsuch as object detection and tracking. Beyond the linear cross-correlator, this\\npaper proposes a kernel cross-correlator (KCC) that breaks traditional\\nlimitations. First, by introducing the kernel trick, the KCC extends the linear\\ncross-correlation to non-linear space, which is more robust to signal noises\\nand distortions. Second, the connection to the existing works shows that KCC\\nprovides a unified solution for correlation filters. Third, KCC is applicable\\nto any kernel function and is not limited to circulant structure on training\\ndata, thus it is able to predict affine transformations with customized\\nproperties. Last, by leveraging the fast Fourier transform (FFT), KCC\\neliminates direct calculation of kernel vectors, thus achieves better\\nperformance yet still with a reasonable computational cost. Comprehensive\\nexperiments on visual tracking and human activity recognition using wearable\\ndevices demonstrate its robustness, flexibility, and efficiency. The source\\ncodes of both experiments are released at this https URL\\n', '\\nAbstract:  Many recent advancements in Computer Vision are attributed to large datasets.\\nOpen-source software packages for Machine Learning and inexpensive commodity\\nhardware have reduced the barrier of entry for exploring novel approaches at\\nscale. It is possible to train models over millions of examples within a few\\ndays. Although large-scale datasets exist for image understanding, such as\\nImageNet, there are no comparable size video classification datasets.\\nIn this paper, we introduce YouTube-8M, the largest multi-label video\\nclassification dataset, composed of ~8 million videos (500K hours of video),\\nannotated with a vocabulary of 4800 visual entities. To get the videos and\\ntheir labels, we used a YouTube video annotation system, which labels videos\\nwith their main topics. While the labels are machine-generated, they have\\nhigh-precision and are derived from a variety of human-based signals including\\nmetadata and query click signals. We filtered the video labels (Knowledge Graph\\nentities) using both automated and manual curation strategies, including asking\\nhuman raters if the labels are visually recognizable. Then, we decoded each\\nvideo at one-frame-per-second, and used a Deep CNN pre-trained on ImageNet to\\nextract the hidden representation immediately prior to the classification\\nlayer. Finally, we compressed the frame features and make both the features and\\nvideo-level labels available for download.\\nWe trained various (modest) classification models on the dataset, evaluated\\nthem using popular evaluation metrics, and report them as baselines. Despite\\nthe size of the dataset, some of our models train to convergence in less than a\\nday on a single machine using TensorFlow. We plan to release code for training\\na TensorFlow model and for computing metrics.\\n\\n    ']\n"
     ]
    }
   ],
   "source": [
    "abs = []\n",
    "abs_data = \"\"\n",
    "is_it_pdf = \".pdf\"\n",
    "count = 0\n",
    "\n",
    "for src in data['src'].dropna(how = \"any\"):\n",
    "    response = requests.get(src, verify=False)\n",
    "#     if is_it_pdf in src:\n",
    "#         print(\"It is pdf\")\n",
    "#     else:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    abs_data = soup.find(\"div\",{\"class\":\"card-body\"})\n",
    "    if abs_data == None:\n",
    "        abs_data = soup.find(\"blockquote\",{'class':'abstract'})\n",
    "#        if abs_data == None:\n",
    "#            abs_data = \"\"\n",
    "#            abs_data.text = \"It is pdf\"\n",
    "    if abs_data != None:\n",
    "        abs.append(abs_data.text)\n",
    "        print(abs_data.text)\n",
    "    else:\n",
    "        abs.append(\"It is pdf\")\n",
    "        print(\"It is pdf\")\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "\n",
    "print(abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf라서 크롤링 해올 수 없는 것들은 Is is pdf라고 저장했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Recurrent neural network grammars (RNNGs) are generative models of (tree , string ) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.'\n",
      " 'It is pdf'\n",
      " 'We introduce the novel task of predicting adverbial presupposition triggers, which is useful for natural language generation tasks such as summarization and dialogue systems. We introduce two new corpora, derived from the Penn Treebank and the Annotated English Gigaword dataset and investigate the use of a novel attention mechanism tailored to this task. Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters, minimizing the added computational cost of our mechanism. We demonstrate that this model statistically outperforms our baselines.'\n",
      " ...\n",
      " 'Research on depth-based human activity analysis achieved outstanding\\nperformance and demonstrated the effectiveness of 3D representation for action\\nrecognition. The existing depth-based and RGB+D-based action recognition\\nbenchmarks have a number of limitations, including the lack of large-scale\\ntraining samples, realistic number of distinct class categories, diversity in\\ncamera views, varied environmental conditions, and variety of human subjects.\\nIn this work, we introduce a large-scale dataset for RGB+D human action\\nrecognition, which is collected from 106 distinct subjects and contains more\\nthan 114 thousand video samples and 8 million frames. This dataset contains 120\\ndifferent action classes including daily, mutual, and health-related\\nactivities. We evaluate the performance of a series of existing 3D activity\\nanalysis methods on this dataset, and show the advantage of applying deep\\nlearning methods for 3D-based human action recognition. Furthermore, we\\ninvestigate a novel one-shot 3D activity recognition problem on our dataset,\\nand a simple yet effective Action-Part Semantic Relevance-aware (APSR)\\nframework is proposed for this task, which yields promising results for\\nrecognition of the novel action classes. We believe the introduction of this\\nlarge-scale dataset will enable the community to apply, adapt, and develop\\nvarious data-hungry learning techniques for depth-based and RGB+D-based human\\nactivity understanding. [The dataset is available at:\\nthis http URL]'\n",
      " 'Cross-correlator plays a significant role in many visual perception tasks,\\nsuch as object detection and tracking. Beyond the linear cross-correlator, this\\npaper proposes a kernel cross-correlator (KCC) that breaks traditional\\nlimitations. First, by introducing the kernel trick, the KCC extends the linear\\ncross-correlation to non-linear space, which is more robust to signal noises\\nand distortions. Second, the connection to the existing works shows that KCC\\nprovides a unified solution for correlation filters. Third, KCC is applicable\\nto any kernel function and is not limited to circulant structure on training\\ndata, thus it is able to predict affine transformations with customized\\nproperties. Last, by leveraging the fast Fourier transform (FFT), KCC\\neliminates direct calculation of kernel vectors, thus achieves better\\nperformance yet still with a reasonable computational cost. Comprehensive\\nexperiments on visual tracking and human activity recognition using wearable\\ndevices demonstrate its robustness, flexibility, and efficiency. The source\\ncodes of both experiments are released at this https URL'\n",
      " 'Many recent advancements in Computer Vision are attributed to large datasets.\\nOpen-source software packages for Machine Learning and inexpensive commodity\\nhardware have reduced the barrier of entry for exploring novel approaches at\\nscale. It is possible to train models over millions of examples within a few\\ndays. Although large-scale datasets exist for image understanding, such as\\nImageNet, there are no comparable size video classification datasets.\\nIn this paper, we introduce YouTube-8M, the largest multi-label video\\nclassification dataset, composed of ~8 million videos (500K hours of video),\\nannotated with a vocabulary of 4800 visual entities. To get the videos and\\ntheir labels, we used a YouTube video annotation system, which labels videos\\nwith their main topics. While the labels are machine-generated, they have\\nhigh-precision and are derived from a variety of human-based signals including\\nmetadata and query click signals. We filtered the video labels (Knowledge Graph\\nentities) using both automated and manual curation strategies, including asking\\nhuman raters if the labels are visually recognizable. Then, we decoded each\\nvideo at one-frame-per-second, and used a Deep CNN pre-trained on ImageNet to\\nextract the hidden representation immediately prior to the classification\\nlayer. Finally, we compressed the frame features and make both the features and\\nvideo-level labels available for download.\\nWe trained various (modest) classification models on the dataset, evaluated\\nthem using popular evaluation metrics, and report them as baselines. Despite\\nthe size of the dataset, some of our models train to convergence in less than a\\nday on a single machine using TensorFlow. We plan to release code for training\\na TensorFlow model and for computing metrics.']\n"
     ]
    }
   ],
   "source": [
    "is_it_have_abs = \"Abstract\"\n",
    "abs = np.array(abs)\n",
    "\n",
    "for current_abs in abs:\n",
    "    current_abs = current_abs.replace(\"Abstract\",\"\")\n",
    "    current_abs = current_abs.strip()\n",
    "    current_abs = current_abs.strip(\"\\n\")\n",
    "\n",
    "print(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abs = pd.DataFrame(abs.reshape(len(abs)), columns=[\"abstract\"])\n",
    "df_abs.to_excel('C:/Users/SeoKyung/Desktop/PA/Paper Assistant Abstract.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
